Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis+SciVis	Dec. 2011	Saliency-Assisted Navigation of Very Large Landscape Images	10.1109/TVCG.2011.231	http://dx.doi.org/10.1109/TVCG.2011.231	1737	1746	6064936	data acquisition;data visualisation;geophysical image processing;image resolution;image sensors;statistical analysis	Internet;camera sensors;image resolution;interactive visualization;landscape images;robotic image acquisition;saliency assisted navigation;statistical signatures	Data visualization;Image color analysis;Image resolution;Navigation	Anomaly Detection;Guided Interaction.;Image Saliency;Interactive Visualization;Scene Perception;Very Large Scale Images	The field of visualization has addressed navigation of very large datasets, usually meshes and volumes. Significantly less attention has been devoted to the issues surrounding navigation of very large images. In the last few years the explosive growth in the resolution of camera sensors and robotic image acquisition techniques has widened the gap between the display and image resolutions to three orders of magnitude or more. This paper presents the first steps towards navigation of very large images, particularly landscape images, from an interactive visualization perspective. The grand challenge in navigation of very large images is identifying regions of potential interest. In this paper we outline a three-step approach. In the first step we use multi-scale saliency to narrow down the potential areas of interest. In the second step we outline a method based on statistical signatures to further cull out regions of high conformity. In the final step we allow a user to interactively identify the exceptional regions of high interest that merit further attention. We show that our approach of progressive elicitation is fast and allows rapid identification of regions of interest. Unlike previous work in this area, our approach is scalable and computationally reasonable on very large images. We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet.	Cheuk Yiu Ip;Varshney, A.	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;	37586231900;37282560200
	InfoVis+SciVis	Dec. 2011	Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization	10.1109/TVCG.2011.208	http://dx.doi.org/10.1109/TVCG.2011.208	1747	1756	6064937	data visualisation;image reconstruction;object detection;video signal processing	3D reconstruction;3D visualization template;application specific semantics;event classification;event illustration;hierarchical event representation;hierarchical event selection;illustrative visualization;importance based selection algorithm;snooker video visualization;video storyboards	Context;Data visualization;Multimedia communication;Semantics;Three dimensional displays;Time series analysis	Illustrative visualization.;Multimedia visualization;Time series data	Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.	Parry, M.L.;Legg, P.A.;Chung, D.H.S.;Griffiths, I.W.;Chen, M.	Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;	38030607100;38026705600;38022083900;38017014600;37677874500
	InfoVis+SciVis	Dec. 2011	Artificial Defocus for Displaying Markers in Microscopy Z-Stacks	10.1109/TVCG.2011.168	http://dx.doi.org/10.1109/TVCG.2011.168	1757	1764	6064938	computer graphic equipment;computerised instrumentation;coprocessors;data visualisation;image colour analysis;image reconstruction;microscopy	3D point visualization;3D structure;GPU;artificial defocus;color based cues;marker display;microscopy z-stacks;mouse wheel;shape from focus reconstruction	Data visualization;Image color analysis;Image segmentation;Microscopy;Optical microscopy;Three dimensional displays	Depth of field;Focus stacks.;Microscopy	As microscopes have a very shallow depth of field, Z-stacks (i.e. sets of images shot at different focal planes) are often acquired to fully capture a thick sample. Such stacks are viewed by users by navigating them through the mouse wheel. We propose a new technique of visualizing 3D point, line or area markers in such focus stacks, by displaying them with a depth-dependent defocus, simulating the microscope's optics; this leverages on the microscopists' ability to continuously twiddle focus, while implicitly performing a shape-from-focus reconstruction of the 3D structure of the sample. User studies confirm that the approach is effective, and can complement more traditional techniques such as color-based cues. We provide two implementations, one of which computes defocus in real time on the GPU, and examples of their application.	Giusti, A.;Taddei, P.;Corani, G.;Gambardella, L.;Magli, C.;Gianaroli, L.	Dalle Molle Inst. for Artificial Intell., Lugano, Switzerland|c|;;;;;	37839568400;37591225000;37972936000;37270036000;37988921000;37972814500
	InfoVis+SciVis	Dec. 2011	Visualization of Topological Structures in Area-Preserving Maps	10.1109/TVCG.2011.254	http://dx.doi.org/10.1109/TVCG.2011.254	1765	1774	6064939	Poincare mapping;computational complexity;data visualisation;ergonomics;feature extraction;fractals;fusion reactors;inspection;plasma toroidal confinement;topology	area-preserving map;automatic extraction;engineering problem;ergodic behavior;fractal complexity;fusion reactor;invariant manifold;island chain;numerical data;scientific problem;topological picture;topological structure visualization;visual inspection;visual representation	Chaos theory;Data visualization;Fusion reactors;Manifolds;Topology	Poincaré map;area-preserving maps;chaos;dynamical systems;invariant manifolds.;topology	Area-preserving maps are found across a wide range of scientific and engineering problems. Their study is made challenging by the significant computational effort typically required for their inspection but more fundamentally by the fractal complexity of salient structures. The visual inspection of these maps reveals a remarkable topological picture consisting of fixed (or periodic) points embedded in so-called island chains, invariant manifolds, and regions of ergodic behavior. This paper is concerned with the effective visualization and precise topological analysis of area-preserving maps with two degrees of freedom from numerical or analytical data. Specifically, a method is presented for the automatic extraction and characterization of fixed points and the computation of their invariant manifolds, also known as separatrices, to yield a complete picture of the structures present within the scale and complexity bounds selected by the user. This general approach offers a significant improvement over the visual representations that are so far available for area-preserving maps. The technique is demonstrated on a numerical simulation of magnetic confinement in a fusion reactor.	Tricoche, X.;Garth, C.;Sanderson, A.	Purdue Univ., West Lafayette, IN, USA|c|;;	37282575100;37282573700;37283733200
	InfoVis+SciVis	Dec. 2011	Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning	10.1109/TVCG.2011.224	http://dx.doi.org/10.1109/TVCG.2011.224	1775	1784	6064940	data visualisation;interactive systems;medical image processing;orthopaedics;rendering (computer graphics);surgery;touch sensitive screens	3D rendering;3D visualization;healthcare;medical imaging;medical visualization table;multitouch table system;orthopedic surgery planning;treatment planning	Biomedical image processing;Orthopedic surgery;Surgery;Three dimensional displays	Medical visualization;multitouch;tabletop display;treatment planning.	Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were two-fold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.	Lundstrom, C.;Rydell, T.;Forsell, C.;Persson, A.;Ynnerman, A.	Center for Med. Image Sci. & Visualization, Linkoping Univ., Linkoping, Sweden|c|;;;;	37284209100;38017009700;37546939800;37604521200;37284192000
	InfoVis+SciVis	Dec. 2011	Load-Balanced Parallel Streamline Generation on Large Scale Vector Fields	10.1109/TVCG.2011.219	http://dx.doi.org/10.1109/TVCG.2011.219	1785	1794	6064941	data visualisation;graph theory;parallel processing;resource allocation	flow complexity;graph based representation;large scale vector fields;load balanced parallel streamline generation;load imbalance;workload aware partitioning algorithm;workload estimation algorithm	Cost function;Mathematical model;Partitioning algorithms	3D vector field visualization;Flow visualization;Parallel processing;Streamlines.	Because of the ever increasing size of output data from scientific simulations, supercomputers are increasingly relied upon to generate visualizations. One use of supercomputers is to generate field lines from large scale flow fields. When generating field lines in parallel, the vector field is generally decomposed into blocks, which are then assigned to processors. Since various regions of the vector field can have different flow complexity, processors will require varying amounts of computation time to trace their particles, causing load imbalance, and thus limiting the performance speedup. To achieve load-balanced streamline generation, we propose a workload-aware partitioning algorithm to decompose the vector field into partitions with near equal workloads. Since actual workloads are unknown beforehand, we propose a workload estimation algorithm to predict the workload in the local vector field. A graph-based representation of the vector field is employed to generate these estimates. Once the workloads have been estimated, our partitioning algorithm is hierarchically applied to distribute the workload to all partitions. We examine the performance of our workload estimation and workload-aware partitioning algorithm in several timings studies, which demonstrates that by employing these methods, better scalability can be achieved with little overhead.	Nouanesengsy, B.;Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;;	37570501300;37403060100;37279493500
	InfoVis+SciVis	Dec. 2011	Extinction-Based Shading and Illumination in GPU Volume Ray-Casting	10.1109/TVCG.2011.198	http://dx.doi.org/10.1109/TVCG.2011.198	1795	1802	6064942	computer graphic equipment;coprocessors;light scattering;lighting;ray tracing;rendering (computer graphics)	a-blending;GPU volume ray casting;Riemann sum;ambient occlusion;color bleeding effects;direct volume rendering;directional soft shadows;dynamic lights;extinction-based shading;interactive frame rates;interactive transfer function;sophisticated illumination models;volume rendering integral;volumetric dataset visualisation	Graphics processing unit;Image color analysis;Light sources;Rendering (computer graphics);Scattering	Ambient Occlusion;Exponential Extinction.;GPU Ray-Casting;Shadows;Volume Rendering	Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.	Schlegel, P.;Makhinya, M.;Pajarola, Renato	Dept. of Inf., Univ. of Zurich, Zurich, Switzerland|c|;;	38026738000;37695663200;37282193800
	InfoVis+SciVis	Dec. 2011	GPU-Based Interactive Cut-Surface Extraction From High-Order Finite Element Fields	10.1109/TVCG.2011.206	http://dx.doi.org/10.1109/TVCG.2011.206	1803	1811	6064943	data visualisation;finite element analysis;image processing;ray tracing;rendering (computer graphics);solid modelling	3D simulation;GPU-based interactive cut-surface extraction;GPU-based ray-tracing system;OpenGL rendering;high-order finite element field;high-order finite element method;image accuracy;image quality;imagery;interactive visualization;scientific visualization;texture mapping;visualization system;visualization tool	Data visualization;Finite element methods;Graphics processing unit;Image color analysis;Linear approximation;Tensile stress	GPU ray-tracing;GPU-based root-finding;High-order finite elements;cut-plane extraction;cutsurface extraction.;spectral/hp elements	We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.	Nelson, B.;Haimes, R.;Kirby, R.M.	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;	37557887400;37282898700;37275716100
	InfoVis+SciVis	Dec. 2011	GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation	10.1109/TVCG.2011.207	http://dx.doi.org/10.1109/TVCG.2011.207	1812	1821	6064944	approximation theory;biomedical electrodes;blood vessels;cancer;cellular biophysics;computer graphic equipment;coprocessors;data visualisation;haemodynamics;interactive systems;liver;medical image processing;numerical analysis;patient treatment;physiological models;rendering (computer graphics);tumours	GPU based real time approximation;RFA therapy;applicator placement planning;blood vessels;cancer cells;cooling blood flow;graphic card;heat sink effect;invasive clinical procedure;liver parenchyma;liver tumor treatment;liver vessels;malignant tissue;modular shader framework;numerical simulation;percutaneous radiofrequency ablation zone;projected slice views;real time visualization;rendering;software assistant prototype;thermal equilibrium representation;weighted distance field	Ablation;Blood flow;Electrodes;Graphics processing unit;Heat sinks;Mathematical model;Radio frequency;Rendering (computer graphics)	GPU;Radiofrequency ablation;ablation zone visualization;distance field;interaction.;volume rendering	Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.	Rieder, C.;Schumann, C.;Hahn, H.K.	;;	38017035400;38028801700;38020362400
	InfoVis+SciVis	Dec. 2011	Feature-Based Statistical Analysis of Combustion Simulation Data	10.1109/TVCG.2011.199	http://dx.doi.org/10.1109/TVCG.2011.199	1822	1831	6064945	chemically reactive flow;combustion;flow simulation;interactive systems;meta data;mixing;numerical analysis;rendering (computer graphics);statistical analysis;turbulence	astrophysics;climate modeling;combustion science;combustion simulation data;cumulative density function;data streaming;direct numerical simulation;feature based statistical analysis;geometrical features;histograms;interactive analysis;large scale scientific data;linked view browser;merge trees;meta data collection;molecular mixing process;molecular reactive process;nonlocal entities;spectral analysis;time series;transport process;turbulent combustion;turbulent flow	Data mining;Data models;Feature extraction;Information analysis;Statistical analysis	Data analysis;Data exploration;Multi-variate Data.;Statistics;Topology;Visualization in Physical Sciences and Engineering	We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.	Bennett, J.C.;Krishnamoorthy, V.;Shusen Liu;Grout, R.W.;Hawkes, E.R.;Chen, J.H.;Shepherd, J.;Pascucci, V.;Bremer, P.-T.	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;;;;;;	37551867600;38028168700;38025553600;37394659000;37299142500;37293022400;38020418600;37284312600;37564112000
	InfoVis+SciVis	Dec. 2011	Quasi Interpolation With Voronoi Splines	10.1109/TVCG.2011.230	http://dx.doi.org/10.1109/TVCG.2011.230	1832	1841	6064946	FIR filters;computational geometry;interpolation;signal reconstruction;signal sampling;splines (mathematics)	FIR filter;Voronoi splines;quasi interpolation;sampling theory;signal reconstruction;unbiased reconstruction method;volumetric data struction	Convolution;Image reconstruction;Interpolation;Spline	Box spline.;Quasi Interpolation;Volume Visualization;Voronoi Spline	We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.	Mirzargar, M.;Entezari, A.	;	37978593500;37268675600
	InfoVis+SciVis	Dec. 2011	Topological Spines: A Structure-preserving Visual Representation of Scalar Fields	10.1109/TVCG.2011.244	http://dx.doi.org/10.1109/TVCG.2011.244	1842	1851	6064947	computational geometry;data visualisation;graph theory;natural sciences computing	Morse-Smale complex;clutter problems;contour trees;extremum graphs;geometric structure;occlusion problems;scalar fields;structure preserving visual representation;topological spines	Approximation methods;Data visualization;Manifolds;Topology	Morse-Smale complex.;Scalar field topology;extremum graph;topological spine	We present topological spines-a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs-sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.	Correa, C.;Lindstrom, P.;Bremer, P.-T.	Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;;	37282925900;37269320000;37564112000
	InfoVis+SciVis	Dec. 2011	Towards Robust Topology of Sparsely Sampled Data	10.1109/TVCG.2011.245	http://dx.doi.org/10.1109/TVCG.2011.245	1852	1861	6064948	data analysis;data visualisation;gradient methods;graph theory;mesh generation;pattern clustering;sampling methods;set theory	Delaunay triangulation;empty region graph;gradient estimation;high dimensional data set;high dimensional signal;k-nearest neighbor;low dimensional data set;neighborhood connection;neighborhood graph;neighborhood strategy;neighborhood-based analysis tool;robust data analysis;scalar function visualization;sparse irregular sampling;sparsely sampled data;spurious connection;topological clustering;topological decomposition	Data mining;Noise measurement;Robustness;Topology	Neighborhood graphs;sparsely sampled data.;topology	Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods - a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.	Correa, C.;Lindstrom, P.	Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;	37282925900;37269320000
	InfoVis+SciVis	Dec. 2011	Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation	10.1109/TVCG.2011.252	http://dx.doi.org/10.1109/TVCG.2011.252	1862	1871	6064949	data visualisation;hydrodynamics;interpolation	3D domain;AMR data visualization;cell-centered adaptive mesh refinement;gridded hydrodynamic data;multi-level dual-mesh interpolation;ray-cast visualizations	Adaptation models;Image edge detection;Interpolation;Isosurfaces;Rendering (computer graphics)	AMR;Adaptive mesh refinement;Enzo;dual meshes;interpolation;isosurfaces;ray casting;stitching cells.		Moran, P.J.;Ellsworth, D.	Ames Res. Center, NASA, Moffett Field, CA, USA|c|;	37264891100;37282594500
	InfoVis+SciVis	Dec. 2011	Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations	10.1109/TVCG.2011.225	http://dx.doi.org/10.1109/TVCG.2011.225	1872	1881	6064950	data flow computing;data mining;data visualisation;digital simulation;disasters;emergency services;floods;risk management	World Lines interface;abstract parameter control;boundary conditions;data flow components;data flow diagram;flood disaster management;flood emergency response strategy;flood simulation;meta flow;natural risk;standard data flow network;steering ensemble simulation;steering information transmission;steering information visualization;virtual city;visual knowledge discovery;visual representation	Control systems;Data visualization;Disaster management;Emergency services;Navigation	Data-Flow;Emergency/Disaster Management;Meta-Flow;Parameter Study;Uncertainty;Visual Knowledge Discovery;Visualization System and Toolkit Design;Visualization of Control.	Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.	Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, M.E.	VRVis Vienna, Vienna, Austria|c|;;;;;;	38111592300;38229386600;38099765400;37408064900;38102461400;38229402400;37282552200
	InfoVis+SciVis	Dec. 2011	Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics	10.1109/TVCG.2011.217	http://dx.doi.org/10.1109/TVCG.2011.217	1882	1891	6064951	biological tissues;biology computing;data visualisation;drugs;graph theory;interactive systems;proteins;toxicology	advanced imaging technique;cells;drug development;focus+context visualization;function protein pattern;glyphs;graph visualization;graph-based visual analysis;high-dimensional fluorescence microscopy data;interactive analysis;interactive visual analysis;lymphocytes;multi-parameter fluorescence microscopy data;patient-drug-interaction;prostate tissue;protein clusters;reagent bindings;robot-driven multi-parameter fluorescence microscopy;toponomics;toxicology	Biological information theory;Fluorescence;Graphics;Image color analysis;Microscopy;Three dimensional displays	Fluorescence Microscopy;Graph Visualization.;Protein Interaction;Toponomics;Visual Analytics	In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.	Oeltze, S.;Freiler, W.;Hillert, R.;Doleisch, H.;Preim, B.;Schubert, W.	Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;	37424645600;38017008700;38017009300;37546620400;37424645300;37410289200
	InfoVis+SciVis	Dec. 2011	Tuner: Principled Parameter Finding for Image Segmentation Algorithms Using Visual Response Surface Exploration	10.1109/TVCG.2011.248	http://dx.doi.org/10.1109/TVCG.2011.248	1892	1901	6064952	Gaussian processes;data visualisation;image sampling;image segmentation;statistical analysis	dynamic positron emission tomography;electron tomogram;ground-truth image;image segmentation;parameter finding;parameter model;parameter space;response value;segmentation algorithm;sparse sampling;statistical model;visual analysis tool;visual response surface exploration	Computational modeling;Gaussian processes;Image segmentation;Response surface methodology;Uncertainty	Gaussian Process Model.;Image segmentation;Parameter exploration	"In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the ""goodness"" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans."	Torsney-Weir, T.;Saad, A.;Moller, T.;Hege, H.-C.;Weber, B.;Verbavatz, J.;Bergner, S.	Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;	38229404800;37405565700;37275858700;37282272000;38002090200;38229406100;37418878100
	InfoVis+SciVis	Dec. 2011	Branching and Circular Features in High Dimensional Data	10.1109/TVCG.2011.177	http://dx.doi.org/10.1109/TVCG.2011.177	1902	1911	6064953	computational geometry;data analysis;data structures;data visualisation;topology	circular features;computational biology;data analysis;data visualization;dimensionality reduction techniques;global circular structures;high dimensional data sets;high-dimensional branching structures;high-dimensional data representation;local circle-valued coordinate functions;motion capture;nontrivial topology;topological techniques	Algorithm design and analysis;Approximation methods;Data visualization;Feature extraction;Topology	Dimensionality reduction;circular coordinates;topological analysis.;visualization	Large observations and simulations in scientific research give rise to high-dimensional data sets that present many challenges and opportunities in data analysis and visualization. Researchers in application domains such as engineering, computational biology, climate study, imaging and motion capture are faced with the problem of how to discover compact representations of highdimensional data while preserving their intrinsic structure. In many applications, the original data is projected onto low-dimensional space via dimensionality reduction techniques prior to modeling. One problem with this approach is that the projection step in the process can fail to preserve structure in the data that is only apparent in high dimensions. Conversely, such techniques may create structural illusions in the projection, implying structure not present in the original high-dimensional data. Our solution is to utilize topological techniques to recover important structures in high-dimensional data that contains non-trivial topology. Specifically, we are interested in high-dimensional branching structures. We construct local circle-valued coordinate functions to represent such features. Subsequently, we perform dimensionality reduction on the data while ensuring such structures are visually preserved. Additionally, we study the effects of global circular structures on visualizations. Our results reveal never-before-seen structures on real-world data sets from a variety of applications.	Bei Wang;Summa, B.;Pascucci, V.;Vejdemo-Johansson, M.	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	38025846900;38017036500;37284312600;38017034400
	InfoVis+SciVis	Dec. 2011	Features in Continuous Parallel Coordinates	10.1109/TVCG.2011.200	http://dx.doi.org/10.1109/TVCG.2011.200	1912	1921	6064954	curve fitting;data visualisation;duality (mathematics)	CPC;CSP;Cartesian coordinate;contemporary visualization technique;continuous parallel coordinates;continuous scatterplot;curve-curve duality;feature curve;smooth scalar field	Data visualization;Feature extraction;Mathematical model;Three dimensional displays;Vectors;Visualization	Features;Parallel Coordinates;Topology;Visualization.	Continuous Parallel Coordinates (CPC) are a contemporary visualization technique in order to combine several scalar fields, given over a common domain. They facilitate a continuous view for parallel coordinates by considering a smooth scalar field instead of a finite number of straight lines. We show that there are feature curves in CPC which appear to be the dominant structures of a CPC. We present methods to extract and classify them and demonstrate their usefulness to enhance the visualization of CPCs. In particular, we show that these feature curves are related to discontinuities in Continuous Scatterplots (CSP). We show this by exploiting a curve-curve duality between parallel and Cartesian coordinates, which is a generalization of the well-known point-line duality. Furthermore, we illustrate the theoretical considerations. Concluding, we discuss relations and aspects of the CPC's/CSP's features concerning the data analysis.	Lehmann, D.J.;Theisel, H.	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;	37601992200;37266875400
	InfoVis+SciVis	Dec. 2011	About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering	10.1109/TVCG.2011.161	http://dx.doi.org/10.1109/TVCG.2011.161	1922	1931	6064955	gradient methods;lighting;rendering (computer graphics)	depth perception;direct volume rendering;directional occlusion shading;dynamic ambient occlusion;gradient based shading;half angle slicing;image comprehension;multidirectional occlusion shading;shadow volume propagation;size perception;spatial comprehension;spherical harmonic lighting;volumetric illumination models	Computational modeling;Harmonic analysis;Image color analysis;Light sources;Rendering (computer graphics);Solid modeling	Volumetric illumination;spatial comprehension.;volume rendering	In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.	Lindemann, F.;Ropinski, T.	Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster, Germany|c|;	38017009000;38471794200
	InfoVis+SciVis	Dec. 2011	Automatic Transfer Functions Based on Informational Divergence	10.1109/TVCG.2011.173	http://dx.doi.org/10.1109/TVCG.2011.173	1932	1941	6064956	optical transfer function;optimisation;rendering (computer graphics);visibility	1D transfer functions;2D transfer functions;Kullback-Leibler distance;automatic transfer functions;communication channel;data value interval;informational divergence;optimization process;spatial segmentation;target distribution;visibility distribution	Data visualization;Information analysis;Mutual information;Probability distribution;Transfer functions	Information theory;Informational divergence;Kullback-Leibler distance.;Transfer function	In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.	Ruiz, M.;Bardera, A.;Boada, I.;Viola, I.;Feixas, M.;Sbert, M.	;;;;;	38017257300;38260088500;38265928900;37282726800;38263173100;38260648800
	InfoVis+SciVis	Dec. 2011	The Effect of Colour and Transparency on the Perception of Overlaid Grids	10.1109/TVCG.2011.242	http://dx.doi.org/10.1109/TVCG.2011.242	1942	1948	6064957	data visualisation;rendering (computer graphics)	alpha value;boundary condition;colour effect;grayscale image;image density;lightness value;overlaid grid;visual intrusiveness	Complexity theory;Data visualization;Educational institutions;Image color analysis	Information visualization;applied perception;automated presentation;computational aesthetics.;visual design	Overlaid reference elements need to be sufficiently visible to effectively relate to the underlying information, but not so obtrusive that they clutter the presentation. We seek to create guidelines for presenting such structures through experimental studies to define boundary conditions for visual intrusiveness. We base our work on the practice of designers, who use transparency to integrate overlaid grids with their underlying imagery. Previous work discovered a useful range of alpha values for black or white grids overlayed on scatterplot images rendered in shades of gray over gray backgrounds of different lightness values. This work compares black grids to blue and red ones on different image types of scatterplots and maps. We expected that the coloured grids over grayscale images would be more visually salient than black ones, resulting in lower alpha values. Instead, we found that there was no significant difference between the boundaries set for red and black grids, but that the boundaries for blue grids were set consistently higher (more opaque). As in our previous study, alpha values are affected by image density rather than image type, and are consistently lower than many default settings. These results have implications for the design of subtle reference structures.	Bartram, L.;Cheung, B.;Stone, M.C.	;;	37353447100;38027547900;37376130500
	InfoVis+SciVis	Dec. 2011	Flow Radar Glyphs&amp;#8212;Static Visualization of Unsteady Flow with Uncertainty	10.1109/TVCG.2011.203	http://dx.doi.org/10.1109/TVCG.2011.203	1949	1958	6064958	computational fluid dynamics;computer graphic equipment;coprocessors;data visualisation;hydrology;interactive systems	2D flow;3D flow;CFD;animated visualization;different spatiotemporal flow behavior;flow radar glyphs;interactive GPU accelerated implementations;radar displays;static images;static unsteady flow visualization;stochastic hydrogeology;visual metaphor;zoomed out views	Data visualization;Radar imaging;Three dimensional displays;Uncertainty;Vectors	Visualization;glyph;uncertainty;unsteady flow.	A new type of glyph is introduced to visualize unsteady flow with static images, allowing easier analysis of time-dependent phenomena compared to animated visualization. Adopting the visual metaphor of radar displays, this glyph represents flow directions by angles and time by radius in spherical coordinates. Dense seeding of flow radar glyphs on the flow domain naturally lends itself to multi-scale visualization: zoomed-out views show aggregated overviews, zooming-in enables detailed analysis of spatial and temporal characteristics. Uncertainty visualization is supported by extending the glyph to display possible ranges of flow directions. The paper focuses on 2D flow, but includes a discussion of 3D flow as well. Examples from CFD and the field of stochastic hydrogeology show that it is easy to discriminate regions of different spatiotemporal flow behavior and regions of different uncertainty variations in space and time. The examples also demonstrate that parameter studies can be analyzed because the glyph design facilitates comparative visualization. Finally, different variants of interactive GPU-accelerated implementations are discussed.	Hlawatsch, M.;Leube, P.;Nowak, W.;Weiskopf, D.	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;;;	37546168600;38017000700;38018564200;37268045000
	InfoVis+SciVis	Dec. 2011	iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization	10.1109/TVCG.2011.218	http://dx.doi.org/10.1109/TVCG.2011.218	1959	1968	6064959	data visualisation;entropy;optimisation;pattern clustering;set theory	2D entropy map;entropy-based viewpoint selection criteria;feature clustering framework;feature-clustering;gradient variation;iView;informative views;interactive track-ball interface;k-means;normal variation;salient composite feature detection;set-cover optimization algorithm;summary presentation;unguided visual exploration;viewpoint suggestion pipeline;visibility-based transfer function;volume rendering;volume visualization;volumetric data	Clustering algorithms;Entropy;Feature extraction;Rendering (computer graphics);Transfer functions	Direct volume rendering;ant colony optimization.;entropy;k-means;set-cover problem;view suggestion	The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.	Ziyi Zheng;Ahmed, N.;Mueller, K.	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	37599599100;38021380500;37273119700
	InfoVis+SciVis	Dec. 2011	Volume Analysis Using Multimodal Surface Similarity	10.1109/TVCG.2011.258	http://dx.doi.org/10.1109/TVCG.2011.258	1969	1978	6064960	computerised tomography;data visualisation;pattern classification	classification space;data value combinations;dual energy computed tomography;industrial manufacturing;information theoretic measure;isosurface similarity;multimodal classification;multimodal surface similarity;volume analysis	Computed tomography;Histograms;Isosurfaces;Mutual information;Transfer functions	Multimodal data;surface similarity.;volume visualization	The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.	Haidacher, M.;Bruckner, S.;Groller, E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;	37403983600;37265895700;37284271200
	InfoVis+SciVis	Dec. 2011	Asymmetric Tensor Field Visualization for Surfaces	10.1109/TVCG.2011.170	http://dx.doi.org/10.1109/TVCG.2011.170	1979	1988	6064961	computational fluid dynamics;data visualisation;deformation;earthquake engineering;geophysics computing	asymmetric tensor field visualization;complex simulated engine fluid flow;dual eigenvectors;earthquake deformation data;elliptical glyphs;evenly spaced hyperstreamlines;fluid flows;hybrid visualization technique;solid deformations;tensor field analysis;tensor magnitude	Data visualization;Eigenvalues and eigenfunctions;Manifolds;Tensile stress;Visualization	Tensor field visualization;asymmetric tensor fields;earthquakeengineering;fluid dynamics;glyph packing;hyperstreamline placement;solid deformation;vector field visualization;view-dependent visualization.	Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.	Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.	SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;	37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200
	InfoVis+SciVis	Dec. 2011	An Interactive Local Flattening Operator to Support Digital Investigations on Artwork Surfaces	10.1109/TVCG.2011.165	http://dx.doi.org/10.1109/TVCG.2011.165	1989	1996	6064962	art;history;image restoration;inference mechanisms;interactive systems;shape recognition	2D fields;2D information analysis;3D geometry;artwork surfaces;chisel marks analysis;computer-based shape reasoning system;cultural heritage;high-frequency shape detail;image content;image processing technique;interactive local flattening operator;local 3D data;locally smooth parametrization technique;multiple photographs;sketch-based system;unfinished sculpture	Geometry;Image processing;Length measurement;Shape analysis;Solid modeling;Surface treatment;Three dimensional displays	Cultural Heritage;Surface characterization;image processing.;interactive inspection;mesh parameterization	Analyzing either high-frequency shape detail or any other 2D fields (scalar or vector) embedded over a 3D geometry is a complex task, since detaching the detail from the overall shape can be tricky. An alternative approach is to move to the 2D space, resolving shape reasoning to easier image processing techniques. In this paper we propose a novel framework for the analysis of 2D information distributed over 3D geometry, based on a locally smooth parametrization technique that allows us to treat local 3D data in terms of image content. The proposed approach has been implemented as a sketch-based system that allows to design with a few gestures a set of (possibly overlapping) parameterizations of rectangular portions of the surface. We demonstrate that, due to the locality of the parametrization, the distortion is under an acceptable threshold, while discontinuities can be avoided since the parametrized geometry is always homeomorphic to a disk. We show the effectiveness of the proposed technique to solve specific Cultural Heritage (CH) tasks: the analysis of chisel marks over the surface of a unfinished sculpture and the local comparison of multiple photographs mapped over the surface of an artwork. For this very difficult task, we believe that our framework and the corresponding tool are the first steps toward a computer-based shape reasoning system, able to support CH scholars with a medium they are more used to.	Pietroni, N.;Cignoni, P.;Scopigno, R.	ISTI, CNR, Pisa, Italy|c|;;	37680454000;37265783400;37270887900
	InfoVis+SciVis	Dec. 2011	Context Preserving Maps of Tubular Structures	10.1109/TVCG.2011.182	http://dx.doi.org/10.1109/TVCG.2011.182	1997	2004	6064963	biology computing;computer displays;data visualisation;orthopaedics;ray tracing;rendering (computer graphics);shape recognition;solid modelling	2D skeleton display;3D skeleton shape;boundary placement;context preserving map;flattened map;geometric structure;harmonic mapping;human colon model;path slicing;sliced structure;tubular 3D structure visualization;tubular structure;virtual dissection method;volumetric ray casting	Geometry;Navigation;Shape analysis;Three dimensional displays;Volume measurement	Geometry-based technique;biomedical visualization;conformal mapping.;medical visualization;volume rendering	When visualizing tubular 3D structures, external representations are often used for guidance and display, and such views in 2D can often contain occlusions. Virtual dissection methods have been proposed where the entire 3D structure can be mapped to the 2D plane, though these will lose context by straightening curved sections. We present a new method of creating maps of 3D tubular structures that yield a succinct view while preserving the overall geometric structure. Given a dominant view plane for the structure, its curve skeleton is first projected to a 2D skeleton. This 2D skeleton is adjusted to account for distortions in length, modified to remove intersections, and optimized to preserve the shape of the original 3D skeleton. Based on this shaped 2D skeleton, a boundary for the map of the object is obtained based on a slicing path through the structure and the radius around the skeleton. The sliced structure is conformally mapped to a rectangle and then deformed via harmonic mapping to match the boundary placement. This flattened map preserves the general geometric context of a 3D object in a 2D display, and rendering of this flattened map can be accomplished using volumetric ray casting. We have evaluated our method on real datasets of human colon models.	Marino, J.;Wei Zeng;Xianfeng Gu;Kaufman, A.	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;;	37605959300;38231202300;38183364800;37268052800
	InfoVis+SciVis	Dec. 2011	Authalic Parameterization of General Surfaces Using Lie Advection	10.1109/TVCG.2011.171	http://dx.doi.org/10.1109/TVCG.2011.171	2005	2014	6064964	computational geometry;data visualisation	Lie advection;area-preserving surface parameterization;authalic parameterization;brain cortical imaging modality;complex surface parameterization;diffeomorphic flow;discrete differential modeling;general surface;geometric structure;triangulated surface representation	Boundary conditions;Geometry;Manifolds;Measurement;Surface treatment;Vectors	Area-preserving surface parameterization;Lie advection;differential forms;surface visualization.	Parameterization of complex surfaces constitutes a major means of visualizing highly convoluted geometric structures as well as other properties associated with the surface. It also enables users with the ability to navigate, orient, and focus on regions of interest within a global view and overcome the occlusions to inner concavities. In this paper, we propose a novel area-preserving surface parameterization method which is rigorous in theory, moderate in computation, yet easily extendable to surfaces of non-disc and closed-boundary topologies. Starting from the distortion induced by an initial parameterization, an area restoring diffeomorphic flow is constructed as a Lie advection of differential 2-forms along the manifold, which yields equality of the area elements between the domain and the original surface at its final state. Existence and uniqueness of result are assured through an analytical derivation. Based upon a triangulated surface representation, we also present an efficient algorithm in line with discrete differential modeling. As an exemplar application, the utilization of this method for the effective visualization of brain cortical imaging modalities is presented. Compared with conformal methods, our method can reveal more subtle surface patterns in a quantitative manner. It, therefore, provides a competitive alternative to the existing parameterization techniques for better surface-based analysis in various scenarios.	Guangyu Zou;Jiaxi Hu;Xianfeng Gu;Jing Hua	Wayne State Univ., Detroit, MI, USA|c|;;;	37301933100;38006143400;37276603700;37285799200
	InfoVis+SciVis	Dec. 2011	TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data	10.1109/TVCG.2011.246	http://dx.doi.org/10.1109/TVCG.2011.246	2015	2024	6064965	data analysis;data mining;data structures;data visualisation;graph theory;probability	TransGraph;data visualization;graph based representation;hierarchical state transition relationships;knowledge extraction;navigation tool;occlusion free;time-varying volumetric data analysis;transition probability;visual mapping	Data mining;Data visualization;Hierarchical systems;Histograms;User interfaces	Time-varying data visualization;hierarchical representation;states;transition relationship;user interface.	A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.	Yi Gu;Chaoli Wang	Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MA, USA|c|;	38021343000;37405886900
	InfoVis+SciVis	Dec. 2011	Voronoi-Based Extraction and Visualization of Molecular Paths	10.1109/TVCG.2011.259	http://dx.doi.org/10.1109/TVCG.2011.259	2025	2034	6064966	computational geometry;data visualisation;feature extraction;information filtering;inspection;interactive systems;lighting;molecular biophysics;skin	Voronoi-based extraction;binding site detection;deferred shading technique;filtering method;interactive molecule visualization;light sources;molecular interaction;molecular path visualization;molecular surface illumination;skin surface;visual analysis;visual inspection;visual tracking	Atomic measurements;Cavity resonators;Filtering theory;Logic gates;Molecular computing;Topology	Molecular visualization;data filtering;geometry-based techniques;view-dependent visualization.	Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.	Lindow, N.;Baum, D.;Hege, H.-C.	Zuse Inst. Berlin, Berlin, Germany|c|;;	38017029700;38182750200;37282272000
	InfoVis+SciVis	Dec. 2011	Symmetry in Scalar Field Topology	10.1109/TVCG.2011.236	http://dx.doi.org/10.1109/TVCG.2011.236	2035	2044	6064967	data analysis;data visualisation;topology;trees (mathematics)	contour tree;data exploration;feature detection;geometric symmetry;repeating pattern;robust similarity measure;scalar field distribution;scalar field topology;scientific data analysis;shape processing;symmetric pattern;symmetry-aware isosurface extraction;symmetry-aware transfer function design;visualization	Level set;Robustness;Shape analysis;Topology;Transfer functions;Vectors	Scalar field symmetry;contour tree;isosurface extraction;persistence;similarity measure;transfer function design.	Study of symmetric or repeating patterns in scalar fields is important in scientific data analysis because it gives deep insights into the properties of the underlying phenomenon. Though geometric symmetry has been well studied within areas like shape processing, identifying symmetry in scalar fields has remained largely unexplored due to the high computational cost of the associated algorithms. We propose a computationally efficient algorithm for detecting symmetric patterns in a scalar field distribution by analysing the topology of level sets of the scalar field. Our algorithm computes the contour tree of a given scalar field and identifies subtrees that are similar. We define a robust similarity measure for comparing subtrees of the contour tree and use it to group similar subtrees together. Regions of the domain corresponding to subtrees that belong to a common group are extracted and reported to be symmetric. Identifying symmetry in scalar fields finds applications in visualization, data exploration, and feature detection. We describe two applications in detail: symmetry-aware transfer function design and symmetry-aware isosurface extraction.	Thomas, D.M.;Natarajan, V.	Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;	37982882900;37278509300
	InfoVis+SciVis	Dec. 2011	A Scale Space Based Persistence Measure for Critical Points in 2D Scalar Fields	10.1109/TVCG.2011.159	http://dx.doi.org/10.1109/TVCG.2011.159	2045	2052	6064968	data analysis;natural sciences computing;solid modelling	2D scalar fields;critical points;extrema;homological persistence;noise robust persistence measure;out-of-core setting;scale space based persistence measure	Feature extraction;Laplace equations;Noise measurement;Noise robustness;Scalability	Scale space;discrete Morse theory.;persistence	This paper introduces a novel importance measure for critical points in 2D scalar fields. This measure is based on a combination of the deep structure of the scale space with the well-known concept of homological persistence. We enhance the noise robust persistence measure by implicitly taking the hill-, ridge- and outlier-like spatial extent of maxima and minima into account. This allows for the distinction between different types of extrema based on their persistence at multiple scales. Our importance measure can be computed efficiently in an out-of-core setting. To demonstrate the practical relevance of our method we apply it to a synthetic and a real-world data set and evaluate its performance and scalability.	Reininghaus, J.;Kasten, J.;Hagen, H.;Hotz, I.	Zuse Inst. Berlin, Berlin, Germany|c|;;;	37590998600;38028453100;37282578800;37282721800
	InfoVis+SciVis	Dec. 2011	Evaluation of Trend Localization with Multi-Variate Visualizations	10.1109/TVCG.2011.194	http://dx.doi.org/10.1109/TVCG.2011.194	2053	2062	6064969	data visualisation;image colour analysis	Oriented Slivers technique;brush strokes technique;color blending technique;data-driven spots technique;dimensional stacking;juxtaposed grayscale map;multiple data value comparison;multivalued data sets;multivariate visualization technique;trend localization evaluation	Data visualization;Gray-scale;Image color analysis;Shape analysis	User study;multi-variate visualization;visual analytics.;visual task design	Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn't require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.	Livingston, M.A.		37619718800
	InfoVis+SciVis	Dec. 2011	Straightening Tubular Flow for Side-by-Side Visualization	10.1109/TVCG.2011.235	http://dx.doi.org/10.1109/TVCG.2011.235	2063	2070	6064970	computational fluid dynamics;data visualisation;flow visualisation;pipe flow	arterial blood flow measurement;automotive industry;engineering;informative interactive visual analysis;integration-based flow visualization;medicine;quantitative flow visualization;side-by-side visualization;spatial relation;time-dependent flow;tubular boundary;tubular flow visualization;tubular fluid flows;tubular gas flow simulation	Data models;Data visualization;Flow visualization;Three dimensional displays;Vectors	Comparative Visualization.;Data Reformation;Flow Visualization	Flows through tubular structures are common in many fields, including blood flow in medicine and tubular fluid flows in engineering. The analysis of such flows is often done with a strong reference to the main flow direction along the tubular boundary. In this paper we present an approach for straightening the visualization of tubular flow. By aligning the main reference direction of the flow, i.e., the center line of the bounding tubular structure, with one axis of the screen, we are able to natively juxtapose (1.) different visualizations of the same flow, either utilizing different flow visualization techniques, or by varying parameters of a chosen approach such as the choice of seeding locations for integration-based flow visualization, (2.) the different time steps of a time-dependent flow, (3.) different projections around the center line , and (4.) quantitative flow visualizations in immediate spatial relation to the more qualitative classical flow visualization. We describe how to utilize this approach for an informative interactive visual analysis. We demonstrate the potential of our approach by visualizing two datasets from two different fields: an arterial blood flow measurement and a tubular gas flow simulation from the automotive industry.	Angelelli, P.;Hauser, H.	;	37889160600;37274158800
	InfoVis+SciVis	Dec. 2011	Vortex Visualization in Ultra Low Reynolds Number Insect Flight	10.1109/TVCG.2011.260	http://dx.doi.org/10.1109/TVCG.2011.260	2071	2079	6064971	biology computing;computational fluid dynamics;computer animation;data visualisation;flow visualisation;vortices;wakes;zoology	CFD simulation;automatic camera animation method;deformable flapping wing;down-stroke;dragonfly;flapping flight theory;geometric flow lines;insect flight;integration-based flow lines;interactive seed placement method;leading edge vortex;occlusion issues;parametric surfaces;perceptual challenges;photogrammetry setup;seed curve generation;ultra low Reynolds number;unsteady 3D flow domain;unsteady flight mechanism;up-stroke;visual analysis;visualization method;vortex detection;vortex visualization;wake;wing reconstruction	Data visualization;Feature extraction;Flow visualization;Insects;Three dimensional displays;Trajectory	Flow visualization;flowing seed points;insect flight;streak lines;streamlines;unsteady flow.;vortex visualization	We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.	Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.	Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;	37665393300;37282584400;38026590900;38017003700
	InfoVis+SciVis	Dec. 2011	Two-Dimensional Time-Dependent Vortex Regions Based on the Acceleration Magnitude	10.1109/TVCG.2011.249	http://dx.doi.org/10.1109/TVCG.2011.249	2080	2087	6064972	computational fluid dynamics;vortices	Galilean invariant property;acceleration magnitude;computational fluid dynamics;flow field;particle motion;scalar field topology;two-dimensional model system;two-dimensional time-dependent vortex region;vortex model;vortex-like minima;vortices temporal evolution	Feature extraction;Flow visualization;Navier-Stokes equations;Shape analysis;Topology	Vortex regions;feature extraction.;time-dependent flow fields	Acceleration is a fundamental quantity of flow fields that captures Galilean invariant properties of particle motion. Considering the magnitude of this field, minima represent characteristic structures of the flow that can be classified as saddle- or vortex-like. We made the interesting observation that vortex-like minima are enclosed by particularly pronounced ridges. This makes it possible to define boundaries of vortex regions in a parameter-free way. Utilizing scalar field topology, a robust algorithm can be designed to extract such boundaries. They can be arbitrarily shaped. An efficient tracking algorithm allows us to display the temporal evolution of vortices. Various vortex models are used to evaluate the method. We apply our method to two-dimensional model systems from computational fluid dynamics and compare the results to those arising from existing definitions.	Kasten, J.;Reininghaus, J.;Hotz, I.;Hege, H.-C.	Zuse Inst. Berlin, Berlin, Germany|c|;;;	38028453100;37590998600;37282721800;37282272000
	InfoVis+SciVis	Dec. 2011	Adaptive Extraction and Quantification of Geophysical Vortices	10.1109/TVCG.2011.162	http://dx.doi.org/10.1109/TVCG.2011.162	2088	2095	6064973	digital simulation;geometry;geophysics computing;oceanography;turbulence;vortices	discrete two dimensional vortex extraction;geometry;geophysical vortices quantification;global ocean simulation;physics;reference model;turbulent flow;vortex strengths	Atmospheric modeling;Data mining;Data models;Data visualization;Feature extraction;Information analysis	Vortex extraction;feature extraction;statistical data analysis.	We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.	Williams, S.;Petersen, M.;Bremer, P.-T.;Hecht, M.;Pascucci, V.;Ahrens, J.;Hlawitschka, M.;Hamann, B.	Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;;;;;;	37534471500;38028525800;37564112000;38028545000;37284312600;37282713700;37403333700;37282068700
	InfoVis+SciVis	Dec. 2011	FoamVis: Visualization of 2D Foam Simulation Data	10.1109/TVCG.2011.204	http://dx.doi.org/10.1109/TVCG.2011.204	2096	2105	6064974	computational fluid dynamics;data visualisation;flow simulation;flow visualisation;foams;polymer solutions;set theory;suspensions	2D foam simulation data visualization capability;complex fluid flow;foam behavior;foam specific visualization software;large complex time dependent data set;material parameter;particulate suspension;polymer solution;standard solver software;surface evolver;time dependent 2D foam simulation data	Analytical models;Computational modeling;Data models;Data visualization;Image color analysis;Visualization	Surface Evolver;bubble-scale simulation;time-dependent visualizations.	Research in the field of complex fluids such as polymer solutions, particulate suspensions and foams studies how the flow of fluids with different material parameters changes as a result of various constraints. Surface Evolver, the standard solver software used to generate foam simulations, provides large, complex, time-dependent data sets with hundreds or thousands of individual bubbles and thousands of time steps. However this software has limited visualization capabilities, and no foam specific visualization software exists. We describe the foam research application area where, we believe, visualization has an important role to play. We present a novel application that provides various techniques for visualization, exploration and analysis of time-dependent 2D foam simulation data. We show new features in foam simulation data and new insights into foam behavior discovered using our application.	Lipsa, D.R.;Laramee, R.S.;Cox, S.J.;Davies, I.T.	Swansea Univ., Swansea, UK|c|;;;	38017004200;37267247900;38016817800;38021331800
	InfoVis+SciVis	Dec. 2011	WYSIWYG (What You See is What You Get) Volume Visualization	10.1109/TVCG.2011.261	http://dx.doi.org/10.1109/TVCG.2011.261	2106	2114	6064975	brightness;colour;data visualisation;feature extraction;rendering (computer graphics);transfer functions	2D images;WYSIWYG volume visualization system;direct volume rendering manipulation;feature clustering;feature identification;feature matching;optical properties;painting applications;sketch-based What You See Is What You Get approach;sparse sketching;transfer function parameter tuning;volume data exploration;volume data visualization	Data visualization;Image color analysis;Real time systems;Rendering (computer graphics);Semantics;Transfer functions	Feature space.;Human-computer interaction;Sketching input;Transfer functions;Volume rendering	In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.	Hanqi Guo;Ningyu Mao;Xiaoru Yuan	Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;	37595201300;38027433600;37403856700
	InfoVis+SciVis	Dec. 2011	Interactive Volume Visualization of General Polyhedral Grids	10.1109/TVCG.2011.216	http://dx.doi.org/10.1109/TVCG.2011.216	2115	2124	6064976	data structures;data visualisation;interactive systems;simulation	GPU-based ray casting;TSFSL;a priori tetrahedralization;face-based data structure;general polyhedral grids;interactive volume visualization;simulation packages;two-sided face sequence lists;volumetric data visualization	Data visualization;Geometry;Graphics processing unit;Rendering (computer graphics)	GPU-based visualization.;Volume rendering;polyhedral grids;unstructured grids	This paper presents a novel framework for visualizing volumetric data specified on complex polyhedral grids, without the need to perform any kind of a priori tetrahedralization. These grids are composed of polyhedra that often are non-convex and have an arbitrary number of faces, where the faces can be non-planar with an arbitrary number of vertices. The importance of such grids in state-of-the-art simulation packages is increasing rapidly. We propose a very compact, face-based data structure for representing such meshes for visualization, called two-sided face sequence lists (TSFSL), as well as an algorithm for direct GPU-based ray-casting using this representation. The TSFSL data structure is able to represent the entire mesh topology in a 1D TSFSL data array of face records, which facilitates the use of efficient 1D texture accesses for visualization. In order to scale to large data sizes, we employ a mesh decomposition into bricks that can be handled independently, where each brick is then composed of its own TSFSL array. This bricking enables memory savings and performance improvements for large meshes. We illustrate the feasibility of our approach with real-world application results, by visualizing highly complex polyhedral data from commercial state-of-the-art simulation packages.	Muigg, P.;Hadwiger, M.;Doleisch, H.;Groller, E.	Vienna Univ. of Technol., Vienna, Austria|c|;;;	37546620600;37394809600;37546620400;37284271200
	InfoVis+SciVis	Dec. 2011	Image Plane Sweep Volume Illumination	10.1109/TVCG.2011.211	http://dx.doi.org/10.1109/TVCG.2011.211	2125	2134	6064977	computer graphic equipment;coprocessors;image processing;ray tracing;rendering (computer graphics)	GPU;IPSVI;image comprehension;image plane sweep volume illumination;image quality;lighting effects;ray casting process;volume rendering technique;volumetric illumination models	Equations;Light sources;Mathematical model;Rendering (computer graphics);Synchronization	Advanced illumination.;GPU-based ray-casting;Interactive volume rendering	In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.	Sunden, E.;Ynnerman, A.;Ropinski, T.	Sci. Visualization Group, Linkoping Univ., Linkoping, Sweden|c|;;	38243026500;37284192000;38471794200
	InfoVis+SciVis	Dec. 2011	Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization	10.1109/TVCG.2011.214	http://dx.doi.org/10.1109/TVCG.2011.214	2135	2143	6064978	computer graphic equipment;coprocessors;data visualisation;interactive systems;natural sciences computing;rendering (computer graphics)	CUDA;GPU accelerated out-of-core multiresolution rendering framework;GPU accelerated tensor reconstruction;computational simulations;constrained memory footprint;data transfer bandwidth;gigabyte sized microtomographic volumes;hierarchical brick tensor decomposition approach;high resolution 3D imaging devices;interactive multiscale tensor reconstruction;interactive visual analysis;multiresolution volume visualization;out-of-core memory footprint;tensor approximation	Approximation methods;Graphics processing unit;Instruction sets;Quantization;Rendering (computer graphics);Tensile stress	GPU/CUDA;interactive volume visualization;multiresolution rendering.;multiscale;tensor reconstruction	Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.	Suter, S.K.;Iglesias Guitian, J.A.;Marton, F.;Agus, M.;Elsener, A.;Zollikofer, C.P.E.;Gopi, M.;Gobbetti, E.;Pajarola, Renato	Univ. of Zurich, Zurich, Switzerland|c|;;;;;;;;	38017011900;38017011700;37550808100;37991435500;38017012300;38017013500;37271691400;37346861300;37282193800
	InfoVis+SciVis	Dec. 2011	An Efficient Direct Volume Rendering Approach for Dichromats	10.1109/TVCG.2011.164	http://dx.doi.org/10.1109/TVCG.2011.164	2144	2152	6064979	colour vision;data visualisation;image classification;image colour analysis;image enhancement;rendering (computer graphics);transfer functions;vision defects	CVD friendly effect;classification information;color blending;color composition mode;color transfer function;color vision deficiency;computational complexity;dichromats;direct volume rendering;image enhancement;image recoloring techniques	Data visualization;Image color analysis;Linear systems;Rendering (computer graphics);Transfer functions;Volume measurement	Dichromacy;direct volume rendering;image recoloring.;volume classification	Color vision deficiency (CVD) affects a high percentage of the population worldwide. When seeing a volume visualization result, persons with CVD may be incapable of discriminating the classification information expressed in the image if the color transfer function or the color blending used in the direct volume rendering is not appropriate. Conventional methods used to address this problem adopt advanced image recoloring techniques to enhance the rendering results frame-by-frame; unfortunately, problematic perceptual results may still be generated. This paper proposes an alternative solution that complements the image recoloring scheme by reconfiguring the components of the direct volume rendering (DVR) pipeline. Our approach optimizes the mapped colors of a transfer function to simulate CVD-friendly effect that is generated by applying the image recoloring to the results with the initial transfer function. The optimization process has a low computational complexity, and only needs to be performed once for a given transfer function. To achieve detail-preserving and perceptually natural semi-transparent effects, we introduce a new color composition mode that works in the color space of dichromats. Experimental results and a pilot study demonstrates that our approach can yield dichromats-friendly and consistent volume visualization in real-time.	Weifeng Chen;Wei Chen;Hujun Bao	State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;	38024756400;37279188600;37271755400
	InfoVis+SciVis	Dec. 2011	Interactive Virtual Probing of 4D MRI Blood-Flow	10.1109/TVCG.2011.215	http://dx.doi.org/10.1109/TVCG.2011.215	2153	2162	6064980	biomedical MRI;blood;blood vessels;data visualisation;flow instability;flow visualisation;haemodynamics;virtual reality	4D MRI blood-flow behaviour;4D velocity field;anatomical structure;anatomical structure segmentation;blood-flow parameter;cardiovascular disease;flow visualization approach;hard-to-automate process;hemodynamics;interactive virtual probing;laborious segmentation process;malformed morphology;object navigation;thoracic artery;time-resolved flow information;visual exploration	Blood flow;Data visualization;Magnetic resonance imaging;Three dimensional displays	Flow visualization;Illustrative visualization;Multivalued images;Phase-contrast cine MRI.;Probing	Better understanding of hemodynamics conceivably leads to improved diagnosis and prognosis of cardiovascular diseases. Therefore, an elaborate analysis of the blood-flow in heart and thoracic arteries is essential. Contemporary MRI techniques enable acquisition of quantitative time-resolved flow information, resulting in 4D velocity fields that capture the blood-flow behavior. Visual exploration of these fields provides comprehensive insight into the unsteady blood-flow behavior, and precedes a quantitative analysis of additional blood-flow parameters. The complete inspection requires accurate segmentation of anatomical structures, encompassing a time-consuming and hard-to-automate process, especially for malformed morphologies. We present a way to avoid the laborious segmentation process in case of qualitative inspection, by introducing an interactive virtual probe. This probe is positioned semi-automatically within the blood-flow field, and serves as a navigational object for visual exploration. The difficult task of determining position and orientation along the view-direction is automated by a fitting approach, aligning the probe with the orientations of the velocity field. The aligned probe provides an interactive seeding basis for various flow visualization approaches. We demonstrate illustration-inspired particles, integral lines and integral surfaces, conveying distinct characteristics of the unsteady blood-flow. Lastly, we present the results of an evaluation with domain experts, valuing the practical use of our probe and flow visualization techniques.	van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, M.E.;Vilanova, A.	Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;	37390973400;37591606800;37374875300;37603313200;37282552200;37282551500
	InfoVis+SciVis	Dec. 2011	Crepuscular Rays for Tumor Accessibility Planning	10.1109/TVCG.2011.184	http://dx.doi.org/10.1109/TVCG.2011.184	2163	2172	6064981	data visualisation;image reconstruction;medical computing;patient care;ray tracing;rendering (computer graphics);safety;tumours	abdominal radiofrequency ablation intervention;access path visualization;clinical practice;crepuscular ray;medical 2D multiplanar reconstruction view;multivolume rendering system;patient death;physician insufficient experience;preoperative planning;safety evaluation;tumor accessibility planning;tumor voxel;volumetric target structure	Biomedical image processing;Rendering (computer graphics);Three dimensional displays;Tumors	Accessibility;medical visualization.;ray casting	In modern clinical practice, planning access paths to volumetric target structures remains one of the most important and most complex tasks, and a physician's insufficient experience in this can lead to severe complications or even the death of the patient. In this paper, we present a method for safety evaluation and the visualization of access paths to assist physicians during preoperative planning. As a metaphor for our method, we employ a well-known, and thus intuitively perceivable, natural phenomenon that is usually called crepuscular rays. Using this metaphor, we propose several ways to compute the safety of paths from the region of interest to all tumor voxels and show how this information can be visualized in real-time using a multi-volume rendering system. Furthermore, we show how to estimate the extent of connected safe areas to improve common medical 2D multi-planar reconstruction (MPR) views. We evaluate our method by means of expert interviews, an online survey, and a retrospective evaluation of 19 real abdominal radio-frequency ablation (RFA) interventions, with expert decisions serving as a gold standard. The evaluation results show clear evidence that our method can be successfully applied in clinical practice without introducing substantial overhead work for the acting personnel. Finally, we show that our method is not limited to medical applications and that it can also be useful in other fields.	Khlebnikov, R.;Kainz, B.;Muehl, J.;Schmalstieg, D.	Graz Univ. of Technol., Graz, Austria|c|;;;	37590719600;37680676000;37590720800;37297103800
	InfoVis+SciVis	Dec. 2011	Distance Visualization for Interactive 3D Implant Planning	10.1109/TVCG.2011.189	http://dx.doi.org/10.1109/TVCG.2011.189	2173	2182	6064982	data visualisation;interactive systems;medical computing	color coding;cylindrical glyphs;distance visualization;distance-based measures;interactive 3D implant planning;medical operation planning system;polygonal object representations;ray-triangle mesh intersection	Biomedical image processing;Distance measurement;Image color analysis;Implants;Rendering (computer graphics)	Distance visualization;biomedical visualization;distance fields.;glyphs;implant planning	An instant and quantitative assessment of spatial distances between two objects plays an important role in interactive applications such as virtual model assembly, medical operation planning, or computational steering. While some research has been done on the development of distance-based measures between two objects, only very few attempts have been reported to visualize such measures in interactive scenarios. In this paper we present two different approaches for this purpose, and we investigate the effectiveness of these approaches for intuitive 3D implant positioning in a medical operation planning system. The first approach uses cylindrical glyphs to depict distances, which smoothly adapt their shape and color to changing distances when the objects are moved. This approach computes distances directly on the polygonal object representations by means of ray/triangle mesh intersection. The second approach introduces a set of slices as additional geometric structures, and uses color coding on surfaces to indicate distances. This approach obtains distances from a precomputed distance field of each object. The major findings of the performed user study indicate that a visualization that can facilitate an instant and quantitative analysis of distances between two objects in interactive 3D scenarios is demanding, yet can be achieved by including additional monocular cues into the visualization.	Dick, C.;Burgkart, R.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;	38013954900;37281609100;37444424000
	InfoVis+SciVis	Dec. 2011	The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms	10.1109/TVCG.2011.243	http://dx.doi.org/10.1109/TVCG.2011.243	2183	2192	6064983	data visualisation;haemodynamics;medical computing;rendering (computer graphics)	4D PC-MRI measurement;CFD;FLOWLENS;WSS;anatomic scope;blood flow exploration;cerebral aneurysms;flexible visual filtering;focus-and-context visualization;hemodynamic attribute;inflow jet;occlusion;visual cluttering;visual exploration;wall shear stress	Aneurysm;Data visualization;Flow visualization;Hemodynamics;Rendering (computer graphics);Shape analysis	Aneurysm.;Flow Visualization;Focus-and-Context;Illustrative Rendering	Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.	Gasteiger, R.;Neugebauer, M.;Beuing, O.;Preim, B.	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;	38017015100;38030357700;38017002900;37424645300
	InfoVis+SciVis	Dec. 2011	Projection-Based Metal-Artifact Reduction for Industrial 3D X-ray Computed Tomography	10.1109/TVCG.2011.228	http://dx.doi.org/10.1109/TVCG.2011.228	2193	2202	6064984	computerised tomography;data visualisation;interpolation	3D volume;3DXCT;artifact-reduction technique;dark-band artifact;industrial 3D X-ray computed tomography;interactive parameter estimation;metal segmentation;multimaterial components;plastic material;projection-based metal-artifact reduction;projection-space pipeline;streaking artifact;visual analysis tool	Computed tomography;Image reconstruction;Information analysis;Interpolation;Three dimensional displays	3D X-ray computed tomography.;Metal-artifact reduction;multi-material components;visual analysis	Multi-material components, which contain metal parts surrounded by plastic materials, are highly interesting for inspection using industrial 3D X-ray computed tomography (3DXCT). Examples of this application scenario are connectors or housings with metal inlays in the electronic or automotive industry. A major problem of this type of components is the presence of metal, which causes streaking artifacts and distorts the surrounding media in the reconstructed volume. Streaking artifacts and dark-band artifacts around metal components significantly influence the material characterization (especially for the plastic components). In specific cases these artifacts even prevent a further analysis. Due to the nature and the different characteristics of artifacts, the development of an efficient artifact-reduction technique in reconstruction-space is rather complicated. In this paper we present a projection-space pipeline for metal-artifacts reduction. The proposed technique first segments the metal in the spatial domain of the reconstructed volume in order to separate it from the other materials. Then metal parts are forward-projected on the set of projections in a way that metal-projection regions are treated as voids. Subsequently the voids, which are left by the removed metal, are interpolated in the 2D projections. Finally, the metal is inserted back into the reconstructed 3D volume during the fusion stage. We present a visual analysis tool, allowing for interactive parameter estimation of the metal segmentation. The results of the proposed artifact-reduction technique are demonstrated on a test part as well as on real world components. For these specimens we achieve a significant reduction of metal artifacts, allowing an enhanced material characterization.	Amirkhanov, A.;Heinzl, C.;Reiter, M.;Kastner, J.;Groller, E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;;	37590979900;37400391300;37593834800;37947609000;37284271200
	InfoVis+SciVis	Dec. 2011	Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization	10.1109/TVCG.2011.229	http://dx.doi.org/10.1109/TVCG.2011.229	2203	2212	6064985	data visualisation	alternative visualizations;high-dimensional data visualization;information visualization pipeline;quality metrics	Data visualization;Measurements	High-Dimensional Data Visualization.;Quality Metrics	In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.	Bertini, E.;Tatu, A.;Keim, D.	Univ. of Konstanz, Konstanz, Germany|c|;;	37283307700;37590724000;37283138700
	InfoVis+SciVis	Dec. 2011	Benefitting InfoVis with Visual Difficulties	10.1109/TVCG.2011.175	http://dx.doi.org/10.1109/TVCG.2011.175	2213	2222	6064986	cognition;data visualisation;psychology	InfoVis practitioners;InfoVis researchers;cognitive difficulty;cross-disciplinary research;decorative chartjunk;distracting elements;efficiency-based design theory;extraneous information;graph design;information visualization practitioners;information visualization researchers;information visualizations;nonefficient visual elements;psychology;user understanding;visual difficulty;visual displays;visual information representations;visual representation;visualization design;visualization interaction;well-cited theory	Cognition;Data visualization;Psychology;Time factors	Desirable difficulites;active processing;cognitive efficiency;engagement;individual differences.	"Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative ""chartjunk"" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations."	Hullman, J.;Adar, E.;Shah, P.	;;	38016234500;37331417100;38018860000
	InfoVis+SciVis	Dec. 2011	Product Plots	10.1109/TVCG.2011.227	http://dx.doi.org/10.1109/TVCG.2011.227	2223	2230	6064987	bar charts;data visualisation;statistical distributions	bar charts;equal area plots;fluctuation diagrams;infovis;joint distribution;marginal distributions;mosaic plots;product plots;statistical graphics;table visualisation;treemaps	Data visualization;Image color analysis;Probability;Statistical analysis	Statistics;bar chart;conditional distribution;joint distribution;mosaic plot.;treemap	We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.	Wickham, H.;Hofmann, H.	;	37591246300;37592793000
	InfoVis+SciVis	Dec. 2011	Visualization Rhetoric: Framing Effects in Narrative Visualization	10.1109/TVCG.2011.255	http://dx.doi.org/10.1109/TVCG.2011.255	2231	2240	6064988	data visualisation;decision making	communicative information visualization;critical theory;decision making;design tactics;end-user interpretation;exploratory information visualization;framing effects;journalism;literary study;narrative information visualization;political messaging;political theory;semiotics;textual annotation;visual representation;visualization rhetoric	Data visualization;Rhetoric;Semiotics	Rhetoric;connotation.;denotation;framing effects;narrative visualization;semiotics	"Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that ""tell a story"" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation."	Hullman, J.;Diakopoulos, N.	;	38016234500;37591165700
	InfoVis+SciVis	Dec. 2011	Adaptive Privacy-Preserving Visualization Using Parallel Coordinates	10.1109/TVCG.2011.163	http://dx.doi.org/10.1109/TVCG.2011.163	2241	2248	6064989	data mining;data privacy;data visualisation	adaptive privacy-preserving visualization;data mining;information visualization techniques;parallel coordinates;privacy protection;privacy-preserving data publishing;screen-space privacy metrics	Clustering algorithms;Data privacy;Data visualization;Privacy	Parallel coordinates;clustering.;privacy	Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.	Dasgupta, A.;Kosara, R.	;	37593202500;37282563400
	InfoVis+SciVis	Dec. 2011	Context-Preserving Visual Links	10.1109/TVCG.2011.183	http://dx.doi.org/10.1109/TVCG.2011.183	2249	2258	6064990	data analysis;data visualisation	complex visualizations;context preserving visual links;image based analysis;information intensive work;information occlusion;synchronized visual highlighting;visual data analysis;visual interference;visual saliency	Data visualization;Histograms;Image color analysis	Visual links;connectedness;highlighting;image-based;routing;saliency.	Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.	Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.	;;;;	38017759700;37844773200;37403918900;37395933400;37297103800
	InfoVis+SciVis	Dec. 2011	Design Study of LineSets, a Novel Set Visualization Technique	10.1109/TVCG.2011.186	http://dx.doi.org/10.1109/TVCG.2011.186	2259	2267	6064991	cartography;data visualisation;geometry;set theory	community analysis task;concave geometry;convex geometry;heuristics;information visualization;linesets;map;search tasks;set visual representation;set visualization;social network	Accuracy;Data visualization;Geometry;Shape analysis;Social network services	Set visualization;clustering;faceted data visualization;graph visualization.	Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.	Alper, B.;Riche, N.H.;Ramos, G.	;;	38030020400;37590950700;38030407700
	InfoVis+SciVis	Dec. 2011	Developing and Evaluating Quilts for the Depiction of Large Layered Graphs	10.1109/TVCG.2011.187	http://dx.doi.org/10.1109/TVCG.2011.187	2268	2275	6064992	flowcharting;graphs;matrix algebra	color-only depiction;flow charts;layered graph depiction;matrix depiction;matrix diagrams;node-link diagrams;quilts;skip link depiction;text-only depiction	Analysis of variance;Atmospheric measurements;Graphics;Particle measurements;Time measurement	Graph drawing;layered graphs;matrix based depiction;node-link diagram.	Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).	Juhee Bae		37595934400
	InfoVis+SciVis	Dec. 2011	Arc Length-Based Aspect Ratio Selection	10.1109/TVCG.2011.167	http://dx.doi.org/10.1109/TVCG.2011.167	2276	2282	6064993	computational geometry;data analysis;data visualisation	arc length based aspect ratio selection;data curve;line segments;parameterization invariant approach;visual data symmetries	Length measurement;Ratio selection;Time series analysis	Aspect ratio selection;Banking to 45 degrees;Orientation resolution.	The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.			
	InfoVis+SciVis	Dec. 2011	Asymmetric Relations in Longitudinal Social Networks	10.1109/TVCG.2011.169	http://dx.doi.org/10.1109/TVCG.2011.169	2283	2290	6064994	data mining;matrix algebra;social networking (online)	Tufte's sparklines;asymmetric relation;cross-sectional network;data rich diagram;dyadic relation;gestalt theory;gestaltlines;glyphs;graphical representation;indirect linkages;intermediate state;longitudinal social network;matrix representation;persistent group structure;visual exploration	Data visualization;Image color analysis;Social network services	Glyphbased Techniques.;Network Visualization;Social Networks;Time Series Data;Visual Knowledge Discovery and Representation	In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.	Brandes, U.;Nick, B.	Dept. of Comput. & Inf. Sci., Univ. of Konstanz, Konstanz, Germany|c|;	37550836200;38016272500
	InfoVis+SciVis	Dec. 2011	VisBricks: Multiform Visualization of Large, Inhomogeneous Data	10.1109/TVCG.2011.250	http://dx.doi.org/10.1109/TVCG.2011.250	2291	2300	6064995	data visualisation;medical computing	VisBricks visualization concept;biomedicine field;data visualization;inhomogeneous data;statistical method	Data visualization;Nonhomogeneous media;Semantics	Inhomogeneous data;multiform visualization.;multiple coordinated views	Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.	Lex, A.;Schulz, H.;Streit, M.;Partl, C.;Schmalstieg, D.	Graz Univ. of Technol., Graz, Austria|c|;;;;	37395933400;37408482600;37403918900;37591066400;37297103800
	InfoVis+SciVis	Dec. 2011	D&#x0B3; Data-Driven Documents	10.1109/TVCG.2011.185	http://dx.doi.org/10.1109/TVCG.2011.185	2301	2309	6064996	Web sites;computer animation;data visualisation;document handling;user interfaces	Web visualization;animation;data-driven documents;document elements;dynamic transforms;native representation;representation-transparent approach;representational transparency;scene graph;standard document object model;toolkit-specific abstraction	Cascading style sheets;Data visualization;Debugging;Image color analysis;Information analysis	2D graphics.;Information visualization;toolkits;user interfaces	Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.	Bostock, M.;Ogievetsky, V.;Heer, J.	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;	37591067400;38016292400;37550791300
	InfoVis+SciVis	Dec. 2011	Flexible Linked Axes for Multivariate Data Visualization	10.1109/TVCG.2011.201	http://dx.doi.org/10.1109/TVCG.2011.201	2310	2316	6064997	data visualisation	PCP;custom visualizations;flexible linked axes;hyperboxes;multivariate data visualization;parallel coordinate displays;parallel coordinates plot-style;radar charts;scatter plot matrices;timewheels	Data visualization;Histograms;Image color analysis;Scattering parameters	Multivariate data;Parallel Coordinates Plot.;scatter plot;visualization	Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.	Claessen, J.H.T.;van Wijk, J.J.	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;	38016239600;37267249200
	InfoVis+SciVis	Dec. 2011	Synthetic Generation of High-Dimensional Datasets	10.1109/TVCG.2011.237	http://dx.doi.org/10.1109/TVCG.2011.237	2317	2324	6064998	data handling;graphical user interfaces;pattern classification;pattern clustering;statistical distributions	classified datasets;complex nonorthogonal trends;graphical user interface;multidimensional clusters;multidimensional correlations;multidimensional outliers;orthogonal projection planes;statistical distributions;synthetic high dimensional datasets generation;user defined parameters	Correlation;Data processing;Probability density function;Scattering parameters	Synthetic data generation;high-dimensional data;interaction.;multivariate data	Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.	Albuquerque, G.;Lowe, T.;Magnor, M.	Comput. Graphics Lab., TU, Braunschweig, Germany|c|;;	37603943800;38028705600;37273816400
	InfoVis+SciVis	Dec. 2011	Stereoscopic Highlighting: 2D Graph Visualization on Stereo Displays	10.1109/TVCG.2011.234	http://dx.doi.org/10.1109/TVCG.2011.234	2325	2333	6064999	data visualisation;graph theory;three-dimensional displays	2D graph visualization;2D layout;3D layout;data attributes;focus+context views;static visual highlighting;stereo displays;stereoscopic highlighting	Data visualization;Graphics;Image color analysis;Stereo image processing;Two dimensional displays	Graph visualization;stereo displays;virtual reality.	In this paper we present a new technique and prototype graph visualization system, stereoscopic highlighting, to help answer accessibility and adjacency queries when interacting with a node-link diagram. Our technique utilizes stereoscopic depth to highlight regions of interest in a 2D graph by projecting these parts onto a plane closer to the viewpoint of the user. This technique aims to isolate and magnify specific portions of the graph that need to be explored in detail without resorting to other highlighting techniques like color or motion, which can then be reserved to encode other data attributes. This mechanism of stereoscopic highlighting also enables focus+context views by juxtaposing a detailed image of a region of interest with the overall graph, which is visualized at a further depth with correspondingly less detail. In order to validate our technique, we ran a controlled experiment with 16 subjects comparing static visual highlighting to stereoscopic highlighting on 2D and 3D graph layouts for a range of tasks. Our results show that while for most tasks the difference in performance between stereoscopic highlighting alone and static visual highlighting is not statistically significant, users performed better when both highlighting methods were used concurrently. In more complicated tasks, 3D layout with static visual highlighting outperformed 2D layouts with a single highlighting method. However, it did not outperform the 2D layout utilizing both highlighting techniques simultaneously. Based on these results, we conclude that stereoscopic highlighting is a promising technique that can significantly enhance graph visualizations for certain use cases.	Alper, B.;Hollerer, T.;Kuchera-Morin, J.;Forbes, A.	Media Arts & Technol. Program, Univ. of California, Santa Barbara, CA, USA|c|;;;	38030020400;37265602700;37568193500;38029040000
	InfoVis+SciVis	Dec. 2011	In Situ Exploration of Large Dynamic Networks	10.1109/TVCG.2011.213	http://dx.doi.org/10.1109/TVCG.2011.213	2334	2343	6065000	data visualisation;graph theory;network theory (graphs)	bot nets;dynamic graph visualization;in situ exploration;large dynamic networks;mental map;model versioning;network structure;social networks;visual analysis;visual representations;visualization techniques;wireless mesh networks	Data visualization;Graphics	Dynamic graph data;multi-focus+context.;multiform visualization	The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.	Hadlak, S.;Schulz, H.;Schumann, H.	;;	37396082800;37408482600;37283240400
	InfoVis+SciVis	Dec. 2011	Parallel Edge Splatting for Scalable Dynamic Graph Visualization	10.1109/TVCG.2011.226	http://dx.doi.org/10.1109/TVCG.2011.226	2344	2353	6065001	data visualisation;graph theory	JUnit open source software project;bibliography dataset;call graph;data exploration;interaction technique;node-link diagram;nonlinear color mapping;parallel edge splatting;scalable dynamic graph visualization;selective data zooming	Data visualization;Encoding;Graphics;Image color analysis;Image edge detection;Software engineering	Dynamic graph visualization;graph splatting;software evolution.;software visualization	We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.	Burch, M.;Vehlow, C.;Beck, F.;Diehl, S.;Weiskopf, D.	VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;;;	37586953400;38017348600;37586060300;37275546500;38470313100
	InfoVis+SciVis	Dec. 2011	Divided Edge Bundling for Directional Network Data	10.1109/TVCG.2011.190	http://dx.doi.org/10.1109/TVCG.2011.190	2354	2363	6065002	data visualisation;directed graphs;matrix algebra;pattern clustering	clustered graphs;directed edge bundling;directional edge patterns;directional network data;graph connectivity;graph theory;graph topology;matrix diagrams;node link diagram;visualization	Data visualization;Encoding;Graphics;Image edge detection	Graph visualization;aggregation;edge bundling;node-link diagrams;physical simulation.	The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten & van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.	Selassie, D.;Heller, B.;Heer, J.	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;	38017434000;38027228800;37550791300
	InfoVis+SciVis	Dec. 2011	Skeleton-Based Edge Bundling for Graph Visualization	10.1109/TVCG.2011.233	http://dx.doi.org/10.1109/TVCG.2011.233	2364	2373	6065003	data visualisation;graph theory;pattern clustering	2D skeletonization;distance fields;edge clustering;graph visualization;graphics hardware;medial axes;skeleton-based edge bundling	Image edge detection;Image processing;Shape analysis;Smoothing methods;Transforms	Graph layouts;edge bundles;image-based information visualization.	In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.	Ersoy, O.;Hurter, C.;Paulovich, F.V.;Telea, A.	Univ. of Groningen, Groningen, Netherlands|c|;;;	37672044200;38017336200;37590969400;37268047100
	InfoVis+SciVis	Dec. 2011	BirdVis: Visualizing and Understanding Bird Populations	10.1109/TVCG.2011.176	http://dx.doi.org/10.1109/TVCG.2011.176	2374	2383	6065004	data visualisation;ecology;environmental science computing;statistical analysis;zoology	BirdVis;biotic processes;bird observation records;bird population understanding;bird population visualization;climate;conservation biologists;crowdsourcing;eBird project;ecological well being;ecology;habitat;interactive visualization system;land managers;local scale environmental covariates;multiscale spatial temporal patterns;ornithologists;spatio temporal bird distribution models;species-habitat associations;statistical framework;vegetation phenology	Biological system modeling;Data visualization;Ornithology;Predictive models;Spatial databases;Tag clouds	Ornithology;multiscale analysis;spatial data;species distribution models;temporal data.	Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case s- udies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.	Ferreira, N.;Lins, L.;Fink, D.;Kelling, S.;Wood, C.;Freire, J.;Silva, C.	;;;;;;	38018628600;37682897900;37410464700;37667188400;38029052800;37283149600;37275249200
	InfoVis+SciVis	Dec. 2011	BallotMaps: Detecting Name Bias in Alphabetically Ordered Ballot Papers	10.1109/TVCG.2011.174	http://dx.doi.org/10.1109/TVCG.2011.174	2384	2391	6065005	local government	Liberal Democrat candidates;alphabetic name bias detection;ballot papers;ballotmaps;electoral data;electoral outcome;ethnicity;fair election;local government election;marginal electoral wards;political party;position bias;visual analysis;vote rank;voting behaviour	Data visualization;Geospatial analysis;Image color analysis;Local government;Nominations and elections	Voting;bias;democracy;election;geovisualization;governance;governance.;hierarchy;treemaps	The relationship between candidates' position on a ballot paper and vote rank is explored in the case of 5000 candidates for the UK 2010 local government elections in the Greater London area. This design study uses hierarchical spatially arranged graphics to represent two locations that affect candidates at very different scales: the geographical areas for which they seek election and the spatial location of their names on the ballot paper. This approach allows the effect of position bias to be assessed; that is, the degree to which the position of a candidate's name on the ballot paper influences the number of votes received by the candidate, and whether this varies geographically. Results show that position bias was significant enough to influence rank order of candidates, and in the case of many marginal electoral wards, to influence who was elected to government. Position bias was observed most strongly for Liberal Democrat candidates but present for all major political parties. Visual analysis of classification of candidate names by ethnicity suggests that this too had an effect on votes received by candidates, in some cases overcoming alphabetic name bias. The results found contradict some earlier research suggesting that alphabetic name bias was not sufficiently significant to affect electoral outcome and add new evidence for the geographic and ethnicity influences on voting behaviour. The visual approach proposed here can be applied to a wider range of electoral data and the patterns identified and hypotheses derived from them could have significant implications for the design of ballot papers and the conduct of fair elections.	Wood, J.;Badawood, D.;Dykes, J.;Slingsby, A.	;;;	37399045100;38017330600;37605079900;37590960700
	InfoVis+SciVis	Dec. 2011	Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization	10.1109/TVCG.2011.232	http://dx.doi.org/10.1109/TVCG.2011.232	2392	2401	6065006	biology computing;data visualisation;genomics;signal processing	aggregation schemes;bacterial-sized genomes;generality;genomic sequence data;perceptual science;scalable genomic alignment visualization;sequence alignment visualization;sequence surveyor;signal processing theory	Bioinformatics;Data visualization;Design methodology;Genomics;Image color analysis	Bioinformatics Visualization;Perception Theory;Scalability Issues;Visual Design.	In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.	Albers, D.;Dewey, C.;Gleicher, M.	Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;	38019392100;37994248400;37282585700
	InfoVis+SciVis	Dec. 2011	Visualization of Parameter Space for Image Analysis	10.1109/TVCG.2011.253	http://dx.doi.org/10.1109/TVCG.2011.253	2402	2411	6065007	data visualisation;image sampling;medical image processing	CellProfiler;Paramorama;biomedical image analysis framework;custom sampling plug-in;interactive visual exploration;interactive visualization;parameter optimization process;parameter sampling;parameter space visualization;visual analysis	Algorithm design and analysis;Image analysis;Information processing;Sampling methods	Information visualization;image analysis;parameter space;sampling.;visual analytics	Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.	Pretorius, A.J.;Bray, M.-A.P.;Carpenter, A.E.;Ruddle, R.A.	Sch. of Comput., Univ. of Leeds, Leeds, UK|c|;;;	38488127500;38287976800;38261206900;37282918500
	InfoVis+SciVis	Dec. 2011	TextFlow: Towards Better Understanding of Evolving Topics in Text	10.1109/TVCG.2011.239	http://dx.doi.org/10.1109/TVCG.2011.239	2412	2421	6065008	data mining;data visualisation;feature extraction;text analysis	TextFlow;coherent visualization;convey complex relationships;critical event;keyword correlation;three-level feature extraction;topic evolution trend;topic mining model;topic mining technique;topics evolution;visualization technique	Data visualization;Image color analysis;Tag clouds;Text analysis	Critical event.;Hierarchical Dirichlet process;Text visualization;Topic evolution	Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.	Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;	37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000
	InfoVis+SciVis	Dec. 2011	Exploratory Analysis of Time-Series with ChronoLenses	10.1109/TVCG.2011.195	http://dx.doi.org/10.1109/TVCG.2011.195	2422	2431	6065009	data analysis;data visualisation;time series	ChronoLenses;exploratory time-series analysis;on-the-fly data point transformation;visual analysis;visual representation;visualization technique	Data visualization;Lenses;Rendering (computer graphics);Time series analysis;Transforms	Exploratory Visualization;Focus+Context;Interaction Techniques.;Lens;Time-series Data	Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.	Jian Zhao;Chevalier, F.;Pietriga, E.;Balakrishnan, R.	DGP, Univ. of Toronto, Toronto, ON, Canada|c|;;;	38024987300;37395495900;37563810700;37394495600
	InfoVis+SciVis	Dec. 2011	CloudLines: Compact Display of Event Episodes in Multiple Time-Series	10.1109/TVCG.2011.179	http://dx.doi.org/10.1109/TVCG.2011.179	2432	2439	6065010	Internet;computer displays;data analysis;data structures;data visualisation;financial management;information resources;security of data;time series	CloudLines;data analysis;data visualization;decay function;event episode compact display;financial service;incremental data sets;interactive distortion;logarithmic time scale;magnifying lens technique;multiple time series visualization technique;network security;online news streams;readability enhancement;temporal context;time-based representation	Data visualization;Estimation;Event detection;Lenses;Time series analysis	Incremental visualization;event based data;lens distortion.	We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.	Krstajic, M.;Bertini, E.;Keim, D.A.	Univ. of Konstanz, Konstanz, Germany|c|;;	38228240900;37283307700;37283138700
	InfoVis+SciVis	Dec. 2011	Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study	10.1109/TVCG.2011.193	http://dx.doi.org/10.1109/TVCG.2011.193	2440	2448	6065011	data visualisation;diagrams;trees (mathematics)	diagram orientation;eye movement data;eye tracking experiment;eye tracking study;gaze trajectory;hierarchy exploration task;node-link diagrams;nonradial diagrams;nonradial layout;orthogonal diagrams;orthogonal tree layout;parent-child relationship;radial node-link tree layouts;radial tree diagrams;static tree diagram;trajectory analysis;visual exploration behavior	Analysis of variance;Data visualization;Hierarchical systems;Tracking;Trajectory;Upper bound	Hierarchy visualization;eye tracking;node-link layout;user study.	Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.	Burch, M.;Konevtsova, N.;Heinrich, J.;Weiskopf, D.	VISUS, Univ. of Stuttgart, Germany|c|;;;	37586953400;38017426500;37665271000;38470313100
	InfoVis+SciVis	Dec. 2011	TreeNetViz: Revealing Patterns of Networks over Tree Structures	10.1109/TVCG.2011.247	http://dx.doi.org/10.1109/TVCG.2011.247	2449	2458	6065012	computational complexity;data visualisation;graph theory;optimisation;tree data structures	TreeNet graph;TreeNetViz;circle layout;compound graph model;expertise areas;network data;networks patterns;optimization;radial space filling visualization;social affiliations;social network;tree structures;visual cluttering;visual complexity	Algorithm design and analysis;Complexity theory;Data visualization;Graphics;Tree data structures	Compound graph;TreeNetViz;multiscale and cross-scale.;network and tree;visualization	Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.	Liang Gou;Xiaolong Zhang	Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA|c|;	38018817100;37537459400
	InfoVis+SciVis	Dec. 2011	Improved Similarity Trees and their Application to Visual Data Classification	10.1109/TVCG.2011.212	http://dx.doi.org/10.1109/TVCG.2011.212	2459	2468	6065013	data analysis;data mining;image classification;iterative methods;trees (mathematics)	image classification;iterative manipulation;multidimensional projection;neighbor joining trees;similarity tree deployment;similarity trees;similarity-based hierarchical data organization;visual classification;visual data analysis;visual data classification;visual data mining	Algorithm design and analysis;Biomedical image processing;Data visualization;Image classification;Phylogeny	Image Classification.;Multidimensional Projections;Similarity Trees	An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.	Paiva, J.G.;Pedrini, H.;Telles, G.P.;Minghim, R.	Univ. of Sao Paulo, Sao Paulo, Brazil|c|;;;	38017782400;37294758000;38181127500;37371567600
	InfoVis+SciVis	Dec. 2011	A Study on Dual-Scale Data Charts	10.1109/TVCG.2011.160	http://dx.doi.org/10.1109/TVCG.2011.160	2469	2478	6065014	charts;data handling	data resolution;design guidelines;dual scale cartesian coordinate data charts;elementary graphical perception task;superimposed charts	Data visualization;Image color analysis;Quantization;Shape analysis;Terminology	Dual-Scale Charts.;Focus+Context;Quantitative Experiment	We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.	Isenberg, P.;Bezerianos, A.;Dragicevic, P.;Fekete, J.	;;;	37591317800;37413699200;37590932700;37407972900
	InfoVis+SciVis	Dec. 2011	Evaluation of Artery Visualizations for Heart Disease Diagnosis	10.1109/TVCG.2011.192	http://dx.doi.org/10.1109/TVCG.2011.192	2479	2488	6065015	biomechanics;cardiology;computerised tomography;data visualisation;diseases;haemodynamics;medical image processing;patient diagnosis;patient treatment;tree data structures	2D tree diagram representation;ESS;cardiologist;color maps;coronary artery disease;endothelial shear stress;formal quantitative user;heart disease diagnosis;hemodynamics;interactive visualization;patient treatment;task taxonomy;visualization technique	Arteries;Blood flow;Data visualization;Heart;Image color analysis;Three dimensional displays	Quantitative evaluation;biomedical and medical visualization.;qualitative evaluation	Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.	Borkin, M.;Gajos, K.;Peters, A.;Mitsouras, D.;Melchionna, S.;Rybicki, F.;Feldman, C.;Pfister, H.	;;;;;;;	38017334100;38017335100;38348003300;37294083800;37422034400;37294079000;37300850800;37275698100
	InfoVis+SciVis	Dec. 2011	Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback	10.1109/TVCG.2011.196	http://dx.doi.org/10.1109/TVCG.2011.196	2489	2497	6065016	art;building management systems;data visualisation;decision making;energy conservation;feedback;power consumption;power engineering computing;ubiquitous computing	abstract visualizations;ambient visualization;artistic visualization;decision making support;distributed point-of-consumption feedback device;environmental conservation efforts;informative art;pervasive computing technology;residential energy consumption;residential energy use feedback visualization;resource consumption	Art;Data visualization;Feedback;Real time systems;Resource management	Ambient visualization;casual infovis;distributed visualization.;informative art;sustainability	Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.	Rodgers, J.;Bartram, L.	;	37399764800;37353447100
	InfoVis+SciVis	Dec. 2011	Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study	10.1109/TVCG.2011.209	http://dx.doi.org/10.1109/TVCG.2011.209	2498	2507	6065017	data visualisation;geographic information systems;groupware;knowledge acquisition;prototypes;user centred design	HC approach;ISO13407 taxonomy;autoethnography;collaborative engagement;contextual inquiry;data prototype;data sketch;data visualization;data wireframe;digital prototype;exploratory behaviour;geovis application design;geovisualization design;human-centered approach;long-term case study;multiple method investigation;structured task protocol;transient visual artefact	Data visualization;Domain specific languages;Human factors;Taxonomy	Evaluation;context of use;design.;field study;geovisualization;prototypes;requirements;sketching	Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.	Lloyd, D.;Dykes, J.	giCentre, City Univ. London, London, UK|c|;	38030446400;37605079900
	InfoVis+SciVis	Dec. 2011	Visual Thinking In Action: Visualizations As Used On Whiteboards	10.1109/TVCG.2011.251	http://dx.doi.org/10.1109/TVCG.2011.251	2508	2517	6065018	data visualisation;psychology	affinity diagramming;data-driven perspective;information visualization;open coding;task-driven perspective;visual thinking;whiteboards	Data visualization;Encoding;Image color analysis	Visualization;diagrams;observational study.;whiteboards	While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.	Walny, J.;Carpendale, S.;Riche, N.H.;Venolia, G.;Fawcett, P.	Univ. of Calgary, Calgary, AB, Canada|c|;;;;	38016653500;37285000100;37590950700;37312523900;38017515000
	InfoVis+SciVis	Dec. 2011	Composite Density Maps for Multivariate Trajectories	10.1109/TVCG.2011.181	http://dx.doi.org/10.1109/TVCG.2011.181	2518	2527	6065019	cartography;data visualisation;time series	block diagram;composite density maps;maritime use cases;multiple density fields;multivariate time series;multivariate trajectories;visual analysis	Computational modeling;Computer architecture;Data visualization;Image color analysis;Trajectory	Geographical Information Systems;Kernel Density Estimation;Multivariate Data;Trajectories;and Raster Maps.	We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.	Scheepens, R.;Willems, N.;van de Wetering, H.;Andrienko, G.;Andrienko, N.;van Wijk, J.J.	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;	37846960800;37846959300;37294473300;37283047100;37283047700;37267249200
	InfoVis+SciVis	Dec. 2011	Focus+Context Metro Maps	10.1109/TVCG.2011.205	http://dx.doi.org/10.1109/TVCG.2011.205	2528	2535	6065020	cartography;graph theory;mobile handsets;railways	energy terms;focus+context metro maps;graph cuts method;metro map visualization;mobile devices;modern city;octilinear transportation lines;regular station distances;train arrival time	Graphics;Layout;Nonlinear distortion;Optimization	Focus+context visualization;graph labeling;metro map;octilinear layout;optimization.	We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.	Yu-Shuen Wang;Ming-Te Chi	;	37407536000;38019484900
	InfoVis+SciVis	Dec. 2011	Flow Map Layout via Spiral Trees	10.1109/TVCG.2011.202	http://dx.doi.org/10.1109/TVCG.2011.202	2536	2544	6065021	cartography;data visualisation;pattern clustering;trees (mathematics)	Steiner tree;flow map layout;good flow maps;logarithmic spirals;object movement;spiral trees;target clustering;thematic maps	Approximation algorithms;Cartography;Cost function;Steiner trees;Tree data structures	Automated Cartography;Flow maps;Spiral Trees.	Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.	Buchin, K.;Speckmann, B.;Verbeek, K.	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;	37402703700;37591266000;37591265900
	InfoVis+SciVis	Dec. 2011	Exploring Uncertainty in Geodemographics with Interactive Graphics	10.1109/TVCG.2011.197	http://dx.doi.org/10.1109/TVCG.2011.197	2545	2554	6065022	cartography;data visualisation;demography;interactive systems;local government;pattern classification	OAC classifier;UK population classification;dimension-reducing quality;geodemographic classifier;geographical area categorisation;interactive graphics;local government;open geodemographic classifier	Classification;Data visualization;Demographics;Image color analysis;Visualization	Geodemographics;OAC;cartography;classification;uncertainty.	Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.	Slingsby, A.;Dykes, J.;Wood, J.	;;	37590960700;37605079900;37399045100
	InfoVis+SciVis	Dec. 2011	Drawing Road Networks with Focus Regions	10.1109/TVCG.2011.191	http://dx.doi.org/10.1109/TVCG.2011.191	2555	2562	6065023	cartography;convex programming;graph theory;mobile computing;polynomials;quadratic programming;real-time systems;traffic information systems	cartographer;convex quadratic program;edge crossings;fish-eye projection;graph drawing;linear inequalities;map distortion;mapping function;mobile maps user;polynomial time solution;prototype tool;real-time system;road networks;user defined focus region	Cartography;Distortion measurement;Graphics;Image analysis;Optimization;Quadratic programming;Visualization	Cartography;fish-eye view;graph drawing;optimization;quadratic programming.;schematic maps	Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.	Haunert, J.-H.;Sering, L.	Univ. of Wu&#x0308;rzburg, Wu&#x0308;rzburg, Germany|c|;	38017278900;38017279300
	InfoVis+SciVis	Dec. 2011	Local Affine Multidimensional Projection	10.1109/TVCG.2011.220	http://dx.doi.org/10.1109/TVCG.2011.220	2563	2571	6065024	affine transforms;data mining;data visualisation;interactive systems	LAMP technique;computational efficiency;local affine multidimensional projection technique;local transformation;orthogonal mapping theory;visual data mining;visualization-oriented fully interactive application	Data mining;Minimization;Robustness	High Dimensional Data;Multidimensional Projection;Visual Data Mining.	Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.	Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.	Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;	38017343000;37590969400;38017342500;38017346900;37590974800
	InfoVis+SciVis	Dec. 2011	Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data	10.1109/TVCG.2011.166	http://dx.doi.org/10.1109/TVCG.2011.166	2572	2580	6065025	data visualisation;rendering (computer graphics)	angular histogram;attribute curve;data set rendering;frequency-based approach;frequency-based visualization;high dimensional data;linear correlation;multivariate data visualization;overplotting problem;parallel coordinates;visual information seeking mantra	Data visualization;Histograms;Vectors	Angular Histogram;Attribute Curves.;Parallel Coordinates	Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.	Zhao Geng;ZhenMin Peng;Laramee, R.S.;Roberts, J.C.;Walker, R.	Visual Comput. Group, Swansea Univ., Swansea, UK|c|;;;;	38031256500;38024566900;37267247900;37278794800;37596627100
	InfoVis+SciVis	Dec. 2011	DICON: Interactive Visual Analysis of Multidimensional Clusters	10.1109/TVCG.2011.188	http://dx.doi.org/10.1109/TVCG.2011.188	2581	2590	6065026	data analysis;data structures;data visualisation;embedded systems;interactive systems;pattern clustering;statistical distributions	DICON;cluster quality;clutter reduction;complex data;fundamental data analysis technique;high-level statistical information;icon-based cluster visualization;interactive visual analysis;layout algorithm;multidimensional attribute display;multidimensional cluster;statistical information;user interaction	Algorithm design and analysis;Clustering algorithms;Encoding;Image color analysis;Information analysis;Visualization	Clustering;Information Visualization.;Visual Analysis	Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.	Nan Cao;Gotz, D.;Jimeng Sun;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;	37604309600;37601397400;37281417100;37272637300
	InfoVis+SciVis	23-28 Oct. 2011	Visual thinking in discovery and invention: From physics to cognitive social science	10.1109/VAST.2011.6102431	http://dx.doi.org/10.1109/VAST.2011.6102431	xii	xii	6102431	cognition;computer graphics	EMPATHICA;cognitive science;cognitive-affective mapping;scientific discovery;technological invention;visual thinking			Summary form only given. This talk will discuss the role of visual thinking in scientific discovery and technological invention. Visual thinking uses picture-like representations as internal mental models or as external depictions such as diagrams. The first part of the talk will analyze the role of visual thinking in 100 great discoveries and 100 great inventions. The second part will discuss the contribution of visual thinking to developing new theories in the social sciences based on advances in cognitive science. Cognitive-affective mapping is a new technique for visualizing the role of emotion in social cognition. EMPATHICA is a new graphical system for resolving conflicts by increasing empathy using cognitive-affective maps.	Thagard, P.	Univ. of Waterloo, Waterloo, ON, Canada|c|	38016995900
	InfoVis+SciVis	23-28 Oct. 2011	Visual analytic roadblocks for novice investigators	10.1109/VAST.2011.6102435	http://dx.doi.org/10.1109/VAST.2011.6102435	3	11	6102435	data analysis;data visualisation	human-visualization interaction cognitive process;investigative analysis scenario;novice investigators;open-coding method;pair analytics;visual analytic roadblocks	Analytical models;Calendars;Cognition;Context;Humans;Visual analytics	Visual analytics;cognitive model;framework;investigative analysis;qualitative experiment;roadblock	We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users' perspectives is still limited. Therefore, we attempted to identify such visual analytic roadblocks for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.	Bum chul Kwon;Fisher, Brian;Ji Soo Yi	Purdue Univ., West Lafayette, IN, USA|c|;;	38235486800;37267458000;38238292000
	InfoVis+SciVis	23-28 Oct. 2011	Perception-based visual quality measures	10.1109/VAST.2011.6102437	http://dx.doi.org/10.1109/VAST.2011.6102437	13	20	6102437	data visualisation	high-dimensional data sets;information-bearing projections;multidimensional scaling;perception-based visual quality measures;perceptual embedding;psychophysics study;ranking function;visual exploration task	Atmospheric measurements;Correlation;Data visualization;Humans;Particle measurements;Training;Visualization		In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.	Albuquerque, G.;Eisemann, M.;Magnor, M.	Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;	37603943800;37546817000;37273816400
	InfoVis+SciVis	23-28 Oct. 2011	Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study	10.1109/VAST.2011.6102438	http://dx.doi.org/10.1109/VAST.2011.6102438	21	30	6102438	data analysis;data visualisation	Mercyhurst College;intelligence analysis process characterization;intelligence program;longitudinal field study;task analysis;visual analytics design	Analytical models;Artificial intelligence;Collaboration;Electronic publishing;Information services;Internet;Visual analytics	Intelligence analysis;qualitatvie user study	While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community's understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis.	Youn-ah Kang;Stasko, J.	Georgia Inst. of Technol., Atlanta, GA, USA|c|;	;37267736900
	InfoVis+SciVis	23-28 Oct. 2011	Interactive visual comparison of multiple trees	10.1109/VAST.2011.6102439	http://dx.doi.org/10.1109/VAST.2011.6102439	31	40	6102439	biology computing;data visualisation;evolution (biological);microorganisms	16S ribosomal RNA;bacterial ancestry;enzymes;evolutionary biology domain;hierarchy visual analysis;interactive visual comparison;multiple trees;phylogenetic trees;protein sequences	Data visualization;Image color analysis;Organisms;Phylogeny;Vegetation;Visualization		Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit.	Bremm, S.;von Landesberger, T.;Hess, M.;Schreck, T.;Weil, P.;Hamacherk, K.	Interactive-Graphics Syst., Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;;;;	37586274500;37586276100;38236436100;37282557600;38242125000;37844908000
	InfoVis+SciVis	23-28 Oct. 2011	Network-based visual analysis of tabular data	10.1109/VAST.2011.6102440	http://dx.doi.org/10.1109/VAST.2011.6102440	41	50	6102440	data analysis;data visualisation	Ploceus system;direct manipulation interface;multivariate data;network semantics;network-based visual analysis;relational algebraic framework;tabular data analysis;visual exploration	Aggregates;Cities and towns;Data visualization;Organizations;Relational databases;Semantics;Visualization		Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience.	Zhicheng Liu;Navathe, S.B.;Stasko, J.T.	Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	37592993600;37284924800;37267736900
	InfoVis+SciVis	23-28 Oct. 2011	Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks	10.1109/VAST.2011.6102441	http://dx.doi.org/10.1109/VAST.2011.6102441	51	60	6102441	data visualisation;graph theory;graphical user interfaces;social networking (online)	Orion interface;academic collaboration;declarative workflow language;distributed software development;drag-and-drop operations;graph manipulation;multidimensional heterogeneous network modelling;multidimensional heterogeneous network transformation;multidimensional heterogeneous network visualization;network analytics;online health communities;relational operators;social networks	Analytical models;Communities;Data models;Data visualization;Joining processes;Social network services	data management;data transformation;end-user programming;graphs;social network analysis;visualization	The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.	Heer, J.;Perer, A.	Stanford Univ., Stanford, CA, USA|c|;	37550791300;37294938400
	InfoVis+SciVis	23-28 Oct. 2011	G-PARE: A visual analytic tool for comparative analysis of uncertain graphs	10.1109/VAST.2011.6102442	http://dx.doi.org/10.1109/VAST.2011.6102442	61	70	6102442	data visualisation;graph theory;learning (artificial intelligence)	G-PARE;adaptive exploration environment;comparative analysis;machine learning algorithms;uncertain graphs;visual analytic tool	Data models;Data visualization;Machine learning algorithms;Prediction algorithms;Predictive models;Uncertainty;Visualization	Comparative Analysis;Model Comparison;Uncertain Graphs;Visualizing Uncertainty	There are a growing number of machine learning algorithms which operate on graphs. Example applications for these algorithms include predicting which customers will recommend products to their friends in a viral marketing campaign using a customer network, predicting the topics of publications in a citation network, or predicting the political affiliations of people in a social network. It is important for an analyst to have tools to help compare the output of these machine learning algorithms. In this work, we present G-PARE, a visual analytic tool for comparing two uncertain graphs, where each uncertain graph is produced by a machine learning algorithm which outputs probabilities over node labels. G-PARE provides several different views which allow users to obtain a global overview of the algorithms output, as well as focused views that show subsets of nodes of interest. By providing an adaptive exploration environment, G-PARE guides the users to places in the graph where two algorithms predictions agree and places where they disagree. This enables the user to follow cascades of misclassifications by comparing the algorithms outcome with the ground truth. After describing the features of G-PARE, we illustrate its utility through several use cases based on networks from different domains.	Sharara, H.;Sopan, A.;Namata, G.;Getoor, L.;Singh, L.	Comput. Sci. Dept., Univ. of Maryland, College Park, MD, USA|c|;;;;	37714206000;37546693400;38072149500;37829614900;37691176100
	InfoVis+SciVis	23-28 Oct. 2011	Visual social network analytics for relationship discovery in the enterprise	10.1109/VAST.2011.6102443	http://dx.doi.org/10.1109/VAST.2011.6102443	71	79	6102443	data mining;data visualisation;graph theory;social networking (online)	SaNDVis;enterprise setting;expertise location;people-centric tasks;relationship discovery tasks;social graph;social media;team building;team coordination;visual social network analytics	Blogs;Databases;Information services;Internet;Social network services;Tagging;Visual analytics	information discovery;social data mining;social networks;social visualization	As people continue to author and share increasing amounts of information in social media, the opportunity to leverage such information for relationship discovery tasks increases. In this paper, we describe a set of systems that mine, aggregate, and infer a social graph from social media inside an enterprise, resulting in over 73 million relationships between 450,000 people. We then describe SaNDVis, a novel visual analytics tool that supports people-centric tasks like expertise location, team building, and team coordination in the enterprise. We also provide details of a 12-month-long, large-scale deployment to almost 1,800 users from which we extract dominant use cases from log and interview data. By integrating social position, evidence, and facets into SaNDVis, we demonstrate how users can use a visual analytics tool to reflect on existing relationships as well as build new relationships in an enterprise setting.	Perer, A.;Guy, I.;Uziel, E.;Ronen, I.;Jacovi, M.	IBM Res., Yorktown Heights, NY, USA|c|;;;;	37294938400;37826398500;38233626100;38232518800;37990793800
	InfoVis+SciVis	23-28 Oct. 2011	How locus of control influences compatibility with visualization style	10.1109/VAST.2011.6102445	http://dx.doi.org/10.1109/VAST.2011.6102445	81	90	6102445	data visualisation;user interfaces	cognitive psychology;containment metaphor;control locus;indentation metaphor;individual personality difference;personality trait;user needs;user preference;user speed;visual analytics design;visualization design;visualization style compatibility;visualization system	Correlation;Data visualization;Encoding;Layout;Particle measurements;Visual analytics		Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as locus of control, which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specifically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual user's needs.	Ziemkiewicz, C.;Crouser, R.J.;Yauilla, A.R.;Su, S.L.;Ribarsky, W.;Chang, R.	Brown Univ., Providence, RI, USA|c|;;;;;	37548028800;38229914800;38233580400;38240721700;37300425000;37592409400
	InfoVis+SciVis	23-28 Oct. 2011	Obvious: A meta-toolkit to encapsulate information visualization toolkits &#x2014; One toolkit to bind them all	10.1109/VAST.2011.6102446	http://dx.doi.org/10.1109/VAST.2011.6102446	91	100	6102446	Java;data visualisation;learning (artificial intelligence)	Improvise;InfoVis Toolkit;JUNG;Java language;Obvious;Prefuse;Rapid-Miner;Weka;coevolution process;data management libraries;data models;information visualization toolkit encapsulation;machine-learning toolkits;meta-toolkit;visual analytics application development	Data models;Data visualization;Java;Libraries;Observers;Visualization		This article describes Obvious: a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics.	Fekete, J.;Hemery, P.;Baudel, T.;Wood, J.	INRIA, Sophia Antipolis, France|c|;;;	37407972900;38072289200;38233516200;37399045100
	InfoVis+SciVis	23-28 Oct. 2011	Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics	10.1109/VAST.2011.6102447	http://dx.doi.org/10.1109/VAST.2011.6102447	101	110	6102447	data analysis;data visualisation;user interfaces	asynchronous collaborative visual analytics;user interaction technique;user study;visualization technique	Animation;Collaboration;Correlation;History;Semantics;Visual analytics	Visual analytics;asynchronous collaboration;insight;multidimensional visualization	Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness.	Yang Chen;Alsakran, J.;Barlowe, S.;Jing Yang;Ye Zhao	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	37600587200;37846905500;37591128900;37292632600;37277701200
	InfoVis+SciVis	23-28 Oct. 2011	Guiding feature subset selection with an interactive visualization	10.1109/VAST.2011.6102448	http://dx.doi.org/10.1109/VAST.2011.6102448	111	120	6102448	data analysis;data visualisation;statistical analysis	SmartStripes;data analysis;entity subset selection;feature correlation;feature subset selection algorithms;filter techniques;high-dimensional data table visualization;interactive visualization;statistical aggregation;statistical ranking measures	Algorithm design and analysis;Atmospheric measurements;Correlation;Data visualization;Particle measurements;Sorting;Visualization		We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.	May, T.;Bannach, A.;Davey, J.;Ruppert, T.;Kohlhammer, J.	Fraunhofer Inst. for Comput. Graphics Res., Darmstadt, Germany|c|;;;;	37603783600;38233628300;37603822500;37593423500;37449689200
	InfoVis+SciVis	23-28 Oct. 2011	Observation-level interaction with statistical models for visual analytics	10.1109/VAST.2011.6102449	http://dx.doi.org/10.1109/VAST.2011.6102449	121	130	6102449	data analysis;data visualisation;principal component analysis;probability	data interactive visual exploration;exploratory interaction;expressive interaction;generative topographic mapping;multidimensional scaling;observation-level interaction;parameter adjustments;probabilistic principal component analysis;sensemaking process;statistical models;visual analytics	Analytical models;Data models;Data visualization;Layout;Principal component analysis;Visual analytics	observation-level interaction;statistical models;visual analytics	In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus observation) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.	Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;	37681759500;38238038000;38232394400;38241765600;38236156800;37419565900
	InfoVis+SciVis	23-28 Oct. 2011	Pointwise local pattern exploration for sensitivity analysis	10.1109/VAST.2011.6102450	http://dx.doi.org/10.1109/VAST.2011.6102450	131	140	6102450	data analysis;data visualisation	anomalous local pattern identification;attribute space;color mapping;jittering;local analysis;multivariate datasets;multivariate phenomena analysis;multivariate visualization techniques;pointwise local pattern exploration system;visual analytic tools;visual sensitivity analysis method	Analytical models;Data mining;Image color analysis;Sensitivity analysis;Vectors;Visualization	Knowledge Discovery;local pattern visualization;sensitivity analysis	Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions.	Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.;Ruiz, C.	Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;;	37668783300;37268441700;37279217900;37413757400
	InfoVis+SciVis	23-28 Oct. 2011	Interactive decision making using dissimilarity to visually represented prototypes	10.1109/VAST.2011.6102451	http://dx.doi.org/10.1109/VAST.2011.6102451	141	149	6102451	data analysis;data visualisation;decision making;forensic science;learning (artificial intelligence);psychology;risk management	dissimilarity;forensic psychiatry;human prototypical reasoning;interactive decision making;interactive visualizations;machine learning approach;multidimensional heterogeneous data;prototype visual representation;risk assessment case;similarity-based classification;similarity-to-prototype approach;visual analytics context	Data mining;Data visualization;Humans;Image color analysis;Prototypes;Visual analytics	dissimilarity based classification;dissimilarity based visualization;interactive visualization;prototypes;visual analytics	To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.	Migut, M.A.;van Gemert, J.C.;Worring, M.	Intell. Syst. Lab. Amsterdam, Univ. of Amsterdam, Amsterdam, Netherlands|c|;;	37589528300;37340470100;37267865600
	InfoVis+SciVis	23-28 Oct. 2011	BaobabView: Interactive construction and analysis of decision trees	10.1109/VAST.2011.6102453	http://dx.doi.org/10.1109/VAST.2011.6102453	151	160	6102453	data visualisation;decision trees;interactive systems	BaobabView;algorithmic support;domain expert;interactive construction;scalable decision tree visualization	Accuracy;Algorithm design and analysis;Data visualization;Decision trees;Histograms;Impurities;Training		We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data.	van den Elzen, S.;van Wijk, J.J.	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;	38233594700;37267249200
	InfoVis+SciVis	23-28 Oct. 2011	From movement tracks through events to places: Extracting and characterizing significant places from mobility data	10.1109/VAST.2011.6102454	http://dx.doi.org/10.1109/VAST.2011.6102454	161	170	6102454	data analysis;data visualisation;pattern clustering	data aggregation analysis;event clustering;event extraction;event spatio-temporal aggregation;mobility data;movement data analysis;movement tracks;place characterization;place extraction;trajectory spatio-temporal aggregation;visual analytics procedure	Aggregates;Clustering algorithms;Context;Data mining;Time series analysis;Trajectory;Visualization	movement;spatial clustering;spatial events;spatio-temporal clustering;spatio-temporal data;trajectories	We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales.	Andrienko, G.;Andrienko, N.;Hurter, C.;Rinzivillo, S.;Wrobel, S.	Fraunhofer Inst., Univ. of Bonn, Bonn, Germany|c|;;;;	37283047100;37283047700;38017336200;37670571400;37668062300
	InfoVis+SciVis	23-28 Oct. 2011	Visual analysis of route diversity	10.1109/VAST.2011.6102455	http://dx.doi.org/10.1109/VAST.2011.6102455	171	180	6102455	Global Positioning System;data analysis;data visualisation;statistics;traffic engineering computing	GPS navigation systems;Microsoft T-drive;high dimensional attributes;route diversity;route suggestion;source-destination pairs;statistics;taxi drivers;trajectory visualization method;transportation management;visual analysis	Cities and towns;Data visualization;Layout;Roads;Trajectory;Vehicles;Visualization		Route suggestion is an important feature of GPS navigation systems. Recently, Microsoft T-drive has been enabled to suggest routes chosen by experienced taxi drivers for given source/destination pairs in given time periods, which often take less time than the routes calculated according to distance. However, in real environments, taxi drivers may use different routes to reach the same destination, which we call route diversity. In this paper we first propose a trajectory visualization method that examines the regions where the diversity exists and then develop several novel visualization techniques to display the high dimensional attributes and statistics associated with different routes to help users analyze diversity patterns. Our techniques have been applied to the real trajectory data of thousands of taxis and some interesting findings about route diversity have been obtained. We further demonstrate that our system can be used not only to suggest better routes for drivers but also to analyze traffic bottlenecks for transportation management.	He Liu;Lu Lu;Huamin Qu;Ni, L.M.	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;	;38240091500;37272637300;38236797100
	InfoVis+SciVis	23-28 Oct. 2011	SensePlace2: GeoTwitter analytics support for situational awareness	10.1109/VAST.2011.6102456	http://dx.doi.org/10.1109/VAST.2011.6102456	181	190	6102456	data analysis;data visualisation;decision making;emergency services;geography;graphical user interfaces;social networking (online)	GeoTwitter analytics support;SensePlace2;crisis management;decision making domains;geographically-grounded situational awareness;geovisual analytics approach;overview-detail methods;place-time-theme indexing schemes;scenario-based design methods;social media;visual interface methods	Crisis management;Decision making;Media;Organizations;Twitter;Visual analytics	crisis management;geovisualization;scenario-based design;situational awareness;social media analytics;spatio-temporal analysis;text analytics	Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.	MacEachren, A.M.;Jaiswal, A.;Robinson, A.C.;Pezanowski, S.;Savelyev, A.;Mitra, P.;Zhang, X.;Blanford, J.	GeoVISTA Center, Pennsylvania State Univ., University Park, PA, USA|c|;;;;;;;	37374699000;37966902300;37829187900;38233564100;38237834200;37286730000;38239991000;38242393000
	InfoVis+SciVis	23-28 Oct. 2011	Visual analytics decision support environment for epidemic modeling and response evaluation	10.1109/VAST.2011.6102457	http://dx.doi.org/10.1109/VAST.2011.6102457	191	200	6102457	data analysis;data visualisation;decision support systems;diseases;epidemics;medical computing	disease mitigation strategies;epidemic modeling;infection rates;infectious diseases modelling;interactive decision support tools;linked decision history visualization;mortality rates;navigation tool;response evaluation;visual analytics decision support environment	Adaptation models;Analytical models;Diseases;History;Spatiotemporal phenomena;Visual analytics		In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time.	Afzal, S.;Maciejewski, R.;Ebert, D.S.	Visualization & Analytics Center, Purdue Univ., West Lafayette, IN, USA|c|;;	38482841300;37396008400;37282598900
	InfoVis+SciVis	23-28 Oct. 2011	SAVE: Sensor anomaly visualization engine	10.1109/VAST.2011.6102458	http://dx.doi.org/10.1109/VAST.2011.6102458	201	210	6102458	computerised instrumentation;data analysis;data visualisation;fault diagnosis;security of data;sensors	anomaly detection analytics;correlation graph;dynamic projection view;sensor anomaly visualization engine;sensor data dynamics;sensor data facets;sensor network failure;sensor network failure scenario;sensor network faults;temporal expansion model;visualization analytics	Correlation;Data visualization;Network topology;Routing;Time series analysis;Topology;Wireless sensor networks		Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.	Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su	IBM Res., Beijing, China|c|;;;;;	37287511900;37543450800;37398853200;38240137400;37298955400;37588016000
	InfoVis+SciVis	23-28 Oct. 2011	A visual navigation system for querying neural stem cell imaging data	10.1109/VAST.2011.6102459	http://dx.doi.org/10.1109/VAST.2011.6102459	211	220	6102459	biology computing;cellular biophysics;data analysis;data visualisation;database management systems;feature extraction;image segmentation;neurophysiology;query processing	cellular biology;database management system;geometric feature extraction;human neural stem cell imaging data querying;image processing system;neurobiologist collaborators;statistical feature extraction;time-lapse imaging microscopes;visual analytic system;visual navigation system;visual query system	Cells (biology);Data visualization;Image segmentation;Navigation;Semantics;Shape;Visualization	Neuroscience;cell imaging;data management;exploration;navigation;query processing;stem cell segmentation;tracking;visual analytics	Cellular biology deals with studying the behavior of cells. Current time-lapse imaging microscopes help us capture the progress of experiments at intervals that allow for understanding of the dynamic and kinematic behavior of the cells. On the other hand, these devices generate such massive amounts of data (250GB of data per experiment) that manual sieving of data to identify interesting patterns becomes virtually impossible. In this paper we propose an end-to-end system to analyze time-lapse images of the cultures of human neural stem cells (hNSC), that includes an image processing system to analyze the images to extract all the relevant geometric and statistical features within and between images, a database management system to manage and handle queries on the data, a visual analytic system to navigate through the data, and a visual query system to explore different relationships and correlations between the parameters. In each stage of the pipeline we make novel algorithmic and conceptual contributions, and the entire system design is motivated by many different yet unanswered exploratory questions pursued by our neurobiologist collaborators. With a few examples we show how such abstract biological queries can be analyzed and answered by our system.	Kulkarni, I.;Mistry, S.Y.;Cummings, B.;Gopi, M.	Dept. of Comput. Sci., Univ. of California, Irvine, CA, USA|c|;;;	38019808500;38232233400;37374779700;37271691400
	InfoVis+SciVis	23-28 Oct. 2011	A visual analytics process for maritime resource allocation and risk assessment	10.1109/VAST.2011.6102460	http://dx.doi.org/10.1109/VAST.2011.6102460	221	230	6102460	data analysis;data visualisation;military computing;resource allocation;risk management	US Coast Guard Atlantic Area Command;US Coast Guard Ninth District Command;United States;maritime environment;maritime resource allocation;maritime risk assessment;search and rescue operation;visual analytics process	Calendars;Data visualization;Decision making;Lakes;Risk management;Time factors;Visual analytics	Coast Guard;Visual analytics;risk assessment	In this paper, we present our collaborative work with the U.S. Coast Guard's Ninth District and Atlantic Area Commands where we developed a visual analytics system to analyze historic response operations and assess the potential risks in the maritime environment associated with the hypothetical allocation of Coast Guard resources. The system includes linked views and interactive displays that enable the analysis of trends, patterns and anomalies among the U.S. Coast Guard search and rescue (SAR) operations and their associated sorties. Our system allows users to determine the potential change in risks associated with closing certain stations in terms of response time, potential lives and property lost and provides optimal direction as to the nearest available station. We provide maritime risk assessment tools that allow analysts to explore Coast Guard coverage for SAR operations and identify regions of high risk. The system also enables a thorough assessment of all SAR operations conducted by each Coast Guard station in the Great Lakes region. Our system demonstrates the effectiveness of visual analytics in analyzing risk within the maritime domain and is currently being used by analysts at the Coast Guard Atlantic Area.	Malik, A.;Maciejewski, R.;Maule, B.;Ebert, D.S.	Purdue Univ. Visualization & Analytics Center (PURVAC), IN, USA|c|;;;	37397435000;37396008400;38233566600;37282598900
	InfoVis+SciVis	23-28 Oct. 2011	ParallelTopics: A probabilistic approach to exploring document collections	10.1109/VAST.2011.6102461	http://dx.doi.org/10.1109/VAST.2011.6102461	231	240	6102461	data analysis;data visualisation;probability;text analysis	ParallelTopics system;document collection;interactive visualization;latent Dirichlet allocation;multitopic document;parallel coordinate metaphor;probabilistic approach;single-topic document;text corpora analysis;visual analytics system	Analytical models;Entropy;Probabilistic logic;Semantics;Text analysis;Text processing;Visualization		Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.	Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.	UNC Charlotte, Charlotte, NC, USA|c|;;;	37606064200;38241251900;37592409400;37300425000
	InfoVis+SciVis	23-28 Oct. 2011	Analysis of large digital collections with interactive visualization	10.1109/VAST.2011.6102462	http://dx.doi.org/10.1109/VAST.2011.6102462	241	250	6102462	data analysis;data visualisation;decision making;information retrieval systems;records management	collection contents;data gathering;decision-making;exploratory analysis;file format composition;interactive visual analytics application;interactive visualization;large digital collection access;large digital collection analysis;long-term preservation;organizational structure	Analytical models;Data mining;Data visualization;Image color analysis;Layout;Rendering (computer graphics);Visualization	Digital collections;archival analysis;data curation;visual analytics	To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections' contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions.	Weijia Xu;Esteva, M.;Suyog Dutt Jain;Varun Jain	Univ. of Texas at Austin, Austin, TX, USA|c|;;;	37833781800;38031284100;38236526000;38238537900
	InfoVis+SciVis	23-28 Oct. 2011	A two-stage framework for designing visual analytics system in organizational environments	10.1109/VAST.2011.6102463	http://dx.doi.org/10.1109/VAST.2011.6102463	251	260	6102463	data analysis;data visualisation;decision making;organisational aspects	Entity Workspace;PatViz;analytical workflow;domain analytical process;individual analytical activities;organizational environments;organizational user decision-making;reasoning process;two-stage framework;visual analytics system design	Context;Human computer interaction;Measurement;Organizations;System analysis and design;Visual analytics	Design Theory;HCI;Visual Analytics	A perennially interesting research topic in the field of visual analytics is how to effectively develop systems that support organizational users' decision-making and reasoning processes. The problem is, however, most domain analytical practices generally vary from organization to organization. This leads to diverse designs of visual analytics systems in incorporating domain analytical processes, making it difficult to generalize the success from one domain to another. Exacerbating this problem is the dearth of general models of analytical workflows available to enable such timely and effective designs. To alleviate these problems, we present a two-stage framework for informing the design of a visual analytics system. This design framework builds upon and extends current practices pertaining to analytical workflow and focuses, in particular, on incorporating both general domain analysis processes as well as individual's analytical activities. We illustrate both stages and their design components through examples, and hope this framework will be useful for designing future visual analytics systems. We validate the soundness of our framework with two visual analytics systems, namely Entity Workspace [8] and PatViz [37].	Xiaoyu Wang;Wenwen Dou;Butkiewicz, T.;Bier, E.A.;Ribarsky, W.	UNC Charlotte, Charlotte, NC, USA|c|;;;;	37601069300;37606064200;37591215700;37282252000;37300425000
	InfoVis+SciVis	23-28 Oct. 2011	Using random projections to identify class-separating variables in high-dimensional spaces	10.1109/VAST.2011.6102465	http://dx.doi.org/10.1109/VAST.2011.6102465	263	264	6102465	data visualisation;statistical analysis	analytic visualization platform;class-separating variable ientification;class-separating views;high-dimensional spaces;noteworthy configuration recognition;projection pursuit;random projections	Cancer;Context modeling;Data mining;Data models;Electronic mail;Handwriting recognition;Visual analytics		Projection Pursuit has been an effective method for finding interesting low-dimensional (usually 2D) projections in multidimensional spaces. Unfortunately, projection pursuit is not scalable to high-dimensional spaces. We introduce a novel method for approximating the results of projection pursuit to find class-separating views by using random projections. We build an analytic visualization platform based on this algorithm that is scalable to extremely large problems. Then, we discuss its extension to the recognition of other noteworthy configurations in high-dimensional spaces.	Anand, A.;Wilkinson, L.;Tuan Nhon Dang	Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;	37548165700;37560536200;37606167900
	InfoVis+SciVis	23-28 Oct. 2011	Evaluation of large display interaction using smart phones	10.1109/VAST.2011.6102466	http://dx.doi.org/10.1109/VAST.2011.6102466	265	266	6102466	computer displays;data analysis;data visualisation;graphical user interfaces;smart phones	analytical reasoning;collaborative data analysis scenarios;computer mice;keyboards;large display interaction evaluation;metaphors;smart phone based techniques;strength-weakness identification;traditional input devices;user performance;user satisfaction;visual analytics;visual interactive interfaces	Computers;Keyboards;Mice;Performance evaluation;Smart phones;Stacking;Three dimensional displays		Visual analytics, the science of analytical reasoning facilitated by visual interactive interfaces [5], puts high demands on the applications visualization as well as interaction capabilities. Due to their size large high-resolution screens have become popular display devices, especially when used in collaborative data analysis scenarios. However, traditional interaction methods based on combinations of computer mice and keyboards often do not scale to the number of users or the size of the display. Modern smart phones featuring multi-modal input/output and considerable memory offer a way to address these issues. In the last couple of years they have become common everyday life gadgets. In this paper we conduct an extensive user study comparing the experience of test candidates when using traditional input devices and metaphors with the one when using new smart phone based techniques, like multi-modal drag and tilt. Candidates were asked to complete various interaction tasks relevant for most applications on a large, monitor-based, high-resolution tiled wall system. Our study evaluates both user performance and satisfaction, identifying strengths and weaknesses of the researched interaction methods in specific tasks. Results reveal good performance of users in certain tasks when using the new interaction techniques. Even first-time users were able to complete a task faster with the smart phone than with traditional devices.	Bauer, J.;Thelen, S.;Ebert, A.	Comput. Graphics & HCI Lab., Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;	38238582800;37646534700;37282550400
	InfoVis+SciVis	23-28 Oct. 2011	Query-based coordinated multiple views with Feature Similarity Space for visual analysis of MRI repositories	10.1109/VAST.2011.6102467	http://dx.doi.org/10.1109/VAST.2011.6102467	267	268	6102467	biomedical MRI;data visualisation;pattern classification;query processing;user interfaces	CMV system;MRI repository;feature similarity space;feature-rich archive;feature-rich dataset;magnetic resonance imaging;multidimensional scaling;neuroanatomical similarity;query-based coordinated multiple views;query-based user interface;supervised classification method;visual analysis	Feature extraction;Frequency selective surfaces;Image color analysis;Magnetic resonance imaging;Neuroimaging;Visualization	Coordinated multiple views;data mining;query-based visualization	It is a laborious process to quantify relationship patterns within a feature-rich archive. For example, understanding the degree of neuroanatomical similarity between the scanned subjects of a Magnetic Resonance Imaging (MRI) repository is a nontrivial task. In this work we present a Coordinated Multiple View (CMV) system for visually analyzing collections of feature-rich datasets. A query-based user interface operates on a feature-respective data scheme, and is geared towards domain experts that are non-specialists in informatics and analytics. We employ multi-dimensional scaling (MDS) to project feature surface representations into three-dimensions, where proximity in location is proportional to the feature similarity. Through query feedback and environment navigation, the user groups clusters that exhibit probable trends across feature and attribute. The system provides supervised classification methods for determining attribute classes within the user selected groups. Finally, using visual or analytical feature-wise exploration the user determines intra-group feature commonality.	Bowman, I.;Joshi, S.H.;Van Horn, J.D.	Lab. of Neuro Imaging, Univ. of California Los Angeles, Los Angeles, CA, USA|c|;;	37603001800;37288595800;38266955400
	InfoVis+SciVis	23-28 Oct. 2011	Reasonable abstractions: Semantics for dynamic data visualization	10.1109/VAST.2011.6102468	http://dx.doi.org/10.1109/VAST.2011.6102468	269	270	6102468	data analysis;data visualisation	Chi model;E-FRP;Stencil system;compilation techniques;complex operators;data flow execution;data parallelism;data state;deterministic semantics;dynamic data analysis chain;dynamic data visualization semantics;execution semantics;mixing task;reasonable abstractions;resource bounded semantics;task-based parallelism;visualization data-state model;visualization programing models	Data models;Data visualization;Dynamic scheduling;Engines;Programming;Rendering (computer graphics);Semantics	Dynamic data;Semantics	Chi showed how to treat visualization programing models abstractly. This provided a firm theoretical basis for the data-state model of visualization. However, Chi's models did not look deeper into fine-grained program properties, such as execution semantics. We present conditionally deterministic and resource bounded semantics for the data flow model of visualization based on E-FRP. These semantics are used in the Stencil system to move between data state and data flow execution, build task-based parallelism, and build complex analysis chains for dynamic data. This initial work also shows promise for other complex operators, compilation techniques to enable efficient use of time and space, and mixing task and data parallelism.	Cottam, J.A.		37546825800
	InfoVis+SciVis	23-28 Oct. 2011	Exploring agent-based simulations using temporal graphs	10.1109/VAST.2011.6102469	http://dx.doi.org/10.1109/VAST.2011.6102469	271	272	6102469	data visualisation;discrete event simulation;graph theory;politics;social sciences computing	Thailand;agent-based simulations;behavioral sciences;data visualization;discrete simulation states;graph structures;interactive analysis;large-scale social science simulation;political power;social sciences;temporal graphs	Algorithm design and analysis;Analytical models;Data models;Data visualization;Electronic mail;Real time systems;Visual analytics		Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand.	Crouser, R.J.;Freeman, J.G.;Chang, R.	Tufts Univ., Medford, MA, USA|c|;;	38229914800;38239232000;38236988200
	InfoVis+SciVis	23-28 Oct. 2011	Visual analytical approaches to evaluating uncertainty and bias in crowd sourced crisis information	10.1109/VAST.2011.6102470	http://dx.doi.org/10.1109/VAST.2011.6102470	273	274	6102470	data analysis;data visualisation;emergency services	Libya;bias evaluation;crisis events;crowdsourced crisis information;humanitarian community;interactive software prototype;intrinsic characteristics;spatial attributes;temporal attributes;uncertainty evaluation;visual analytical approach	Data visualization;Information science;Prototypes;Software;Uncertainty;User-generated content;Visualization		Concerns about verification mean the humanitarian community are reluctant to use information collected during crisis events, even though such information could potentially enhance the response effort. Consequently, a program of research is presented that aims to evaluate the degree to which uncertainty and bias are found in public collections of incident reports gathered during crisis events. These datasets exemplify a class whose members have spatial and temporal attributes, are gathered from heterogeneous sources, and do not have readily available attribution information. An interactive software prototype, and existing software, are applied to a dataset related to the current armed conflict in Libya to identify `intrinsic' characteristics against which uncertainty and bias can be evaluated. Requirements on the prototype are identified, which in time will be expanded into full research objectives.	Dillingham, I.;Dykes, J.;Wood, J.	giCentre, City Univ. London, London, UK|c|;;	38233564700;37605079900;37399045100
	InfoVis+SciVis	23-28 Oct. 2011	TreeVersity: Comparing tree structures by topology and node&#39;s attributes differences	10.1109/VAST.2011.6102471	http://dx.doi.org/10.1109/VAST.2011.6102471	275	276	6102471	pattern classification;trees (mathematics)	LifeFlow;TreeVersity;data classification;hierarchy;node attributes differences;structural changes;topology attributes differences;traffic agencies;tree structures comparison	Computer science;Data visualization;Educational institutions;Image color analysis;Topology;Vegetation;Visualization		It is common to classify data in hierarchies, they provide a comprehensible way of understanding big amounts of data. From budgets to organizational charts or even the stock market, trees are everywhere and people find them easy to use. However when analysts need to compare two versions of the same tree structure, or two related taxonomies, the task is not so easy. Much work has been done on this topic, but almost all of it has been restricted to either compare the trees by topology, or by the node attribute values. With this project we are proposing TreeVersity, a framework for comparing tree structures, both by structural changes and by differences in the node attributes. This paper is based on our previous work on comparing traffic agencies using LifeFlow [1, 2] and on a first prototype of TreeVersity.	Gomez, J.A.G.;Buck-Coleman, A.;Plaisant, C.;Shneiderman, B.	HCIL & Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;;;	38237955600;38233542700;37283026800;37283016400
	InfoVis+SciVis	23-28 Oct. 2011	Visual sentiment analysis on twitter data streams	10.1109/VAST.2011.6102472	http://dx.doi.org/10.1109/VAST.2011.6102472	277	278	6102472	cartography;data analysis;data visualisation;social networking (online)	Twitter data streams;high density geo maps;pixel cell-based sentiment calendars;stream analysis;text-based Web posts;time-based visual sentiment analysis techniques;topic-based sentiment analysis	Calendars;Data mining;Data visualization;Motion pictures;Twitter;Visual analytics	Sentiment Analysis;Topic Extraction;Twitter Analysis;Visual Opinion Analysis	Twitter currently receives about 190 million tweets (small text-based Web posts) a day, in which people share their comments regarding a wide range of topics. A large number of tweets include opinions about products and services. However, with Twitter being a relatively new phenomenon, these tweets are underutilized as a source for evaluating customer sentiment. To explore high-volume twitter data, we introduce three novel time-based visual sentiment analysis techniques: (1) topic-based sentiment analysis that extracts, maps, and measures customer opinions; (2) stream analysis that identifies interesting tweets based on their density, negativity, and influence characteristics; and (3) pixel cell-based sentiment calendars and high density geo maps that visualize large volumes of data in a single view. We applied these techniques to a variety of twitter data, (e.g., movies, amusement parks, and hotels) to show their distribution and patterns, and to identify influential opinions.	Ming Hao;Rohrdantz, C.;Janetzko, H.;Dayal, U.;Keim, D.A.;Haug, L.;Mei-Chun Hsu	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;;	37274264300;37601356700;37594026300;37275646700;37283138700;37681663300;38237585200
	InfoVis+SciVis	23-28 Oct. 2011	Analysts aren&#39;t machines: Inferring frustration through visualization interaction	10.1109/VAST.2011.6102473	http://dx.doi.org/10.1109/VAST.2011.6102473	279	280	6102473	data analysis;data visualisation;graphical user interfaces;hidden Markov models;learning (artificial intelligence);pattern classification	action-level visualization interaction logs;analyst action;analyst reasoning;classifier;hidden Markov models;interaction sequences;machine learning evaluation methods;user emotion transitions;user frustration;visual analytics;visual interface;visualization interaction	Accuracy;Data visualization;Face;Hidden Markov models;Humans;Predictive models;Visual analytics		Recent work in visual analytics has explored the extent to which information regarding analyst action and reasoning can be inferred from interaction. However, these methods typically rely on humans instead of automatic extraction techniques. Furthermore, there is little discussion regarding the role of user frustration when interacting with a visual interface. We demonstrate that automatic extraction of user frustration is possible given action-level visualization interaction logs. An experiment is described which collects data that accurately reflects user emotion transitions and corresponding interaction sequences. This data is then used in building HiddenMarkov Models (HMMs) which statistically connect interaction events with frustration. The capabilities of HMMs in predicting user frustration are tested using standard machine learning evaluation methods. The resulting classifier serves as a suitable predictor of user frustration that performs similarly across different users and datasets.	Harrison, L.;Wenwen Dou;Aidong Lu;Ribarsky, W.;Xiaoyu Wang	Comput. Sci., UNC - Charlotte, Charlotte, NC, USA|c|;;;;	37546111900;37606064200;37545504600;37300425000;37601069300
	InfoVis+SciVis	23-28 Oct. 2011	Automated measures for interpretable dimensionality reduction for visual classification: A user study	10.1109/VAST.2011.6102474	http://dx.doi.org/10.1109/VAST.2011.6102474	281	282	6102474	data analysis;data visualisation;learning (artificial intelligence);pattern classification	2D representation;data transformation functions;evolutionary computing;expression structural properties;human perception;interpretable dimensionality reduction;labeled data visualization;labeled higher dimensional data;machine learning;mathematical expression comprehensibility;transformation interpretability;visual analytics;visual classification;visualization axis interpretability	Atmospheric measurements;Data visualization;Humans;Indexes;Particle measurements;Support vector machines;Visualization	data transformation;user study;visualization		Icke, I.;Rosenberg, A.	Grad. Center, City Univ. of New York, New York, NY, USA|c|;	38233506100;38236481600
	InfoVis+SciVis	23-28 Oct. 2011	3D Visualization of temporal changes in bloggers&#39; activities and interests	10.1109/VAST.2011.6102475	http://dx.doi.org/10.1109/VAST.2011.6102475	283	284	6102475	Web sites;data visualisation	3D visualization framewrok;blogger activities;blogger interests;dependency database;dependency structures;temporal change analysis	Blogs;Data visualization;Databases;Educational institutions;Three dimensional displays;Time frequency analysis;Visualization		This paper presents a novel system for analyzing temporal changes in bloggers' activities and interests on a topic through a 3D visualization of dependency structures related to the topic. Having a dependency database built from a blog archive, our 3D visualization framework helps users to interactively exploring temporal changes in bloggers' activities and interests related to the topic.	Itoh, M.;Yoshinaga, N.;Toyoda, M.;Kitsuregawa, M.	Inst. of Ind. Sci., Univ. of Tokyo, Tokyo, Japan|c|;;;	37534010200;37598015400;37328454400;37283954000
	InfoVis+SciVis	23-28 Oct. 2011	A state transition approach to understanding users&#39; interactions	10.1109/VAST.2011.6102476	http://dx.doi.org/10.1109/VAST.2011.6102476	285	286	6102476	data analysis;data visualisation	expert interactive analysis understanding;state transition approach;user interaction understanding;visual analytics	Cognition;Data visualization;Educational institutions;Joining processes;Visual analytics;Wires		Understanding users' interactions is considered as one of the important research topics in visual analytics. Although numerous empirical user studies have been performed to understand a user's interaction, a limited study has been successful in connecting the user's interaction to his/her reasoning. In this paper, we present an approach of understanding experts' interactive analysis by connecting their interactions to conclusions (i.e. findings) through a state transition approach.	Dong Hyun Jeong;Soo-Yeon Ji;Ribarsky, W.;Chang, R.	Univ. of the District of Columbia, Washington, DC, USA|c|;;;	37400451800;37399189900;37300425000;37592409400
	InfoVis+SciVis	23-28 Oct. 2011	Visualizing an information assurance risk taxonomy	10.1109/VAST.2011.6102477	http://dx.doi.org/10.1109/VAST.2011.6102477	287	288	6102477	data analysis;data mining;data visualisation;risk management;security of data	In-Spire visual analysis software;Starlight software;abstracts;information assurance risk taxonomy visualization;keywords groupings;risk management strategies;scientific research journals;text mining operations;visual analysis	Abstracts;Availability;Databases;Educational institutions;Security;Taxonomy;Visualization	Information Assurance;Information Security;Risk;Risk Management;Visual Analysis	The researchers explore the intersections between Information Assurance and Risk using visual analysis of text mining operations. The methodological approach involves searching for and extracting for analysis those abstracts and keywords groupings that relate to risk within a defined subset of scientific research journals. This analysis is conducted through a triangulated study incorporating visualizations produced using both Starlight and In-Spire visual analysis software. The results are definitional, showing current attitudes within the Information Assurance research community towards risk management strategies, while simultaneously demonstrating the value of visual analysis processes when engaging in sense making of a large body of knowledge.	Lemieux, V.;Endicott-Popovsky, B.;Eckler, K.;Dang, T.;Jansen, A.	;;;;	38233540100;38198370000;38242758000;38242773100;37990064400
	InfoVis+SciVis	23-28 Oct. 2011	Find distance function, hide model inference	10.1109/VAST.2011.6102478	http://dx.doi.org/10.1109/VAST.2011.6102478	289	290	6102478	data analysis;data visualisation	data analysis approach;domain-specific distance function;iterative feedback mechanism;model inference;multidimensional scaling visualization	Analytical models;Computational modeling;Data models;Data visualization;Stress;Vectors;Visual analytics		Faced with a large, high-dimensional dataset, many turn to data analysis approaches that they understand less well than the domain of their data. An expert's knowledge can be leveraged into many types of analysis via a domain-specific distance function, but creating such a function is not intuitive to do by hand. We have created a system that shows an initial visualization, adapts to user feedback, and produces a distance function as a result. Specifically, we present a multidimensional scaling (MDS) visualization and an iterative feedback mechanism for a user to affect the distance function that informs the visualization without having to adjust the parameters of the visualization directly. An encouraging experimental result suggests that using this tool, data attributes with useless data are given low importance in the distance function.	Jingjing Liu;Brown, E.T.;Chang, R.	Tufts Univ., Medford, MA, USA|c|;;	38239756300;38237586900;38236983500
	InfoVis+SciVis	23-28 Oct. 2011	KD-photomap: Exploring photographs in space and time	10.1109/VAST.2011.6102479	http://dx.doi.org/10.1109/VAST.2011.6102479	291	292	6102479	Internet;Web sites;cartography;data analysis;data visualisation	KD-photomap;Web-based visual analytics system;calendar controls;collection browsing;data spatial filtering;geotagged Flickr photographs;interactive histograms;photograph exploration;temporal filtering;time windows	Google;Histograms;Multimedia communication;Servers;Spatiotemporal phenomena;Visual analytics;XML		KD-photomap is a web-based visual analytics system for browsing collections of geotagged Flickr photographs in search of interesting pictures, places, and events. Spatial filtering of the data is performed through zooming, moving or searching along the map. Temporal filtering is possible through defining time windows using interactive histograms and calendar controls. Information about the number and spatiotemporal distribution of photos captured in an explored area is continuously provided using various visual cues.	Peca, I.;Zhi, H.;Vrotsou, K.;Andrienko, N.;Andrienko, G.	Fraunhofer Inst. for Intell. Anal. & Inf. Syst. (IAIS), Univ. of Bonn, Bonn, Germany|c|;;;;	38233565500;38242822400;37939017400;37283047700;37283047100
	InfoVis+SciVis	23-28 Oct. 2011	PORGY: Interactive and visual reasoning with graph rewriting systems	10.1109/VAST.2011.6102480	http://dx.doi.org/10.1109/VAST.2011.6102480	293	294	6102480	data visualisation;graph theory;inference mechanisms;interactive programming;rewriting systems	PORGY;graph rewriting systems;interactive reasoning;transformation rules;visual reasoning;visualization design	Biological system modeling;Calculus;Computational modeling;History;Layout;Visualization		Graph rewriting systems are easily described and explained. They can be seen as a game where one iterates transformation rules on an initial graph, until some condition is met. A rule describes a local pattern (i.e. a subgraph) that must be identified in a graph and specifies how to transform this subgraph. The graph rewriting formalism is at the same time extremely rich and complex, making the study of a model expressed in terms of graph rewriting quite challenging. For instance, predicting whether rules can be applied in any order is often difficult. When modelling complex systems, graphical formalisms have clear advantages: they are more intuitive and make it easier to visualize a system and convey intuitions about it. This work focuses on the design of an interactive visual graph rewriting system which supports graphical manipulations and computation to reason and simulate on a system. PORGY has been designed based on regular exchanges with graph rewriting systems experts and users over the past three years. The design choices relied on a careful methodology inspired from Munzner's nested process model for visualization design and validation [4].	Pinaud, B.;Dubois, J.;Melancon, G.	Univ. of Bordeaux, Bordeaux, France|c|;;	37396011000;38269861900;37283186100
	InfoVis+SciVis	23-28 Oct. 2011	Exploring proportions: Comparative visualization of categorical data	10.1109/VAST.2011.6102481	http://dx.doi.org/10.1109/VAST.2011.6102481	295	296	6102481	data visualisation	categorical dimensions;multidimensional categorical data comparative visualization;over-under-proportional relationship representation;proportion exploration;social survey;visualization-driven strategies	Bars;Data visualization;Joints;Layout;Probability;USA Councils;Visualization		This poster describes an approach to facilitate comparisons in multi-dimensional categorical data. The key idea is to represent over- or under-proportional relationships explicitly. On an overview level, the visualization of various measures conveys pair-wise relationships between categorical dimensions. For more details, interaction supports to relate a single category to all categories of multiple dimensions. We discuss methods for representing relationships and visualization-driven strategies for ordering dimensions and categories, and we illustrate the approach by means of data from a social survey.	Piringer, H.;Buchetics, M.	VRVis Res. Center, Vienna, Austria|c|;	37282562500;38233558900
	InfoVis+SciVis	23-28 Oct. 2011	Pexel and heatmap visual analysis of multidimensional gun/homicide data	10.1109/VAST.2011.6102482	http://dx.doi.org/10.1109/VAST.2011.6102482	297	298	6102482	data analysis;data visualisation;police data processing;statistical analysis	2D pexel;bar graphs;details-on-demand;dynamic query;firearm homicide data;firearm homicide rate;gun availability;gun data;heatmap visual analysis;linked-view;residual plot;scatterplots;statistical significance filter	Availability;Correlation;Data visualization;Fires;Heating;Image color analysis;Visualization		We present a visual analysis tool for mining correlations in county-level, multidimensional gun/homicide data. The tool uses 2D pexels, heatmaps, linked-views, dynamic queries and details-on-demand to analyze annual county-level data on firearm homicide rates and gun availability, as well as various socio-demographic measures. A statistical significance filter was implemented as a visual means to validate exploratory hypotheses. Results from expert evaluations indicate that our methods outperform typical graphical techniques used by statisticians, such as bar graphs, scatterplots and residual plots, to show spatial and temporal relationships. Our visualization has the potential to convey the impact of gun availability on firearm homicides to the public health arena and the general public.	Rothenberger, S.D.;Wenskovitch, J.E.;Marai, G.E.	Dept. of Stat., Univ. of Pittsburgh, Pittsburgh, PA, USA|c|;;	37317865100;38233577000;37937697100
	InfoVis+SciVis	23-28 Oct. 2011	City sentinel - VAST 2011 mini challenge 1 award: &#x201C;Outstanding integration of computational and visual methods&#x201D;	10.1109/VAST.2011.6102485	http://dx.doi.org/10.1109/VAST.2011.6102485	305	306	6102485	data analysis;data mining;data visualisation;epidemics;information retrieval;medical computing	City sentinel;VAST 2011 mini challenge 1 award;computational methods;epidemic outbreak;hidden information retrieval;in-house built visual analytic software;text mining;textual documents;tweet messages;visual methods;visualization tools	Accidents;Blood;Cities and towns;Data mining;Image color analysis;Motion pictures;Tag clouds		We present City Sentinel, an in-house built visual analytic software capable of handling a large collection of textual documents by combining diverse text mining and visualization tools. We applied this tool for the Vast Challenge 2011, Mini Challenge 1 over millions of tweet messages. We demonstrate how City Sentinel aided the analyst in retrieving the hidden information from the tweet messages to analyze and locate a hypothetical epidemic outbreak.	Banfi, N.;Dudas, L.;Fekete, Z.;Gobolos-Szabo, J.;Lukacs, A.;Nagy, A.;Szabo, A.;Szabo, Z.;Szucs, G.	Comput. & Autom. Res. Inst. (MTA SZTAKI), Hungary|c|;;;;;;;;	38233559000;38242805600;37681667500;38233559600;37682650700;38235266600;38242541600;38242778300;38232133700
	InfoVis+SciVis	23-28 Oct. 2011	Mapping an epidemic outbreak: Effective analysis and presentation	10.1109/VAST.2011.6102486	http://dx.doi.org/10.1109/VAST.2011.6102486	307	308	6102486	Web sites;cartography;data analysis;data visualisation;epidemics;medical computing	Vastopolis city;commercial software;data analysis;dispersion pattern;epidemic outbreak mapping;map;microblog challenge;outbreak origin;symptom visualization;visual analysis	Bridges;Data visualization;Dispersion;Rivers;Software;Stomach;Synthetic aperture sonar	ArcGIS;Information Visualization;Spatial Analysis	The microblog challenge presented an opportunity to use commercial software for visual analysis. An epidemic outbreak occurred in the city of Vastopolis, requiring visualizations of symptoms and their spread over time. Using these tools, analysts could successfully identify the outbreak's origin and pattern of dispersion. The maps used to analyze the data and present the results provided clear, easily understood representations, and presented a logical explanation of a complex progression of events.	Boone, K.;Swing, E.	;	38239847300;37374975000
	InfoVis+SciVis	23-28 Oct. 2011	ScatterBlogs: Geo-spatial document analysis	10.1109/VAST.2011.6102488	http://dx.doi.org/10.1109/VAST.2011.6102488	309	310	6102488	Web sites;data visualisation;document handling;geography;security of data	MC1;ScatterBlogs;geo-spatial document analysis;interaction facilities;microblog analysis;search backend;spatio-temporal anomaly detection;system combinatoric facilities;visual frontend;visual representations	Accidents;Cities and towns;Context;Lenses;Spatiotemporal phenomena;Tag clouds;Visualization		We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system's combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.	Bosch, H.;Thom, D.;Worner, M.;Koch, S.;Puttmann, E.;Jackle, D.;Ertl, T.	Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;;;;	37683989300;38233559700;37667957300;37593029700;38233561200;38233561600;37268023800
	InfoVis+SciVis	23-28 Oct. 2011	epSpread - Storyboarding for visual analytics	10.1109/VAST.2011.6102489	http://dx.doi.org/10.1109/VAST.2011.6102489	311	312	6102489	Web sites;data analysis;data visualisation;epidemics;medical computing	VAST Challenge 2011 Mini-Challenge 1;epSpread;epidemic spread;geolocated microblogging data;heatmaps;individual time points;queries;ranges;storyboarding tool;streamgraphs;visual analytics;word clouds	Cities and towns;Data visualization;Electronic mail;Heating;Tag clouds;Visual analytics	Coordinated Multiple Views;VAST 2011;Visual Analytics;epidemic visualization;information visualization	We present epSpread, an analysis and storyboarding tool for geolocated microblogging data. Individual time points and ranges are analysed through queries, heatmaps, word clouds and streamgraphs. The underlying narrative is shown on a storyboard-style timeline for discussion, refinement and presentation. The tool was used to analyse data from the VAST Challenge 2011 Mini-Challenge 1, tracking the spread of an epidemic using microblogging data. In this article we describe how the tool was used to identify the origin and track the spread of the epidemic.	ap Cenydd, L.;Walker, R.;Pop, S.;Miles, H.;Hughes, C.;Teahan, W.;Roberts, J.C.	Sch. of Comput. Sci., Bangor Univ., Bangor, UK|c|;;;;;;	37589811000;37596627100;37588391300;38235916900;38170583200;37282659000;37278794800
	InfoVis+SciVis	23-28 Oct. 2011	MobileAnalymator: Animating data changes on mobile devices	10.1109/VAST.2011.6102490	http://dx.doi.org/10.1109/VAST.2011.6102490	313	314	6102490	Internet;Java;SQL;computer animation;data analysis;data visualisation;geography;mobile computing;notebook computers	Adobe Flash;Internet based application;Java;MobileAnalymator;MySQL;data change animation;geospatial-temporal data analysis;integrated tangible interaction;mobile analysis animator;mobile devices;spatial-temporal autocorrelations;tablet;visual analytic system	Animation;Blogs;Data visualization;Geospatial analysis;Internet;Mobile handsets;Visual analytics		MobileAnalymator (Mobile Analysis Animator) is a visual analytic system designed to analyze geospatial-temporal data on mobile devices. The system is an Internet based application that allows analysts to work in flexile enviornments at anytime. Its client side is developed by Adobe Flash to animate and interact with data. The server side uses Java and MySQL to query, compute, and serve data. The analyst can run the analytical task from a tablet (or computer) with Internet connection. MobileAnalymator adopted spatial and temporal autocorrelations in the interface design and integrated tangible interaction in the navigation to support analysis process.	Chen, Y.V.;Qian, Z.C.;Li Zhang	Interaction Design, Purdue Univ., West Lafayette, IN, USA|c|;;	38241087200;38238364000;38240128900
	InfoVis+SciVis	23-28 Oct. 2011	Geovisual analytics for cyber security: Adopting the GeoViz Toolkit	10.1109/VAST.2011.6102491	http://dx.doi.org/10.1109/VAST.2011.6102491	315	316	6102491	Perl;data analysis;data visualisation;geographic information systems;security of data	ArcGIS 10;GeoViz Toolkit;Perl scripts;VAST 2011 Network Security MiniChallenge;cyber security;data security;geography;geovisual analytics method;network security	Computer security;Data visualization;Geography;Histograms;IP networks;Shape	Coordinated and multiple views;GeoViz Toolkit;cyber security;geovisual analytics;situation awareness	For the VAST 2011 Network Security Mini-Challenge, we adopted geovisual analytic methods and applied them in the field of network security. We used the GeoViz Toolkit [1] to represent cyber security events, by fabricating a simple geography of several sets of blocks (one for the workstations, one for the servers, and one for the Internet) using ArcGIS 10 (by ESRI - Environmental System Research Institute). Security data was tabulated using Perl scripts to parse the logs in order to create representations of event frequency and where they occurred on the network. The tabulated security data was then added as attributes of the geography. Exploration of the data and subsequent analysis of the meaning and impact of the cyber security events was made possible using the GeoViz Toolkit.	Giacobe, N.A.;Sen Xu	Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA|c|;	37595223800;38235993300
	InfoVis+SciVis	23-28 Oct. 2011	Guiding security analysis through visualization	10.1109/VAST.2011.6102492	http://dx.doi.org/10.1109/VAST.2011.6102492	317	318	6102492	SQL;data visualisation;database management systems;security of data	SQL queries;VAST 2010 Mini Challenge 2;data security;database application;log event activity monitoring;multiple views visualization;network log data;security analysis;suspicious activity	Data visualization;Databases;Electronic mail;Image color analysis;Intrusion detection;Visualization		We present a multiple views visualization for the security data in the VAST 2010 Mini Challenge 2. The visualization is used to monitor log event activity on the network log data included in the challenge. Interactions are provided that allow analysts to investigate suspicious activity and escalate events as needed. Additionally, a database application is used to allow SQL queries for more detailed investigation.	Harrison, L.;Wenwen Dou;Aidong Lu;Ribarsky, W.;Xiaoyu Wang	Comput. Sci., UNC - Charlotte, Charlotte, NC, USA|c|;;;;	37546111900;37606064200;37545504600;37300425000;37601069300
	InfoVis+SciVis	23-28 Oct. 2011	An integrated visualization on network events VAST 2011 mini challenge #2 award: &#x201C;Outstanding integrated overview display&#x201D;	10.1109/VAST.2011.6102493	http://dx.doi.org/10.1109/VAST.2011.6102493	319	321	6102493	Internet;data visualisation;programming languages;public domain software;security of data	VAST 2011 mini challenge #2 award;Web programming languages;canvas;data set security trend visualization;heat map development;integrated visualization;log synchronization;network security trends;open source database;open source tools;outstanding integrated overview display;parallel coordinates charts;processing	Arrays;Data visualization;Fires;Heating;Image color analysis;Security;Synchronization	heat map;logs;security trends;vast challenge;visual analysis	To visualize security trends for the data set provided by the VAST 2011 Mini Challenge #2 a custom tool has been developed. Open source tools [1,2], web programming languages [4,7] and an open source database [3] has been used to work with the data and create a visualization for security log files containing network security trends. In this paper, the tools and methods used for the analysis are described. The methods include the log synchronization with different timezone and the development of heat maps and parallel coordinates charts. To develop the visualization, Processing and Canvas [4,7] was used.	Lamagna, W.M.	Master on Datamining & Knowledge Discovery, Univ. de Buenos Aires, Buenos Aires, Argentina|c|	38233607900
	InfoVis+SciVis	23-28 Oct. 2011	Analyst&#39;s workspace: Protecting vastopolis	10.1109/VAST.2011.6102495	http://dx.doi.org/10.1109/VAST.2011.6102495	323	324	6102495	computer displays;data analysis;data visualisation	VAST 2011 mini-challenge #3;Vastopolis protection;analyst workspace;high-resolution displays;sensemaking environment	Bioterrorism;Browsers;Marine animals;Rivers;Visual analytics	Visual analytics;high-resolution displays;intelligence analysis;large;space	Analyst's Workspace is a sensemaking environment designed specifically for use of large, high-resolution displays. It employs a spatial workspace to integrate foraging and synthesis activities into a unified process. In this paper we describe how Analyst's Workspace solved the VAST 2011 mini-challenge #3 and discuss some of the unique features of the environment.	Andrews, C.;Hossain, M.S.;Gad, S.;Ramakrishnan, N.;North, C.	;;;;	37587847300;38242697300;38237673700;37273204200;37419565900
	InfoVis+SciVis	23-28 Oct. 2011	Jigsaw to save vastopolis	10.1109/VAST.2011.6102496	http://dx.doi.org/10.1109/VAST.2011.6102496	325	326	6102496	data analysis;data visualisation;document handling	Jigsaw computational analysis capability;Jigsaw system;Jigsaw visualizations;VAST 2011 Mini Challenge 3;Vastopolis;documents	Data visualization;Electronic mail;Information retrieval;Manuals;Organizations;Text analysis;Visualization	Visual analytics;data ingestion;evidence marshalling;information visualization;investigative analysis	This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw's computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.	Braunstein, E.;Gorg, C.;Zhicheng Liu;Stasko, J.	Mercyhurst Coll., USA|c|;;;	38235560700;38263959200;37592993600;37267736900
	InfoVis+SciVis	23-28 Oct. 2011	Interactive data analysis with nSpace2&#x00AE;	10.1109/VAST.2011.6102497	http://dx.doi.org/10.1109/VAST.2011.6102497	327	328	6102497	Internet;data analysis;data visualisation;public domain software	VAST 2011 Mini Challenge 3 dataset;Web-based tool;back-and-forth flow analysis process;innovative visual analytics tool;interactive data analysis;nSpace2	Arrays;Data visualization;Electronic mail;Graphical user interfaces;Humans;Terrorism;Visual analytics	analysis workflow;human information interaction;sense-making;visual analytics	nSpace2 is an innovative visual analytics tool that was the primary platform used to search, evaluate, and organize the data in the VAST 2011 Mini Challenge #3 dataset. nSpace2 is a web-based tool that is designed to facilitate the back-and-forth flow of the multiple steps of an analysis process, including search, data triage, organization, sense-making, and reporting. This paper describes how nSpace2 was used to assist every step of the analysis process for this VAST challenge.	Canfield, C.M.;Sheffield, D.	;	38236119900;38082608400
	InfoVis+SciVis	23-28 Oct. 2011	Visual analytics of terrorist activities related to epidemics	10.1109/VAST.2011.6102498	http://dx.doi.org/10.1109/VAST.2011.6102498	329	330	6102498	computer network security;data analysis;data visualisation;epidemics;medical computing;social networking (online);terrorism	MC 1;MC 2;MC 3;Twitter;VAST 2011 Grand Challenge;computer network threat analysis;criminal activities;epidemic spread;geo-tagged microblogging message analysis;news articles collection;situational awareness approach;terrorist activities;visual analytics	Data analysis;Imaging;Rivers;Software;Tag clouds;Terrorism;Visual analytics		The task of the VAST 2011 Grand Challenge was to investigate potential terrorist activities and their relation to the spread of an epidemic. Three different data sets were provided as part of three Mini Challenges (MCs). MC 1 was about analyzing geo-tagged microblogging (Twitter) messages to characterize the spread of an epidemic. MC 2 required analyzing threats to a computer network using a situational awareness approach. In MC 3 possible criminal and terrorist activities were to be analyzed based on a collection of news articles. To solve the Grand Challenge, insight from each of the individual MCs had to be integrated appropriately.	Bertini, E.;Buchmuller, J.;Fischer, F.;Huber, S.;Lindemeier, T.;Maass, F.;Mansmann, F.;Ramm, T.;Regenscheit, M.;Rohrdantz, C.;Scheible, C.;Schreck, T.;Sellien, S.;Stoffel, F.;Tautzenberger, M.;Zieker, M.;Keim, D.A.	Data Anal. & Visualization Group, Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;;;;;;;;;;	37283307700;38233607000;38242836400;38242146100;38233610100;38233609600;37392086200;38233608600;38233605200;37601356700;38233604500;37282557600;38233604000;38233603600;38233606900;38233606500;37283138700
