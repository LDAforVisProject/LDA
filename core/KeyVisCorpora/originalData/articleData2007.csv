Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis+SciVis	Nov.-Dec. 2007	Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats	10.1109/TVCG.2007.70522	http://dx.doi.org/10.1109/TVCG.2007.70522	1105	1112	4376129	IP networks;Internet;data visualisation;security of data;telecommunication network planning;telecommunication security;telecommunication traffic	IP address space;Internet;Treemap;interactive monitoring;interactive visualization;network infrastructure;network traffic;personal computers;resource planning;security threats interpretation	Computer security;Computerized monitoring;Continents;Data analysis;Data security;Data visualization;IP networks;Protection;Stability;Telecommunication traffic	Information visualization;network monitoring;network security;treemap	The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.	Mansmann, F.	Univ. of Konstanz, Konstanz|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets	10.1109/TVCG.2007.70537	http://dx.doi.org/10.1109/TVCG.2007.70537	1113	1120	4376130	computer games;data visualisation;human factors;sport;tree data structures	AdaptiviTree visualization;adaptive tree visualization;online fantasy games;prediction display;statistics;tournament-style brackets	Displays;Economic forecasting;Educational institutions;Industrial economics;Jupiter;Monitoring;Shape;Statistics;Toy industry;Visualization	Online fantasy sports;adaptive tree visualization.;bracket;picks;tournament	Online pick'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.	Tan, D.S.;Smith, G.;Bongshin Lee;Robertson, G.G.	Microsoft Res., Redmond|c|;;;	37955052000;37960251500;37293389400;37448060300
	InfoVis+SciVis	Nov.-Dec. 2007	ManyEyes: a Site for Visualization at Internet Scale	10.1109/TVCG.2007.70577	http://dx.doi.org/10.1109/TVCG.2007.70577	1121	1128	4376131	Web sites;data analysis;data visualisation	Internet scale;Many Eyes;data analysis;data visualization;public Web site	Collaboration;Collaborative tools;Data analysis;Data visualization;Displays;Eyes;Internet;Publishing;Space technology;Web page design	Communication-Minded Visualization.;Social Data Analysis;Social Software;Visualization;World Wide Web	We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.	Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.	IBM Res., Yorktown Heights|c|;;;;	37681355300;37550759700;37326291000;37830149600;37542455400
	InfoVis+SciVis	Nov.-Dec. 2007	Scented Widgets: Improving Navigation Cues with Embedded Visualizations	10.1109/TVCG.2007.70589	http://dx.doi.org/10.1109/TVCG.2007.70589	1129	1136	4376132	data visualisation;graphical user interfaces	design guidelines;embedded visualizations;graphical user interface controls;information spaces navigation;navigation cues;scented widgets;visual cues	Animal structures;Application software;Collaboration;Costs;Data analysis;Data visualization;Guidelines;Radio navigation;Switches;User interfaces	Information visualization;information foraging;social data analysis;social navigation;user interface toolkits	This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.	Willett, W.;Heer, J.;Agrawala, M.	Univ. of California, Berkeley|c|;;	37945380800;37550791300;37282718200
	InfoVis+SciVis	Nov.-Dec. 2007	Show Me: Automatic Presentation for Visual Analysis	10.1109/TVCG.2007.70594	http://dx.doi.org/10.1109/TVCG.2007.70594	1137	1144	4376133	algebraic specification;data analysis;data visualisation;specification languages;user interfaces	algebraic specification language;automatic presentation;data analysis;data visualization;graphic design;small multiple display;user interface;visual analysis system	Best practices;Data analysis;Data visualization;Displays;Encoding;Graphics;Information analysis;Specification languages;User interfaces	Automatic presentation;best practices;data visualization;graphic design;small multiples.;visual analysis	This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.	Mackinlay, J.;Hanrahan, P.;Stolte, C.	Tableau Software, Seattle|c|;;	37372036700;37349803800;37442008700
	InfoVis+SciVis	Nov.-Dec. 2007	Casual Information Visualization: Depictions of Data in Everyday Life	10.1109/TVCG.2007.70541	http://dx.doi.org/10.1109/TVCG.2007.70541	1145	1152	4376134	data visualisation	ambient infovis;casual audiences;casual information visualization;casual infovis;cognition;interactive visual model;social infovis;system evaluation	Cognition;Data visualization;Finance;Focusing;Government;Information analysis;Refining;Technology management;Testing;Vocabulary	Casual information visualization;ambient infovis;design;editorial;evaluation.;social infovis	Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.	Pousman, Z.;Stasko, J.T.;Mateas, M.	Georgia Inst.of Technol, Atlanta|c|;;	37945316800;37267736900;37329261300
	InfoVis+SciVis	Nov.-Dec. 2007	Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis	10.1109/TVCG.2007.70558	http://dx.doi.org/10.1109/TVCG.2007.70558	1161	1168	4376135	data visualisation;geographic information systems;interactive systems;statistical analysis	geographically weighted visualization;geowigs;interactive graphics;multivariate local variation;multivariate statistical value;scale-varying exploratory analysis	Ethics;Extraterrestrial measurements;Extraterrestrial phenomena;Geography;Graphics;Software prototyping;Statistical analysis;Statistical distributions;Statistics;Visualization	Geographical weighting;coordinated views;directional;exploratory data analysis;interaction;multivariate;scale		Dykes, J.;Brunsdon, C.	City Univ., London|c|;	37605079900;37945380100
	InfoVis+SciVis	Nov.-Dec. 2007	Visualizing the History of Living Spaces	10.1109/TVCG.2007.70621	http://dx.doi.org/10.1109/TVCG.2007.70621	1153	1160	4376136	data visualisation;human factors;image motion analysis;image sensors;spatiotemporal phenomena;user interfaces;video cameras	building designer;data visualisation;living space;motion sensor;video camera	Buildings;Cameras;History;Humans;Information security;Large-scale systems;Monitoring;Privacy;Space technology;Visualization	Sensor networks;spatio-temporal visualization.;surveillance;timeline;user interfaces	The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.	Ivanov, Y.A.	Mitsubuishi Electr. Res. Labs.|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships	10.1109/TVCG.2007.70574	http://dx.doi.org/10.1109/TVCG.2007.70574	1169	1175	4376137	data visualisation;interactive systems;town and country planning	focus-dependent multiresolution visualization;information visualization view displays;interactive urban visualization tool;urban model 3D view;urban relationships	Aggregates;Buildings;Cities and towns;Cognitive science;Computer architecture;Computer science;Data visualization;Electronic mail;Three dimensional displays;Urban planning	information visualization;multi-resolution;urban models	Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user's perspectives on the data, thereby diminishing the user's spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user's mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.	Chang, R.;Wessel, G.;Kosara, R.;Sauda, E.;Ribarsky, W.	UNC Charlotte, Charlotte|c|;;;;	37592409400;37948880500;37282563400;37945352600;37300425000
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.	10.1109/TVCG.2007.70570	http://dx.doi.org/10.1109/TVCG.2007.70570	1176	1183	4376138	SQL;data visualisation;geographic information systems;spatiotemporal phenomena	Google Earth;KML;LandSerf GIS;MySQL;PHP;data dials;de facto exchange standards;geographical mashups;geovisualization mashup;interactive visual exploration;mobile directory service;multi-scale density surfaces;spatial tag clouds;spatio-temporal dataset;tag maps;visual encodings	Application software;Data mining;Data visualization;Earth;Encoding;Filters;Geographic Information Systems;Mashups;Reflection;Spatial resolution	Large dataset visualization;applications of infovis.;geographic visualization;multiresolution visualization;text and document visualization	Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical 'mashups' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial 'tag clouds', 'tag maps', 'data dials' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the 'mashup' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.	Wood, J.;Dykes, J.;Slingsby, A.;Clarke, K.	City Univ., London|c|;;;	37399045100;37605079900;37590960700;37548107100
	InfoVis+SciVis	Nov.-Dec. 2007	Hotmap: Looking at Geographic Attention	10.1109/TVCG.2007.70561	http://dx.doi.org/10.1109/TVCG.2007.70561	1184	1191	4376139	data acquisition;data visualisation;geographic information systems;interactive systems	GIS;Hotmap;URL;data acquisition;geographic attention;geographic visualization;imagery acquisition;logarithmic color scheme;low-saturation background image;mapping system imagery pyramid;online interactive mapping system;tuning image	Cities and towns;Failure analysis;Geographic Information Systems;Geography;Image analysis;Image color analysis;Navigation;Space heating;Uniform resource locators;Visualization	GIS;Geographical visualization;heatmap;online mapping systems;server log analysis;social navigation	Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system's imagery pyramid to superpose a heatmap of the log files over the original maps. Users' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.	Fisher, D.	Microsoft Res., Redmond|c|	37542391000
	InfoVis+SciVis	Nov.-Dec. 2007	VisLink: Revealing Relationships Amongst Visualizations	10.1109/TVCG.2007.70521	http://dx.doi.org/10.1109/TVCG.2007.70521	1192	1199	4376140	data visualisation;query formulation	VisLink;data visualizations;information encoding;inter-representational query;search filters;spreading activation	Computer science;Data visualization;Encoding;Filters;Information analysis;Statistics;Two dimensional displays	3D visualization;Graph visualization;edge aggregation.;hierarchies;node-link diagrams;structural comparison	We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.	Collins, C.	Univ. of Toronto, Toronto|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Visualization of Heterogeneous Data	10.1109/TVCG.2007.70617	http://dx.doi.org/10.1109/TVCG.2007.70617	1200	1207	4376141	data integrity;data visualisation	Maya Viz u-forms;data attributes mapping;data integration;data visualization;resource description framework;schema matching problem;semantic Web	Data models;Data visualization;Government;Mashups;Resource description framework;Semantic Web;Space technology;Visual databases;Web services;Wikipedia	Data integration;RDF;attribute inference	Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.	Cammarano, M.	Stanford Univ., Stanford|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Sequential Document Visualization	10.1109/TVCG.2007.70592	http://dx.doi.org/10.1109/TVCG.2007.70592	1208	1215	4376142	data visualisation;document handling;statistical analysis;time series	discrete categorical time series;histogram vectors;multinomial simplex summarization;sequential document visualization;statistical models	Amino acids;Data visualization;Frequency;Histograms;Multidimensional systems;Principal component analysis;Proteins;Statistics;Time series analysis	Document visualization;local fitting.;multi-resolution analysis	Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization.	Yi Mao;Dillon, J.V.;Lebanon, G.	Purdue Univ., West Lafayette|c|;;	37957484800;37954686000;37427770800
	InfoVis+SciVis	Nov.-Dec. 2007	A Taxonomy of Clutter Reduction for Information Visualisation	10.1109/TVCG.2007.70535	http://dx.doi.org/10.1109/TVCG.2007.70535	1216	1223	4376143	data structures;data visualisation;pattern classification	clutter reduction method;data classification;information visualisation;large datasets;multivariate data;visual representation	Algorithm design and analysis;Computer displays;Data visualization;Government;Hardware;Performance analysis;Prototypes;Software;Taxonomy;Usability	Clutter reduction;information visualisation;large datasets;occlusion;taxonomy.	Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.	Ellis, G.;Dix, A.	Lancaster Univ, Lancaster|c|;	37283380700;37283381700
	InfoVis+SciVis	Nov.-Dec. 2007	Toward a Deeper Understanding of the Role of Interaction in Information Visualization	10.1109/TVCG.2007.70515	http://dx.doi.org/10.1109/TVCG.2007.70515	1224	1231	4376144	data visualisation;human computer interaction	Infovis community;Infovis interaction techniques;Infovis systems;information visualization;taxonomy	Computer displays;Computer graphics;Conference proceedings;Data visualization;Filters;Human computer interaction;Rendering (computer graphics);Research and development;Taxonomy;Visual analytics	Information visualization;interaction;interaction techniques;taxonomy;visual analytics	Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.	Ji Soo Yi	Georgia Inst. of Technol., Atlanta|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive Tree Comparison for Co-located Collaborative Information Visualization	10.1109/TVCG.2007.70568	http://dx.doi.org/10.1109/TVCG.2007.70568	1232	1239	4376145	data visualisation;groupware	colocated collaborative information visualization;interactive tree comparison;shared interactive tabletop display	Biomedical imaging;Collaboration;Collaborative tools;Collaborative work;Data analysis;Data visualization;Displays;Information analysis;Information processing;Technological innovation	Information visualization;co-located work;collaboration;hierarchical data comparison	In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.	Isenberg, P.;Carpendale, S.	Univ. of Calgary, Calgary|c|;	38268343800;37285000100
	InfoVis+SciVis	Nov.-Dec. 2007	Animated Transitions in Statistical Data Graphics	10.1109/TVCG.2007.70539	http://dx.doi.org/10.1109/TVCG.2007.70539	1240	1247	4376146	computer animation;data visualisation;statistical analysis	DynaVis;animated transitions;bar charts;graphical perception;pie charts;scatter plots;statistical data graphics;visualization system	Animation;Collaboration;Data visualization;Drilling;Graphics;Guidelines;Information analysis;Marketing and sales;Scattering;Taxonomy	Statistical data graphics;animation;design;experiment;information visualization;transitions		Heer, J.;Robertson, G.G.	Univ. of California at Berkeley, Berkeley|c|;	37550791300;37448060300
	InfoVis+SciVis	Nov.-Dec. 2007	Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques	10.1109/TVCG.2007.70540	http://dx.doi.org/10.1109/TVCG.2007.70540	1248	1253	4376147	data structures;data visualisation;navigation;user interfaces	hierarchical data represention;interactive navigation;structure-aware multiscale navigation;zoomable treemap browsing;zoomable treemaps;zoomable user interfaces	Data visualization;File systems;Filling;Layout;Navigation;Tree graphs;User interfaces	Information visualization;multi-scale interaction;structure-aware navigation;zoomable treemaps.	Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.	Blanch, R.;Lecolinet, E.	Univ. of Grenoble 1, Grenoble|c|;	37945254300;38342554200
	InfoVis+SciVis	Nov.-Dec. 2007	Visualizing Causal Semantics Using Animations	10.1109/TVCG.2007.70528	http://dx.doi.org/10.1109/TVCG.2007.70528	1254	1261	4376148	behavioural sciences computing;computer animation;data visualisation	Michotte rules;animation;causal amplification;causal dampening;causal multiplicity;causal semantics visualization;causal strength;complex causal relations;static graphs	Animation;Fires;Humans;Iron;Motion pictures;Physics;Spatiotemporal phenomena;Tires;Uncertainty;Visualization	Causality;animated graphs;graph semantics.;perception;semantics;visualization;visualizing cause and effect	Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.	Kadaba, N.R.	Univ. of Manitoba, Winnipeg|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Spatialization Design: Comparing Points and Landscapes	10.1109/TVCG.2007.70596	http://dx.doi.org/10.1109/TVCG.2007.70596	1262	1269	4376149	colour graphics;data visualisation	colour scale;grey scale;information landscapes;non-spatial data;non-trivial search;point estimation task;point-based displays;spatial layout;spatialization design;spatialized data;visual representations	Data visualization;Encoding;Fuel economy;Spatial databases;Surface fitting;Surface topography;Three dimensional displays;Two dimensional displays;Usability;Visual databases	2D;3D;Colour;Greyscale;Information Landscape;Numerosity;Points;Spatialization;Surface;User Study	Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.	Tory, M.;Sprague, D.W.;Fuqu Wu;Wing Yan So;Munzner, T.	Victoria Univ., Victoria|c|;;;;	37275861300;37568763300;37956239000;37952248400;37349490300
	InfoVis+SciVis	Nov.-Dec. 2007	Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.	10.1109/TVCG.2007.70623	http://dx.doi.org/10.1109/TVCG.2007.70623	1270	1277	4376150	data visualisation;image colour analysis;image texture	color blending;color mixing;color weaving;encoding;image texture;information carrying capacity;multivariate data visualization;quantitative assessment	Astronomy;Color;Data visualization;Displays;Encoding;Frequency;Geology;Meteorology;Weaving	Color;color blending.;color weaving;perception;visualization	In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. - - We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.	Hagh-Shenas, H.	Boston Sci. Corp., Natick|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Overview Use in Multiple Visual Information Resolution Interfaces	10.1109/TVCG.2007.70583	http://dx.doi.org/10.1109/TVCG.2007.70583	1278	1285	4376151	data visualisation;graphical user interfaces	display capacity;multi-level structure;multiple visual information resolution interfaces;target matching;visual target perceivability;visual targets	Data visualization;Displays;Electronic mail;Encoding;History;Object detection	Multiple resolutions;overview use;user study.	In interfaces that provide multiple visual information resolutions (VIR), low-VIR overviews typically sacrifice visual details for display capacity, with the assumption that users can select regions of interest to examine at higher VI Rs. Designers can create low VIRs based on multi-level structure inherent in the data, but have little guidance with single-level data. To better guide design tradeoff between display capacity and visual target perceivability, we looked at overview use in two multiple-VIR interfaces with high-VIR displays either embedded within, or separate from, the overviews. We studied two visual requirements for effective overview and found that participants would reliably use the low-VIR overviews only when the visual targets were simple and had small visual spans. Otherwise, at least 20% chose to use the high-VIR view exclusively. Surprisingly, neither of the multiple-VIR interfaces provided performance benefits when compared to using the high-VIR view alone. However, we did observe benefits in providing side-by-side comparisons for target matching. We conjecture that the high cognitive load of multiple-VIR interface interactions, whether real or perceived, is a more considerable barrier to their effective use than was previously considered.	Lam, H.;Munzner, T.;Kincaid, R.	Univ. of British Columbia, Vancouver|c|;;	37873130000;37349490300;37587984100
	InfoVis+SciVis	Nov.-Dec. 2007	Visualizing Changes of Hierarchical Data using Treemaps	10.1109/TVCG.2007.70529	http://dx.doi.org/10.1109/TVCG.2007.70529	1286	1293	4376152	data visualisation;tree data structures	hierarchical data visualization;software tool;treemap layout algorithm;treemap snapshots;visual patterns	Computer science;Data analysis;Data engineering;Data visualization;Displays;File systems;Software tools;Spirals;Stability;Switches	Treemap;tree comparison;treemap layout algorithm.;visualize changes	While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.	Ying Tu	Ohio State Univ., Columbus|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Exploring Multiple Trees through DAG Representations	10.1109/TVCG.2007.70556	http://dx.doi.org/10.1109/TVCG.2007.70556	1294	1301	4376153	data visualisation;directed graphs;merging;pattern classification;trees (mathematics)	DAG representations;DAG visualisation;directed acyclic graph;merging;multiple classification trees;multiple trees	Bibliographies;Classification tree analysis;Feedback;History;Merging;Taxonomy;Testing;Tree data structures;Tree graphs;Visualization	Directed Acyclic Graph.;Multiple trees	We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed.	Graham, M.;Kennedy, J.	Napier Univ, Edinburgh|c|;	37739295500;37334180100
	InfoVis+SciVis	Nov.-Dec. 2007	NodeTrix: a Hybrid Visualization of Social Networks	10.1109/TVCG.2007.70582	http://dx.doi.org/10.1109/TVCG.2007.70582	1302	1309	4376154	data structures;data visualisation;matrix algebra;social sciences computing	InfoVis 2004 coauthorship dataset;NodeTrix visualization;adjacency matrices;dragging selections;hardware capabilities;hybrid representation;interaction techniques;social networks hybrid visualization	Aggregates;Animation;Color;Layout;Matrix converters;Sparse matrices	Aggregation;Hybrid visualization;Interaction.;Matrix visualization;Network visualization	The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.	Henry, N.;Fekete, J.;McGuffin, M.J.	Univ. of Sydney, Sydney|c|;;	37839948300;37407972900;37403234300
	InfoVis+SciVis	Nov.-Dec. 2007	Multi-Level Graph Layout on the GPU	10.1109/TVCG.2007.70580	http://dx.doi.org/10.1109/TVCG.2007.70580	1310	1319	4376155	computer graphics;graph theory;parallel programming	Internet service provider;data parallel programming model;directed graph layout;general multi-level scheme;graph partitioning;multi-core architectures;multi-level graph layout;naturally unstructured graph;spectral partitioning	Acceleration;Application software;Computer architecture;High performance computing;Network topology;Parallel programming;Partitioning algorithms;Quality management;Visualization;Web and internet services	GPU;Graph layout;graph partitioning.	This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.	Frishman, Y.;Tal, A.	Israel Inst. of Technol., Haifa|c|;	37646534300;37337567000
	InfoVis+SciVis	Nov.-Dec. 2007	Illustrative Deformation for Data Exploration	10.1109/TVCG.2007.70565	http://dx.doi.org/10.1109/TVCG.2007.70565	1320	1327	4376157	computational geometry;data visualisation;interactive systems;rendering (computer graphics)	data exploration;data manipulation;data object geometry;data rendering quality;focus+context techniques;information visualization;interaction techniques	Cognitive science;Data visualization;Focusing;Geometrical optics;Information geometry;Lenses;Navigation;Silver;Surgery;Taxonomy	Volume deformation;focus+context visualization;interaction techniques	Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.	Correa, C.;Silver, D.;Chen, M.	State Univ. of New Jersey, Brunswick|c|;;	37282925900;37274132700;37280982800
	InfoVis+SciVis	Nov.-Dec. 2007	An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)	10.1109/TVCG.2007.70538	http://dx.doi.org/10.1109/TVCG.2007.70538	1328	1335	4376158	computational geometry;data visualisation;edge detection	3D shape visualization;edge detection;feature lines;illustrative visualization framework;image processing;photic extremum lines	Data visualization;Geometry;Humans;Image edge detection;Image processing;Layout;Lighting;Shape control;Solid modeling	Surface and volume illustration;digital geometry processing.;illumination;photic extremum lines (PELs);ridges and valleys;silhouettes;suggestive contours	Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.	Xuexiang Xie;Ying He;Feng Tian;Hock-Soon Seah;Xianfeng Gu;Hong Qin	Nanyang Technol. Univ.|c|;;;;;	37629748900;37532431100;37271188400;37282337400;37276603700;37276553900
	InfoVis+SciVis	Nov.-Dec. 2007	Semantic Layers for Illustrative Volume Rendering	10.1109/TVCG.2007.70591	http://dx.doi.org/10.1109/TVCG.2007.70591	1336	1343	4376159	data visualisation;formal specification;fuzzy logic;fuzzy set theory;rendering (computer graphics);transfer functions	formal specification;fuzzy logic arithmetic;fuzzy set;illustrative volume rendering;natural language;semantic layer;transfer function;visual style	Arithmetic;Density measurement;Focusing;Fuzzy logic;Fuzzy sets;Natural languages;Rendering (computer graphics);Transfer functions;User interfaces;Visualization	Focus+Context Techniques;Illustrative Visualization;Volume Visualization	Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.	Rautek, P.;Bruckner, S.;Groller, E.	Vienna Univ. of Technol., Vienna|c|;;	37828701300;37265895700;37284271200
	InfoVis+SciVis	Nov.-Dec. 2007	Enhancing Depth-Perception with Flexible Volumetric Halos	10.1109/TVCG.2007.70555	http://dx.doi.org/10.1109/TVCG.2007.70555	1344	1351	4376160	computational complexity;computer graphic equipment;data visualisation;interactive systems;pattern classification;rendering (computer graphics);transfer functions	GPU-based direct volume rendering;depth complexity;depth-perception enhancement;feature-preserving spreading algorithm;flexible volumetric halos;illustrative visualization;interactively defined halo transfer function;structure classification	Biomedical imaging;Computed tomography;Data visualization;Humans;Image resolution;Lighting;Optical attenuators;Rendering (computer graphics);Spatial resolution;Transfer functions	Volume rendering;halos;illustrative visualization	Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.	Bruckner, S.	Vienna Univ. of Technol., Vienna|c|	38485349900
	InfoVis+SciVis	Nov.-Dec. 2007	Registration Techniques for Using Imperfect and Partially Calibrated Devices in Planar Multi-Projector Displays	10.1109/TVCG.2007.70587	http://dx.doi.org/10.1109/TVCG.2007.70587	1352	1359	4376161	parallel processing;rendering (computer graphics);resource allocation	adapt tiles;hierarchical tiles;interactive graphics;load balancing;machine tiles;parallel age;render tiles;resource utilization;screen-space tiles;tile-based level	Computational geometry;Displays;Graphics;Load management;Parallel processing;Personal communication networks;Power system management;Rendering (computer graphics);Resource management;Tiles	Geometric calibration;photometric calibration;tiled displays	Today's PCs incorporate multiple CPUs and GPUs and are easily arranged in clusters for high-performance, interactive graphics. We present an approach based on hierarchical, screen-space tiles to parallelizing rendering with level of detail. Adapt tiles, render tiles, and machine tiles are associated with CPUs, GPUs, and PCs, respectively, to efficiently parallelize the workload with good resource utilization. Adaptive tile sizes provide load balancing while our level of detail system allows total and independent management of the load on CPUs and GPUs. We demonstrate our approach on parallel configurations consisting of both single PCs and a cluster of PCs.	Niski, K.	NVIDIA Corp., Santa Clara|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	A Unified Paradigm For Scalable Multi-Projector Displays	10.1109/TVCG.2007.70536	http://dx.doi.org/10.1109/TVCG.2007.70536	1360	1367	4376162	computer displays;data visualisation;image resolution;optimisation	Nyquist resolution;graphics platform;high-resolution images;optimization;projector blending method;real-time interactive frame;scalable multiprojector display;superimposed multiprojector projection paradigm;tiled projection paradigm;unified paradigm;visualization system	Brightness;Displays;Graphics;Image quality;Image resolution;Large-scale systems;Photometry;Robustness;Solid modeling;Visualization	Multi-projector displays;automatic geometric alignment;blending;large format displays;photometric correction;stitching;super-resolution;superimposed projection.;tiled displays	We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform state-of-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.	Damera-Venkata, N.;Chang, N.L.;DiCarlo, J.M.	Hewlett-Packard Lab., Palo Alto|c|;;	37371254400;37596623500;37950227700
	InfoVis+SciVis	Nov.-Dec. 2007	Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays	10.1109/TVCG.2007.70586	http://dx.doi.org/10.1109/TVCG.2007.70586	1368	1375	4376163	cameras;computational geometry;display devices;image registration;image resolution;optical projectors	closed-form model;geometric registration technique;imagery registration;low-resolution camera;partially calibrated devices;planar multiprojector displays;rational Bezier patches	Calibration;Cameras;Collaborative work;Displays;Educational institutions;Laboratories;Lenses;Photometry;Rendering (computer graphics);Visualization	Geometric calibration;photometric calibration;tiled displays	Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.	Bhasker, E.;Juang, R.;Majumder, A.	Univ. of California, Irvine|c|;;	37828782600;37927188200;37408075400
	InfoVis+SciVis	Nov.-Dec. 2007	Time Dependent Processing in a Parallel Pipeline Architecture	10.1109/TVCG.2007.70600	http://dx.doi.org/10.1109/TVCG.2007.70600	1376	1383	4376164	data acquisition;data visualisation;parallel architectures	data acquisition technology;data streaming;parallel cluster computer;parallel distributed-memory computers;parallel distributed-memory environments;parallel pipeline architecture;temporal processing;time dependent processing;time varying data;visualization pipelines	Analytical models;Application software;Computer architecture;Concurrent computing;Data visualization;Distributed computing;Interpolation;Libraries;Pipelines;Software algorithms	data-parallel visualization pipeline;time-varying data	Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.	Biddiscombe, J.;Geveci, B.;Martin, K.;Moreland, K.;Thompson, D.	Swiss Nat. Supercomput. Centre, Manno|c|;;;;	37948935700;37282729500;37436263300;37284250900;37265831900
	InfoVis+SciVis	Nov.-Dec. 2007	Multifield	10.1109/TVCG.2007.70615	http://dx.doi.org/10.1109/TVCG.2007.70615	1384	1391	4376165	data visualisation;finite state machines;information theory;statistical analysis	finite state cellular automata;fuzzy application dependent notion;information theoretic concept;local statistical complexity;multifield visualization	Biological system modeling;Biological systems;Computational fluid dynamics;Computational modeling;Computer vision;Data mining;Data visualization;Electromagnetic fields;Electromagnetic modeling;Information theory	Cluster detection analysis;evolution graph view;glyph visualization;molecular dynamics visualization;out-of-core techniques;time-dependent scattered data	Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.	Janicke, H.	Univ. of Leipzig, Leipzig|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive Visual Analysis of Perfusion Data	10.1109/TVCG.2007.70569	http://dx.doi.org/10.1109/TVCG.2007.70569	1392	1399	4376166	correlation methods;medical image processing;principal component analysis	PCA;contrast agent enhancement;coronary heart disease;correlation analysis;diagnostic evaluation;dynamic medical image data;evaluation methods;feature-based approaches;human tissue;interactive visual analysis;medical diagnosis;perfusion data evaluation;principal component analysis;regional blood flow;statistical methods	Biomedical imaging;Blood flow;Data analysis;Diseases;Focusing;Humans;Medical diagnosis;Medical diagnostic imaging;Principal component analysis;Statistical analysis	Integrating InfoVis/SciVis;Multi-field Visualization;Time-varying Volume Data;Visual Data Mining	Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.	Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.	Univ. of Magdeburg, Magdeburg|c|;;;;	37424645600;37546620400;37274158800;37546620600;37424645300
	InfoVis+SciVis	Nov.-Dec. 2007	Variable Interactions in Query-Driven Visualization	10.1109/TVCG.2007.70519	http://dx.doi.org/10.1109/TVCG.2007.70519	1400	1407	4376167	data visualisation;query processing;statistical analysis	correlation field;cumulative distribution function;query-driven visualization;statistical information	Analytical models;Chemicals;Combustion;Data visualization;Distribution functions;Fires;Histograms;Large-scale systems;Performance analysis;Throughput	Multivariate Data;Query-Driven Visualization	Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a users query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.	Gosink, L.J.	Univ. of California, Davis|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Visual Analysis of the Air Pollution Problem in Hong Kong	10.1109/TVCG.2007.70523	http://dx.doi.org/10.1109/TVCG.2007.70523	1408	1415	4376168	air pollution;data visualisation;graph theory;meteorology	Hong Kong;S-shape axis;air pollution problem;circular pixel bar charts;enhanced parallel coordinates;polar systems;weather data visualization;weighted complete graphs	Air pollution;Cities and towns;Data visualization;Environmentally friendly manufacturing techniques;Industrial pollution;Pattern analysis;Power generation;Vehicles;Visual analytics;Wind speed	Weather data visualization;air pollution;parallel coordinates;polar system;visual analytics.	We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.	Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Topological Landscapes: A Terrain Metaphor for Scientific Data	10.1109/TVCG.2007.70601	http://dx.doi.org/10.1109/TVCG.2007.70601	1416	1423	4376169	data visualisation;software tools;user interfaces	feature detection;illustration tools;scientific data visualization;terrain metaphor;terrain topography;topological landscapes;user interfaces;visual analytics	Computer vision;Data visualization;Histograms;Humans;Isosurfaces;Laboratories;Surfaces;Topology;Two dimensional displays;User interfaces	Contour Tree;Feature Detection (primary keyword);SOAR;Terrain;Topology;User Interfaces;Visual Analytics	"Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called ""topological landscapes,"" which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible."	Weber, G.H.;Bremer, P.-T.;Pascucci, V.	Lawrence Berkeley Nat. Lab., Berkeley|c|;;	37411444100;38266676800;38262212300
	InfoVis+SciVis	Nov.-Dec. 2007	IStar: A Raster Representation for Scalable Image and Volume Data	10.1109/TVCG.2007.70572	http://dx.doi.org/10.1109/TVCG.2007.70572	1424	1431	4376170	image representation;image segmentation;rendering (computer graphics);topology	IStar;dual graph;graph structure;graphics hardware;multivariate image;raster representation;real-time rates;real-time rendering;scalable image representation;segmented data set;topology information;volume data	Data analysis;Data visualization;Graphics;Image analysis;Image coding;Image reconstruction;Image segmentation;Pipelines;Rendering (computer graphics);Topology	Compression;Image Representation;Multi-field Visualization;Topology	Topology has been an important tool for analyzing scalar data and flow fields in visualization. In this work, we analyze the topology of multivariate image and volume data sets with discontinuities in order to create an efficient, raster-based representation we call IStar. Specifically, the topology information is used to create a dual structure that contains nodes and connectivity information for every segmentable region in the original data set. This graph structure, along with a sampled representation of the segmented data set, is embedded into a standard raster image which can then be substantially downsampled and compressed. During rendering, the raster image is upsampled and the dual graph is used to reconstruct the original function. Unlike traditional raster approaches, our representation can preserve sharp discontinuities at any level of magnification, much like scalable vector graphics. However, because our representation is raster-based, it is well suited to the real-time rendering pipeline. We demonstrate this by reconstructing our data sets on graphics hardware at real-time rates.	Kniss, J.;Hunt, W.;Potter, K.;Sen, P.	Univ. of New Mexico, Albuquerque|c|;;;	37324263400;37970233500;37665456000;37401656800
	InfoVis+SciVis	Nov.-Dec. 2007	Topologically Clean Distance Fields	10.1109/TVCG.2007.70603	http://dx.doi.org/10.1109/TVCG.2007.70603	1432	1439	4376171	computational geometry;curve fitting;topology	MS complex;Morse theory;curved skeleton representation;filament structures;porous solids;simulated porous solid;topologically clean distance fields;volumetric domain	Analytical models;Computer science;Data analysis;Data visualization;Feature extraction;Laboratories;Materials science and technology;Projectiles;Scientific computing;Solid modeling	Morse theory;Morse-Smale complex;critical point;distance field;material science;porous solid;topological simplification;wavefront	"Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the ""difference"" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact."	Gyulassy, A.G.;Duchaineau, M.A.;Natarajan, V.;Pascucci, V.;Bringa, Eduardo M.;Hamann, B.	Univ. of California at Davis, Davis|c|;;;;;	37870001700;37267813100;37278509300;38262212300;37320622500;37282068700
	InfoVis+SciVis	Nov.-Dec. 2007	Efficient Computation of Morse-Smale Complexes for Three-dimensional Scalar Functions	10.1109/TVCG.2007.70552	http://dx.doi.org/10.1109/TVCG.2007.70552	1440	1447	4376172	computational geometry;data structures;data visualisation;topology	Morse-Smale complex;geometry;gradient behavior representation;three-dimensional scalar function;topological data structure;topology-based visualization	Computer science;Computer vision;Data analysis;Data structures;Data visualization;Geometry;Isosurfaces;Surface topography;Topology;Tree graphs	3D scalar fields;Morse theory;Morse-Smale complexes;computational topology;feature detection;multiresolution;simplification	The Morse-Smale complex is an efficient representation of the gradient behavior of a scalar function, and critical points paired by the complex identify topological features and their importance. We present an algorithm that constructs the Morse-Smale complex in a series of sweeps through the data, identifying various components of the complex in a consistent manner. All components of the complex, both geometric and topological, are computed, providing a complete decomposition of the domain. Efficiency is maintained by representing the geometry of the complex in terms of point sets.	Gyulassy, A.;Natarajan, V.;Pascucci, V.;Hamann, B.	Univ. of California, Davis|c|;;;	37870001700;37278509300;37284312600;37282068700
	InfoVis+SciVis	Nov.-Dec. 2007	Similarity-Guided Streamline Placement with Error Evaluation	10.1109/TVCG.2007.70595	http://dx.doi.org/10.1109/TVCG.2007.70595	1448	1455	4376173	data visualisation;error statistics;flow visualisation	Boolean decision;Euclidean distance;error evaluation;flow;quantitative error metric;shape matching;similarity-guided streamline placement;streamline representation	Computer vision;Convolution;Euclidean distance;Extraterrestrial measurements;Magnetic field measurement;Magnetic fields;Magnetic properties;Magnetohydrodynamics;Robustness;Shape measurement	Adaptive streamlines;shape matching;vector field reconstruction	Most streamline generation algorithms either provide a particular density of streamlines across the domain or explicitly detect features, such as critical points, and follow customized rules to emphasize those features. However, the former generally includes many redundant streamlines, and the latter requires Boolean decisions on which points are features (and may thus suffer from robustness problems for real-world data). We take a new approach to adaptive streamline placement for steady vector fields in 2D and 3D. We define a metric for local similarity among streamlines and use this metric to grow streamlines from a dense set of candidate seed points. The metric considers not only Euclidean distance, but also a simple statistical measure of shape and directional similarity. Without explicit feature detection, our method produces streamlines that naturally accentuate regions of geometric interest. In conjunction with this method, we also propose a quantitative error metric for evaluating a streamline representation based on how well it preserves the information from the original vector field. This error metric reconstructs a vector field from points on the streamline representation and computes a difference of the reconstruction from the original vector field.	Yuan Chen;Cohen, J.D.;Krolik, J.H.	Johns Hopkins Univ., Baltimore|c|;;	37965943900;37275763600;37955208400
	InfoVis+SciVis	Nov.-Dec. 2007	Efficient Visualization of Lagrangian Coherent Structures by Filtered AMR Ridge Extraction	10.1109/TVCG.2007.70554	http://dx.doi.org/10.1109/TVCG.2007.70554	1456	1463	4376174	Lyapunov methods;computational fluid dynamics;feature extraction;filtering theory;flow visualisation;mesh generation	Lagrangian coherent structure visualization;adaptive mesh refinement;arbitrary sampling grids;filtered AMR ridge extraction;finite Lyapunov exponent fields;vector fields	Adaptive filters;Adaptive mesh refinement;Computational efficiency;Fluid dynamics;Grid computing;Isosurfaces;Lagrangian functions;Sampling methods;Topology;Visualization	coherent structures;flow visualization;ridge extraction;unsteady vector fields;vector field topology	This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.	Sadlo, F.;Peikert, R.	ETH Zurich, Zurich|c|;	37282541900;37282541100
	InfoVis+SciVis	Nov.-Dec. 2007	Efficient Computation and Visualization of Coherent Structures in Fluid Flow Applications	10.1109/TVCG.2007.70551	http://dx.doi.org/10.1109/TVCG.2007.70551	1464	1471	4376175	Lyapunov methods;computational fluid dynamics;data visualisation;flow visualisation	Lagrangian structure;coherent structure;data visualization;finite-time Lyapunov exponent;fluid flow visualization;space-time flow domain	Automotive engineering;Biomedical engineering;Computational efficiency;Computer vision;Data analysis;Fluid flow;Lagrangian functions;Object detection;Performance analysis;Visualization	3D vector field visualization;feature detection;flow visualization	The recently introduced notion of Finite-Time Lyapunov Exponent to characterize Coherent Lagrangian Structures provides a powerful framework for the visualization and analysis of complex technical flows. Its definition is simple and intuitive, and it has a deep theoretical foundation. While the application of this approach seems straightforward in theory, the associated computational cost is essentially prohibitive. Due to the Lagrangian nature of this technique, a huge number of particle paths must be computed to fill the space-time flow domain. In this paper, we propose a novel scheme for the adaptive computation of FTLE fields in two and three dimensions that significantly reduces the number of required particle paths. Furthermore, for three-dimensional flows, we show on several examples that meaningful results can be obtained by restricting the analysis to a well-chosen plane intersecting the flow domain. Finally, we examine some of the visualization aspects of FTLE-based methods and introduce several new variations that help in the analysis of specific aspects of a flow.	Garth, C.;Gerhardt, F.;Tricoche, X.	Univ. of Kaiserslautern, Kaiserslautern|c|;;	37282573700;37645639800;37282575100
	InfoVis+SciVis	Nov.-Dec. 2007	Texture-based feature tracking for effective time-varying data visualization	10.1109/TVCG.2007.70599	http://dx.doi.org/10.1109/TVCG.2007.70599	1472	1479	4376176	data visualisation;feature extraction;image texture;tracking	effective time-varying data visualization;image registration;texture-based feature tracking	Computational fluid dynamics;Data mining;Data visualization;Electronic mail;Fluid dynamics;Hurricanes;IEEE members;Predictive models;Tracking;Weather forecasting	Feature tracking;flow visualization;texture-based analysis;time-varying data;visualization	Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.	Caban, J.J.;Joshi, A.;Rheingans, P.	Univ. of Maryland Baltimore County, Baltimore|c|;;	38259877600;37278517400;37282292000
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver	10.1109/TVCG.2007.70571	http://dx.doi.org/10.1109/TVCG.2007.70571	1480	1487	4376177	biodiffusion;biology computing;biomedical MRI;brain;data visualisation;iterative methods;neurophysiology;tensors	DT-MRI;FIM;GPU;brain;diffusion tensor magnetic resonance imaging;fast iterative method;graphics processing unit;interactive visualization;numerical algorithm;parallel-hardware Hamilton-Jacobi solver;volumetric optimal path analysis;volumetric white matter connectivity	Anisotropic magnetoresistance;Concurrent computing;Costs;Diffusion tensor imaging;Equations;Graphics;Iterative algorithms;Radio access networks;Tensile stress;Visualization	Diffusion tensor visualization;graphics hardware;interactivity.	In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (graphics processing unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the fast iterative method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.	Jeong, W.-K.;Fletcher, P.T.;Ran Tao;Whitaker, R.T.	Univ. of Utah, Salt Lake City|c|;;;	37268212100;37266394000;37958455500;37267322600
	InfoVis+SciVis	Nov.-Dec. 2007	Visualizing Whole-Brain DTI Tractography with GPU-based Tuboids and LoD Management	10.1109/TVCG.2007.70532	http://dx.doi.org/10.1109/TVCG.2007.70532	1488	1495	4376178	biomedical MRI;brain;computer graphic equipment;data visualisation;diseases;medical image processing;optimisation;rendering (computer graphics)	GPU-based rendering technique;GPU-based tuboid;Phong shading;curvature-correct text labeling;diffusion tensor imaging;diseases;environment mapping;fragment processing load;fully-shaded streamtube impostor;human brain;input geometry;level-of-detail management;occlusion query-based pathway;raycast normal computation;scheduling scheme;texture-based draft shading;tractography technique;vertex processing	Computer graphics;Data mining;Diffusion tensor imaging;Diseases;Hardware;Humans;Labeling;Rendering (computer graphics);Streaming media;Visualization	Tuboids;interactive gpu-centric rendering;neuronal pathways.;streamtubes	Diffusion tensor imaging (DTI) of the human brain, coupled with tractography techniques, enable the extraction of large- collections of three-dimensional tract pathways per subject. These pathways and pathway bundles represent the connectivity between different brain regions and are critical for the understanding of brain related diseases. A flexible and efficient GPU-based rendering technique for DTI tractography data is presented that addresses common performance bottlenecks and image-quality issues, allowing interactive render rates to be achieved on commodity hardware. An occlusion query-based pathway LoD management system for streamlines/streamtubes/tuboids is introduced that optimizes input geometry, vertex processing, and fragment processing loads, and helps reduce overdraw. The tuboid, a fully-shaded streamtube impostor constructed entirely on the GPU from streamline vertices, is also introduced. Unlike full streamtubes and other impostor constructs, tuboids require little to no preprocessing or extra space over the original streamline data. The supported fragment processing levels of detail range from texture-based draft shading to full raycast normal computation, Phong shading, environment mapping, and curvature-correct text labeling. The presented text labeling technique for tuboids provides adaptive, aesthetically pleasing labels that appear attached to the surface of the tubes. Furthermore, an occlusion query aggregating and scheduling scheme for tuboids is described that reduces the query overhead. Results for a tractography dataset are presented, and demonstrate that LoD-managed tuboids offer benefits over traditional streamtubes both in performance and appearance.	Petrovic, V.	Univ. of California at Irvine, Irvine|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Topological Visualization of Brain Diffusion MRI Data	10.1109/TVCG.2007.70602	http://dx.doi.org/10.1109/TVCG.2007.70602	1496	1503	4376179	biodiffusion;biomedical MRI;brain;data visualisation;feature extraction;medical image processing;probability;tracking	brain diffusion MRI data visualization;feature extraction;generic tensor fields;probabilistic fiber tracking method;topological visualization	Algorithm design and analysis;Anatomy;Brain;Data visualization;Humans;Magnetic resonance imaging;Noise robustness;Tensile stress;Topology;Uncertainty	Diffusion tensor;probabilistic fiber tracking;tensor topology;uncertainty visualization.	Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.	Schultz, T.;Theisel, H.;Seidel, H.-P.	MPI Inf., Saarbrucken|c|;;	37606352800;37266875400;37271851300
	InfoVis+SciVis	Nov.-Dec. 2007	Stochastic DT-MRI Connectivity Mapping on the GPU	10.1109/TVCG.2007.70597	http://dx.doi.org/10.1109/TVCG.2007.70597	1504	1511	4376180	Bayes methods;biodiffusion;biomedical MRI;brain;computer graphic equipment;data visualisation;medical image processing;neurophysiology;probability;stochastic processes;tensors	Bayesian formulation;GPU;brain;data visualization;diffusion tensor;graphics hardware;graphics processing unit;inversion method;magnetic resonance imaging;neuronal fiber path;parallel algorithm;probability;stochastic DT-MRI connectivity mapping;stochastic fiber tract mapping	Anisotropic magnetoresistance;Diffusion tensor imaging;Ellipsoids;Graphics;Hardware;Injuries;Magnetic resonance imaging;Stochastic processes;Tensile stress;Visualization	diffusion tensor;magnetic resonance imaging;stochastic tractography	We present a method for stochastic fiber tract mapping from diffusion tensor MRI (DT-MRI) implemented on graphics hardware. From the simulated fibers we compute a connectivity map that gives an indication of the probability that two points in the dataset are connected by a neuronal fiber path. A Bayesian formulation of the fiber model is given and it is shown that the inversion method can be used to construct plausible connectivity. An implementation of this fiber model on the graphics processing unit (GPU) is presented. Since the fiber paths can be stochastically generated independently of one another, the algorithm is highly parallelizable. This allows us to exploit the data-parallel nature of the GPU fragment processors. We also present a framework for the connectivity computation on the GPU. Our implementation allows the user to interactively select regions of interest and observe the evolving connectivity results during computation. Results are presented from the stochastic generation of over 250,000 fiber steps per iteration at interactive frame rates on consumer-grade graphics hardware.	McGraw, T.;Nadar, M.	West Virginia Univ, Morgantown|c|;	37294450700;37294453300
	InfoVis+SciVis	Nov.-Dec. 2007	Efficient Surface Reconstruction using Generalized Coulomb Potentials	10.1109/TVCG.2007.70553	http://dx.doi.org/10.1109/TVCG.2007.70553	1512	1519	4376181	computational geometry;electric potential;octrees;surface fitting	adaptive grid;distance transform;fast convection algorithm;generalized Coulomb potentials;geometrically adaptive method;noisy point clouds;octree;sparse point clouds;surface reconstruction	Clouds;Mathematics;Noise level;Noise robustness;Surface contamination;Surface fitting;Surface reconstruction;Tagging;Topology	Generalized Coulomb potentials;Implicit surfaces;Octrees;Polygonization;Surface reconstruction	We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.	Jalba, A.C.;Roerdink, J.B.T.M.	Univ. of Groningen, Groningen|c|;	37279264300;37279298200
	InfoVis+SciVis	Nov.-Dec. 2007	Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT	10.1109/TVCG.2007.70598	http://dx.doi.org/10.1109/TVCG.2007.70598	1520	1527	4376182	computerised tomography;data visualisation;image fusion;image registration;image resolution;measurement;medical image processing;surface fitting	dual X-ray exposure technology;dual energy computed tomography;image fusion;metrology;multimaterial component;surface extraction;surface geometry	Computed tomography;Computer industry;Data mining;Density measurement;Energy resolution;Image fusion;Metrology;Noise reduction;Testing;X-ray imaging	DECT image fusion;Dual Energy CT;dimensional measurement;local surface extraction;metrology;variance comparison.	This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.	Heinzl, C.;Kastner, J.	Upper Austrian Univ. of Appl. Sci., Wels|c|;	37400391300;37947609000
	InfoVis+SciVis	Nov.-Dec. 2007	Construction of Simplified Boundary Surfaces from Serial-sectioned Metal Micrographs	10.1109/TVCG.2007.70543	http://dx.doi.org/10.1109/TVCG.2007.70543	1528	1535	4376183	computational complexity;computational geometry;data visualisation;feature extraction;grain boundaries;image segmentation;interpolation;materials testing;mesh generation;physics computing;surface structure;tantalum	boundary interpolation methods;constrained Potts model;marching tetrahedra methods;polycrystal grain boundary surface construction;segmented cross-section image data;serial-sectioned metal micrographs;simplified boundary surface construction;surface complexity;triangulated boundary surface extraction;voxel-accurate simplification algorithm	Application software;Computer graphics;Crystalline materials;Data analysis;Data mining;Data visualization;Grain boundaries;Image segmentation;Materials science and technology;Surface morphology	Life Sciences and Engineering;Polygonal meshes;Surface extraction;Visualization in Physical Sciences	We present a method for extracting boundary surfaces from segmented cross-section image data. We use a constrained Potts model to interpolate an arbitrary number of region boundaries between segmented images. This produces a segmented volume from which we extract a triangulated boundary surface using well-known marching tetrahedra methods. This surface contains staircase-like artifacts and an abundance of unnecessary triangles. We describe an approach that addresses these problems with a voxel-accurate simplification algorithm that reduces surface complexity by an order of magnitude. Our boundary interpolation and simplification methods are novel contributions to the study of surface extraction from segmented cross-sections. We have applied our method to construct polycrystal grain boundary surfaces from micrographs of a sample of the metal tantalum.	Dillard, S.E.;Bingert, J.F.;Thoma, D.;Hamann, B.	Univ. of California, Davis|c|;;;	37945275200;37377270300;38182096600;37282068700
	InfoVis+SciVis	Nov.-Dec. 2007	Random-Accessible Compressed Triangle Meshes	10.1109/TVCG.2007.70585	http://dx.doi.org/10.1109/TVCG.2007.70585	1536	1543	4376184	application program interfaces;cache storage;computational geometry;mesh generation	API;I/O request;cache-coherent layout;cache-oblivious layout;data transfer;disk storage;multilevel cache;novel order-preserving compression method;random-accessible compressed triangle mesh;sequential access compression scheme	Bandwidth;Cache storage;Computational modeling;Computer displays;Data structures;Data visualization;Decoding;Delay;Memory management;Space technology	Mesh compression;cache-coherent layouts;external memory algorithms;mesh data structures;random access	With the exponential growth in size of geometric data, it is becoming increasingly important to make effective use of multilevel caches, limited disk storage, and bandwidth. As a result, recent work in the visualization community has focused either on designing sequential access compression schemes or on producing cache-coherent layouts of (uncompressed) meshes for random access. Unfortunately combining these two strategies is challenging as they fundamentally assume conflicting modes of data access. In this paper, we propose a novel order-preserving compression method that supports transparent random access to compressed triangle meshes. Our decompression method selectively fetches from disk, decodes, and caches in memory requested parts of a mesh. We also provide a general mesh access API for seamless mesh traversal and incidence queries. While the method imposes no particular mesh layout, it is especially suitable for cache-oblivious layouts, which minimize the number of decompression I/O requests and provide high cache utilization during access to decompressed, in-memory portions of the mesh. Moreover, the transparency of our scheme enables improved performance without the need for application code changes. We achieve compression rates on the order of 20:1 and significantly improved I/O performance due to reduced data transfer. To demonstrate the benefits of our method, we implement two common applications as benchmarks. By using cache-oblivious layouts for the input models, we observe 2-6 times overall speedup compared to using uncompressed meshes.	Yoon, S.-E.;Lindstrom, P.	Korea Adv. Inst. of Sci. & Technol.|c|;	37279394100;37269320000
	InfoVis+SciVis	Nov.-Dec. 2007	LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation	10.1109/TVCG.2007.70576	http://dx.doi.org/10.1109/TVCG.2007.70576	1544	1551	4376185	data visualisation;interactive systems;knowledge based systems;medical image processing;rendering (computer graphics)	LiveSync deformed viewing sphere;interactive volume rendering;knowledge-based navigation;medical image;visualization method	Anatomical structure;Biomedical imaging;Computed tomography;Data visualization;Displays;History;Image segmentation;Medical diagnostic imaging;Navigation;Transfer functions	Navigation;interaction;linked views;medical visualization;viewpoint selection.	Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.	Kohlmann, P.;Bruckner, S.;Kanitsar, A.	Vienna Univ. of Technol., Vienna|c|;;	37623778100;37265895700;37282727500
	InfoVis+SciVis	Nov.-Dec. 2007	Navigating in a Shape Space of Registered Models	10.1109/TVCG.2007.70581	http://dx.doi.org/10.1109/TVCG.2007.70581	1552	1559	4376186	CAD;data visualisation;product development	continuous shape space;design criteria;dynamic visualization;product development;registered models;shape-related design criteria	Design engineering;Face;Fingers;Humans;Linear regression;Navigation;Product development;Shape measurement;Solid modeling;Visualization	Morphable model;barycentric coordinates;design space.;shape space	New product development involves people with different backgrounds. Designers, engineers, and consumers all have different design criteria, and these criteria interact. Early concepts evolve in this kind of collaborative context, and there is a need for dynamic visualization of the interaction between design shape and other shape-related design criteria. In this paper, a morphable model is defined from simplified representations of suitably chosen real cars, providing a continuous shape space to navigate, manipulate and visualize. Physical properties and consumer-provided scores for the real cars (such as 'weight' and 'sportiness') are estimated for new designs across the shape space. This coupling allows one to manipulate the shape directly while reviewing the impact on estimated criteria, or conversely, to manipulate the criterial values of the current design to produce a new shape with more desirable attributes.	Smith, R.C.;Pawlicki, R.;Finger, J.;Vetter, T.	GM R&D, Bangalore|c|;;;	37280035100;37282920800;37956948500;37281818300
	InfoVis+SciVis	Nov.-Dec. 2007	Querying and Creating Visualizations by Analogy	10.1109/TVCG.2007.70584	http://dx.doi.org/10.1109/TVCG.2007.70584	1560	1567	4376187	data visualisation;meta data;pipeline processing;public domain software;query processing	VisTrails;data exploration;multiview visualizations;open-source system;pipelines;provenance metadata;query-by-example;visual exploration;visualization systems	Application software;Data engineering;Data mining;Data visualization;Isosurfaces;Open source software;Pipelines;Programming profession;Software systems;User interfaces	analogy;query-by-example;visualization systems	While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.	Scheidegger, C.E.;Vo, H.T.;Koop, D.;Freire, J.;Silva, C.T.	Univ. of Utah, Salt Lake|c|;;;;	37550809300;37549893300;37647314800;37283149600;37275249200
	InfoVis+SciVis	Nov.-Dec. 2007	Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding	10.1109/TVCG.2007.70544	http://dx.doi.org/10.1109/TVCG.2007.70544	1568	1575	4376188	data visualisation;video signal processing	3D spatial context;complex environments;contextualized videos;multiple spatially-related videos;spatial relationships;video surveillance;video texture projection	Buildings;Cameras;Context modeling;Security;Space exploration;Space technology;Surveillance;Testing;Videos;Visualization	design space;situational awareness;testbed design and evaluation.;videos;virtual environment models	Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person's path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.	Yi Wang;Krum, D.M.;Coelho, E.M.;Bowman, D.A.	Virginia Tech., Blacksburg|c|;;;	37601156200;37391946800;37875473700;37282977600
	InfoVis+SciVis	Nov.-Dec. 2007	Lattice-Based Volumetric Global Illumination	10.1109/TVCG.2007.70573	http://dx.doi.org/10.1109/TVCG.2007.70573	1576	1583	4376189	data visualisation;lighting;physics computing;rendering (computer graphics)	angular discretization;face-centered cubic lattice;lattice-based volumetric global illumination;multiple scattering;packing density;rendering	FCC;Lattices;Light scattering;Lighting;Optical scattering;Particle scattering;Rendering (computer graphics);Sampling methods;Vectors;Visualization	FCC lattice;GPU.;Volume visualization;lattice;multiple scattering;participating media;sampling;volume rendering	We describe a novel volumetric global illumination framework based on the face-centered cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.	Feng Qiu;Fang Xu;Zhe Fan;Neophytos, N.;Kaufman, A.;Mueller, K.	Stony Brook Univ., Stony Brook|c|;;;;;	37416126400;37275296400;37273608100;37945247700;37268052800;37273119700
	InfoVis+SciVis	Nov.-Dec. 2007	A Flexible Multi-Volume Shader Framework for Arbitrarily Intersecting Multi-Resolution Datasets	10.1109/TVCG.2007.70534	http://dx.doi.org/10.1109/TVCG.2007.70534	1584	1591	4376190	octrees;rendering (computer graphics)	3D-texture-based rendering;GPU-based depth peeling technique;convex polyhedral volume lenses;flexible multivolume shader framework;intersecting multiresolution datasets;multiple intersecting multi-gigabyte volumes;multiresolution octree-based structure;out-of-core techniques;slice-based volume rendering;view-dependent octree traversal;volumetric datasets	Data visualization;Displays;Geometry;Graphics;Lenses;Petroleum;Pipelines;Rendering (computer graphics);Solids;Spatial resolution	Multi-volume visualization;constructive solid geometry;display algorithms;shading	We present a powerful framework for 3D-texture-based rendering of multiple arbitrarily intersecting volumetric datasets. Each volume is represented by a multi-resolution octree-based structure and we use out-of-core techniques to support extremely large volumes. Users define a set of convex polyhedral volume lenses, which may be associated with one or more volumetric datasets. The volumes or the lenses can be interactively moved around while the region inside each lens is rendered using interactively defined multi-volume shaders. Our rendering pipeline splits each lens into multiple convex regions such that each region is homogenous and contains a fixed number of volumes. Each such region is further split by the brick boundaries of the associated octree representations. The resulting puzzle of lens fragments is sorted in front-to-back or back-to-front order using a combination of a view-dependent octree traversal and a GPU-based depth peeling technique. Our current implementation uses slice-based volume rendering and allows interactive roaming through multiple intersecting multi-gigabyte volumes.	Plate, J.;Froehlich, B.	Bauhaus-Univ. Weimar, Weimar|c|;	37442670800;37282977500
	InfoVis+SciVis	Nov.-Dec. 2007	Scalable Hybrid Unstructured and Structured Grid Raycasting	10.1109/TVCG.2007.70588	http://dx.doi.org/10.1109/TVCG.2007.70588	1592	1599	4376191	ray tracing;rendering (computer graphics)	focus-context technique;grid raycasting;hardware-assisted volume rendering;hybrid bricking approach;interactive specification;visibility sorting	Computational fluid dynamics;Computational modeling;Data visualization;Finite volume methods;Grid computing;Interpolation;Memory management;Quality management;Sorting;Temperature	Focus+Context Techniques;Hardware-Assisted Volume Rendering;Volume Rendering of Unstructured Grids	This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.	Muigg, P.;Hadwiger, M.;Doleisch, H.;Hauser, H.	VRVis Res. Center|c|;;;	37546620600;37394809600;37546620400;37274158800
	InfoVis+SciVis	Nov.-Dec. 2007	Transform Coding for Hardware-accelerated Volume Rendering	10.1109/TVCG.2007.70516	http://dx.doi.org/10.1109/TVCG.2007.70516	1600	1607	4376192	computer graphic equipment;data compression;real-time systems;rendering (computer graphics);transform coding	GPU;compression quality;decompression;dequantization;graphics memory;hardware-accelerated volume rendering;inverse transform;large volume data sets;real-time volume rendering;software volume rendering;transform coding;volumetric compression	Data visualization;Decoding;Encoding;Graphics;Hardware;Pipelines;Production;Rendering (computer graphics);Resource management;Transform coding	Compressed Volume Rendering;Hardware-accelerated Volume Rendering;Transform Coding;Volume Compression	Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.	Fout, N.	Univ. of California, Davis|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Molecular Surface Abstraction	10.1109/TVCG.2007.70578	http://dx.doi.org/10.1109/TVCG.2007.70578	1608	1615	4376193	biochemistry;biology computing;chemistry computing;data visualisation;molecular biophysics;molecular configurations;proteins;rendering (computer graphics)	electrostatic charge;mesh restructuring;molecular surface abstraction;protein;spatio-physico-chemical property;structural biology;stylized rendering algorithm;surface marking;visualization technique	Chemical processes;Displays;Electrostatics;Filters;Labeling;Mesh generation;Proteins;Shape;Surface texture;Visualization	cartographic labeling;molecular surfaces;molecular visualization;surfaces;textures	In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.	Cipriano, G.;Gleicher, M.	Univ. of Wisconsin, Madison|c|;	37882969500;37282585700
	InfoVis+SciVis	Nov.-Dec. 2007	Two-Level Approach to Efficient Visualization of Protein Dynamics	10.1109/TVCG.2007.70517	http://dx.doi.org/10.1109/TVCG.2007.70517	1616	1623	4376194	biology computing;data visualisation;groupware;proteins;rendering (computer graphics)	collaborative bioinformatics project;graphics hardware geometry shader capability;graphics processor unit;protein dynamics;slow dynamics visualization;two-level rendering approach	Amino acids;Assembly;Biology computing;Computational modeling;Computer Society;Graphics;Hardware;Large-scale systems;Proteins;Visualization	Molecular visualization;hardware acceleration;protein dynamics.	Proteins are highly flexible and large amplitude deformations of their structure, also called slow dynamics, are often decisive to their function. We present a two-level rendering approach that enables visualization of slow dynamics of large protein assemblies. Our approach is aligned with a hierarchical model of large scale molecules. Instead of constantly updating positions of large amounts of atoms, we update the position and rotation of residues, i.e., higher level building blocks of a protein. Residues are represented by one vertex only indicating its position and additional information defining the rotation. The atoms in the residues are generated on-the-fly on the GPU, exploiting the new graphics hardware geometry shader capabilities. Moreover, we represent the atoms by billboards instead of tessellated spheres. Our representation is then significantly faster and pixel precise. We demonstrate the usefulness of our new approach in the context of our collaborative bioinformatics project.	Lampe, O.D.	Christian Michelsen Res., Bergen|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Visual Verification and Analysis of Cluster Detection for Molecular Dynamics	10.1109/TVCG.2007.70614	http://dx.doi.org/10.1109/TVCG.2007.70614	1624	1631	4376195	molecular dynamics method;nucleation	condensation processes;energy efficiency;molecular cluster detection algorithm;molecular datasets;molecular thermodynamics;nucleation simulations;potential cluster evolution;steam turbines;vapor-liquid condensation;visual verification	Clouds;Clustering algorithms;Data visualization;Detection algorithms;Energy efficiency;Energy resolution;Interactive systems;Metastasis;Thermodynamics;Turbines	Cluster detection analysis;evolution graph view;glyph visualization;molecular dynamics visualization;out-of-core techniques;time-dependent scattered data	A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.	Grottel, S.	Univ. Stuttgart, Stuttgart|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	CoViCAD: Comprehensive Visualization of Coronary Artery Disease	10.1109/TVCG.2007.70550	http://dx.doi.org/10.1109/TVCG.2007.70550	1632	1639	4376196	biomedical MRI;cardiology;data visualisation;image segmentation;medical image processing	CoViCAD;bulls eye plot;coronary artery disease;coronary artery tree;late enhancement contours;late enhancement data;medical visualization;patient diagnosis;polygonal heart model;segmented cardiac MRI data;visualization;whole heart anatomical data	Arteries;Blood;Coronary arteriosclerosis;Data visualization;Heart;Magnetic resonance imaging;Medical diagnostic imaging;Muscles;Myocardium;Protocols	Cardiac MRI;bull's eye plot.;late enhancement;viability	We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.	Termeer, M.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.	Vienna Univ. of Technol., Vienna|c|;;;	37869997400;37374875300;37282551500;37374887400
	InfoVis+SciVis	Nov.-Dec. 2007	Visualizing Large-Scale Uncertainty in Astrophysical Data	10.1109/TVCG.2007.70530	http://dx.doi.org/10.1109/TVCG.2007.70530	1640	1647	4376197	astronomy computing;data visualisation;rendering (computer graphics)	large-scale virtual astrophysical environment;log-scale distance;magic-glass design;trajectory uncertainty;uncertainty visualization;unified color-coding scheme	Astronomy;Buildings;Context modeling;Data engineering;Data visualization;Earth;Ellipsoids;Extraterrestrial measurements;Large-scale systems;Uncertainty	Uncertainty visualization;astronomy.;interstellar data;large spatial scale	Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.	Hongwei Li	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation	10.1109/TVCG.2007.70518	http://dx.doi.org/10.1109/TVCG.2007.70518	1648	1655	4376198	biological tissues;computer animation;data visualisation;image classification;medical image processing;probability;rendering (computer graphics);uncertainty handling	diagnostic medical imaging;direct user interaction;direct volume rendering;medical data sets;medical volume rendering;probabilistic animation;probabilistic transfer function model;tissue classification task;uncertainty visualization	Animation;Biomedical imaging;Computed tomography;Data visualization;Focusing;Medical diagnostic imaging;Medical simulation;Sampling methods;Transfer functions;Uncertainty	Uncertainty;medical visualization;probability;transfer function;volume rendering	"Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a ""sensitivity lens"" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy."	Lundstrom, C.	Linkoping Univ., Linkoping|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Grid With a View: Optimal Texturing for Perception of Layered Surface Shape	10.1109/TVCG.2007.70559	http://dx.doi.org/10.1109/TVCG.2007.70559	1656	1663	4376199	data visualisation;grid computing;image texture	layered surface shape perception;layered surface visualizations;optimal texturing;projected grid textures;relative texture spacing	Biomedical imaging;Data visualization;Geologic measurements;Geology;Humans;Isosurfaces;Pediatrics;Probes;Shape control;Surface texture	Perception;layered surfaces.;optimal visualization;texturing	We present the results of two controlled studies comparing layered surface visualizations under various texture conditions. The task was to estimate surface normals, measured by accuracy of a hand-set surface normal probe. A single surface visualization was compared with the two-surfaces case under conditions of no texture and with projected grid textures. Variations in relative texture spacing on top and bottom surfaces were compared, as well as opacity of the top surface. Significant improvements are found for the textured cases over non-textured surfaces. Either larger or thinner top-surface textures, and lower top surface opacities are shown to give less bottom surface error. Top surface error appears to be highly resilient to changes in texture. Given the results we also present an example of how appropriate textures might be useful in volume visualization.	Bair, A.;House, D.	Texas A&M Univ., College Station|c|;	37565577300;37284216700
	InfoVis+SciVis	Nov.-Dec. 2007	Conjoint Analysis to Measure the Perceived Quality in Volume Rendering	10.1109/TVCG.2007.70542	http://dx.doi.org/10.1109/TVCG.2007.70542	1664	1671	4376200	data visualisation;rendering (computer graphics)	conjoint analysis;market research;perceived quality;user feedback;visualization algorithms;volume rendering	Data visualization;Design engineering;Feedback;Focusing;Humans;Market research;Psychology;Rendering (computer graphics);Testing;Volume measurement	Conjoint Analysis;Parameterized Algorithms;Volume Visualization	Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.	Giesen, J.;Mueller, K.;Schuberth, E.;Lujin Wang;Zolliker, P.	Univ. des Saarlandes, Saarbrucken|c|;;;;	37325999500;37273119700;37703642700;37280763200;37680882500
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive sound rendering in complex and dynamic scenes using frustum tracing	10.1109/TVCG.2007.70567	http://dx.doi.org/10.1109/TVCG.2007.70567	1672	1679	4376201	acoustic signal processing;interactive systems;ray tracing;rendering (computer graphics)	complex-dynamic scene;frustum tracing;interactive sound rendering;interactive system;ray packet tracing;virtual scene	Acceleration;Acoustic beams;Acoustic reflection;Computational modeling;Data visualization;Hardware;Layout;Optical reflection;Ray tracing;Rendering (computer graphics)	Acoustic propagation;Ray tracing	We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.	Lauterbach, C.;Chandak, A.;Manocha, D.	Univ. of North Carolina-Chapel Hill, Chapel Hill|c|;;	37606258500;37883391100;37267825600
	InfoVis+SciVis	Nov.-Dec. 2007	Listener-based Analysis of Surface Importance for Acoustic Metrics	10.1109/TVCG.2007.70575	http://dx.doi.org/10.1109/TVCG.2007.70575	1680	1687	4376202	architectural acoustics;data visualisation;transient response	acoustic metrics;acoustic quality measure;impulse response;listener-based analysis;phonon tracing;room acoustics visualization;speech clarity;speech comprehensibility	Absorption;Acoustic applications;Acoustic measurements;Acoustic reflection;Data visualization;Frequency;Geometry;Optical reflection;Optical surface waves;Phonons	Acoustic Metric;Applications of Visualization;Phonon Tracing;Room Acoustics;Sound analytics		Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.	IRTG Kaiserslautern, Kaiserslautern|c|;;;;	37838754300;37282727900;37945296000;37282573700;37282578800
	InfoVis+SciVis	Nov.-Dec. 2007	Shadow-Driven 4D Haptic Visualization	10.1109/TVCG.2007.70593	http://dx.doi.org/10.1109/TVCG.2007.70593	1688	1695	4376203	data visualisation;force feedback;haptic interfaces;rendering (computer graphics)	2D haptic interface;2D knot diagrams;2D pen-and-paper;2D shadow-driven editing protocol;3D architectural design;3D mathematical knots;4D haptic visualization;4D shapes;blackboard skills;collision-sensing haptics;force feedback;higher-dimensional objects;natural analogy;reactive 3D shadow-space controllers;reduced- dimension shadows;two-dimensional floor plans	Education;Floors;Geometry;Graphics;Haptic interfaces;Mathematical model;Protocols;Rendering (computer graphics);Shape;Visualization	haptics;knot theory;visualization	"Just as we can work with two-dimensional floor plans to communicate 3D architectural design, we can exploit reduced- dimension shadows to manipulate the higher-dimensional objects generating the shadows. In particular, by taking advantage of physically reactive 3D shadow-space controllers, we can transform the task of interacting with 4D objects to a new level of physical reality. We begin with a teaching tool that uses 2D knot diagrams to manipulate the geometry of 3D mathematical knots via their projections; our unique 2D haptic interface allows the user to become familiar with sketching, editing, exploration, and manipulation of 3D knots rendered as projected images on a 2D shadow space. By combining graphics and collision-sensing haptics, we can enhance the 2D shadow-driven editing protocol to successfully leverage 2D pen-and-paper or blackboard skills. Building on the reduced-dimension 2D editing tool for manipulating 3D shapes, we develop the natural analogy to produce a reduced-dimension 3D tool for manipulating 4D shapes. By physically modeling the correct properties of 4D surfaces, their bending forces, and their collisions in the 3D haptic controller interface, we can support full-featured physical exploration of 4D mathematical objects in a manner that is otherwise far beyond the experience accessible to human beings. As far as we are aware, this paper reports the first interactive system with force-feedback that provides ""4D haptic visualization"" permitting the user to model and interact with 4D cloth-like objects."	Hui Zhang;Hanson, A.J.	Indiana Univ., Bloomington|c|;	37559775500;37333439100
	InfoVis+SciVis	Nov.-Dec. 2007	High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions	10.1109/TVCG.2007.70560	http://dx.doi.org/10.1109/TVCG.2007.70560	1696	1703	4376204	computer vision;data visualisation;medical computing;rendering (computer graphics);surgery	concurrent 3D visualization;graphics hardware;high-quality multimodal volume rendering;multi-volume raycasting;neurosurgical interventions preoperative planning;optimal skin incision;radiological imaging	Anatomy;Brain;Graphics;Neurosurgery;Pathology;Process planning;Skin;Skull;Surgery;Visualization	Hardware Assisted Raycasting;Multimodal Volume Rendering;Surgery Planning	Surgical approaches tailored to an individual patient's anatomy and pathology have become standard in neurosurgery. Precise preoperative planning of these procedures, however, is necessary to achieve an optimal therapeutic effect. Therefore, multiple radiological imaging modalities are used prior to surgery to delineate the patient's anatomy, neurological function, and metabolic processes. Developing a three-dimensional perception of the surgical approach, however, is traditionally still done by mentally fusing multiple modalities. Concurrent 3D visualization of these datasets can, therefore, improve the planning process significantly. In this paper we introduce an application for planning of individual neurosurgical approaches with high-quality interactive multimodal volume rendering. The application consists of three main modules which allow to (1) plan the optimal skin incision and opening of the skull tailored to the underlying pathology; (2) visualize superficial brain anatomy, function and metabolism; and (3) plan the patient-specific approach for surgery of deep-seated lesions. The visualization is based on direct multi-volume raycasting on graphics hardware, where multiple volumes from different modalities can be displayed concurrently at interactive frame rates. Graphics memory limitations are avoided by performing raycasting on bricked volumes. For preprocessing tasks such as registration or segmentation, the visualization modules are integrated into a larger framework, thus supporting the entire workflow of preoperative planning.	Beyer, J.;Hadwiger, M.;Wolfsberger, S.	VRVis Res. Center, Vienna|c|;;	37409575800;37394809600;37282642600
	InfoVis+SciVis	Nov.-Dec. 2007	Topology, Accuracy, and Quality of Isosurface Meshes Using Dynamic Particles	10.1109/TVCG.2007.70604	http://dx.doi.org/10.1109/TVCG.2007.70604	1704	1711	4376205	mesh generation;partial differential equations	Delaunay triangulation;dynamic particle;isosurface triangulation;partial differential equation;surface sampling theory	Biomedical measurements;Data visualization;Geometry;Image reconstruction;Interpolation;Isosurfaces;Numerical simulation;Sampling methods;Solid modeling;Topology	Delaunay triangulation.;Isosurface extraction;particle systems	This paper describes a method for constructing isosurface triangulations of sampled, volumetric, three-dimensional scalar fields. The resulting meshes consist of triangles that are of consistently high quality, making them well suited for accurate interpolation of scalar and vector-valued quantities, as required for numerous applications in visualization and numerical simulation. The proposed method does not rely on a local construction or adjustment of triangles as is done, for instance, in advancing wavefront or adaptive refinement methods. Instead, a system of dynamic particles optimally samples an implicit function such that the particles' relative positions can produce a topologically correct Delaunay triangulation. Thus, the proposed method relies on a global placement of triangle vertices. The main contributions of the paper are the integration of dynamic particles systems with surface sampling theory and PDE-based methods for controlling the local variability of particle densities, as well as detailing a practical method that accommodates Delaunay sampling requirements to generate sparse sets of points for the production of high-quality tessellations.	Meyer, M.;Kirby, R.M.;Whitaker, R.	Univ. of Utah, Salt Lake City|c|;;	37564728700;37275716100;37267322600
	InfoVis+SciVis	Nov.-Dec. 2007	Visualization of Cosmological Particle-Based Datasets	10.1109/TVCG.2007.70526	http://dx.doi.org/10.1109/TVCG.2007.70526	1712	1718	4376206	astronomical image processing;cosmology;data visualisation;star formation;stellar evolution	ParaView;astronomy mission;cosmic history;cosmic transition tracing;cosmological particle-based dataset visualization;early universe evolution;first stars formation;grid representation;isosurface extraction;particle-based simulation;photon mapping;point simulation data interpolation	Astronomy;Chemical elements;Data mining;Data visualization;Helium;History;Hydrogen;Isosurfaces;Space missions;Telescopes	Astronomy;Cosmology.;Interpolation;Isosurface	We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.	Navratil, P.A.	Univ. of Texas, Austin|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Segmentation of Three-dimensional Retinal Image Data	10.1109/TVCG.2007.70590	http://dx.doi.org/10.1109/TVCG.2007.70590	1719	1726	4376207	data visualisation;image segmentation;medical image processing;optical tomography;support vector machines	data analysis;human retinal diseases;optical coherence tomography;retinal layers;semiautomatic segmentation;support vector machine;three-dimensional retinal image data segmentation;volume visualization	Data analysis;Data visualization;Diseases;Humans;Image segmentation;Noise level;Performance analysis;Retina;Support vector machines;Tomography	image analysis;image processing.;optical coherence tomography;retinal;segmentation;support vector machine;volume visualization	"We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have ""global awareness"". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities."	Fuller, A.R.;Zawadzki, R.J.;Choi, S.;Wiley, D.F.;Werner, J.S.;Hamann, B.	Univ. of California at Davis, Davis|c|;;;;;	37953777500;37945292600;37964205700;37282066500;37950733300;37282068700
	InfoVis+SciVis	Nov.-Dec. 2007	Interactive Isosurface Ray Tracing of Time-Varying Tetrahedral Volumes	10.1109/TVCG.2007.70566	http://dx.doi.org/10.1109/TVCG.2007.70566	1727	1734	4376208	ray tracing;rendering (computer graphics)	aggressive packet/frustum traversal;interactive isosurface ray tracing;polygonal ray tracing;rendering;tetrahedral finite-element scalar fields;time-varying tetrahedral volumes	Computational modeling;Computer graphics;Data mining;Data visualization;Finite element methods;Geometry;Hardware;Isosurfaces;Ray tracing;Workstations	Isosurfaces;Ray Tracing;Scalar Fields;Tetrahedra;Time-varying data.;Unstructured meshes	We describe a system for interactively rendering isosurfaces of tetrahedral finite-element scalar fields using coherent ray tracing techniques on the CPU. By employing state-of-the art methods in polygonal ray tracing, namely aggressive packet/frustum traversal of a bounding volume hierarchy, we can accommodate large and time-varying unstructured data. In conjunction with this efficiency structure, we introduce a novel technique for intersecting ray packets with tetrahedral primitives. Ray tracing is flexible, allowing for dynamic changes in isovalue and time step, visualization of multiple isosurfaces, shadows, and depth-peeling transparency effects. The resulting system offers the intuitive simplicity of isosurfacing, guaranteed-correct visual results, and ultimately a scalable, dynamic and consistently interactive solution for visualizing unstructured volumes.	Wald, I.;Friedrich, H.;Knoll, A.;Hansen, C.D.	Univ. of Utah, Santa Clara|c|;;;	37282958300;37412440500;37692671900;37266777200
	InfoVis+SciVis	Nov.-Dec. 2007	Generalized Streak Lines: Analysis and Visualization of Boundary Induced Vortices	10.1109/TVCG.2007.70557	http://dx.doi.org/10.1109/TVCG.2007.70557	1735	1742	4376209	computational fluid dynamics;confined flow;data visualisation;flow visualisation;shear flow;vortices	boundary induced vortex;computational fluid dynamics;data visualisation;shear flow visualisation;singularity tracking algorithm;streak line	Automobiles;Buildings;Computational modeling;Drag;Fluid flow;Friction;Lead;Stress;Turbines;Visualization	Skin friction;flow visualization;generalized streak line;singularity tracking;time-dependent vector fields.;vortex	We present a method to extract and visualize vortices that originate from bounding walls of three-dimensional time- dependent flows. These vortices can be detected using their footprint on the boundary, which consists of critical points in the wall shear stress vector field. In order to follow these critical points and detect their transformations, affected regions of the surface are parameterized. Thus, an existing singularity tracking algorithm devised for planar settings can be applied. The trajectories of the singularities are used as a basis for seeding particles. This leads to a new type of streak line visualization, in which particles are released from a moving source. These generalized streak lines visualize the particles that are ejected from the wall. We demonstrate the usefulness of our method on several transient fluid flow datasets from computational fluid dynamics simulations.	Wiebel, A.;Tricoche, X.;Schneider, D.;Scheuermann, G.	Univ. Leipzig, Leipzig|c|;;;	37565763400;37282575100;37869538100;37282574800
	InfoVis+SciVis	Nov.-Dec. 2007	Moment Invariants for the Analysis of 2D Flow Fields	10.1109/TVCG.2007.70579	http://dx.doi.org/10.1109/TVCG.2007.70579	1743	1750	4376210	data structures;data visualisation;feature extraction;pattern classification	2D flow field;2D flow pattern extraction;2D flow pattern visualisation;complex flow structures;computer vision application;critical point classification;feature space representation;flow field data visualization;moment invariants;multiscale moment representation;pattern recognition	Algorithm design and analysis;Application software;Computer vision;Data analysis;Data mining;Data visualization;Feature extraction;Pattern analysis;Pattern recognition;Space technology	Feature Detection;Flow Visualization;Image Processing;Pattern Recognition	We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.	Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertram, M.-H.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.	Univ. of Kaiserslautern, Kaiserslautern|c|;;;;;;;;	37946182500;37945209200;37945208900;37282721800;37282067000;37282573700;37722986700;37282068700;37282578800
	InfoVis+SciVis	Nov.-Dec. 2007	Virtual Rheoscopic Fluids for Flow Visualization	10.1109/TVCG.2007.70610	http://dx.doi.org/10.1109/TVCG.2007.70610	1751	1758	4376211	flow visualisation;mechanical engineering computing;rendering (computer graphics)	Taylor-Couette flow simulations;anisotropic particles;complex flow structures;flow velocity;flow visualization techniques;natural convection;shear layers orientation;thermocapillary convection;virtual analogues;virtual rheoscopic fluid rendering;virtual rheoscopic fluids	Additives;Anisotropic magnetoresistance;Computational modeling;Computer vision;Laboratories;Microscopy;Reflectivity;Rendering (computer graphics);Surface texture;Visualization	Flow visualization;rheoscopic fluids.	Physics-based flow visualization techniques seek to mimic laboratory flow visualization methods with virtual analogues. In this work we describe the rendering of a virtual rheoscopic fluid to produce images with results strikingly similar to laboratory experiments with real-world rheoscopic fluids using products such as Kalliroscope. These fluid additives consist of microscopic, anisotropic particles which, when suspended in the flow, align with both the flow velocity and the local shear to produce high-quality depictions of complex flow structures. Our virtual rheoscopic fluid is produced by defining a closed-form formula for the orientation of shear layers in the flow and using this orientation to volume render the flow as a material with anisotropic reflectance and transparency. Examples are presented for natural convection, thermocapillary convection, and Taylor-Couette flow simulations. The latter agree well with photographs of experimental results of Taylor-Couette flows from the literature.	Barth, W.L.	Texas Advanced Computing Center, Austin|c|	
	InfoVis+SciVis	Nov.-Dec. 2007	Cores of Swirling Particle Motion in Unsteady Flows	10.1109/TVCG.2007.70545	http://dx.doi.org/10.1109/TVCG.2007.70545	1759	1766	4376212	computational fluid dynamics;flow instability;flow visualisation;swirling flow	mathematical characterization;parallel vector operator;space-time domain;swirling particle motion;unsteady flow visualization	Aerospace industry;Aircraft;Airplanes;Blood flow;Data mining;Feature extraction;Numerical simulation;Robustness;Turbomachinery;Visualization	feature extraction;particle motion;unsteady flow visualization	In nature and in flow experiments particles form patterns of swirling motion in certain locations. Existing approaches identify these structures by considering the behavior of stream lines. However, in unsteady flows particle motion is described by path lines which generally gives different swirling patterns than stream lines. We introduce a novel mathematical characterization of swirling motion cores in unsteady flows by generalizing the approach of Sujudi/Haimes to path lines. The cores of swirling particle motion are lines sweeping over time, i.e., surfaces in the space-time domain. They occur at locations where three derived 4D vectors become coplanar. To extract them, we show how to re-formulate the problem using the parallel vectors operator. We apply our method to a number of unsteady flow fields.	Weinkauf, T.;Sahner, J.;Theisel, H.;Hege, H.-C.	Zuse Inst. Berlin, Berlin|c|;;;	37282635100;37565764600;37266875400;37282272000
	VAST	Oct. 30 2007-Nov. 1 2007	InfoVis as Seen by the World Out There: 2007 in Review	10.1109/VAST.2007.4388989	http://dx.doi.org/10.1109/VAST.2007.4388989	x	x	4388989			Blogs;Books;Computer science;Data analysis;Education;Visual communication;Writing		How we as insiders see and understand InfoVis is quite different from how it is seen by most people in the world out there. Most people get only glimpses of what we do, and those glimpses rarely tell the story clearly. Think about the view of InfoVis that has been created in 2007 through marketing, blogs, and articles. This view is peppered with misperception. In this presentation, I'll take you on a tour of InfoVis' exposure in 2007: the highlights and the failures that have shaped the world's perception of our beloved and important work. The world needs what we do, but this need remains largely unsatisfied.	Few, Stephen	Perceptual Edge, University of California, Berkeley|c|	37956021200
	VAST	Oct. 30 2007-Nov. 1 2007	Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications	10.1109/VAST.2007.4388990	http://dx.doi.org/10.1109/VAST.2007.4388990	3	10	4388990	computer vision;feature extraction;learning (artificial intelligence);security of data;singular value decomposition;video surveillance;wavelet transforms	activity analysis;anomaly detection;computer vision;semisupervised learning;singular value decomposition;spatio-temporal trajectory volume;surveillance application;visual feedback loop;wavelet-based feature descriptor	Application software;Cameras;Collaboration;Computer vision;Data security;Feeds;Humans;Surveillance;System testing;Trajectory	HOSVD;anomaly detection;surveillance;trajectory;wavelets	In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.	Janoos, F.;Singh, S.;Irfanoglu, O.;Machiraju, R.;Parent, R.	Ohio State Univ., Columbus|c|;;;;	37294440400;37966484200;37827945300;37269516700;37324916700
	VAST	Oct. 30 2007-Nov. 1 2007	FemaRepViz: Automatic Extraction and Geo-Temporal Visualization of FEMA National Situation Updates	10.1109/VAST.2007.4388991	http://dx.doi.org/10.1109/VAST.2007.4388991	11	18	4388991	data visualisation;geographic information systems;information retrieval;learning (artificial intelligence);pattern clustering;text analysis	FEMA national update report;FactXtractor;FemaRepViz;data visualization;entity-extractor;geo-temporal visualization;information extraction;machine-learning based algorithm;novel clustering-based disambiguation algorithm;text document	Clustering algorithms;Data mining;Decision making;Decision support systems;Earth;Earthquakes;Information analysis;Tsunami;Visual analytics;Visualization	geo-temporal visualization;geospatial analytics;knowledge discovery;text processing;visual analytics	An architecture for visualizing information extracted from text documents is proposed. In conformance with this architecture, a toolkit, FemaRepViz, has been implemented to extract and visualize temporal, geospatial, and summarized information from FEMA national update reports. Preliminary tests have shown satisfactory accuracy for FEMARepViz. A central component of the architecture is an entity extractor that extracts named entities like person names, location names, temporal references, etc. FEMARepViz is based on FactXtractor, an entity-extractor that works on text documents. The information extracted using FactXtractor is processed using GeoTagger, a geographical name disambiguation tool based on a novel clustering-based disambiguation algorithm. To extract relationships among entities, we propose a machine-learning based algorithm that uses a novel stripped dependency tree kernel. We illustrate and evaluate the usefulness of our system on the FEMA National Situation Updates. Daily reports are fetched by FEMARepViz from the FEMA website, segmented into coherent sections and each section is classified into one of several known incident types. We use concept Vista, Google maps and Google earth to visualize the events extracted from the text reports and allow the user to interactively filter the topics, locations, and time-periods of interest to create a visual analytics toolkit that is useful for rapid analysis of events reported in a large set of text documents.	Chi-Chun Pan;Mitra, P.	Pennsylvania State Univ., State College|c|;	37880213000;37286730000
	VAST	Oct. 30 2007-Nov. 1 2007	Stories in GeoTime	10.1109/VAST.2007.4388992	http://dx.doi.org/10.1109/VAST.2007.4388992	19	26	4388992	data visualisation;geographic information systems;humanities	GeoTime geo-temporal event visualization tool;analytic sense-making cohesion;hypertext linked visualization;pattern detection;story system;visual annotation	Collaboration;Context;Data mining;Data visualization;Event detection;Graphical user interfaces;Humans;Information analysis;Pattern analysis;Visual analytics	human information interaction;narrative;pattern detection;sense-making;story making;story telling;visual analytics	A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.	Eccles, R.;Kapler, T.;Harper, R.;Wright, W.	Oculus Info. Inc., Toronto|c|;;;	37425695700;37704437500;37594531000;37654961400
	VAST	Oct. 30 2007-Nov. 1 2007	LAHVA: Linked Animal-Human Health Visual Analytics	10.1109/VAST.2007.4388993	http://dx.doi.org/10.1109/VAST.2007.4388993	27	34	4388993	medical information systems;patient monitoring;statistical analysis;surveillance;veterinary medicine	LAHVA;animal surveillance;coordinated animal-human health monitoring;disease outbreaks;factor specification;filtering;human emergency room data;industrial wastewater;linked animal-human health visual analytics;patient health information;respiratory syndromes;seasonal influenza;statistical analysis;veterinary hospital data	Alarm systems;Animals;Cats;Dogs;Hospitals;Humans;Influenza;Monitoring;Statistical analysis;Visual analytics		Coordinated animal-human health monitoring can provide an early warning system with fewer false alarms for naturally occurring disease outbreaks, as well as biological, chemical and environmental incidents. This monitoring requires the integration and analysis of multi-field, multi-scale and multi-source data sets. In order to better understand these data sets, models and measurements at different resolutions must be analyzed. To facilitate these investigations, we have created an application to provide a visual analytics framework for analyzing both human emergency room data and veterinary hospital data. Our integrated visual analytic tool links temporally varying geospatial visualization of animal and human patient health information with advanced statistical analysis of these multi-source data. Various statistical analysis techniques have been applied in conjunction with a spatio-temporal viewing window. Such an application provides researchers with the ability to visually search the data for clusters in both a statistical model view and a spatio-temporal view. Our interface provides a factor specification/filtering component to allow exploration of causal factors and spread patterns. In this paper, we will discuss the application of our linked animal-human visual analytics (LAHVA) tool to two specific case studies. The first case study is the effect of seasonal influenza and its correlation with different companion animals (e.g., cats, dogs) syndromes. Here we use data from the Indiana Network for Patient Care (INPC) and Banfield Pet Hospitals in an attempt to determine if there are correlations between respiratory syndromes representing the onset of seasonal influenza in humans and general respiratory syndromes in cats and dogs. Our second case study examines the effect of the release of industrial wastewater in a community through companion animal surveillance.	Maciejewski, R.;Tyner, B.;Yun Jang;Cheng Zheng;Nehme, R.R.V.;Ebert, D.S.;Cleveland, W.S.;Ouzzani, M.;Grannis, S.J.;Glickman, L.T.	Purdue Univ. Regional Visualization & Analytics Center (PURVAC), West Lafayette|c|;;;;;;;;;	37396008400;37945189900;37557344300;37959894600;37397099000;38472157300;37282344300;38365116400;37646590100;37945190400
	VAST	Oct. 30 2007-Nov. 1 2007	Visual Analytics on Mobile Devices for Emergency Response	10.1109/VAST.2007.4388994	http://dx.doi.org/10.1109/VAST.2007.4388994	35	42	4388994	data visualisation;decision making;emergency services;information retrieval;interactive systems;mobile computing	data visualization;decision making;emergency response;fire evacuation;information access;interactive mobile visual analytic system;mobile devices;situational awareness;ubiquitous environment	Computer graphics;Data analysis;Data visualization;Decision making;Handheld computers;Information analysis;Mobile computing;Sensor systems;Terrorism;Visual analytics	emergency response;mobile visualization;visual analytics	Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.	SungYe Kim;Yun Jang;Mellema, A.;Ebert, D.S.;Collins, T.	Purdue Univ., West Lafayette|c|;;;;	37404975800;37557344300;37945218200;38472156900;37549519600
	VAST	Oct. 30 2007-Nov. 1 2007	Visual Analytics Approach to User-Controlled Evacuation Scheduling	10.1109/VAST.2007.4388995	http://dx.doi.org/10.1109/VAST.2007.4388995	43	50	4388995	decision making;genetic algorithms;scheduling;transportation	automated scheduling;decision making;genetic algorithm;heterogeneous objects;task-analytical approach;time-critical applications;transportation-planning tasks;user-controlled evacuation scheduling;visual analytics approach	Decision making;Genetic algorithms;Humans;Information analysis;Information processing;Space vehicles;Time factors;Transportation;Visual analytics;Visualization	Geovisualization;coordinated multiple views;task-centered design;transportation planning;vehicle scheduling	Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.	Andrienko, G.;Andrienko, N.;Bartling, U.	Fraunhofer Inst., Sankt Augustin|c|;;	37283047100;37283047700;37945217400
	VAST	Oct. 30 2007-Nov. 1 2007	Thin Client Visualization	10.1109/VAST.2007.4388996	http://dx.doi.org/10.1109/VAST.2007.4388996	51	58	4388996	Internet;Java;XML;data visualisation;geographic information systems;groupware;network computers	AJAX;RSS;Web 2.0;XML;asynchronous JavaScript;geospatial visualization;scalable vector graphics;thin client collaborative visualization framework	Application software;Collaboration;Displays;Graphics;Java;Portals;Shape;Streaming media;Visual analytics;Visualization	JavaScript;linked view visual analytics;scalable vector graphics;visualization components;web 2.0	We have developed a Web 2.0 thin client visualization framework called GeoBoosttrade. Our framework focuses on geospatial visualization and using scalable vector graphics (SVG), AJAX, RSS and GeoRSS we have built a complete thin client component set. Our component set provides a rich user experience that is completely browser based. It includes maps, standard business charts, graphs, and time-oriented components. The components are live, interactive, linked, and support real time collaboration.	Eick, S.G.;Eick, M.A.;Fugitt, J.;Horst, B.;Khailo, M.;Lankenau, R.A.	SSS Res., Inc., Naperville|c|;;;;;	37282570100;37295267800;37295269700;37945812500;37945319800;37295269900
	VAST	Oct. 30 2007-Nov. 1 2007	IMAS: The Interactive Multigenomic Analysis System	10.1109/VAST.2007.4388997	http://dx.doi.org/10.1109/VAST.2007.4388997	59	66	4388997	biology computing;data visualisation;genetics;interactive systems	DNA sequence;Web-based database;data analysis service;interactive multigenomic analysis system;visual analysis tool	Amino acids;Bioinformatics;Biological information theory;DNA;Diseases;Genomics;Proteins;Sequences;Visual analytics;Visual databases	Bioinformatics;Visual Analytics	This paper introduces a new Visual Analysis tool named IMAS (Interactive Multigenomic Analysis System), which combines common analysis tools such as Glimmer, BLAST, and Clustal-W into a unified Visual Analytic framework. IMAS displays the primary DNA sequence being analyzed by the biologist in a highly interactive, zoomable visual display. The user may analyze the sequence in a number of ways, and visualize these analyses in a coherent, sequence aligned form, with all related analysis products grouped together. This enables the user to rapidly perform analyses of DNA sequences without the need for tedious and error-prone cutting and pasting of sequence data from text files to and from web-based databases and data analysis services, as is now common practice.	Shaw, C.D.;Dasch, G.A.;Eremeeva, M.E.	Simon Fraser Univ. Surrey, Surrey|c|;;	37358198200;37945288700;37945292000
	VAST	Oct. 30 2007-Nov. 1 2007	Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation	10.1109/VAST.2007.4388998	http://dx.doi.org/10.1109/VAST.2007.4388998	67	74	4388998	data visualisation;interactive systems	interactive data management;massive data sets;smart data aggregation;user situational awareness;visual analytics system;visualization system	Automation;Data visualization;Databases;Displays;Energy management;Human resource management;Information analysis;Information retrieval;Technology management;Visual analytics	Data management;data retrieval;information visualization;situational awareness;smart aggregation;visual analytics	Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user's situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user's SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.	Tesone, D.R.;Goodall, J.R.	Appl. Visions Inc., Sacramento|c|;	37708756000;37550746600
	VAST	Oct. 30 2007-Nov. 1 2007	ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data	10.1109/VAST.2007.4388999	http://dx.doi.org/10.1109/VAST.2007.4388999	75	82	4388999	aerosols;data analysis;data mining;data visualisation;environmental science computing;mass spectroscopy;pattern classification;pattern clustering	ClusterSculptor visual analytics tool;aerosol mass spectra;atmospheric science;cluster analysis;cluster sculpting;clustering engine;data classification models;data mining;high-dimensional data analysis	Analysis of variance;Clustering algorithms;Couplings;Data mining;Displays;Iterative methods;Shape measurement;Space exploration;Visual analytics;Visualization	High-Dimensional Data;Space and Environmental Sciences;Visual Analytics;Visual Data Mining;Visualization in Earth	Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.	Eun Ju Nam;Han, Y.;Mueller, K.;Zelenyuk, A.;Imre, D.	Stony Brook Univ., Stony Brook|c|;;;;	37944542400;37836058500;37273119700;37945190700;37947994000
	VAST	Oct. 30 2007-Nov. 1 2007	Analysis Guided Visual Exploration of Multivariate Data	10.1109/VAST.2007.4389000	http://dx.doi.org/10.1109/VAST.2007.4389000	83	90	4389000	data mining;data visualisation	Xmd-vTool freeware multivariate data visualization system;analysis-guided visual exploration system;graphical representation;knowledge discovery task;multivariate data visual exploration;nugget management system	Data mining;Data visualization;Displays;Environmental management;Humans;Impedance;Information analysis;Knowledge management;Visual analytics;Visual databases	Analysis Guided Exploration;Discovery Management;Visual Analytics;Visual Knowledge Discovery	Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users' exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users' visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users' exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users' efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS.	Di Yang;Rundensteiner, E.A.;Ward, M.O.	Worcester Polytech. Inst., Worcester|c|;;	37966748000;37279217900;37268441700
	VAST	Oct. 30 2007-Nov. 1 2007	Intelligent Visual Analytics Queries	10.1109/VAST.2007.4389001	http://dx.doi.org/10.1109/VAST.2007.4389001	91	98	4389001	data mining;data visualisation;interactive systems;query processing;very large databases	intelligent visual analytics query concept;interactive visualization;large multidimensional data set visualization;parallel coordinate;pattern discovery;scatter plot;visual map;visual representation	Computer graphics;Data visualization;Data warehouses;Filtering;Marketing and sales;Pattern analysis;Performance analysis;Scattering;Visual analytics;Visual databases	Interactive Queries;Similarity Queries;Visual Analytics Query	Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.	Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.	Hewlett Packard Lab., Palo Alto|c|;;;;	37274264300;37275646700;37283138700;37563668400;37669961800
	VAST	Oct. 30 2007-Nov. 1 2007	Point Placement by Phylogenetic Trees and its Application to Visual Analysis of Document Collections	10.1109/VAST.2007.4389002	http://dx.doi.org/10.1109/VAST.2007.4389002	99	106	4389002	data visualisation;text analysis;tree data structures	document representation;document visualization;phylogenetic trees point placement;textual document collection;visual map analysis	Computer graphics;Electronic mail;Extraterrestrial measurements;Internet;Multidimensional systems;Phylogeny;Text analysis;Text processing;Visual databases;Visualization	Document Analysis;Document Visualization;Multidimensional Visualization;Phylogenetic Trees;Text Analytics	The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents.	Cuadros, A.M.;Paulovich, F.V.;Minghim, R.;Telles, G.P.	Univ. de Sao Paulo, Sao Carlos|c|;;;	37946651100;37590969400;37371567600;38181127500
	VAST	Oct. 30 2007-Nov. 1 2007	Analyzing Large-Scale News Video Databases to Support Knowledge Visualization and Intuitive Retrieval	10.1109/VAST.2007.4389003	http://dx.doi.org/10.1109/VAST.2007.4389003	107	114	4389003	content-based retrieval;data mining;semantic networks;video databases;video retrieval	automatic semantic video analysis;human intelligence;intuitive retrieval;knowledge discovery;knowledge visualization;large-scale news video databases;semantic video retrieval systems;valuable feedback	Artificial intelligence;Broadcasting;Data mining;Displays;Information retrieval;Large-scale systems;Multimedia communication;USA Councils;Visual databases;Visualization	Knowledge Discovery;Knowledge Visualization;Semantic Video Classification	In this paper, we have developed a novel framework to enable more effective investigation of large-scale news video database via knowledge visualization. To relieve users from the burdensome exploration of well-known and uninteresting knowledge of news reports, a novel interestingness measurement for video news reports is presented to enable users to find news stories of interest at first glance and capture the relevant knowledge in large-scale video news databases efficiently. Our framework takes advantage of both automatic semantic video analysis and human intelligence by integrating with visualization techniques on semantic video retrieval systems. Our techniques on intelligent news video analysis and knowledge discovery have the capacity to enable more effective visualization and exploration of large-scale news video collections. In addition, news video visualization and exploration can provide valuable feedback to improve our techniques for intelligent news video analysis and knowledge discovery.	Hangzai Luo;Jianping Fan;Jing Yang;Ribarsky, W.;Satoh, S.	East China Normal Univ., Shanghai|c|;;;;	37275772500;37271216800;37292632600;37300425000;37266330000
	VAST	Oct. 30 2007-Nov. 1 2007	Literature Fingerprinting: A New Method for Visual Literary Analysis	10.1109/VAST.2007.4389004	http://dx.doi.org/10.1109/VAST.2007.4389004	115	122	4389004	computer aided instruction;data visualisation	automatic literature analysis;characteristic fingerprint;computer-based literary analysis;interactive visual analysis;literature fingerprinting;visual literary analysis;visualization technique	Application software;Art;Computer applications;Fingerprint recognition;Information analysis;Iron;Lifting equipment;Visual analytics;Visualization;Vocabulary	Visual literature analysis;literature fingerprinting;visual analytics	In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting.	Keim, D.A.;Oelke, D.	Univ. of Konstanz, Konstanz|c|;	37283138700;37591207400
	VAST	Oct. 30 2007-Nov. 1 2007	NewsLab: Exploratory Broadcast News Video Analysis	10.1109/VAST.2007.4389005	http://dx.doi.org/10.1109/VAST.2007.4389005	123	130	4389005	image resolution;image segmentation;video signal processing	NewsLab;drill-down roll-up navigation;exploratory broadcast news video analysis;exploratory visualization approach;filtering;fine-grained video segments;hierarchical theme structure;hierarchical time structure;history animation;interactive lens metaphor;keyword based search;multiresolution navigation;video collections	Animation;Broadcasting;Filtering;History;Large-scale systems;Lenses;Multimedia communication;Navigation;Rivers;Visualization	Large data exploration;animation;broadcast video analysis;clustering;comparative analysis;time filtering	In this paper, we introduce NewsLab, an exploratory visualization approach for the analysis of large scale broadcast news video collections containing many thousands of news stories over extended periods of time. A river metaphor is used to depict the thematic changes of the news over time. An interactive lens metaphor allows the playback of fine-grained video segments selected through the river overview. Multi-resolution navigation is supported via a hierarchical time structure as well as a hierarchical theme structure. Themes can be explored hierarchically according to their thematic structure, or in an unstructured fashion using various ranking criteria. A rich set of interactions such as filtering, drill-down/roll-up navigation, history animation, and keyword based search are also provided. Our case studies show how this set of tools can be used to find emerging topics in the news, compare different broadcasters, or mine the news for topics of interest.	Ghoniem, M.;Dongning Luo;Jing Yang;Ribarsky, W.	UNC Charlotte, Charlotte|c|;;;	37688563600;37545990500;37292632600;37300425000
	VAST	Oct. 30 2007-Nov. 1 2007	Jigsaw: Supporting Investigative Analysis through Interactive Visualization	10.1109/VAST.2007.4389006	http://dx.doi.org/10.1109/VAST.2007.4389006	131	138	4389006	data visualisation;text analysis	Jigsaw;interactive visualization;multiple coordinated views;sense-making processes;text documents collections;visual analytic system	Algorithm design and analysis;Costs;Data visualization;Electronic mail;Embedded computing;Information analysis;Information systems;Performance analysis;Visual analytics;Yarn	Visual analytics;information visualization;intelligence analysis;investigative analysis;multiple views	Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.	Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.	Georgia Inst. of Technol., Atlanta|c|;;;	37267736900;37428446300;37592993600;37968367000
	VAST	Oct. 30 2007-Nov. 1 2007	SpiralView: Towards Security Policies Assessment through Visual Correlation of Network Resources with Evolution of Alarms	10.1109/VAST.2007.4389007	http://dx.doi.org/10.1109/VAST.2007.4389007	139	146	4389007	computer network management;data visualisation;interactive systems;intranets;telecommunication computing;telecommunication security	corporate network;interactive bar chart;network management;network monitoring;security alarm;security policy assessment;spiral visualization;visual correlation	Computer interfaces;Computer security;Data security;Data visualization;Engines;Information security;Intrusion detection;Monitoring;Spirals;Telecommunication traffic	Data Exploration;Intrusion Detection;Network security;Visualization	This article presents SpiralView, a visualization tool for helping system administrators to assess network policies. The tool is meant to be a complementary support to the routine activity of network monitoring, enabling a retrospective view on the alarms generated during and extended period of time. The tool permits to reason about how alarms distribute over time and how they correlate with network resources (e.g., users, IPs, applications, etc.), supporting the analysts in understanding how the network evolves and thus in devising new security policies for the future. The spiral visualization plots alarms in time, and, coupled with interactive bar charts and a users/applications graph view, is used to present network data and perform queries. The user is able to segment the data in meaningful subsets, zoom on specific related information, and inspect for relationships between alarms, users, and applications. In designing the visualizations and their interaction, and through tests with security experts, several ameliorations over the standard techniques have been provided.	Bertini, E.;Hertzog, P.;Lalanne, D.	Univ. of Fribourg, Fribourg|c|;;	37283307700;37948939200;37589762800
	VAST	Oct. 30 2007-Nov. 1 2007	Session Viewer: Visual Exploratory Analysis of Web Session Logs	10.1109/VAST.2007.4389008	http://dx.doi.org/10.1109/VAST.2007.4389008	147	154	4389008	Internet;data visualisation;human factors;search engines;statistical analysis	Session Viewer visualization tool;Web search usage behaviors;detailed log examinations;large-scale Web session log analysis;statistical methods;visual exploratory analysis	Aggregates;Bridges;Buildings;Data analysis;Data visualization;Frequency;Human computer interaction;Information analysis;Large-scale systems;Statistical analysis	Web session log analysis;information visualization;visual exploratory data analysis	Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.	Lam, H.;Russell, D.;Tang, D.;Munzner, T.	Univ. of British Columbia Google, Vancouver|c|;;;	37873130000;37562313000;37652594600;37349490300
	VAST	Oct. 30 2007-Nov. 1 2007	WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions	10.1109/VAST.2007.4389009	http://dx.doi.org/10.1109/VAST.2007.4389009	155	162	4389009	data visualisation;financial data processing;fraud;transaction processing	categorical data visualization;financial institution;financial wire transaction;fraudulent activity;search-by-example technique;time-varying data;transaction pattern extraction	Collaborative tools;Computer graphics;Data mining;Data visualization;Financial management;Law;Legal factors;Risk analysis;Risk management;Wire	Fraud detection;categorial time-varying data;financial data visualization	Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors.	Chang, R.;Ghoniem, M.;Kosara, R.;Ribarsky, W.;Jing Yang;Suma, E.;Ziemkiewicz, C.;Kern, D.;Sudjianto, A.	UNC at Charlotte, Charlotte|c|;;;;;;;;	37592409400;37688563600;37282563400;37300425000;37292632600;37297278600;37548028800;37960273700;37967877700
	VAST	Oct. 30 2007-Nov. 1 2007	Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations	10.1109/VAST.2007.4389010	http://dx.doi.org/10.1109/VAST.2007.4389010	163	170	4389010	Web sites;data visualisation;groupware;interactive systems	collaborative online knowledge system;revert graph visualization;social dynamics;visual analytic tool;wikipedia	Collaboration;Collaborative tools;Collaborative work;Costs;Encyclopedias;History;Knowledge based systems;Visual analytics;Visualization;Wikipedia	Wikipedia;collaboration;graph;revert;user model;visualization;wiki	"Wikipedia is a wiki-based encyclopedia that has become one of the most popular collaborative on-line knowledge systems. As in any large collaborative system, as Wikipedia has grown, conflicts and coordination costs have increased dramatically. Visual analytic tools provide a mechanism for addressing these issues by enabling users to more quickly and effectively make sense of the status of a collaborative environment. In this paper we describe a model for identifying patterns of conflicts in Wikipedia articles. The model relies on users' editing history and the relationships between user edits, especially revisions that void previous edits, known as ""reverts"". Based on this model, we constructed Revert Graph, a tool that visualizes the overall conflict patterns between groups of users. It enables visual analysis of opinion groups and rapid interactive exploration of those relationships via detail drill- downs. We present user patterns and case studies that show the effectiveness of these techniques, and discuss how they could generalize to other systems."	Suh, B.;Chi, Ed H.;Pendleton, B.A.;Kittur, A.	Palo Alto Res. Center, Palo Alto|c|;;;	37823184000;37448030800;37830268500;37946538100
	VAST	Oct. 30 2007-Nov. 1 2007	Design Considerations for Collaborative Visual Analytics	10.1109/VAST.2007.4389011	http://dx.doi.org/10.1109/VAST.2007.4389011	171	178	4389011	cognition;data visualisation;groupware;human computer interaction;human factors;interactive systems;visual perception	asynchronous collaborative visual analytics design;cognitive process;collaborative visualization system;human sensemaking;human visual perception system;interactive information visualization;social interaction	Collaboration;Collaborative software;Collaborative work;Data visualization;Decision making;Displays;Humans;Information analysis;Visual analytics;Visual system	analysis;collaboration;computer-supported cooperative work;design;visualization	Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.	Heer, J.;Agrawala, M.	Univ. of California, Berkeley|c|;	37550791300;37282718200
	VAST	Oct. 30 2007-Nov. 1 2007	Visual Analysis of Controversy in User-generated Encyclopedias	10.1109/VAST.2007.4389012	http://dx.doi.org/10.1109/VAST.2007.4389012	179	186	4389012	Internet;groupware	Internet;Web-based collaborative authoring environment;Wikipedia pages;controversy visual analysis;user-generated encyclopedia	Collaboration;Collaborative tools;Encyclopedias;History;Information analysis;Information science;Internet;Social network services;Visualization;Wikipedia	Wikipedia;controversy;social network analysis	"Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the ""who revises whom""- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy."	Brandes, U.;Lerner, J.	Univ. of Konstanz, Konstanz|c|;	37550836200;37552262100
	VAST	Oct. 30 2007-Nov. 1 2007	DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data	10.1109/VAST.2007.4389013	http://dx.doi.org/10.1109/VAST.2007.4389013	187	194	4389013	data analysis;data structures;data visualisation;interactive systems;user interfaces	Data Meadow visual canvas;DataRoses graphical set representation;data visualization;direct manipulation interface;dynamic query slider;large-scale multivariate data analysis;visual analytics	Bars;Data visualization;Feedback;Filtering;History;Large-scale systems;Mice;Multidimensional systems;Protocols;Visual analytics	Multivariate data;dynamic queries;iterative analysis;parallel coordinates;small multiples;starplot;visual analytics	Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.	Elmqvist, N.;Stasko, J.;Tsigas, P.	Univ. Paris-Sud, Paris|c|;;	37295438200;37267736900;37295439000
	VAST	Oct. 30 2007-Nov. 1 2007	VAST to Knowledge: Combining tools for exploration and mining	10.1109/VAST.2007.4389015	http://dx.doi.org/10.1109/VAST.2007.4389015	197	198	4389015	data mining;data visualisation;text analysis	VAST;data mining;data visualization;knowledge discovery;knowledge exploration;text mining;visual analytics	Artificial intelligence;Automatic testing;Data mining;Data visualization;Electronic mail;Information analysis;Natural language processing;Navigation;Pattern analysis;Text mining	Text mining;digital libraries;information visualization;knowledge discovery;visual analytics	The investigation of the VAST Contest collection provided a valuable test for text mining techniques. Our group has focused on creating analytical tools to unveil relevant patterns and to aid with the content navigation in such text collections. Our results show how such an approach, in combination with visualization techniques, can ease the discovery process especially when multiple tools founded on the same approach to data mining are used in complement to and in concert with one another.	Auvil, L.;Llora, X.	Univ. of Illinois at Urbana-Champaign, Urbana|c|;	37296761400;37565890900
	VAST	Oct. 30 2007-Nov. 1 2007	VAST 2007 Contest Interactive Poster: Data Analysis Using NdCore and REGGAE	10.1109/VAST.2007.4389016	http://dx.doi.org/10.1109/VAST.2007.4389016	199	200	4389016	data analysis;data mining;data visualisation;legislation;relational databases;text analysis	ATS intelligent discovery;NdCore tool;REGGAE tool;VAST contest scenario;data analysis;ecoterrorism;endangered species issue;relational database;relationship generating graph analysis engine;text document;visual analytics;wildlife law enforcement	Application software;Data analysis;Engines;Multidimensional systems;Performance analysis;Prototypes;Relational databases;Text analysis;User interfaces;Wildlife	data discovery;text analysis;visual analytics;visualization	ATS intelligent discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (relationship generating graph analysis engine). The paper describes these tools and how they were used to discover the contest's scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism.	Schwendiman, L.;McLean, J.;Larson, J.	ATS Intelligent Discovery, Silverdale|c|;;	37946768100;37957250200;37970751200
	VAST	Oct. 30 2007-Nov. 1 2007	Visual Analytics with Jigsaw	10.1109/VAST.2007.4389017	http://dx.doi.org/10.1109/VAST.2007.4389017	201	202	4389017	data visualisation;document handling	Jigsaw visual analytic system;VAST '07 Contest;document collection;information visualization;multiple coordinated views	Calendars;Data mining;Displays;Electronic mail;Information analysis;Information systems;Usability;Visual analytics;Visualization;Yarn	Visual analytics;information visualization;intelligence analysis;investigative analysis;multiple views	This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST '07 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents.	Gorg, C.;Zhicheng Liu;Parekh, N.;Singhal, K.;Stasko, J.	Georgia Inst. of Technol., Atlanta|c|;;;;	;37592993600;37949736600;37968367000;37267736900
	VAST	Oct. 30 2007-Nov. 1 2007	Something&#39;s &#34;Fishy&#34; at Global Ways and Gill Breeders - Analysis with nSpace and GeoTime	10.1109/VAST.2007.4389018	http://dx.doi.org/10.1109/VAST.2007.4389018	203	204	4389018	data visualisation;geographic information systems;interactive systems	data visualization;geographic information system;interactive visual analytics tool	Chromium;Cognition;Data visualization;Graphical user interfaces;Humans;Information analysis;Information systems;Space technology;User interfaces;Visual analytics	geo-spatial information systems;human information interaction;sense making;temporal analysis;visual analytics	GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This poster paper describes how the capabilities of the tools were used to facilitate and expedite every stage of an analyst workflow.	Chien, L.;Tat, A.;Wright, W.	;;	37721458000;37326091400;37654961400
	VAST	Oct. 30 2007-Nov. 1 2007	TextPlorer: An application supporting text analysis	10.1109/VAST.2007.4389019	http://dx.doi.org/10.1109/VAST.2007.4389019	205	206	4389019	Internet;data visualisation;human computer interaction;pattern clustering;portals;text analysis;user interfaces	Textplorer application-supporting text document analysis;Web interface;Web portal;concept map;data processing module;data visualization;entity relation extraction;hierarchical clustering;named entity extraction;table-view;text summarization tool;timeline tool;tree-view;user interaction	Data mining;Data processing;Data visualization;Filtering;Information systems;Ontologies;Portals;Text analysis;Visual databases;Weapons	Text;VAST contest;Visualization;entity-relation extraction;named-entity extraction	TexPlorer is an integrated system for exploring and analyzing large amounts of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using a timeline tool, tree-view, table-view, and concept maps, TexPlorer provides an analytical interface for exploring a set of text documents from different perspectives and allows users to explore vast amount of text documents efficiently.	Chi-Chun Pan;Jaiswal, A.R.;Junyan Luo;Robinson, A.	Pennsylvania State Univ., State College|c|;;;	37880213000;37966902300;37878910400;37829187900
	VAST	Oct. 30 2007-Nov. 1 2007	University of British Columbia &#x00026; Simon Fraser University - The Bricolage	10.1109/VAST.2007.4389020	http://dx.doi.org/10.1109/VAST.2007.4389020	207	208	4389020	data visualisation;groupware;information analysis	VAST;bricolage approach;collaborative techniques;sensemaking;visual analytics	Africa;Animals;Chaos;Collaboration;Collaborative work;Computer interfaces;Decision making;Gas insulated transmission lines;Information analysis;Performance analysis	bricolage;collaboration;evaluation;meta-analysis;theory building		Chao, W.	Simon Fraser Univ., Columbia|c|	
	VAST	Oct. 30 2007-Nov. 1 2007	VisPad: Integrating Visualization, Navigation and Synthesis	10.1109/VAST.2007.4389021	http://dx.doi.org/10.1109/VAST.2007.4389021	209	210	4389021	information dissemination;navigation	VisPad;information dissemination;information synthesis;navigation view;visual exploration process	Computer science;Connectors;Data visualization;Graphical user interfaces;Image generation;Information filtering;Information filters;Mathematics;Navigation;User interfaces	Information synthesis;Navigation;Presentation	We present a new framework - VisPad - to support the user to revisit the visual exploration process, and to synthesize and disseminate information. It offers three integrated views. The data view allows the user to interactively explore the data. The navigation view captures the exploration process. It enables the user to revisit any particular state and reuse it. The knowledge view enables the user to record his/her findings and the relations between these findings.	Shrinivasan, Y.B.;van Wijk, J.J.	Tech. Univ. Eindhoven, Eindhoven|c|;	37681468200;37267249200
	VAST	Oct. 30 2007-Nov. 1 2007	C-GROUP: A Visual Analytic Tool for Pairwise Analysis of Dynamic Group Membership	10.1109/VAST.2007.4389022	http://dx.doi.org/10.1109/VAST.2007.4389022	211	212	4389022	computer animation;data visualisation;groupware;social sciences computing;user interfaces	computer animation;data visualization;dynamic group membership;pairwise analysis;social network;user interface;visual analytic tool	Bipartite graph;Communication networks;Data analysis;Data visualization;Educational institutions;Electronic mail;Information analysis;Navigation;Social network services;Visual analytics		C-GROUP is a tool for analyzing dynamic group membership in social networks over time. Unlike most network visualization tools, which show the group structure within an entire network, or the group membership for a single actor, C-GROUP allows users to focus their analysis on a pair of individuals of interest. And unlike most dynamic social network visualization tools, which focus on the addition and deletion of nodes (actors) and edges (relationships) over time, C-GROUP focuses on changing group memberships over time. C-GROUP provides users with a flexible interface for defining (and redefining) groups interactively, and allows users to view the changing group memberships for the pair over time. This helps to highlight the similarities and differences between the individuals and their evolving group memberships. C-GROUP allows users to dynamically select the time granularity of the temporal evolution and supports two novel visual representations of the evolving group memberships. This flexibility gives users alternate views that are appropriate for different network sizes and provides users with different insights into the grouping behavior.	Hyunmo Kang;Getoor, L.;Singh, L.	Univ. of Maryland, College Park|c|;;	37291403000;37829614900;37691176100
	VAST	Oct. 30 2007-Nov. 1 2007	Situation Awareness Tool for Global Argus	10.1109/VAST.2007.4389023	http://dx.doi.org/10.1109/VAST.2007.4389023	213	214	4389023	data visualisation;geographic information systems;graphical user interfaces;interactive systems	Global Argus situation awareness interactive tool;InteleView/World Wind geographical information system;biological event detection;biological event tracking;graphical user interface;visualization tool	Animals;Computer graphics;Data analysis;Data visualization;Diseases;Event detection;Humans;Information analysis;NASA;Real time systems	biological events;biosurveillance;situation awareness;visual analytics;visualization	We present a visualization tool to enhance situation awareness for Global Argus, a system that tracks and detects indications and warnings of biological events in near real time. Because Global Argus generates massive amounts of data daily, its analysts often struggle to interpret the information. To overcome this problem, we have developed the Global Argus situation awareness tool (GASAT) using the InteleView/World Wind geographical information system. This tool allows users to visualize current and past events in a particular region, and thus to understand how events evolve over time. Combined with the other tools that we are developing, GASAT will contribute to enhanced situation awareness in the tracking and detection of biological events.	Jae Choi;Sang-joon Lee;Gigitashvilli, S.;Wilson, J.	Georgetown Univ., Washington|c|;;;	37964473000;37966125200;37946376100;37958923500
	VAST	Oct. 30 2007-Nov. 1 2007	Spectra transformed for model-testing and visual exploration	10.1109/VAST.2007.4389024	http://dx.doi.org/10.1109/VAST.2007.4389024	215	216	4389024	pattern recognition;regression analysis	dynamic regression plotting;model testing;polyphonic music signal;spectra;visual exploration	Animation;Data visualization;Educational institutions;Frequency;Image segmentation;Multiple signal classification;Music information retrieval;Performance evaluation;Spirals;Testing	I.5.5 [Pattern recognition]: ImplementationInteractive systems	The presence of highly tangled patterns in spectra and other serial data exacerbates the difficulty of performing visual comparison between a test model for a particular pattern and the data. The use of a simple map that plants peaks in the data directly onto their corresponding position in a residual plot with respect to a chosen test model not only retrieves the advantages of dynamic regression plotting, but in practical cases also causes patterns in the data to congregate in meaningful ways with respect to more than one reference curve in the plane. The technique is demonstrated on a polyphonic music signal.	Catravas, P.	Union Coll., Schenectady|c|	37692041000
	VAST	Oct. 30 2007-Nov. 1 2007	Formalizing Analytical Discourse in Visual Analytics	10.1109/VAST.2007.4389025	http://dx.doi.org/10.1109/VAST.2007.4389025	217	218	4389025	natural language interfaces;problem solving	analytical discourse;collaborative discourse;complex mental attitude;computational analysis;cooperative human-machine communication;crisis management scenario;human reasoning;visual analytic reasoning process;visual analytics;visual interactive dialogues	Collaboration;Collaborative work;Context;Crisis management;Data analysis;Educational institutions;Humans;Information analysis;Man machine systems;Visual analytics	Analytical discourse;human-computer collaboration;science of interaction	This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse.	Guoray Cai	Penn State Univ., University Park|c|	37853099200
	VAST	Oct. 30 2007-Nov. 1 2007	Sunfall: A Collaborative Visual Analytics System for Astrophysics	10.1109/VAST.2007.4389026	http://dx.doi.org/10.1109/VAST.2007.4389026	219	220	4389026	astronomical image processing;data analysis;data visualisation;graphical user interfaces;learning (artificial intelligence);statistical analysis	Nearby Supernova Factory;Sunfall;astrophysics;collaborative visual analytics system;data analysis;image processing algorithms;interactive data visualization;machine learning;software tools;spectral data;statistical analysis;user-driven scientific exploration;visual interfaces	Astrophysics;Data visualization;Image processing;International collaboration;Large-scale systems;Machine learning algorithms;Production facilities;Software tools;Time factors;Visual analytics	Data and knowledge visualization;astrophysics;scientific visualization;visual analytics;visual exploration	Computational and experimental sciences produce and collect ever- larger and complex datasets, often in large-scale, multi-institution projects. The inability to gain insight into complex scientific phenomena using current software tools is a bottleneck facing virtually all endeavors of science. In this paper, we introduce Sunfall, a collaborative visual analytics system developed for the Nearby Supernova Factory, an international astrophysics experiment and the largest data volume supernova search currently in operation. Sunfall utilizes novel interactive visualization and analysis techniques to facilitate deeper scientific insight into complex, noisy, high-dimensional, high-volume, time-critical data. The system combines novel image processing algorithms, statistical analysis, and machine learning with highly interactive visual interfaces to enable collaborative, user-driven scientific exploration of supernova image and spectral data. Sunfall is currently in operation at the Nearby Supernova Factory; it is the first visual analytics system in production use at a major astrophysics project.	Aragon, C.R.;Bailey, S.J.;Poon, S.;Runge, K.J.;Thomas, R.C.	Lawrence Berkeley Nat. Lab., Berkeley|c|;;;;	37564069800;37272122100;38476551100;37948511900;37874439800
	VAST	Oct. 30 2007-Nov. 1 2007	Visual Analysis of Dynamic Networks with Geological Clustering	10.1109/VAST.2007.4389027	http://dx.doi.org/10.1109/VAST.2007.4389027	221	222	4389027	data mining;data visualisation	associated geological information;dynamic networks;geological clustering;knowledge discovery;network layout;social network analysis;visual analysis	Australia;Computer networks;Data visualization;Geology;History;Information analysis;Information technology;Performance analysis;Social network services;Visual analytics	Centrality;Clustering;Dynamic Network;Hierarchy;Network Visualization;Temporal Network;Visual Analytics	"Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user's mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the ""History of the FIFA World Cup Competition"" data set."	Ahmed, A.;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu	;;;;	37288875000;37288138500;37291728000;37961817500;37273812200
	VAST	Oct. 30 2007-Nov. 1 2007	From Tasks to Tools: A Field Study in Collaborative Visual Analytics	10.1109/VAST.2007.4389028	http://dx.doi.org/10.1109/VAST.2007.4389028	223	224	4389028	cognitive systems;task analysis	activity theory;cognitive task analysis;collaborative visual analytics;grounded theory;sensemaking	Chaos;Cognition;Cognitive science;Collaborative tools;Collaborative work;Computer interfaces;Computer security;Information analysis;Space technology;Visual analytics	collaboration;evaluation;field methods;meta-analysis;theory building	This poster presents an exploratory field study of a VAST 2007 contest entry. We applied cognitive task analysis (CTA), grounded theory (GT), and activity theory (AT), to analysis of field notes and interviews from participants. Our results are described in the context of activity theory and sensemaking, two theoretical perspectives that we have found to be particularly useful in understanding analytic tasks.	Ha, D.;Kim, M.;Wade, A.;Chao, W.O.;Ho, K.;Kaastra, L.;Fisher, Brian;Dill, J.	Simon Fraser Univ., Burnaby|c|;;;;;;;	37958326000;37962435000;38181511600;37955194300;37959707800;37946773000;37267458000;37278563100
	VAST	Oct. 30 2007-Nov. 1 2007	Outlook for Visual Analytics Research Funding	10.1109/VAST.2007.4389030	http://dx.doi.org/10.1109/VAST.2007.4389030	227	227	4389030			Australia;Bioinformatics;Disaster management;Europe;Genetics;Laboratories;Terrorism;Visual analytics		Visual Analytics has become a rapidly growing field of study. It is also a field that is addressing very significant real world problems in homeland security, business analytics, emergency management, genetics and bioinformatics, investigative analysis, medical analytics, and other areas. For both these reasons, it is attracting new funding and will continue to do so in the future. Visual analytics has also become an international field, with significant research efforts in Canada, Europe, and Australia, as well as the U.S. There is significant new research funding in Canada and Germany with other efforts being discussed, including a major program sponsored by the European Union. The contributors to this panel are some of the primary thought leaders providing research funding or involved in setting up the funding apparatus. We have asked them to present their needs, funding programs, and expectations from the research community. They all come from different perspectives, different missions, and different expectations. They will present their views of the range of activity in both the U.S. and internationally and discuss what is coming. Come learn about these programs, initiatives, and plans, and how you can contribute.	Thomas, J.;Keim, D.;Kielman, Joe;Rosenblum, Larry	Pacific Northwest National Laboratory|c|;;;	37273308900;37283138700;37829627200;37371985200
	VAST	Oct. 30 2007-Nov. 1 2007	VAST 2007 Contest - Blue Iguanodon	10.1109/VAST.2007.4389032	http://dx.doi.org/10.1109/VAST.2007.4389032	231	232	4389032	data visualisation;graphical user interfaces	illegal activities;large heterogeneous data collection;terrorist activities;visual analytic tools	Data analysis;Data mining;Data visualization;Graphical user interfaces;Information services;Internet;Laboratories;NIST;Visual analytics;Web sites	contest;evaluation;human information interaction;metrics;sense making;visual analytics	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006.	Grinstein, G.;Plaisant, C.;Laskowski, S.;O'Connell, T.;Scholtz, J.;Whiting, M.	Univ. of Massachusetts, Lowell|c|;;;;;	38470495900;38260687100;37837224000;37948663500;37268671300;37357067600
	VAST	Oct. 30 2007-Nov. 1 2007	VAST 2007 Contest - Analysis with nSpace and GeoTime	10.1109/VAST.2007.4389033	http://dx.doi.org/10.1109/VAST.2007.4389033	233	234	4389033	data analysis;data visualisation	VAST contest dataset;analytical visualization application;massive dataset analysis;nSpace-GeoTime tool	Animation;Chromium;Cognition;Data visualization;Graphical user interfaces;Information analysis;Pattern analysis;Space technology;User interfaces;Visual analytics	geo-spatial information systems;human information interaction;sense making;temporal analysis;visual analytics	GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This paper describes how the capabilities of the tools were used to facilitate and expedite every stage of the analysis.	Chien, L.;Tat, A.;Kapler, T.;Enns, P.;Kuan, W.;Wright, W.	Oculus Info Inc., Toronto|c|;;;;;	37721458000;37326091400;37704437500;37946706100;37968125800;37654961400
	VAST	Oct. 30 2007-Nov. 1 2007	Jigsaw meets Blue Iguanodon - The VAST 2007 Contest	10.1109/VAST.2007.4389034	http://dx.doi.org/10.1109/VAST.2007.4389034	235	236	4389034	data visualisation;text analysis	Blue Iguanodon;Jigsaw;document collection;information visualization;multiple views;visual analytics	Filters;Gas insulated transmission lines;Information analysis;Information systems;Java;Radio access networks;USA Councils;Visual analytics;Visualization;Yarn	Visual analytics;information visualization;intelligence analysis;investigative analysis;multiple views	This article describes our use of the Jigsaw system in working on the VAST 2007 contest. Jigsaw provides multiple views of a document collection and the individual entities within those documents, with a particular focus on exposing connections between entities. We describe how we refined the identified entities in order to better facilitate Jigsaw's use and how the different views helped us to uncover key parts of the underlying plot.	Gorg, C.;Zhicheng Liu;Parekh, N.;Singhal, K.;Stasko, J.	Georgia Inst. of Technol., Atlanta|c|;;;;	37428446300;37592993600;37949736600;37968367000;37267736900
	VAST	Oct. 30 2007-Nov. 1 2007	VAST to Knowledge: Combining tools for exploration and mining	10.1109/VAST.2007.4389035	http://dx.doi.org/10.1109/VAST.2007.4389035	237	238	4389035			Artificial intelligence;Automatic testing;Data mining;Data visualization;Electronic mail;Information analysis;Natural language processing;Navigation;Pattern analysis;Text mining	Text mining;digital libraries;information visualization;knowledge discovery;visual analytics	The investigation of the VAST Contest collection provided a valuable test for text mining techniques. Our group has focused on creating analytical tools to unveil relevant patterns and to aid with the content navigation in such text collections. Our results show how such an approach, in combination with visualization techniques, can ease the discovery process especially when multiple tools founded on the same approach to data mining are used in complement to and in concert with one another.	Auvil, L.;Llora, Xavier	Automated Learning Group, National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign. e-mail: lauvil@uiuc.edu|c|;	37296761400;37565890900
	VAST	Oct. 30 2007-Nov. 1 2007	University of British Columbia & Simon Fraser University - The Bricolage	10.1109/VAST.2007.4470207	http://dx.doi.org/10.1109/VAST.2007.4470207	239	240	4470207			Africa;Animals;Chaos;Collaboration;Collaborative work;Computer interfaces;Decision making;Gas insulated transmission lines;Information analysis;Performance analysis			Chao, W.;Ha, D.;Ho, K.;Kaastra, L.;Kim, M.;Wade, A.;Fisher, B.	;;;;;;	37955194300;37958326000;37959707800;37946773000;37962435000;38181511600;38356306400
	VAST	Oct. 30 2007-Nov. 1 2007	Intelligence Analysis Using Titan	10.1109/VAST.2007.4389036	http://dx.doi.org/10.1109/VAST.2007.4389036	241	242	4389036	data visualisation	Titan Informatics Toolkit Project;information visualization capabilities;intelligence analysis;visualization toolkit	Collaborative tools;Graphical user interfaces;Ice;Image databases;Informatics;Information analysis;Joining processes;Laboratories;Visual databases;Visualization	information visualization;visual analytics	The open source Titan informatics toolkit project, which extends the visualization toolkit (VTK) to include information visualization capabilities, is being developed by Sandia National Laboratories in collaboration with Kitware. The VAST Contest provided us with an opportunity to explore various ideas for constructing an analysis tool, while allowing us to exercise our architecture in the solution of a complex problem. As amateur analysts, we found the experience both enlightening and fun.	Crossno, P.;Wylie, B.;Wilson, A.;Greenfield, J.;Stanton, E.;Shead, T.;Ice, L.;Moreland, K.;Baumes, J.;Geveci, B.	Sandia Nat. Lab., Albuquerque|c|;;;;;;;;;	37282576500;38180014300;37554778300;37944468900;37931637200;37681611000;37570533600;37284250900;37698159600;37282729500
	VAST	Oct. 30 2007-Nov. 1 2007	VAST 2007 Contest TexPlorer	10.1109/VAST.2007.4389037	http://dx.doi.org/10.1109/VAST.2007.4389037	243	244	4389037	data visualisation;text analysis	VAST 2007 Contest TexPlorer;concept maps;data processing modules;entity relation extraction;hierarchical clustering;named entity extraction;table-view;text documents;text summarization tools;time-line tool;tree-view	Data analysis;Data mining;Data processing;Data visualization;Filtering;Information systems;Ontologies;Portals;Visual databases;Weapons	Text;VAST contest;Visualization	TexPlorer is an integrated system for exploring and analyzing vast amount of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using time line tool, tree-view, table-view, and concept maps, TexPlorer provides visualizations from different aspects and allows analysts to explore vast amount of text documents efficiently.	Chi-Chun Pan;Jaiswal, A.R.;Junyan Luo;Robinson, A.;Mitra, P.;Turton, I.	Pennsylvania State Univ., University Park|c|;;;;;	37880213000;37966902300;37878910400;37829187900;37286730000;37872420000
	VAST	Oct. 30 2007-Nov. 1 2007	VAST 2007 Contest Data Analysis Using NdCore and REGGAE	10.1109/VAST.2007.4389038	http://dx.doi.org/10.1109/VAST.2007.4389038	245	246	4389038	data analysis;data mining;data visualisation;relational databases;text analysis	ATS Intelligent Discovery;NdCore application;REGGAE application;contest scenario discovery;data analysis;ecoterrorism;endangered species issues;relational databases;relationship generating graph analysis engine;text analysis;wildlife law enforcement	Data analysis;Engines;Multidimensional systems;Performance analysis;Prototypes;Relational databases;Text analysis;User interfaces;Visual analytics;Wildlife	data discovery;text analysis;visual analytics;visualization	ATS Intelligent Discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (Relationship Generating Graph Analysis Engine). The paper describes these tools and how they were used to discover the contest's scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism.	Schwendiman, L.;McLean, J.;Larson, J.	ATS, Silverdale|c|;;	37946768100;37957250200;37970751200
