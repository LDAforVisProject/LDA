Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	VAST	Oct. 31 2006-Nov. 2 2006	Time Tree: Exploring Time Changing Hierarchies	10.1109/VAST.2006.261450	http://dx.doi.org/10.1109/VAST.2006.261450	3	10	4035741	data visualisation;graphical user interfaces;tree data structures	TimeTree;hierarchical organization chart;hierarchy visualization;individual career path;intelligence analysis;knowledge representation;organization information gathering;time changing hierarchy	Aggregates;Chromium;Data visualization;Engineering profession;History;Information analysis;Navigation;Organization Charts;Tree graphs;Visual analytics	DOI Tree;TimeTree;organizational chart;timeseries data;tree visualization;visual analytics	Intelligence analysis often involves the task of gathering information about an organization. Knowledge about individuals in an organization and their relationships, often represented as a hierarchical organization chart, is crucial for understanding the organization. However, it is difficult for intelligence analysts to follow all individuals in an organization. Existing hierarchy visualizations have largely focused on the visualization of fixed structures and can not effectively depict the evolution of a hierarchy over time. We introduce TimeTree, a novel visualization tool designed to enable exploration of a changing hierarchy. TimeTree enables analysts to navigate the history of an organization, identify events associated with a specific entity (visualized on a TimeSlider), and explore an aggregate view of an individual's career path (a CareerTree). We demonstrate the utility of TimeTree by investigating a set of scenarios developed by an expert intelligence analyst. The scenarios are evaluated using a real dataset composed of eighteen thousand career events from more than eight thousand individuals. Insights gained from this analysis are presented	Card, S.K.;Suh, B.;Pendleton, B.A.;Heer, J.;Bodnar, J.W.	Palo Alto Res. Center, CA|c|;;;;	37444594200;37823184000;37830268500;37550791300;37830251400
	VAST	Oct. 31 2006-Nov. 2 2006	Visual Exploration of Spatio-temporal Relationships for Scientific Data	10.1109/VAST.2006.261451	http://dx.doi.org/10.1109/VAST.2006.261451	11	18	4035742	data mining;data visualisation;graphical user interfaces;scientific information systems;visual databases	analysis algorithm;features extraction;knowledge discovery process;spatio-temporal relationship;temporally-varying scientific dataset;visual analysis system;visual interface	Bifurcation;Computational fluid dynamics;Computer science;Data engineering;Data mining;Feature extraction;Merging;Spatial databases;Visual analytics;Visual databases	D.2.2 [Design Tools and Techniques]: User Interfaces;Feature Extraction;H.2.8 [Database Applications]: Data Mining;H.2.8 [Database Applications]: Scientific Databases;Knowledge Discovery;Scientific Analytics;Spatio-temporal Predicates;Trajectory Analysis;Visual Analytics	Spatio-temporal relationships among features extracted from temporally-varying scientific datasets can provide useful information about the evolution of an individual feature and its interactions with other features. However, extracting such useful relationships without user guidance is cumbersome and often an error prone process. In this paper, we present a visual analysis system that interactively discovers such relationships from the trajectories of derived features. We describe analysis algorithms to derive various spatial and spatio-temporal relationships. A visual interface is presented using which the user can interactively select spatial and temporal extents to guide the knowledge discovery process. We show the usefulness of our proposed algorithms on datasets originating from computational fluid dynamics. We also demonstrate how the derived relationships can help in explaining the occurrence of critical events like merging and bifurcation of the vortices	Mehta, S.;Parthasarathy, S.;Machiraju, R.	Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;;	37275792500;37269057900;37269516700
	VAST	Oct. 31 2006-Nov. 2 2006	Visual Analytics of Paleoceanographic Conditions	10.1109/VAST.2006.261452	http://dx.doi.org/10.1109/VAST.2006.261452	19	26	4035743	geophysics;geophysics computing;oceanographic techniques;oceanography	El Nino;analytical method;climate change forecasting;climatic condition;decade scale oceanic phenomena;global weather anomaly;interactive visual analysis;interactive visual interface;paleo time-series;paleoceanographic condition;paleoceanography;paleodata;visual analytics	Geology;History;Humans;Hurricanes;Image reconstruction;Laboratories;Ocean temperature;Time series analysis;Visual analytics;Weather forecasting	H.1.2 [User/Machine Systems]: Human information processingÂ¿Visual Analytics;Infovis;J.2 [Physical Sciences and Engineering]: Earth and atmospheric sciencesÂ¿Applications;exploratory analysis;multiple linked views;parallel coordinates	Decade scale oceanic phenomena like El Nino are correlated with weather anomalies all over the globe. Only by understanding the events that produced the climatic conditions in the past will it be possible to forecast abrupt climate changes and prevent disastrous consequences for human beings and their environment. Paleoceanography research is a collaborative effort that requires the analysis of paleo time-series, which are obtained from a number of independent techniques and instruments and produced by a variety of different researchers and/or laboratories. The complexity of these phenomena that consist of massive, dynamic and often conflicting data can only be faced by means of analytical reasoning supported by a highly interactive visual interface. This paper presents an interactive visual analysis environment for paleoceanography that permits to gain insight into the paleodata and allow the control and steering of the analytical methods involved in the reconstruction of the climatic conditions of the past	Theron, R.	Departamento de Informalica y Automatica, Univ. de Salamanca|c|	37265587000
	VAST	Oct. 31 2006-Nov. 2 2006	Avian Flu Case Study with nSpace and GeoTime	10.1109/VAST.2006.261427	http://dx.doi.org/10.1109/VAST.2006.261427	27	34	4035744	data visualisation;diseases;graphical user interfaces	GeoTime analysis tool;analytical synergy;avian flu case study;epidemiology analysis;geo-temporal analysis;information triage;knowledge acquisition;nSpace analysis tool;visual analytics	Collaborative work;Graphical user interfaces;Influenza;Information analysis;Information retrieval;NIST;Performance analysis;Time series analysis;Visual analytics;Visualization	geo-spatial information systems;human information interaction;information visualization;sense making;temporal analysis;user centered design;visual analytics	GeoTime and nSpace are new analysis tools that provide innovative visual analytic capabilities. This paper uses an epidemiology analysis scenario to illustrate and discuss these new investigative methods and techniques. In addition, this case study is an exploration and demonstration of the analytical synergy achieved by combining GeoTime's geo-temporal analysis capabilities, with the rapid information triage, scanning and sense-making provided by nSpace. A fictional analyst works through the scenario from the initial brainstorming through to a final collaboration and report. With the efficient knowledge acquisition and insights into large amounts of documents, there is more time for the analyst to reason about the problem and imagine ways to mitigate threats. The use of both nSpace and GeoTime initiated a synergistic exchange of ideas, where hypotheses generated in either software tool could be cross-referenced, refuted, and supported by the other tool	Proulx, P.;Tandon, S.;Bodnar, A.;Schroh, D.;Harper, R.;Wright, W.	Oculus Info Inc., Toronto, Ont.|c|;;;;;	37604342500;37823346300;37830130500;37704437400;37594531000;37654961400
	VAST	Oct. 31 2006-Nov. 2 2006	Visual Analysis of Historic Hotel Visitation Patterns	10.1109/VAST.2006.261428	http://dx.doi.org/10.1109/VAST.2006.261428	35	42	4035745	behavioural sciences computing;data visualisation;hotel industry;social sciences computing;spreadsheet programs	complex social network;consumer behavior analysis;display cyclic pattern;distributed online evaluation;geographic event;historic hotel visitation pattern;human geography;improvise visualization;intelligence analysis;iterative data collection;visual identification analysis;wrapping spreadsheet technique	Calendars;Consumer behavior;Data visualization;Displays;Geography;Humans;Intelligent networks;Pattern analysis;Social network services;Wrapping	D.2.2 [Software Engineering]: Design Tools and TechniquesÂ¿User Interfaces;Geovisualization;H.5.2 [Information Systems]: Information Interfaces and PresentationÂ¿User Interfaces;coordinated multiple views;exploratory visualization;historical geography;travel pattern analysis	Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations	Weaver, C.;Fyfe, D.;Robinson, A.;Holdsworth, D.;Peuquet, D.;MacEachren, A.M.	Dept. of Geogr., Pennsylvania State Univ.|c|;;;;;	37564883300;37830097900;37829187900;37838441900;37830095400;37374699000
	VAST	Oct. 31 2006-Nov. 2 2006	D-Dupe: An Interactive Tool for Entity Resolution in Social Networks	10.1109/VAST.2006.261429	http://dx.doi.org/10.1109/VAST.2006.261429	43	50	4035746	data mining;interactive systems;social sciences computing;user interfaces	D-Dupe interactive tool;data mining algorithm;data quality problem;entity resolution;entity-resolution;social network analysis;social network visualization;task-specific network visualization;task-specific visual interface		Data cleaning and integration;H.2.8 [Information Systems]: Database ApplicationsÂ¿Data mining;H.5.2 [Information Interfaces and Presentation]: User InterfacesÂ¿User-centered design;user interfaces;visual analytics;visual data mining	Visualizing and analyzing social networks is a challenging problem that has been receiving growing attention. An important first step, before analysis can begin, is ensuring that the data is accurate. A common data quality problem is that the data may inadvertently contain several distinct references to the same underlying entity; the process of reconciling these references is called entity-resolution. D-Dupe is an interactive tool that combines data mining algorithms for entity resolution with a task-specific network visualization. Users cope with complexity of cleaning large networks by focusing on a small subnetwork containing a potential duplicate pair. The subnetwork highlights relationships in the social network, making the common relationships easy to visually identify. D-Dupe users resolve ambiguities either by merging nodes or by marking them distinct. The entity resolution process is iterative: as pairs of nodes are resolved, additional duplicates may be revealed; therefore, resolution decisions are often chained together. We give examples of how users can flexibly apply sequences of actions to produce a high quality entity resolution result. We illustrate and evaluate the benefits of D-Dupe on three bibliographic collections. Two of the datasets had already been cleaned, and therefore should not have contained duplicates; despite this fact, many duplicates were rapidly identified using D-Dupe's unique combination of entity resolution algorithms within a task-specific visual interface	Bilgic, M.;Licamele, L.;Getoor, L.	Maryland Univ., College Park, MD|c|;;	37831461700;37829618300;37829614900
	VAST	Oct. 31 2006-Nov. 2 2006	Interactive Visual Synthesis of Analytic Knowledge	10.1109/VAST.2006.261430	http://dx.doi.org/10.1109/VAST.2006.261430	51	58	4035747	data mining;data visualisation;graphical user interfaces;groupware;interactive systems	analytic knowledge;evolving corpus automatic management;information annotation;interactive visual synthesis;progressive visual analysis;synthesized knowledge;user-system cooperative visual synthesis;visual investigation;visual knowledge discovery	Calendars;Context;Data visualization;Information analysis;Information systems;Joining processes;Knowledge management;Network synthesis;Performance analysis;Visual analytics	H.1.2 [Information Systems]: Models and PrinciplesÂ¿User/Machine Systems H.5.1 [Information Systems]:;Intelligence analysis;Problem-solving solving environments;Visual Analytics;Visual Knowledge Discovery	"A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term ""analytic knowledge"" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work"	Gotz, D.;Zhou, M.X.;Aggarwal, V.	IBM T. J. Watson Res. Center, Yorktown Heights, NY|c|;;	37601397400;37399569300;37567125300
	VAST	Oct. 31 2006-Nov. 2 2006	Visual Analysis of Conflicting Opinions	10.1109/VAST.2006.261431	http://dx.doi.org/10.1109/VAST.2006.261431	59	66	4035748	classification;computational linguistics;data visualisation;decision trees	The Da Vinci Code;conflicting opinion;conflicting reviews;decision tree;feature selection process;feature space dimensionality reduction;log likelihood test;negative reviews;positive reviews;predictive term;semantic analysis;statistic association analysis;syntactic analysis;term variation pattern;terminology variation analysis;visual analysis;visualization tool	Chaos;Chromium;Decision trees;Pattern analysis;Statistical analysis;Terminology;Testing;User interfaces;Visual analytics;Visualization	Visual analytics;conflicting opinions;decision tree;predictive text analysis;sense making;terminology variation	Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time	Chen, C.;SanJuan, E.;Weaver, C.	Drexel Univ., Philadelphia, PA|c|;;	37280749300;37840812000;37564883300
	VAST	Oct. 31 2006-Nov. 2 2006	Have Green - A Visual Analytics Framework for Large Semantic Graphs	10.1109/VAST.2006.261432	http://dx.doi.org/10.1109/VAST.2006.261432	67	74	4035749	data visualisation;semantic networks	Have Green;graph visualization;information analytics;information visualization;network visualization;semantic graph;visual analytics framework	Computer displays;Fuses;Information analysis;Laboratories;Ontologies;Pattern analysis;Performance analysis;Software systems;Visual analytics;Visualization	1.6.9 [Visualization] - Information Visualization, Visualization Systems and Software, Visualization Techniques Methodologies;Graph and Network Visualization;Information Analytics;Information Visualization;Visual Analytics	A semantic graph is a network of heterogeneous nodes and links annotated with a domain ontology. In intelligence analysis, investigators use semantic graphs to organize concepts and relationships as graph nodes and links in hopes of discovering key trends, patterns, and insights. However, as new information continues to arrive from a multitude of sources, the size and complexity of the semantic graphs will soon overwhelm an investigator's cognitive capacity to carry out significant analyses. We introduce a powerful visual analytics framework designed to enhance investigators' natural analytical capabilities to comprehend and analyze large semantic graphs. The paper describes the overall framework design, presents major development accomplishments to date, and discusses future directions of a new visual analytics system known as Have Green	Pak Chung Wong;Chin, G.;Foote, H.;Mackey, P.;Thomas, J.	Pacific Northwest Nat. Lab., Richland, WA|c|;;;;	37280665600;37284824700;37372586800;37550755900;37273308900
	VAST	Oct. 31 2006-Nov. 2 2006	Exploring Large-Scale Video News via Interactive Visualization	10.1109/VAST.2006.261433	http://dx.doi.org/10.1109/VAST.2006.261433	75	82	4035750	data visualisation;video signal processing	intelligent news video analysis;interactive visualization;large-scale news video;security application;semantic video classification;video visualization system	Computational intelligence;Computer industry;Computer science;Databases;Decision making;Informatics;Information analysis;Investments;Large-scale systems;Visualization	1.2.6 [Artificial Intelligence]: LearningÂ¿Concept learning;1.3.6 [Computer Graphics]: Methodology and TechniquesÂ¿Interaction Techniques;News Visualization;Semantic Video Classification	In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels	Hangzai Luo;Jianping Fan;Jing Yang;Ribarsky, W.;Satoh, S.	Dept. of Comput. Sci., North Carolina Univ., Charlotte, NC|c|;;;;	37275772500;37271216800;37292632600;37300425000;37823835000
	VAST	Oct. 31 2006-Nov. 2 2006	Interactive Visualization and Analysis of Network and Sensor Data on Mobile Devices	10.1109/VAST.2006.261434	http://dx.doi.org/10.1109/VAST.2006.261434	83	90	4035751	data visualisation;mobile computing;mobile radio;notebook computers;sensor fusion;wireless sensor networks	PDA;emergency planning;inheld data analytics;instant replay video;interactive visualization;mobile device;network data visualization;play statistics;sensor data;synchronized video;text analysis;wireless network access	Data visualization;Decision making;Displays;Game theory;Graphics;Information analysis;Monitoring;Personnel;Safety;Visual analytics	I.3.2 [Computer Graphics]: Graphics SystemsÂ¿Network Graphics;I.3.8 [Computer Graphics]: ApplicationsÂ¿Visual Analytics;mobile visualization;network visualization;visual analytics	Mobile devices are rapidly gaining popularity due to their small size and their wide range of functionality. With the constant improvement in wireless network access, they are an attractive option not only for day to day use. but also for in-field analytics by first responders in widespread areas. However, their limited processing, display, graphics and power resources pose a major challenge in developing effective applications. Nevertheless, they are vital for rapid decision making in emergencies when combined with appropriate analysis tools. In this paper, we present an efficient, interactive visual analytic system using a PDA to visualize network information from Purdue's Ross-Ade Stadium during football games as an example of in-held data analytics combined with text and video analysis. With our system, we can monitor the distribution of attendees with mobile devices throughout the stadium through their access of information and association/disassociation from wireless access points, enabling the detection of crowd movement and event activity. Through correlative visualization and analysis of synchronized video (instant replay video) and text information (play statistics) with the network activity, we can provide insightful information to network monitoring personnel, safety personnel and analysts. This work provides a demonstration and testbed for mobile sensor analytics that will help to improve network performance and provide safety personnel with information for better emergency planning and guidance	Pattath, A.;Bue, B.;Yun Jang;Ebert, D.;Xuan Zhong;Coyle, E.	Regional Visualization & Analytics Center, Purdue Univ., West Lafayette, IN|c|;;;;;	37296890200;37296901100;37557344300;38472156500;37290193000;37273340400
	VAST	Oct. 31 2006-Nov. 2 2006	NetLens: Iterative Exploration of Content-Actor Network Data	10.1109/VAST.2006.261426	http://dx.doi.org/10.1109/VAST.2006.261426	91	98	4035752	data models;data visualisation;digital libraries;graphical user interfaces	NetLens interface;abstract data model;content-actor network data;digital library;human-computer interaction;incremental data exploration;information retrieval;information visualization;iterative query refinement;network visualization;piccolo	Data models;Data visualization;Displays;Graphical user interfaces;Laboratories;Law;Legal factors;Software libraries;User interfaces;Visual analytics	Human-Computer Interaction;content-actor network data;digital library;incremental data exploration;information visualization;iterative query refinement;network visualization;piccolo;user interfaces	Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases	Hyunmo Kang;Plaisant, C.;Bongshin Lee;Bederson, B.B.	Univ. of Maryland Inst. for Adv. Comput. Studies|c|;;;	37291403000;37283026800;37293389400;37279760100
	VAST	Oct. 31 2006-Nov. 2 2006	Interactive Wormhole Detection in Large Scale Wireless Networks	10.1109/VAST.2006.261435	http://dx.doi.org/10.1109/VAST.2006.261435	99	106	4035753	data visualisation;radio networks;security of data;telecommunication security	automatic detection algorithm;interactive visualization of wormholes;interactive wormhole detection;intrusion detection;large scale wireless network;network topology visualization;routing protocol;user interaction	Communication system security;Detection algorithms;Hardware;Information security;Large-scale systems;Monitoring;Network topology;Routing protocols;Visualization;Wireless networks	C.2.0 [Computer-Communication Networks]: GeneralÂ¿Security and protection;H.5.2 [Information Systems]: Information Interfaces and PresentationÂ¿User interfaces;Interactive Detection;Topology Visualization;Visualization on Network Security;Wireless Networks;Wormhole Attacks	Wormhole attacks in wireless networks can severely deteriorate the network performance and compromise the security through spoiling the routing protocols and weakening the security enhancements. This paper develops an approach, interactive visualization of wormholes (IVoW), to monitor and detect such attacks in large scale wireless networks in real time. We characterize the topology features of a network under wormhole attacks through the node position changes and visualize the information at dynamically adjusted scales. We integrate an automatic detection algorithm with appropriate user interactions to handle complicated scenarios that include a large number of moving nodes and multiple worm-hole attackers. Various visual forms have been adopted to assist the understanding and analysis of the reconstructed network topology and improve the detection accuracy. Extended simulation has demonstrated that the proposed approach can effectively locate the fake neighbor connections without introducing many false alarms. IVoW does not require the wireless nodes to be equipped with any special hardware, thus avoiding any additional cost. The proposed approach demonstrates that interactive visualization can be successfully combined with network security mechanisms to greatly improve the intrusion detection capabilities	Weichao Wang;Aidong Lu	Kansas Univ.|c|;	37538916500;37545504600
	VAST	Oct. 31 2006-Nov. 2 2006	Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation	10.1109/VAST.2006.261436	http://dx.doi.org/10.1109/VAST.2006.261436	107	114	4035754	data visualisation;knowledge representation;telecommunication traffic	analytic reasoning;knowledge representation;network pattern;network traffic analysis system;network traffic visualization	Chromium;Data visualization;Filtering;Image sequence analysis;Knowledge representation;Laboratories;Pattern analysis;Telecommunication traffic;Traffic control;Web pages	network traffic visualization;visual analysis	This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory	Ling Xiao;Gerth, J.;Hanrahan, P.	Stanford Univ., Palo Alto, CA|c|;;	37836526900;37840462500;37349803800
	VAST	Oct. 31 2006-Nov. 2 2006	Accelerating Network Traffic Analytics Using Query-Driven Visualization	10.1109/VAST.2006.261437	http://dx.doi.org/10.1109/VAST.2006.261437	115	122	4035755	data mining;data visualisation;query formulation;telecommunication traffic	compressed bitmap indexing;data filtering;data mining;hypothesis testing;interactive ad-hoc formulation;interactive visual data analysis;knowledge discovery;multiresolution query formulation;network connection data analysis;network security;network traffic analytics;query-driven visualization;scientific data management	Acceleration;Data analysis;Data visualization;Filtering;Indexing;Knowledge management;Technology management;Telecommunication traffic;Testing;Time factors	data mining;network security;query-driven visualization;visual analytics	Realizing operational analytics solutions where large and complex data must be analyzed in a time-critical fashion entails integrating many different types of technology. This paper focuses on an interdisciplinary combination of scientific data management and visualization/analysis technologies targeted at reducing the time required for data filtering, querying, hypothesis testing and knowledge discovery in the domain of network connection data analysis. We show that use of compressed bitmap indexing can quickly answer queries in an interactive visual data analysis application, and compare its performance with two alternatives for serial and parallel filtering/querying on 2.5 billion records' worth of network connection data collected over a period of 42 weeks. Our approach to visual network connection data exploration centers on two primary factors: interactive ad-hoc and multiresolution query formulation and execution over n dimensions and visual display of the n-dimensional histogram results. This combination is applied in a case study to detect a distributed network scan and to then identify the set of remote hosts participating in the attack. Our approach is sufficiently general to be applied to a diverse set of data understanding problems as well as used in conjunction with a diverse set of analysis and visualization tools	Bethel, E.W.;Campbell, S.;Dart, E.;Stockinger, K.;Kesheng Wu	Lawrence Berkeley Nat. Lab., California Univ.|c|;;;;	;37551989600;37829631700;37283413300;37278663800
	VAST	Oct. 31 2006-Nov. 2 2006	Monitoring Network Traffic with Radial Traffic Analyzer	10.1109/VAST.2006.261438	http://dx.doi.org/10.1109/VAST.2006.261438	123	128	4035756	Internet;computer animation;data visualisation;intranets;telecommunication traffic	HistoMap technique;Internet;geographic distortion technique;information visualization;intranet;network packet volume;network traffic monitoring;network type distribution information;radial traffic analyzer;scalable visualization toolkit	Animation;Computer networks;Computerized monitoring;Data analysis;Data visualization;Displays;IP networks;Information analysis;Performance analysis;Telecommunication traffic	Geography-based Solutions;Information Visualization;Network Traffic Monitoring;Visual Analytics	Extensive spread of malicious code on the Internet and also within intranets has risen the user's concern about what kind of data is transferred between her or his computer and other hosts on the network. Visual analysis of this kind of information is a challenging task, due to the complexity and volume of the data type considered, and requires special design of appropriate visualization techniques. In this paper, we present a scalable visualization toolkit for analyzing network activity of computer hosts on a network. The visualization combines network packet volume and type distribution information with geographic information, enabling the analyst to use geographic distortion techniques such as the HistoMap technique to become aware of the traffic components in the course of the analysis. The presented analysis tool is especially useful to compare important network load characteristics in a geographically aware display, to relate communication partners, and to identify the type of network traffic occurring. The results of the analysis are helpful in understanding typical network communication activities, and in anticipating potential performance bottlenecks or problems. It is suited for both off-line analysis of historic data, and via animation for on-line monitoring of packet-based network traffic in real time	Keim, D.A.;Mansmann, F.;Schneidewind, J.;Schreck, T.	Databases, Data Min. & Visualization Group, Konstanz Univ.|c|;;;	37283138700;37392086200;37669961800;37282557600
	VAST	Oct. 31 2006-Nov. 2 2006	Toward a Multi-Analyst, Collaborative Framework for Visual Analytics	10.1109/VAST.2006.261439	http://dx.doi.org/10.1109/VAST.2006.261439	129	136	4035757	data visualisation;groupware;knowledge representation	collaborative visualization;data management;distributed visualization;interactive collaboration;knowledge representation;multidimensional visualization;visual analytics;visual knowledge discovery;visual representation	Collaboration;Collaborative work;Data visualization;History;Humans;Information analysis;Knowledge representation;Multidimensional systems;Uncertainty;Visual analytics	Collaborative and distributed visualization;Data management and knowledge representation;Visual Analytics;Visual knowledge discovery	We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts	Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.	Stony Brook Univ., NY|c|;;;;;	37840264500;37273119700;37418690100;37284911300;37344836300;37268052800
	VAST	Oct. 31 2006-Nov. 2 2006	Collaborative Visual Analytics: Inferring from the Spatial Organization and Collaborative Use of Information	10.1109/VAST.2006.261415	http://dx.doi.org/10.1109/VAST.2006.261415	137	144	4035758	data visualisation;graphical user interfaces;groupware	collaborative visual analytics;computational agent;graphical interface;indirect collaboration;indirect human computer interaction;remote-collaborative sense-making activity;spatial information organization;task-relevant information;temporal information organization	Collaboration;Collaborative work;Computer interfaces;Computer science;Data visualization;Humans;Information analysis;Information retrieval;Problem-solving;Visual analytics	Agents;H.3.3 [Information Search and Retrieval]: Information filtering, Relevance feedback, Selection process;H.4.1 [Office Automation]: Groupware;H.5.3 [Group and Organization Interfaces]: Collaborative computing, Computer-supported cooperative work;Indirect collaboration;Indirect human computer interaction;Sense-making;Spatial information organization;Visual analytics	We introduce a visual analytics environment for the support of remote-collaborative sense-making activities. Team members use their individual graphical interfaces to collect, organize and comprehend task-relevant information relative to their areas of expertise. A system of computational agents infers possible relationships among information items through the analysis of the spatial and temporal organization and collaborative use of information. The computational agents support the exchange of information among team members to converge their individual contributions. Our system allows users to navigate vast amounts of shared information effectively and remotely dispersed team members to work independently without diverting from common objectives as well as to minimize the necessary amount of verbal communication	Keel, P.E.	Comput. Sci. & Artificial Intelligence Lab., Massachusetts Inst. of Technol.|c|	37830092200
	VAST	Oct. 31 2006-Nov. 2 2006	Beyond Usability: Evaluation Aspects of Visual Analytic Environments	10.1109/VAST.2006.261416	http://dx.doi.org/10.1109/VAST.2006.261416	145	150	4035759	data analysis;data visualisation;graphical user interfaces;interactive systems	analytical reasoning;collaboration;creativity;evaluation metrics;interaction;interactive visual interfaces;situation awareness;usability;utility;visual analytic environments;visual representations	Collaborative work;Hardware;Humans;Information analysis;Information retrieval;Production;Speech recognition;Usability;Visual analytics;Visualization	analytic environments;metrics;visualization	"A new field of research, visual analytics, has been introduced. This has been defined as ""the science of analytical reasoning facilitated by interactive visual interfaces"" (Thomas and Cook, 2005). Visual analytic environments, therefore, support analytical reasoning using visual representations and interactions, with data representations and transformation capabilities, to support production, presentation, and dissemination. As researchers begin to develop visual analytic environments, it is advantageous to develop metrics and methodologies to help researchers measure the progress of their work and understand the impact their work has on the users who work in such environments. This paper presents five areas or aspects of visual analytic environments that should be considered as metrics and methodologies for evaluation are developed. Evaluation aspects need to include usability, but it is necessary to go beyond basic usability. The areas of situation awareness, collaboration, interaction, creativity, and utility are proposed as the five evaluation areas for initial consideration. The steps that need to be undertaken to develop systematic evaluation methodologies and metrics for visual analytic environments are outlined"	Scholtz, J.	Pacific Northwest Nat. Lab., Richland, WA|c|	37268671300
	VAST	Oct. 31 2006-Nov. 2 2006	Visualizing the Performance of Computational Linguistics Algorithms	10.1109/VAST.2006.261417	http://dx.doi.org/10.1109/VAST.2006.261417	151	157	4035760	computational linguistics;document handling;portals;program visualisation;software performance evaluation	AJAX;ROC curves;SVG visualization components;analysis portal;computational linguistics algorithm performance visualization;confusion matrices;document classification;document clustering;document visualizations;interactive reports;scalable vector graphics;thin-client Web-based components	Algorithm design and analysis;Clustering algorithms;Computational linguistics;Content based retrieval;Information retrieval;Performance analysis;Portals;Storage automation;Text analysis;Visualization	AJAX;ROC curves;SVG;confusion matrices;document categorization;thin-client	We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components	Eick, S.G.;Mauger, J.;Ratner, A.	SSS Res., Inc., Naperville, IL|c|;;	37282570100;37838214600;37662038500
	VAST	Oct. 31 2006-Nov. 2 2006	Scentindex: Conceptually Reorganizing Subject Indexes for Reading	10.1109/VAST.2006.261418	http://dx.doi.org/10.1109/VAST.2006.261418	159	166	4035761	electronic publishing;indexing;information needs	ScentIndex;book index;conceptual subject index reorganization;contextualization;ebooks;navigational cues;personalized information access;reading;visual analytic environments		Book Index;Information Scent;contextualization;eBooks;personalized information access	A great deal of analytical work is done in the context of reading, in digesting the semantics of the material, the identification of important entities, and capturing the relationship between entities. Visual analytic environments, therefore, must encompass reading tools that enable the rapid digestion of large amount of reading material. Other than plain text search, subject indexes, and basic highlighting, tools are needed for rapid foraging of text. In this paper, we describe a technique that presents an enhanced subject index for a book by conceptually reorganizing it to suit particular expressed user information needs. Users first enter information needs via keywords describing the concepts they are trying to retrieve and comprehend. Then our system, called ScentIndex, computes what index entries are conceptually related and reorganizes and displays these index entries on a single page. We also provide a number of navigational cues to help users peruse over this list of index entries and find relevant passages quickly. Compared to regular reading of a paper book, our study showed that users are more efficient and more accurate in finding, comparing, and comprehending material in our system	Chi, Ed H.;Lichan Hong;Heiser, J.;Card, S.K.	Palo Alto Res. Center, CA|c|;;;	37448030800;37347459100;37837705900;37444594200
	VAST	Oct. 31 2006-Nov. 2 2006	A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories	10.1109/VAST.2006.261421	http://dx.doi.org/10.1109/VAST.2006.261421	167	174	4035762	data analysis;data visualisation;graphical user interfaces;pattern recognition;query processing	PatternFinder integrated interface;ball-and-chain visualization;event pattern discovery;multivariate temporal data;query visualization;result-set visualization;tabular visualization;temporal pattern discovery;temporal pattern searching;visual interface	Chromium;Computer science;Data visualization;Database languages;History;Medical treatment;Pattern analysis;Spatial databases;User interfaces;Visual databases	Temporal query;information visualization;user interface	Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)	Fails, J.A.;Karlson, A.;Shahamat, L.	Dept. of Comput. Sci., Maryland Univ.|c|;;	37830130000;38266509300;37565888100
	VAST	Oct. 31 2006-Nov. 2 2006	User Interfaces for the Exploration of Hierarchical Multi-dimensional Data	10.1109/VAST.2006.261422	http://dx.doi.org/10.1109/VAST.2006.261422	175	182	4035763	data mining;query processing;user interfaces	OLAP;data querying;hierarchical multidimensional data exploration;parallel dimension axis;scalable interface;user interfaces	Chromium;Data analysis;Data mining;Data visualization;Information systems;Marketing and sales;Polarization;Scattering;Usability;User interfaces	Data exploration;OLAP;parallel coordinates;visualization	A variety of user interfaces have been developed to support the querying of hierarchical multi-dimensional data in an OLAP setting such as pivot tables and Polaris. They are used to regularly check portions of a dataset and to explore a new dataset for the first time. In this paper, we establish criteria for OLAP user interface capabilities to facilitate comparison. Two criteria are the number of displayed dimensions along which comparisons can be made and the number of dimensions that are viewable at once - visual comparison depth and width. We argue that interfaces with greater visual comparison depth support regular checking of known data by users that know roughly where to look, while interfaces with greater comparison width support exploration of new data by users that have no a priori starting point and need to scan all dimensions. Pivot tables and Polaris are examples of the former. The main contribution of this paper is to introduce a new scalable interface that uses parallel dimension axis which supports the latter, greater visual comparison width. We compare our approach to both table based and parallel coordinate based interfaces. We present an implementation of our interface SGViewer, user scenarios and provide an evaluation that supports the usability of our interface	Sifer, M.	Sch. of Econ. & Inf. Syst., Wollongong Univ., NSW|c|	37347571400
	VAST	Oct. 31 2006-Nov. 2 2006	Exploratory Visualization of Multivariate Data with Variable Quality	10.1109/VAST.2006.261424	http://dx.doi.org/10.1109/VAST.2006.261424	183	190	4035764	data integrity;data visualisation	data quality;exploratory visualization;multivariate data visualization;uncertainty visualization;variable quality;visual mapping	Computer errors;Computer science;Data mining;Data visualization;Displays;Estimation error;Humans;Information analysis;Spatiotemporal phenomena;Uncertainty	H.5.2 [Information Interfaces and Presentation]: User InterfacesÂ¿Graphical user interfaces;Uncertainty visualization;data quality;multivariate visualization	Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches	Xie Zaixian;Huang Shiping;Ward, M.O.;Rundensteiner, E.A.	Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;	37829093300;37557769100;37268441700;37279217900
	VAST	Oct. 31 2006-Nov. 2 2006	Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis	10.1109/VAST.2006.261425	http://dx.doi.org/10.1109/VAST.2006.261425	191	198	4035765	data visualisation;image retrieval;interactive systems	automated intelligent image analysis;high dimensional visualization;image retrieval;information visualization;interaction tools;interactive visual exploration;large image databases;multidimensional scaling based image layout;semantic image analysis;semantic image browser;semantic image classification;value and relation display;visual analytics	Computer science;Computerized monitoring;Displays;Image analysis;Image classification;Image databases;Image retrieval;Information retrieval;Visual analytics;Visualization	1.4.8 [Image Processing and Computer Vision]: Scene AnalysisÂ¿Object recognition;H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalÂ¿Search process;H.5.2 [Information Interfaces and Presentation]: User InterfacesÂ¿Graphical user interfaces;Image retrieval;image layout;multi-dimensional visualization;semantic image classification;visual analytics	Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks	Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.	Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;	37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700
	VAST	Oct. 31 2006-Nov. 2 2006	Pixnostics: Towards Measuring the Value of Visualization	10.1109/VAST.2006.261423	http://dx.doi.org/10.1109/VAST.2006.261423	199	206	4035766	data analysis;data visualisation;image processing	pixel image analysis;visual analytics;visual data analysis;visual data exploration;visualization value measurement	Color;Data analysis;Data visualization;Humans;Image analysis;Pattern analysis;Pixel;Space technology;USA Councils;Visual analytics	1.6.9 [Visualization]: Information VisualizationÂ¿Visualization Techniques and Methodologies;Visual Analytics;Visual Data Exploration;Visualization technique	During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach	Schneidewind, J.;Sips, M.;Keim, D.A.	Konstanz Univ.|c|;;	37669961800;37827860500;37283138700
	VAST	Oct. 31 2006-Nov. 2 2006	VAST 2006 Contest - A Tale of Alderwood	10.1109/VAST.2006.261420	http://dx.doi.org/10.1109/VAST.2006.261420	215	216	4035768	data analysis;data visualisation	Alderwood;human information interaction;sense making;visual analytics science and technology contest	Cities and towns;Data analysis;Data visualization;Feedback;Graphical user interfaces;Humans;IEEE news;Laboratories;NIST;Visual analytics	H.5.2 [Information Interfaces & Presentations]: User Interfaces - Graphical User Interfaces (GUI);contest;evaluation;human information interaction;metrics;sense making;visual analytics	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The first visual analytics science and technology (VAST) contest was held in conjunction with the 2006 IEEE VAST Symposium. The competition entailed the identification of possible political shenanigans in the fictitious town of Alderwood. A synthetic data set was made available as well as tasks. We summarize how we prepared and advertised the contest, developed some initial metrics for evaluation, and selected the winners. The winners were invited to participate at an additional live competition at the symposium to provide them with feedback from senior analysts	Grinstein, G.;O'Connell, T.;Laskowski, S.;Plaisant, C.;Scholtz, J.;Whiting, M.	Univ. of Massachusetts Lowell, MA|c|;;;;;	37360588500;37825268500;37837224000;37283026800;37268671300;37357067600
	InfoVis+SciVis	Sept.-Oct. 2006	Vis/InfoVis 2006 pre-pages	10.1109/TVCG.2006.191	http://dx.doi.org/10.1109/TVCG.2006.191	vispre	vispre	4015415					These pre-pages to the issue contain a table of contents, a list of supporting organizations, a message from the Editor-in-Chief, the preface, committee and reviewer listings, 2005 visualization awards, and the keynote and capstone addressess for Vis and InfoVis.			
	InfoVis+SciVis	Sept.-Oct. 2006	ASK-GraphView: A Large Scale Graph Visualization System	10.1109/TVCG.2006.120	http://dx.doi.org/10.1109/TVCG.2006.120	669	676	4015416	data visualisation;graph theory;pattern clustering	ASK-GraphView;cluster labeling;graph clustering;interactive navigation;large scale graph visualization system;node-link-based graph visualization system;weighted undirected input graph	Aggregates;Clustering algorithms;Filtering;Finite element methods;Labeling;Large-scale systems;Navigation;Scalability;Tree graphs;Visualization	Graph Clustering.;Graph Visualization;Information Visualization	We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling	Abello, J.;Neeraj Krishnan	Rutgers Univ., New Brunswick, NJ|c|;	38357070200;37823691100
	InfoVis+SciVis	Sept.-Oct. 2006	MatrixExplorer: a Dual-Representation System to Explore Social Networks	10.1109/TVCG.2006.160	http://dx.doi.org/10.1109/TVCG.2006.160	677	684	4015417	data visualisation;diagrams;graph theory;matrix algebra;pattern clustering;social sciences computing	MatrixExplorer;clustering functions;dual-representation system;interactive filtering;matrix-based representations;network visualization system;node-link diagrams;social networks		consensus.;exploratory process;interactive clustering;matrix ordering;matrix-based representations;node-link diagrams;social networks visualization	MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process	Henry, N.;Fekete, J.	LRI|c|;	37839948300;37407972900
	InfoVis+SciVis	Sept.-Oct. 2006	Visual Analysis of Multivariate State Transition Graphs	10.1109/TVCG.2006.192	http://dx.doi.org/10.1109/TVCG.2006.192	685	692	4015418	data visualisation;diagrams;pattern clustering;tree data structures;trees (mathematics)	arc diagram;bar tree;hierarchically structured quantitative data visualization;industrial wafer stepper;interactive attribute-based clustering facility;multivariate state transition graphs;node-link diagram;relational data;visual analysis	Automata;Computer languages;Computer science;Data visualization;Industrial relations;Mathematics;Semiconductor device modeling;State-space methods;Tree graphs	Graph visualization;finite state machines.;interactive clustering;multivariate visualization;state spaces;transition systems	We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges	Pretorius, A.J.;van Wijk, J.J.	Dept. of Math. & Comput. Sci., Technische Univ. Eindhoven|c|;	37283038200;37267249200
	InfoVis+SciVis	Sept.-Oct. 2006	Balancing Systematic and Flexible Exploration of Social Networks	10.1109/TVCG.2006.122	http://dx.doi.org/10.1109/TVCG.2006.122	693	700	4015419	data analysis;data visualisation;graph theory;graphical user interfaces;matrix algebra;social sciences computing	SocialAction;attribute ranking;data analysis;matrix overview;network visualization;social network analysis;statistical methods	Aggregates;Coordinate measuring machines;Data analysis;Data visualization;Filters;Gain measurement;Navigation;Pattern analysis;Social network services;Statistical analysis	Social networks;attribute ranking;coordinated views;exploratory data analysis;interactive graph visualization	Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks	Perer, A.;Shneiderman, B.	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	37294938400;37283016400
	InfoVis+SciVis	Sept.-Oct. 2006	Multi-Scale Banking to 45 Degrees	10.1109/TVCG.2006.163	http://dx.doi.org/10.1109/TVCG.2006.163	701	708	4015420	computational geometry;data visualisation;human factors;optimisation;spectral analysis;visual perception	aspect ratio;line chart;line segments;multiscale banking;optimization technique;spectral analysis;visual perception;visualization tools	Acceleration;Banking;Carbon dioxide;Data visualization;Design optimization;Frequency;Observatories;Spectral analysis;Time measurement;Visual perception	Information visualization;banking to 45 degrees;graphical perception;line charts;sparklines;time-series	In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst's perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples	Heer, J.;Agrawala, M.	Comput. Sci. Div., California Univ., Berkeley, CA|c|;	37550791300;37282718200
	InfoVis+SciVis	Sept.-Oct. 2006	Measuring Data Abstraction Quality in Multiresolution Visualizations	10.1109/TVCG.2006.161	http://dx.doi.org/10.1109/TVCG.2006.161	709	716	4015421	data analysis;data structures;data visualisation;pattern clustering;sampling methods;very large databases	XmdvTool;data abstraction quality measures;data clustering;histogram difference measure;multivariate data analysis;nearest neighbor measure;public-domain multiresolution visualization system	Bioinformatics;Coordinate measuring machines;Data analysis;Data visualization;Delay;Density measurement;Displays;Histograms;Nearest neighbor searches;Sampling methods	Clustering;Metrics;Multiresolution Visualization Authors 1:;Sampling	Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks	Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Jing Yang	Worcester Polytech. Inst., MA|c|;;;	37841616400;37268441700;37279217900;37292632600
	InfoVis+SciVis	Sept.-Oct. 2006	Enabling Automatic Clutter Reduction in Parallel Coordinate Plots	10.1109/TVCG.2006.138	http://dx.doi.org/10.1109/TVCG.2006.138	717	724	4015422	data visualisation;hidden feature removal;probability;sampling methods	automatic clutter reduction;binning technique;occlusion;parallel coordinate plots;probabilistic approach;random sampling	Coordinate measuring machines;Data visualization;Displays;Filtering;Lenses;Motion measurement;Sampling methods	Sampling;clutter;density reduction;information visualisation;lens;occlusion;overplotting;parallel coordinates.;random sampling	We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement	Ellis, G.;Dix, A.	Lancaster Univ.|c|;	37283380700;37283381700
	InfoVis+SciVis	Sept.-Oct. 2006	Topographic Visualization of Prefix Propagation in the Internet	10.1109/TVCG.2006.185	http://dx.doi.org/10.1109/TVCG.2006.185	725	732	4015423	Internet;data visualisation;graph theory;telecommunication network routing	BGPlay service;ISP;Internet Service Providers;Internet routing monitoring tool;graph drawing;prefix propagation;topographic map;topographic visualization	Displays;IP networks;Local area networks;Monitoring;Real time systems;Routing;Springs;Testing;Visualization;Web and internet services	Graph Drawing;Interdomain Routing;Internet Visualization;Spring Embedder	We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators	Cortese, P.F.;Moneta, A.;Patrignani, M.;Pizzonia, M.	Dipt. di Informatica e Automazione, Rome Univ.|c|;;;	37827873200;37827870000;37267060000;37294504700
	InfoVis+SciVis	Sept.-Oct. 2006	Network Visualization by Semantic Substrates	10.1109/TVCG.2006.166	http://dx.doi.org/10.1109/TVCG.2006.166	733	740	4015424	data visualisation;graphical user interfaces	NVSS 1.0;graphical user interfaces;information visualization designers;legal citations;legal precedent data;network visualization;user-defined semantic substrates	Automatic control;Data visualization;Displays;Filters;Graphical user interfaces;Law;Legal factors;Scalability;Terminology;Tunneling	Network visualization;graphical user interfaces;information visualization;semantic substrate	Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations	Shneiderman, B.;Aris, A.	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	37283016400;37561646300
	InfoVis+SciVis	Sept.-Oct. 2006	Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data	10.1109/TVCG.2006.147	http://dx.doi.org/10.1109/TVCG.2006.147	741	748	4015425	curve fitting;data visualisation;splines (mathematics);tree data structures;trees (mathematics)	B-spline curve;adjacency relation visualization;compound graph;hierarchical data;hierarchical edge bundles;tree visualization method;visual clutter	Cables;Data visualization;Displays;Social network services;Software systems;Spline;Tree data structures;Tree graphs;Wires	Network visualization;curves;edge aggregation;edge bundling;edge concentration;graph visualization;hierarchies;node-link diagrams;tree visualization;treemaps.	A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations	Holten, D.	Technische Univ. Eindhoven|c|	37827881300
	InfoVis+SciVis	Sept.-Oct. 2006	Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement	10.1109/TVCG.2006.198	http://dx.doi.org/10.1109/TVCG.2006.198	749	756	4015426	cartography;data visualisation	PixelMaps;cartogram-based map distortion;geo-spatial point set visualization;global shape functions;information visualization;local pixel placement;shape transformation;spatially-transformed maps	Cellular phones;Cities and towns;Credit cards;Data analysis;Data visualization;Genomics;Kernel;Marketing and sales;Shape;Telephony	Cartogram;Geo-spatial Data;Pixel Placement;Shape Transformation	In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets	Panse, C.;Sips, M.;Keim, D.A.;North, S.C.	Eidgenossische Tech. Hochschule, Zurich|c|;;;	37282557300;37827860500;37283138700;37372818600
	InfoVis+SciVis	Sept.-Oct. 2006	Worldmapper: The World as You&#39;ve Never Seen it Before	10.1109/TVCG.2006.202	http://dx.doi.org/10.1109/TVCG.2006.202	757	764	4015427	Internet;cartography;data visualisation;geographic information systems;socio-economic effects	Web;Worldmapper project;cartogram;computer graphics;geographic data visualization technique;map projection;socio-economic data representation	Application software;Area measurement;Computer graphics;Data visualization;Educational institutions;Energy consumption;Internet;Power generation economics;Shape;Statistics	Cartogram.;Computer Graphics;Data Visualization;Geographic Visualization;Social Visualization;Worldmapper	This paper describes the Worldmapper project, which makes use of novel visualization techniques to represent a broad variety of social and economic data about the countries of the world. The goal of the project is to use the map projections known as cartograms to depict comparisons and relations between different territories, and its execution raises many interesting design challenges that were not all apparent at the outset. We discuss the approaches taken towards these challenges, some of which may have considerably broad application. We conclude by commenting on the positive initial response to the Worldmapper images published on the Web, which we believe is due, at least in part, to the particular effectiveness of the cartogram as a tool for communicating quantitative geographic data	Dorling, D.;Barford, A.;Newman, M.	Univ. of Sheffield|c|;;	37827878600;37827879900;37840240600
	InfoVis+SciVis	Sept.-Oct. 2006	Spatial Analysis of News Sources	10.1109/TVCG.2006.179	http://dx.doi.org/10.1109/TVCG.2006.179	765	772	4015428	Internet;data visualisation;geographic information systems;information resources;text analysis	GIS;Lydia large-scale newspaper analysis system;Web data visualization;document visualization;entity datamap;geographic data visualization;information analytics;news sources;regional bias display;spatial analysis;spatial visualization;text visualization	Cities and towns;Computer science;Data analysis;Data visualization;Displays;Frequency estimation;Information analysis;Large-scale systems;Natural language processing;World Wide Web	GIS;Geographic Visualization;Information analytics;Newspapers;Spidering;Text and Document Visualization;WWW data visualization	People in different places talk about different things. This interest distribution is reflected by the newspaper articles circulated in a particular area. We use data from our large-scale newspaper analysis system (Lydia) to make entity datamaps, a spatial visualization of the interest in a given named entity. Our goal is to identify entities which display regional biases. We develop a model of estimating the frequency of reference of an entity in any given city from the reference frequency centered in surrounding cities, and techniques for evaluating the spatial significance of this distribution	Mehler, A.;Bao, Y.;Xin Li;Yue Wang;Skiena, S.	Dept. of Comput. Sci., Stony Brook Univ.|c|;;;;	37839290200;37828493400;37539506500;37311551500;37390017300
	InfoVis+SciVis	Sept.-Oct. 2006	Dynamic Map Labeling	10.1109/TVCG.2006.136	http://dx.doi.org/10.1109/TVCG.2006.136	773	780	4015429	cartography;computational complexity;data visualisation;geographic information systems;human computer interaction;optimisation;user interfaces	G-Vis system;GIS;HCI;Web browser;computational cartography;continental USA full-detail dynamic map;dynamic map labeling;human-computer interface;interactive display;label consistency;label filtering;label placement;label popping;label selection;optimization problem		GIS;HCI;Map labeling;computational cartography;dynamic maps;human-computer interface;label consistency;label filtering;label placement;label selection;preprocessing.;realtime	"We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for ""consistent"" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call ""invariant point placements"". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser"	Been, K.;Daiches, E.;Yap, C.	Yeshiva Univ.|c|;;	37298478100;37827862300;38467585700
	InfoVis+SciVis	Sept.-Oct. 2006	Visualization of Barrier Tree Sequences	10.1109/TVCG.2006.196	http://dx.doi.org/10.1109/TVCG.2006.196	781	788	4015430	biology computing;computer animation;data visualisation;macromolecules;molecular biophysics;organic compounds;sequences;trees (mathematics)	RNA folding landscape visualization;RNA molecule spatial structures;barrier tree animation;barrier tree sequence visualization;dynamic supergraph layout problem;graph drawing;tolerance algorithm	Animation;Bioinformatics;Biomedical signal processing;Computer science;Heuristic algorithms;Joining processes;RNA;Tree graphs;US Department of Transportation;Visualization	Graph drawing;RNA folding;barrier tree;dynamic graph;energy landscape;fitness landscape	Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation	Heine, C.;Scheuermann, G.;Flamm, C.;Hofacker, I.L.;Stadler, P.F.	Dept. of Comput. Sci., Leipzig Univ.|c|;;;;	37410427900;37282574800;37827878900;37271796900;37271818100
	InfoVis+SciVis	Sept.-Oct. 2006	Visualizing Business Data with Generalized Treemaps	10.1109/TVCG.2006.200	http://dx.doi.org/10.1109/TVCG.2006.200	789	796	4015431	business data processing;business graphics;data models;data visualisation;tree data structures	business data visualization;business graphics;generalized treemap algorithm;hierarchical data visualization;histogram;layout algorithm;pie chart;squarified algorithm	Data visualization	Information visualization;business graphics;hierarchical data;treemap	Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles	Vliegen, R.;van Wijk, J.J.	MagnaView|c|;	37827870300;37267249200
	InfoVis+SciVis	Sept.-Oct. 2006	FacetMap: A Scalable Search and Browse Visualization	10.1109/TVCG.2006.142	http://dx.doi.org/10.1109/TVCG.2006.142	797	804	4015432	data visualisation;interactive systems;meta data;personal information systems;query processing	FacetMap graphical approach;FacetMap interactive query-driven visualization;Web;browse visualization;data store text-based browsing;data store text-based searching;faceted metadata-rich data stores;graphical visualization;interactive information retrieval;search visualization;visual metaphor	Data visualization;Driver circuits;Electronic mail;Filters;Information retrieval;Investments;Microcomputers;Operating systems;Web pages;Web search	Graphical visualization;faceted metadata;interactive information retrieval	The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach			
	InfoVis+SciVis	Sept.-Oct. 2006	Visual Exploration of Complex Time-Varying Graphs	10.1109/TVCG.2006.193	http://dx.doi.org/10.1109/TVCG.2006.193	805	812	4015433	computational geometry;data visualisation;trees (mathematics)	biconnected components;bioinformatics;computer network;force-directed approach;graph layout;graph visualization;network visualization;quasitree drawing algorithm;spanning tree skeleton;tree-like graph structure	Algorithm design and analysis;Animation;Data mining;Data visualization;Filters;Heuristic algorithms;Information analysis;Layout;Stock markets;Tree graphs	Graph and network visualization;financial data visualization;hierarchy visualization;time series data	Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality	Kumar, G.	British Columbia Univ., Vancouver, BC|c|	
	InfoVis+SciVis	Sept.-Oct. 2006	Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components	10.1109/TVCG.2006.177	http://dx.doi.org/10.1109/TVCG.2006.177	813	820	4015434			Application software;Bioinformatics;Computer networks;Engineering drawings;IP networks;Peer to peer computing;Proteins;Skeleton;Tomography;Tree graphs	Graph and Network Visualization;Quasi-Tree	Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality.	Archambault, D.;Munzner, T.;Auber, D.	University of British Columbia|c|;;	37396011500;37349490300;38470850300
	InfoVis+SciVis	Sept.-Oct. 2006	IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs	10.1109/TVCG.2006.156	http://dx.doi.org/10.1109/TVCG.2006.156	821	828	4015435	data visualisation;human computer interaction;notebook computers;user interfaces	PDA interface simulation;book database;fisheye distortion;geometric-semantic zoom;information-visualization technique;pen-driven Wacom board;personal digital assistant;scatterplot tool;user interaction technique	Cells (biology);Clustering algorithms;Complex networks;Constraint optimization;Data visualization;Engineering drawings;Industrial relations;Quadratic programming;Robustness;Stress	Graph drawing;constraints;force directed algorithms;layout;multidimensional scaling.;stress majorization	Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style	Dwyer, T.;Koren, Y.;Marriott, K.	Konstanz Univ.|c|;;	37326161000;37414256700;37354163600
	InfoVis+SciVis	Sept.-Oct. 2006	User Interaction with Scatterplots on Small Screens - A Comparative Evaluation of Geometric-Semantic Zoom and Fisheye Distortion	10.1109/TVCG.2006.187	http://dx.doi.org/10.1109/TVCG.2006.187	829	836	4015436	data visualisation;large screen displays	embedded bar matrix;embedded time-series graph;geospatially-referenced multidimensional time-series data;high-resolution display;information visualization perceptual scalability;large tiled display;space-time-attribute visualization;spatial grouping	Books;Data visualization;Displays;Marketing and sales;Navigation;Personal digital assistants;Scattering;Spatial databases;Usability;Visual databases	PDA;Small screen;fisheye;focus+context.;scatter plot;zoom	Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays	Buering, T.	Virginia Tech., VA|c|	
	InfoVis+SciVis	Sept.-Oct. 2006	The Perceptual Scalability of Visualization	10.1109/TVCG.2006.184	http://dx.doi.org/10.1109/TVCG.2006.184	837	844	4015437			Biological information theory;Computer displays;Data visualization;Educational institutions;Encoding;Humans;Large screen displays;Monitoring;Multidimensional systems;Scalability	Information visualization;empirical evaluation;large displays	Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.	Yost, B.;North, C.	IEEE|c|;	37550898300;37419565900
	InfoVis+SciVis	Sept.-Oct. 2006	Complex Logarithmic Views for Small Details in Large Contexts	10.1109/TVCG.2006.126	http://dx.doi.org/10.1109/TVCG.2006.126	845	852	4015438	computational geometry;conformal mapping;data visualisation;graph theory	Euclidean space;complex logarithmic view;complex root function;conformal mapping function;data visualization;geometrical compression	Computer graphics;Conformal mapping;Data visualization;Image coding;Image recognition;Information geometry;Information science;Navigation;Nonlinear distortion;Shape	Detail in context;analytic functions;complex logarithm;conformal mappings;interaction.	Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples	Bottger, J.;Balzer, M.;Deussen, O.	Dept. of Comput. & Inf. Sci., Konstanz Univ.|c|;;	37691047700;37282568100;37266781000
	InfoVis+SciVis	Sept.-Oct. 2006	Software Design Patterns for Information Visualization	10.1109/TVCG.2006.178	http://dx.doi.org/10.1109/TVCG.2006.178	853	860	4015439	data visualisation;object-oriented programming;software architecture	information visualization;pattern spanning data representation;software architecture;software design pattern	Application software;Buildings;Computer languages;Context;Data visualization;Graphics;Programming profession;Software architecture;Software design;Software engineering	Design patterns;information visualization;object-oriented programming;software engineering	Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication	Heer, J.;Agrawala, M.	Comput. Sci. Div., California Univ., Berkeley, CA|c|;	37550791300;37282718200
	InfoVis+SciVis	Sept.-Oct. 2006	A Pipeline for Computer Aided Polyp Detection	10.1109/TVCG.2006.112	http://dx.doi.org/10.1109/TVCG.2006.112	861	868	4015440	computerised tomography;conformal mapping;feature extraction;image texture;medical image processing;pattern clustering;rendering (computer graphics);virtual reality	2D clustering method;2D pattern recognition problem;computer aided polyp detection;conformal colon flattening;conformal mapping;image texture;interactive virtual colonoscopy system;shape analysis;translucent electronic biopsy transfer function;volume rendering;volumetric ray casting algorithm;volumetric texture feature	Colon;Colonic polyps;Colonography;Image converters;Image segmentation;Pattern recognition;Pipelines;Rendering (computer graphics);Shape;Virtual colonoscopy	Computer Aided Detection;Texture Analysis;Virtual Colonoscopy;Volume Rendering	We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy	Hong, W.;Feng Qiu;Kaufman, A.	Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;	37277099300;37416126400;37268052800
	InfoVis+SciVis	Sept.-Oct. 2006	Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline	10.1109/TVCG.2006.146	http://dx.doi.org/10.1109/TVCG.2006.146	869	876	4015441	computerised tomography;data visualisation;image resolution;medical image processing;rendering (computer graphics);virtual reality	CT-scan;GPU-based raycaster;data management component;data reduction;forensic medicine;full body virtual autopsy;interactive 3D visualization;multiresolution rendering technique;transfer function;volume rendering pipeline	Autopsy;Biomedical imaging;Cadaver;Computed tomography;Data visualization;Forensics;Large-scale systems;Medical diagnostic imaging;Pipelines;Transfer functions	Forensics;autopsies;large scale data.;medical visualization;volume rendering	This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases	Ljung, P.;Winskog, C.;Persson, A.;Lundstrom, C.;Ynnerman, A.	Div. for Visual Inf. Technol. & Applications, Linkoping Univ.|c|;;;;	37284208400;37828700500;37604521200;37284209100;37284192000
	InfoVis+SciVis	Sept.-Oct. 2006	Real-Time Illustration of Vascular Structures	10.1109/TVCG.2006.172	http://dx.doi.org/10.1109/TVCG.2006.172	877	884	4015442	blood vessels;data visualisation;rendering (computer graphics)	GPU-accelerated shadow-like depth indicator;GPU-based hatching algorithm;real-time vascular visualization method;rendering technique;static monoscopic 3D visualization;tubular structure;vascular structure	Absorption;Liver;Medical treatment;Reflection;Shape;Surface morphology;Surgery;Topology;Veins;Visualization	Vessel visualization;evaluation;functional realism;illustrative rendering;spatial perception	We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects	Ritter, F.;Hansen, C.;Dicken, V.;Konrad, O.;Preim, B.;Peitgen, H.-O.	MeVis GmbH|c|;;;;;	37645939800;37824134900;37828698600;37828698700;37424645300;37442956900
	InfoVis+SciVis	Sept.-Oct. 2006	Lines of Curvature for Polyp Detection in Virtual Colonoscopy	10.1109/TVCG.2006.158	http://dx.doi.org/10.1109/TVCG.2006.158	885	892	4015443	computational geometry;data visualisation;feature extraction;medical image processing;mesh generation;rendering (computer graphics);virtual reality	3D volume data;colonic polyp detection;computer-aided diagnosis;curvature line;data visualization;false-positive detection;feature detection;rendering technique;triangular surface meshes;virtual colonoscopy	Biomedical imaging;Cancer;Colon;Colonic polyps;Colonography;Computer aided diagnosis;Data visualization;Medical diagnostic imaging;Shape;Virtual colonoscopy	Medical visualization;implicit surface.;line of curvature;polyp detection;virtual colonoscopy	Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p<0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections	Zhao, L.;Botha, C.P.;Bescos, J.O.;Truyen, R.;Vos, F.M.;Post, F.H.	Data Visualization Group, Delft Univ. of Technol.|c|;;;;;	37834977900;37373834100;37591606800;37394318300;37271678400;37295045800
	InfoVis+SciVis	Sept.-Oct. 2006	Outlier-Preserving Focus+Context Visualization in Parallel Coordinates	10.1109/TVCG.2006.170	http://dx.doi.org/10.1109/TVCG.2006.170	893	900	4015444	data structures;data visualisation;feature extraction;rendering (computer graphics)	context visualization;data abstraction;data representation;focus visualization;outlier detection;output-oriented visualization approach;parallel coordinate;rendering technique;small-scale feature detection	Computer vision;Concurrent computing;Costs;Data visualization;Humans;Information processing;Jamming;Multidimensional systems;Navigation;Visual system	Parallel coordinates;focus+context visualization;large data visualization.;outliers & trends	Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions	Novotny, M.;Hauser, H.	Comenius Univ., Bratislava|c|;	37823192400;37274158800
	InfoVis+SciVis	Sept.-Oct. 2006	Composite Rectilinear Deformation for Stretch and Squish Navigation	10.1109/TVCG.2006.127	http://dx.doi.org/10.1109/TVCG.2006.127	901	908	4015445	data visualisation;rendering (computer graphics)	composite rectilinear deformation;information visualization;real-time rendering;rubber sheet navigation;screen-space location;squish navigation;stretch navigation	Cameras;Computer science;Displays;Graphics;History;Layout;Navigation;Pipelines;Rubber;Visualization	Focus+Context;information visualization;navigation.;real time rendering	We present the first scalable algorithm that supports the composition of successive rectilinear deformations. Earlier systems that provided stretch and squish navigation could only handle small datasets. More recent work featuring rubber sheet navigation for large datasets has focused on rendering and on application-specific issues. However, no algorithm has yet been presented for carrying out such navigation methods; our paper addresses this problem. For maximum flexibility with large datasets, a stretch and squish navigation algorithm should allow for millions of potentially deformable regions. However, typical usage only changes the extents of a small subset k of these n regions at a time. The challenge is to avoid computations that are linear in n, because a single deformation can affect the absolute screen-space location of every deformable region. We provide an O(klogn) algorithm that supports any application that can lay out a dataset on a generic grid, and show an implementation that allows navigation of trees and gene sequences with millions of items in sub-millisecond time	Slack, J.;Munzner, T.	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC|c|;	37561415800;37349490300
	InfoVis+SciVis	Sept.-Oct. 2006	Multi-variate, Time Varying, and Comparative Visualization with Contextual Cues	10.1109/TVCG.2006.164	http://dx.doi.org/10.1109/TVCG.2006.164	909	916	4015446	data visualisation;rendering (computer graphics)	contextual information;data visualization;multivariate time-varying comparative visualization;numerical operation;rendering technique;volume shader;volume tree	Animation;Computer science;Data visualization;Filling;Humans;Switches;Transfer functions	comparative;focus + context;multi-variate;time-varying	Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed	Woodring, J.;Han-Wei Shen	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;	37542815100;37279493500
	InfoVis+SciVis	Sept.-Oct. 2006	Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data	10.1109/TVCG.2006.165	http://dx.doi.org/10.1109/TVCG.2006.165	917	924	4015447	data visualisation;rendering (computer graphics)	3D multifield scalar data;3D volume visualization technique;correlation field;data visualization;multifield-graph method	Computational modeling;Computer science;Computer simulation;Data visualization;Tensile stress	Visualization;correlation;multifield	We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets	Sauber, N.;Theisel, H.;Seidel, H.-P.	Max-Planck-Inst. fur Inf., Saarbrucken|c|;;	37550815800;37266875400;37271851300
	InfoVis+SciVis	Sept.-Oct. 2006	Saliency-guided Enhancement for Volume Visualization	10.1109/TVCG.2006.174	http://dx.doi.org/10.1109/TVCG.2006.174	925	932	4015448	data visualisation;rendering (computer graphics)	saliency-guided enhancement;visual-saliency-based operator;volume rendering;volume visualization	Art;Biomedical imaging;Data visualization;Geometry;Humans;Large-scale systems;Mouth;Optical attenuators;Pipelines;Transfer functions	Saliency;non-photorealistic rendering;perceptual enhancement;visual attention;volume rendering	Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator	Youngmin Kim;Varshney, A.	Maryland Univ., College Park, MD|c|;	37836140000;37282560200
	InfoVis+SciVis	Sept.-Oct. 2006	Importance-Driven Focus of Attention	10.1109/TVCG.2006.152	http://dx.doi.org/10.1109/TVCG.2006.152	933	940	4015449	data visualisation;focusing	automatic feature focusing;characteristic viewpoint estimation;cut-away view incorporation;data visualisation;expressive feature view;importance distribution;importance-driven attention focus;information-theoretic framework;mutual information measure;visual emphasis;volumetric data set	Application software;Automatic control;Biomedical imaging;Computed tomography;Data visualization;Focusing;Humans;Medical diagnostic imaging;Mutual information;Workstations	Illustrative visualization;characteristic viewpoint estimation;focus+context techniques;interacting with volumetric datasets;volume visualization	This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views	Viola, I.;Feixas, M.;Sbert, M.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;	37282726800;37426689600;37396572900;37282552200
	InfoVis+SciVis	Sept.-Oct. 2006	ClearView: An Interactive Context Preserving Hotspot Visualization Technique	10.1109/TVCG.2006.124	http://dx.doi.org/10.1109/TVCG.2006.124	941	948	4015450	data visualisation;focusing;image resolution;rendering (computer graphics);user interfaces	ClearView;complex volumetric data;context information focus;image information;interactive context preserving hotspot visualization technique;mental exercise;point-and-click interface;texture-based volume ray-casting;visual clutter	Computer graphics;Context;Data visualization;Focusing;Information filtering;Information filters;Navigation;Rendering (computer graphics);Shape;Topology	GPU rendering;TermsÂ¿Focus & Context;volume raycasting	Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information	Kruger, J.;Schneider, J.;Westermann, R.	Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;;	37548560500;37560044500;37444424000
	InfoVis+SciVis	Sept.-Oct. 2006	Visualization Tools for Vorticity Transport Analysis in Incompressible Flow	10.1109/TVCG.2006.199	http://dx.doi.org/10.1109/TVCG.2006.199	949	956	4015451	computational fluid dynamics;data visualisation;flow visualisation;turbines;vortices	CFD simulations;computational fluid dynamics;convergence;explorative analysis;incompressible flow;meshing errors;quantitative analysis;simulation quality;upstream direction;visualization tools;vortex regions;vorticity equation;vorticity transport analysis;water turbines	Analytical models;Angular velocity;Computational fluid dynamics;Convergence;Equations;Performance analysis;Silver;Turbines;Turbomachinery;Visualization	Flow visualization;linked views.;unsteady flow;vorticity transport	Vortices are undesirable in many applications while indispensable in others. It is therefore of common interest to understand their mechanisms of creation. This paper aims at analyzing the transport of vorticity inside incompressible flow. The analysis is based on the vorticity equation and is performed along pathlines which are typically started in upstream direction from vortex regions. Different methods for the quantitative and explorative analysis of vorticity transport are presented and applied to CFD simulations of water turbines. Simulation quality is accounted for by including the errors of meshing and convergence into analysis and visualization. The obtained results are discussed and interpretations with respect to engineering questions are given	Sadlo, F.;Peikert, R.;Sick, M.	Comput. Sci. Dept., ETH Zurich|c|;;	37282541900;37282541100;37828727500
	InfoVis+SciVis	Sept.-Oct. 2006	Vortex Visualization for Practical Engineering Applications	10.1109/TVCG.2006.201	http://dx.doi.org/10.1109/TVCG.2006.201	957	964	4015452	computational fluid dynamics;data visualisation;external flows;feature extraction;flow visualisation;mesh generation;missiles;pattern clustering;vortices	complex vortical flows;core line extraction technique;feature-based vortex detection;k-means clustering;large computational fluid dynamics;missile flow field;practical engineering applications;scalar fields;serrated wing;simulation data sets;unstructured meshes;vortex visualization technique	Computational fluid dynamics;Computational modeling;Computer vision;Data mining;Data visualization;Geometry;Large-scale systems;Missiles;Spinning;Topology	Vortex detection;feature mining;vortex visualization	In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability	Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.	Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;	37828704100;37826582200;38181602100;37269516700
	InfoVis+SciVis	Sept.-Oct. 2006	An Advanced Evenly-Spaced Streamline Placement Algorithm	10.1109/TVCG.2006.116	http://dx.doi.org/10.1109/TVCG.2006.116	965	972	4015453	Runge-Kutta methods;computational fluid dynamics;data visualisation;flow visualisation;interpolation	adaptive distance control;adaptive step size;advanced evenly-spaced streamline placement algorithm;cubic Hermite polynomial interpolation;distance checking;double queues;error control;flow line layout;fourth-order Runge-Kutta integrator;local flow variance;placement quality;rapid accurate streamline advection;robust loop detection strategy;sample-spacing;topological seeding	Adaptive control;Error correction;Interpolation;Iterative algorithms;Noise robustness;Pixel;Polynomials;Programmable control;Streaming media;Visualization	Flow visualization;closed streamlines.;evenly-spaced streamlines;seeding strategy;streamline placement	This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection	Zhanping Liu;Moorhead, R.J.;Groner, J.	HPC, Mississippi State Univ., MS|c|;;	37671605200;37282559500;37828782100
	InfoVis+SciVis	Sept.-Oct. 2006	Fine-grained Visualization Pipelines and Lazy Functional Languages	10.1109/TVCG.2006.145	http://dx.doi.org/10.1109/TVCG.2006.145	973	980	4015454	computer graphic equipment;data visualisation;functional languages;functional programming;pipeline processing	Haskell;demand-driven processing;fine-grained visualization pipelines;functional abstraction;lazy functional languages;pipeline-like function composition;programming language;streaming form;surface extraction algorithms	Assembly;Buildings;Computer languages;Data mining;Data processing;Data visualization;Functional programming;Pipeline processing;Power system modeling;US Department of Transportation	Pipeline model;functional programming.;laziness	The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization	Duke, D.;Wallace, M.;Borgo, R.	Sch. of Comput., Leeds Univ.|c|;;	37282576200;37827249700;37591074800
	InfoVis+SciVis	Sept.-Oct. 2006	A Novel Visualization Model for Web Search Results	10.1109/TVCG.2006.111	http://dx.doi.org/10.1109/TVCG.2006.111	981	988	4015455	data visualisation;interactive systems;online front-ends;query processing;search engines;solar system	Web pages;WebSearchViz;interactive visualization system;semantic relationships;solar system;user exploration;user navigation;visual space	Data visualization;Humans;Navigation;Planets;Solar system;Sun;Visual perception;Web pages;Web search;Web sites	Visualization model;Web search results;movement;speed	This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space	Nguyen, T.N.;Zhang, J.	Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA|c|;	37280728200;37836748400
	InfoVis+SciVis	Sept.-Oct. 2006	A Trajectory-Preserving Synchronization Method for Collaborative Visualization	10.1109/TVCG.2006.114	http://dx.doi.org/10.1109/TVCG.2006.114	989	996	4015456	data visualisation;groupware;motion control;position control;synchronisation	application participants;collaborative visualization;content change handling;dynamic object interaction;false negative collision detection problems;false positive collision detection problems;motion trajectory-preserving synchronization method;network latency;unpredictable user interventions	Broadcasting;Collaboration;Collaborative work;Data visualization;Delay;Fluid dynamics;Meteorology;Network servers;Problem-solving;Virtual environment	Collaborative visualization;distributed synchronization.;motion synchronization;network latency	In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users would perceive a synchronized view of the shared data. Failing this requirement, the user's ability in performing the desirable collaborative tasks would be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments	Li, L.W.F.;Li, F.W.B.;Lau, Rynson W.H.	Dept. of Comput. Sci., City Univ. of Hong Kong|c|;;	37835889100;37400967400;37271835000
	InfoVis+SciVis	Sept.-Oct. 2006	Concurrent Visualization in a Production Supercomputing Environment	10.1109/TVCG.2006.128	http://dx.doi.org/10.1109/TVCG.2006.128	997	1004	4015457	computer animation;data compression;data visualisation;geophysics computing;image coding;image resolution;parallel machines;pipeline processing;rendering (computer graphics);storms;weather forecasting	Atlantic hurricane season;GEOS4;MPEG compression;NASA Ames Columbia supercomputer;National Hurricane Center;atmospheric circulation models;concurrent visualization pipeline;ensemble prediction;global ocean circulation model;low-bandwidth distribution;multiple visualization streams;parallel forecast model;production supercomputing environment;remote sites;runtime model performance;temporal resolution animations;time-critical context	Animation;Atmospheric modeling;Hurricanes;NASA;Pipelines;Predictive models;Production;Supercomputers;Time factors;Visualization	ECCO;GEOS4 global climate model;Supercomputing;concurrent visualization;high temporal resolution visualization;hurricane visualization;interactive visual computing;ocean modeling.;time-varying data	"We describe a concurrent visualization pipeline designed for operation in a production supercomputing environment. The facility was initially developed on the NASA Ames ""Columbia"" supercomputer for a massively parallel forecast model (GEOS4). During the 2005 Atlantic hurricane season, GEOS4 was run 4 times a day under tight time constraints so that its output could be included in an ensemble prediction that was made available to forecasters at the National Hurricane Center. Given this time-critical context, we designed a configurable concurrent pipeline to visualize multiple global fields without significantly affecting the runtime model performance or reliability. We use MPEG compression of the accruing images to facilitate live low-bandwidth distribution of multiple visualization streams to remote sites. We also describe the use of our concurrent visualization framework with a global ocean circulation model, which provides a 864-fold increase in the temporal resolution of practically achievable animations. In both the atmospheric and oceanic circulation models, the application scientists gained new insights into their model dynamics, due to the high temporal resolution animations attainable"	Ellsworth, D.;Green, B.;Henze, C.;Moran, P.;Sandstrom, T.	AMTl, NASA Ames Res. Center, Moffett Field, CA|c|;;;;	37282594500;37273679700;37373380100;37264891100;37837582600
	InfoVis+SciVis	Sept.-Oct. 2006	Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments	10.1109/TVCG.2006.176	http://dx.doi.org/10.1109/TVCG.2006.176	1005	1012	4015458	astronomy computing;cosmology;data visualisation;user interfaces	3D landmarks;astronomical contexts;cosmological scales;global overview mode;large-scale astrophysical environments;physical navigation;power-law spatial seating;pragmatic cognitive understanding;scalable WIM;scalable world-in-miniature map;spatial context awareness;spatial knowledge range;travel task performance;user interface;virtual cosmic exploration	Astronomy;Context awareness;Context modeling;Impedance;Large-scale systems;Navigation;Space exploration;User interfaces;Virtual environment;Visualization	Astrophysical visualization;interaction techniques;large-scale exploration;world-in-miniature (WIM)	Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user's ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy	Li, Y.;Chi-Wing Fu;Hanson, A.J.	Indiana Univ., IN|c|;;	37835045200;37336329800;37333439100
	InfoVis+SciVis	Sept.-Oct. 2006	Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations	10.1109/TVCG.2006.189	http://dx.doi.org/10.1109/TVCG.2006.189	1013	1020	4015459	assembling;data visualisation;digital simulation;virtual prototyping;virtual reality	automotive assembly operation;collected questionnaires;data visualisation;deformation effects;digital mock-up;filtering technique;glyph apparition;industrial assembly simulations;industry maintenance simulations;interactive manipulation;proximity information;virtual objects;virtual prototyping;virtual reality environment;visual contact cues	Assembly;Design engineering;Displays;Force feedback;Haptic interfaces;Large scale integration;Light sources;Virtual environment;Virtual prototyping;Virtual reality	assembly/maintenance simulation;contact;force;glyph;light;proximity;virtual prototyping;visual cues	This paper describes a set of visual cues of contact designed to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations. These visual cues display information of proximity, contact and effort between virtual objects when the user manipulates a part inside a digital mock-up. The set of visual cues encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Light sources can also be added at the level of contact points. A filtering technique is proposed to decrease the number of glyphs displayed at the same time. Various effects - such as change in color, change in size, and deformation of shape - can be applied to the glyphs as a function of proximity with other objects or amplitude of the contact forces. A preliminary evaluation was conducted to gather the subjective preference of a group of participants during the simulation of an automotive assembly operation. The collected questionnaires showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas	Sreng, J.;Lecuyer, A.;Megard, C.;Andriot, C.	CEA LSI, Fontenay-aux-Roses|c|;;;	37828724200;37295204100;37828726000;37297749600
	InfoVis+SciVis	Sept.-Oct. 2006	High-Level User Interfaces for Transfer Function Design with Semantics	10.1109/TVCG.2006.148	http://dx.doi.org/10.1109/TVCG.2006.148	1021	1028	4015460	Gaussian distribution;computer animation;data visualisation;graphical user interfaces;medical computing;principal component analysis;rendering (computer graphics);transfer functions	computer animation;data visualization;direct volume rendering;high-level user interface;optical property;parametric model;principal component analysis;semantic information;transfer function design	Animation;Application software;Biomedical optical imaging;Computer graphics;Data visualization;Nonlinear optics;Parametric statistics;Rendering (computer graphics);Transfer functions;User interfaces	Volume rendering;semantic models.;transfer function design	Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation	Salama, C.R.;Keller, M.;Kohlmann, P.	Comput. Graphics & Multimedia Syst. Group, Siegen Univ.|c|;;	37840859800;37589324500;37623778100
	InfoVis+SciVis	Sept.-Oct. 2006	LOD Map - A Visual Interface for Navigating Multiresolution Volume Visualization	10.1109/TVCG.2006.159	http://dx.doi.org/10.1109/TVCG.2006.159	1029	1036	4015461	data visualisation;graphical user interfaces;image resolution;rendering (computer graphics);trees (mathematics)	LOD map;entropy measure;information theory;level-of-detail quality;medical data set;multiresolution volume visualization;navigation;treemap representation;visual interface;visual representation	Biomedical imaging;Chaos;Data visualization;Distortion measurement;Entropy;Image resolution;Information theory;Navigation;Rendering (computer graphics);Signal resolution	LOD map;knowledge representation;large volume visualization Author 1:;multiresolution rendering;perceptual reasoning	In multiresolution volume visualization, a visual representation of level-of-detail (LOD) quality is important for us to examine, compare, and validate different LOD selection algorithms. While traditional methods rely on ultimate images for quality measurement, we introduce the LOD map - an alternative representation of LOD quality and a visual interface for navigating multiresolution data exploration. Our measure for LOD quality is based on the formulation of entropy from information theory. The measure takes into account the distortion and contribution of multiresolution data blocks. A LOD map is generated through the mapping of key LOD ingredients to a treemap representation. The ordered treemap layout is used for relative stable update of the LOD map when the view or LOD changes. This visual interface not only indicates the quality of LODs in an intuitive way, but also provides immediate suggestions for possible LOD improvement through visually-striking features. It also allows us to compare different views and perform rendering budget control. A set of interactive techniques is proposed to make the LOD adjustment a simple and easy task. We demonstrate the effectiveness and efficiency of our approach on large scientific and medical data sets	Wang, C.;Han-Wei Shen	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;	37559027700;37279493500
	InfoVis+SciVis	Sept.-Oct. 2006	Analyzing Complex FTMS Simulations: a Case Study in High-Level Visualization of Ion Motions	10.1109/TVCG.2006.118	http://dx.doi.org/10.1109/TVCG.2006.118	1037	1044	4015462	Fourier transform spectrometers;Fourier transforms;data visualisation;physics computing;rendering (computer graphics);trapped ions	FTMS simulation;Fourier transform mass spectrometry;computer animation;dynamic property;parameterized camera control mechanism;particle visualization;rendering ion motion	Analytical models;Animation;Cameras;Data mining;Data visualization;Fourier transforms;Mass spectroscopy;Motion analysis;Motion control;Rendering (computer graphics)	Particle visualization;motion;motion features		Burakiewicz, W.		37828783300
	InfoVis+SciVis	Sept.-Oct. 2006	Detection and Visualization of Defects in 3D Unstructured Models of Nematic Liquid Crystals	10.1109/TVCG.2006.133	http://dx.doi.org/10.1109/TVCG.2006.133	1045	1052	4015463	data visualisation;feature extraction;mesh generation;nematic liquid crystals;physics computing	3D unstructured model;nematic liquid crystals;scientific visualization;semi-automatic defect detection	Biosensors;Detection algorithms;Feature extraction;Isosurfaces;Liquid crystals;Nearest neighbor searches;Organic materials;Physics;Solids;Visualization	defects;disclination;feature extraction;nematic liquid crystal;scientific visualization;unstructured grid	A method for the semi-automatic detection and visualization of defects in models of nematic liquid crystals (NLCs) is introduced; this method is suitable for unstructured models, a previously unsolved problem. The detected defects - also known as disclinations - are regions were the alignment of the liquid crystal rapidly changes over space; these defects play a large role in the physical behavior of the NLC substrate. Defect detection is based upon a measure of total angular change of crystal orientation (the director) over a node neighborhood via the use of a nearest neighbor path. Visualizations based upon the detection algorithm clearly identify complete defect regions as opposed to incomplete visual descriptions provided by cutting-plane and isosurface approaches. The introduced techniques are currently in use by scientists studying the dynamics of defect change	Mehta, K.;Jankun-Kelly, T.J.	Mississippi State Univ., MS|c|;	38272355300;38275083200
	InfoVis+SciVis	Sept.-Oct. 2006	Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities	10.1109/TVCG.2006.186	http://dx.doi.org/10.1109/TVCG.2006.186	1053	1060	4015464	Rayleigh-Taylor instability;bubbles;computational fluid dynamics;geometry;hydrodynamics;topology;turbulence	Morse theory;Rayleigh-Taylor instability;bubble growth;falling spikes;geometric tracking;heavy fluid;hydrodynamic instabilities;light fluid;multiscale analysis technique;original interface plane;rising bubbles;segmentations;statistical measures;tiny vertical perturbations;topological features;turbulent mixing layer	Acceleration;Analytical models;Application software;Extraterrestrial measurements;Fluid dynamics;Hydrodynamics;Large-scale systems;Particle measurements;Shape;Time measurement	Morse theory;multi-resolution;topology	When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications	Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;	37281901900;37564112000;37284319900;38182458500;37284312600
	InfoVis+SciVis	Sept.-Oct. 2006	Hub-based Simulation and Graphics Hardware Accelerated Visualization for Nanotechnology Applications	10.1109/TVCG.2006.150	http://dx.doi.org/10.1109/TVCG.2006.150	1061	1068	4015465	computer graphic equipment;data visualisation;flow visualisation;mesh generation;middleware;nanotechnology;online front-ends;physics computing;rendering (computer graphics)	Hub-based simulation;Web browser;computational nanotechnology application;graphics hardware accelerated visualization;grid supercomputing resources;middleware;science gateway	Acceleration;Analytical models;Computational modeling;Graphics;Hardware;Middleware;Nanotechnology;Rendering (computer graphics);Visual analytics;Visualization	flow visualization;graphics hardware;nanotechnology simulation.;remote visualization;volume visualization	The Network for computational nanotechnology (NCN) has developed a science gateway at nanoHUB.org for nanotechnology education and research. Remote users can browse through online seminars and courses, and launch sophisticated nanotechnology simulation tools, all within their Web browser. Simulations are supported by a middleware that can route complex jobs to grid supercomputing resources. But what is truly unique about the middleware is the way that it uses hardware accelerated graphics to support both problem setup and result visualization. This paper describes the design and integration of a remote visualization framework into the nanoHUB for interactive visual analytics of nanotechnology simulations. Our services flexibly handle a variety of nanoscience simulations, render them utilizing graphics hardware acceleration in a scalable manner, and deliver them seamlessly through the middleware to the user. Rendering is done only on-demand, as needed, so each graphics hardware unit can simultaneously support many user sessions. Additionally, a novel node distribution scheme further improves our system's scalability. Our approach is not only efficient but also cost-effective. Only half-dozen render nodes are anticipated to support hundreds of active tool sessions on the nanoHUB. Moreover, this architecture and visual analytics environment provides capabilities that can serve many areas of scientific simulation and analysis beyond nanotechnology with its ability to interactively analyze and visualize multivariate scalar and vector fields	Wei Qiao;McLennan, M.;Kennell, R.;Ebert, D.S.;Klimeck, G.	Purdue Univ., West Lafayette, IN|c|;;;;	37282552800;37393469800;37393471900;37282598900;37270404800
	InfoVis+SciVis	Sept.-Oct. 2006	Feature Aligned Volume Manipulation for Illustration and Visualization	10.1109/TVCG.2006.144	http://dx.doi.org/10.1109/TVCG.2006.144	1069	1076	4015466	computer graphic equipment;data visualisation;medical computing;rendering (computer graphics)	GPU-based technique;anatomical structure;biological structure;data visualization;feature aligned volume manipulation;medical illustration;segment alignment;surface alignment;surgical procedure;volume graphics;volumetric model	Biological system modeling;Biology computing;Computational modeling;Computer graphics;Data visualization;Deformable models;Rendering (computer graphics);Silver;Skin;Surgery	GPU computing;Illustrative manipulation;Illustrative visualization;computer-assisted medical illustration;volume deformation;volume rendering	In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics	Correa, C.;Silver, D.;Chen, M.	Dept. of Electr. & Comput. Eng., State Univ. of New Jersey, NJ|c|;;	37282925900;37274132700;37280982800
	InfoVis+SciVis	Sept.-Oct. 2006	Exploded Views for Volume Data	10.1109/TVCG.2006.140	http://dx.doi.org/10.1109/TVCG.2006.140	1077	1084	4015467	data visualisation;hidden feature removal;rendering (computer graphics)	GPU-based volume ray casting algorithm;context information;exploded views;force-based model;occlusion;view-dependent explosion;volume data	Casting;Computer graphics;Data visualization;Explosions;Force control;Geometry;Rendering (computer graphics);Tomography	exploded views;illustrative visualization;volume rendering	Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second	Bruckner, S.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;	37265895700;37284271200
	InfoVis+SciVis	Sept.-Oct. 2006	Caricaturistic Visualization	10.1109/TVCG.2006.123	http://dx.doi.org/10.1109/TVCG.2006.123	1085	1092	4015468	art;data visualisation;face recognition;feature extraction	art;caricaturistic visualization;characteristic feature;reference model;visual representation	Art;Brain modeling;Computer graphics;Context;Evolution (biology);Face;Focusing;Humans;Quality control;Visualization	exploded views;illustrative visualization;volume rendering	Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable	Rautek, P.;Viola, I.;Groller, E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;	37828701300;37282726800;37284271200
	InfoVis+SciVis	Sept.-Oct. 2006	Visual Signatures in Video Visualization	10.1109/TVCG.2006.194	http://dx.doi.org/10.1109/TVCG.2006.194	1093	1100	4015469	feature extraction;flow visualisation;human factors;motion estimation;video retrieval;video signal processing	flow visualization technique;video clips;video visualization;visual signature representation	Biomedical imaging;Biomedical optical imaging;Bones;Computer displays;Data mining;Data visualization;Human factors;Image motion analysis;Layout;Pipelines	GPU rendering.;Video visualization;flow visualization;human factors;optical flow;user study;video processing;visual signatures;volume visualization	Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events	Chen, M.;Hashim, R.R.;Botchen, R.P.;Weiskopf, D.;Ertl, T.;Thornton, I.M.	Dept. of Comput. Sci., Swansea Univ.|c|;;;;;	37280982800;37829295700;37565744300;38470313000;38356649100;37591073500
	InfoVis+SciVis	Sept.-Oct. 2006	Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays	10.1109/TVCG.2006.121	http://dx.doi.org/10.1109/TVCG.2006.121	1101	1108	4015470	calibration;cameras;client-server systems;computer displays;distributed algorithms	asynchronous distributed calibration;camera;centralized technique;high-resolution displays;plug-and-play projector;reconfigurable multiprojector displays;single-program-multiple-data calibration algorithm	Calibration;Cameras;Computer architecture;Computer displays;Distributed computing;Fault detection;Instruments;Photometry;Project management;Two dimensional displays	Multi-projector displays;distributed algorithms.;geometric and color calibration;projector-camera systems	Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays	Bhasker, E.S.;Majumder, A.	Dept. of Comput. Sci., California Univ., Irvine, CA|c|;	37828782600;37408075400
	InfoVis+SciVis	Sept.-Oct. 2006	Dynamic View Selection for Time-Varying Volumes	10.1109/TVCG.2006.137	http://dx.doi.org/10.1109/TVCG.2006.137	1109	1116	4015471	computer animation;data visualisation;dynamic programming;rendering (computer graphics)	computer animation;curvature distributions;dynamic programming approach;dynamic view selection;opacity distribution;salient feature colors;smooth transition generation;static view selection method;time-varying dataset;time-varying view selection;time-varying volumes;volume rendering images	Animation;Data visualization;Diversity reception;Dynamic programming;Image analysis;Image color analysis;Information entropy;Optimization methods;Rendering (computer graphics);Volume measurement	dynamic view selection;image based method;information entropy;optimization.;static view selection	Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set	Guangfeng Ji;Han-Wei Shen	Ohio State Univ., Columbus, OH|c|;	37840642900;37279493500
	InfoVis+SciVis	Sept.-Oct. 2006	Enhancing Depth Perception in Translucent Volumes	10.1109/TVCG.2006.139	http://dx.doi.org/10.1109/TVCG.2006.139	1117	1124	4015472	computerised tomography;diagnostic radiography;image reconstruction;medical image processing;rendering (computer graphics);surgery;visual perception	absorptive lighting model;aerial perspective;computerised tomography volumes;depth perception enhancement;digitally reconstructed radiographs;image reconstruction;stereopsis effect;surgical planning;synthetic X-ray images;translucent volumes	Biomedical computing;Computed tomography;Diagnostic radiography;Humans;Image reconstruction;Light scattering;Orthopedic surgery;Rendering (computer graphics);Shape;Surface reconstruction	Radiograph;Stereo;Stereopsis;Volume Rendering;X--ray	We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning	Kersten, M.A.;Stewart, A.J.;Troje, N.;Ellis, R.	Med. Comput. Lab., Queen''s Univ.|c|;;;	37829586000;37591698700;37828778600;37850225600
	InfoVis+SciVis	Sept.-Oct. 2006	Texturing of Layered Surfaces for Optimal Viewing	10.1109/TVCG.2006.183	http://dx.doi.org/10.1109/TVCG.2006.183	1125	1132	4015473	data analysis;data visualisation;decision trees;feature extraction;genetic algorithms;image texture;pattern classification;search problems;surface texture	Gaussian bumps;data analysis methods;decision trees;genetic algorithm;layered three-dimensional surface texturing;linear discriminant analysis;noisy terrain fields;parallel coordinates;parameterized texture space;perceptual optimal visualizations;texture parameter space search;texture pattern generation	Analysis of variance;Data analysis;Gaussian noise;Genetic algorithms;Guidelines;Humans;Linear discriminant analysis;Space exploration;Surface texture;Visualization	data mining;decision trees;genetic algorithm;human-in-the-loop;layered surfaces;linear discriminant analysis;optimal visualization;parallel coordinates;perception	"This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a ""human in the loop"" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines"	Bair, A.S.;House, D.H.;Ware, C.	Texas A&M Univ., College Station, TX|c|;;	37565577300;37284216700;37265850800
	InfoVis+SciVis	Sept.-Oct. 2006	Subjective Quantification of Perceptual Interactions among some 2D Scientific Visualization Methods	10.1109/TVCG.2006.180	http://dx.doi.org/10.1109/TVCG.2006.180	1133	1140	4015474	Poisson distribution;data visualisation;graphical user interfaces;visual perception	2D icon-based visualization methods;2D scientific visualization methods;Poisson-disk distributed icons;ad-hoc artificial datasets;filtering interference;icon brightness;icon size;icon spacing;multivalued data visualization;perceptual interactions;scientific dataset visualization;spatial resolution;visual elements	Brightness;Data visualization;Design optimization;Displays;Filtering;Graphics;Information analysis;Interference;Spatial resolution;Stress	2D visualization methods;Perception models;perceptual interactions;visual design.;visualization evaluation	We present an evaluation of a parameterized set of 2D icon-based visualization methods where we quantified how perceptual interactions among visual elements affect effective data exploration. During the experiment, subjects quantified three different design factors for each method: the spatial resolution it could represent, the number of data values it could display at each point, and the degree to which it is visually linear. The class of visualization methods includes Poisson-disk distributed icons where icon size, icon spacing, and icon brightness can be set to a constant or coupled to data values from a 2D scalar field. By only coupling one of those visual components to data, we measured filtering interference for all three design factors. Filtering interference characterizes how different levels of the constant visual elements affect the evaluation of the data-coupled element. Our novel experimental methodology allowed us to generalize this perceptual information, gathered using ad-hoc artificial datasets, onto quantitative rules for visualizing real scientific datasets. This work also provides a framework for evaluating visualizations of multi-valued data that incorporate additional visual cues, such as icon orientation or color	Acevedo, D.;Laidlaw, D.H.	Dept. of Comput. Sci., Brown Univ., Providence, RI|c|;	38180784500;37275712600
	InfoVis+SciVis	Sept.-Oct. 2006	Occlusion-Free Animation of Driving Routes for Car Navigation Systems	10.1109/TVCG.2006.167	http://dx.doi.org/10.1109/TVCG.2006.167	1141	1148	4015475	computer animation;driver information systems;navigation;solid modelling	2D screen arrangement;3D terrain surface;car navigation systems;continuously deforming inverse problem;nonperspective image;nonperspective terrain navigation;occlusion-free driving routes animation;occlusion-free geographical landmark animation;visually-pleasing navigation frames	Animation;Geometry;Inverse problems;Layout;Navigation;Rendering (computer graphics);Roads;Shape;Surface texture;Visual perception	car navigation systems;nonperspective projection;occlusion-free animation;temporal coherence;visual perception	This paper presents a method for occlusion-free animation of geographical landmarks, and its application to a new type of car navigation system in which driving routes of interest are always visible. This is achieved by animating a nonperspective image where geographical landmarks such as mountain tops and roads are rendered as if they are seen from different viewpoints. The technical contribution of this paper lies in formulating the nonperspective terrain navigation as an inverse problem of continuously deforming a 3D terrain surface from the 2D screen arrangement of its associated geographical landmarks. The present approach provides a perceptually reasonable compromise between the navigation clarity and visual realism where the corresponding nonperspective view is fully augmented by assigning appropriate textures and shading effects to the terrain surface according to its geometry. An eye tracking experiment is conducted to prove that the present approach actually exhibits visually-pleasing navigation frames while users can clearly recognize the shape of the driving route without occlusion, together with the spatial configuration of geographical landmarks in its neighborhood	Takahashi, S.;Yoshida, K.;Shimada, K.;Nishita, T.	Tokyo Univ., Chiba|c|;;;	37280401000;37826572100;37324632500;37267968100
	InfoVis+SciVis	Sept.-Oct. 2006	Interactive Visualization of Intercluster Galaxy Structures in the Horologium-Reticulum Supercluster	10.1109/TVCG.2006.155	http://dx.doi.org/10.1109/TVCG.2006.155	1149	1156	4015476	astronomy computing;clusters of galaxies;cosmology;data visualisation	2D projection techniques;3D galaxy positions;3D perception;GyVe interactive visualization tool;astronomical RA-DEC-cz coordinate system;geometrical distinct glyphs;horologium-reticulum supercluster;interactive user control;interactive visualization;intercluster galaxy structures;sparse three-dimensional point data;statistical techniques;torsional rocking	Astronomy;Collaboration;Collaborative tools;Computer science;Control systems;Data visualization;Large-scale systems;Shape;Space technology;Spectroscopy	Sparse point visualization;astronomy;cosmology	We present GyVe, an interactive visualization tool for understanding structure in sparse three-dimensional (3D) point data. The scientific goal driving the tool's development is to determine the presence of filaments and voids as defined by inferred 3D galaxy positions within the horologium-reticulum supercluster (HRS). GyVe provides visualization techniques tailored to examine structures defined by the intercluster galaxies. Specific techniques include: interactive user control to move between a global overview and local viewpoints, labelled axes and curved drop lines to indicate positions in the astronomical RA-DEC-cz coordinate system, torsional rocking and stereo to enhance 3D perception, and geometrically distinct glyphs to show potential correlation between intercluster galaxies and known clusters. We discuss the rationale for each design decision and review the success of the techniques in accomplishing the scientific goals. In practice, GyVe has been useful for gaining intuition about structures that were difficult to perceive with 2D projection techniques alone. For example, during their initial session with GyVe, our collaborators quickly confirmed scientific conclusions regarding the large-scale structure of the HRS previously obtained over months of study with 2D projections and statistical techniques. Further use of GyVe revealed the spherical shape of voids and showed that a presumed filament was actually two disconnected structures	Miller, J.;Quammen, C.W.;Fleenor, M.C.	Dept of Comput. Sci., North Carolina Univ., Chapel Hill, NC|c|;;	37830883100;37828726400;37828722500
	InfoVis+SciVis	Sept.-Oct. 2006	An Atmospheric Visual Analysis and Exploration System	10.1109/TVCG.2006.117	http://dx.doi.org/10.1109/TVCG.2006.117	1157	1164	4015477	astronomy computing;atmospheric techniques;rendering (computer graphics);storms;weather forecasting	2D contour;3D atmospheric data sets;3D isosurfaces;Doppler storm data;atmospheric visual analysis;cloud simulation;correlative visualization;drop trajectory modeling;exploration system;integrated atmospheric visual analysis;interactive weather data sets analysis;meteorological grid structures;meteorological research;multifield data set analysis;multiscale data set analysis;multisource data sets;physics-based atmospheric rendering;rendering techniques;small cumulus clouds;spatially correlated fields;storm models;three-dimensional interactive visualization;warm rain formation;weather forecasting model;weather phenomenon	Clouds;Data analysis;Data visualization;Isosurfaces;Meteorology;Performance analysis;Predictive models;Rain;Storms;Weather forecasting	glyph rendering;grid structures;transfer function;volume rendering;volume visualization;warm rain entrainment process;weather visualization	Meteorological research involves the analysis of multi-field, multi-scale, and multi-source data sets. Unfortunately, traditional atmospheric visualization systems only provide tools to view a limited number of variables and small segments of the data. These tools are often restricted to 2D contour or vector plots or 3D isosurfaces. The meteorologist must mentally synthesize the data from multiple plots to glean the information needed to produce a coherent picture of the weather phenomenon of interest. In order to provide better tools to meteorologists and reduce system limitations, we have designed an integrated atmospheric visual analysis and exploration system for interactive analysis of weather data sets. Our system allows for the integrated visualization of 1D, 2D, and 3D atmospheric data sets in common meteorological grid structures and utilizes a variety of rendering techniques. These tools provide meteorologists with new abilities to analyze their data and answer questions on regions of interest, ranging from physics-based atmospheric rendering to illustrative rendering containing particles and glyphs. In this paper, we discuss the use and performance of our visual analysis for two important meteorological applications. The first application is warm rain formation in small cumulus clouds. In this, our three-dimensional, interactive visualization of modeled drop trajectories within spatially correlated fields from a cloud simulation has provided researchers with new insight. Our second application is improving and validating severe storm models, specifically the weather research and forecasting (WRF) model. This is done through correlative visualization of WRF model and experimental Doppler storm data	Song, Y.;Ye, J.;Svakhine, N.;Lasher-Trapp, S.;Baldwin, M.;Ebert, D.S.	Purdue Univ., West Lafayette, IN|c|;;;;;	37560039000;37825593000;37565760800;37828763500;37827488300;37282598900
	InfoVis+SciVis	Sept.-Oct. 2006	Visualization of Fibrous and Thread-like Data	10.1109/TVCG.2006.197	http://dx.doi.org/10.1109/TVCG.2006.197	1165	1172	4015478	brain;medical image processing;neurophysiology;rendering (computer graphics);scanning electron microscopy	fiber network;fiber network rendering;fibrous visualization;image vascular;interactive techniques;knife-edge scanning microscopy;microvascular data;neural tissue;neuron rendering;self-orienting surfaces;serial block-face scanning electron microscopy;thread-like data;thread-like neuron structures;volumetric data sets;whole-brain tissue	Computer science;Data acquisition;Data visualization;Hardware;Image segmentation;Lighting;Neurons;Rendering (computer graphics);Scanning electron microscopy;Yarn	GPU acceleration;global illumination;neuron visualization;orientation filtering	Thread-like structures are becoming more common in modern volumetric data sets as our ability to image vascular and neural tissue at higher resolutions improves. The thread-like structures of neurons and micro-vessels pose a unique problem in visualization since they tend to be densely packed in small volumes of tissue. This makes it difficult for an observer to interpret useful patterns from the data or trace individual fibers. In this paper we describe several methods for dealing with large amounts of thread-like data, such as data sets collected using knife-edge scanning microscopy (KESM) and serial block-face scanning electron microscopy (SBF-SEM). These methods allow us to collect volumetric data from embedded samples of whole-brain tissue. The neuronal and microvascular data that we acquire consists of thin, branching structures extending over very large regions. Traditional visualization schemes are not sufficient to make sense of the large, dense, complex structures encountered. In this paper, we address three methods to allow a user to explore a fiber network effectively. We describe interactive techniques for rendering large sets of neurons using self-orienting surfaces implemented on the GPU. We also present techniques for rendering fiber networks in a way that provides useful information about flow and orientation. Third, a global illumination framework is used to create high-quality visualizations that emphasize the underlying fiber structure. Implementation details, performance, and advantages and disadvantages of each approach are discussed	Melek, Z.;Mayerich, D.;Yuksel, C.;Keyser, J.	Dept. of Comput. Sci., Texas A&M Univ., College Station, TX|c|;;;	37284004900;38267901600;37828699700;37282588300
	InfoVis+SciVis	Sept.-Oct. 2006	Comparative Visualization for Wave-based and Geometric Acoustics	10.1109/TVCG.2006.125	http://dx.doi.org/10.1109/TVCG.2006.125	1173	1180	4015479	acoustic wave diffraction;acoustic wave interference;architectural acoustics;finite element analysis;geometrical acoustics;ray tracing;wave equations	acoustic metric;comparative visualization;finite element method;geometric acoustic;interactive simulation;interference pattern visualization;neutralization effects;phase-dependent amplification;phonon tracing;room acoustic modeling;single simulation algorithm;wave equation;wave-based acoustic	Acoustic diffraction;Acoustic waves;Displays;Finite element methods;Frequency estimation;Interference;Partial differential equations;Phonons;Solid modeling;Visualization	acoustic simulation;comparative visualization;nite element method;phonon map;ray tracing	We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects	Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.	IRTG, Kaiserslautern|c|;;;;;;	37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100
	InfoVis+SciVis	Sept.-Oct. 2006	Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites	10.1109/TVCG.2006.151	http://dx.doi.org/10.1109/TVCG.2006.151	1181	1188	4015480	biomedical MRI;brain;data visualisation;image reconstruction;image segmentation;image texture;medical image processing;surgery	GPU programming;camera;diffusion tensor imaging;fiber structures;fiber tracking model;human brain;hybrid visualization;interactive multimodal inspection;neurosurgery;point sprites;real-time dense bundle rendering;real-time visualization approach;streamline techniques;surgical planning;triangle strip texture;tube-like appearance;vertex program;visual quality;visual representation;white matter tracts	Diffusion tensor imaging;Humans;Image reconstruction;Meeting planning;Neurosurgery;Sprites (computer);Streaming media;Strips;Surgery;Visualization	Diffusion tensor data;fiber tracking;streamline visualization	Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning	Merhof, D.;Sonntag, M.;Enders, F.;Nimsky, C.;Hastreiter, P.;Greiner, G.	Dept. of Neurosurgery, Univ. Erlangen|c|;;;;;	38266637000;37824387300;37550815500;37550816800;37373297800;37372696400
	InfoVis+SciVis	Sept.-Oct. 2006	Analyzing Vortex Breakdown Flow Structures by Assignment of Colors to Tensor Invariants	10.1109/TVCG.2006.119	http://dx.doi.org/10.1109/TVCG.2006.119	1189	1196	4015481	flow visualisation;pattern formation;vortices	associated tensor fields;equivalent flow topology;flow patterns;flow visualization;fluid dynamics;red-green-blue color space;rotating lid;tensor norm;topological flow field analysis;vectorial tensor invariants field;vortex breakdown flow structures	Aerodynamics;Australia;Color;Data visualization;Eigenvalues and eigenfunctions;Electric breakdown;Fluid dynamics;Information analysis;Tensile stress;Topology	Flow visualization;Invariants;Tensor field Topology	Topological methods are often used to describe flow structures in fluid dynamics and topological flow field analysis usually relies on the invariants of the associated tensor fields. A visual impression of the local properties of tensor fields is often complex and the search of a suitable technique for achieving this is an ongoing topic in visualization. This paper introduces and assesses a method of representing the topological properties of tensor fields and their respective flow patterns with the use of colors. First, a tensor norm is introduced, which preserves the properties of the tensor and assigns the tensor invariants to values of the RGB color space. Secondly, the RGB colors of the tensor invariants are transferred to corresponding hue values as an alternative color representation. The vectorial tensor invariants field is reduced to a scalar hue field and visualization of iso-surfaces of this hue value field allows us to identify locations with equivalent flow topology. Additionally highlighting by the maximum of the eigenvalue difference field reflects the magnitude of the structural change of the flow. The method is applied on a vortex breakdown flow structure inside a cylinder with a rotating lid	Rutten, M.;Chong, M.S.	German Aerosp. Center|c|;	37437412100;37824731300
	InfoVis+SciVis	Sept.-Oct. 2006	Superellipsoid-based, Real Symmetric Traceless Tensor Glyphs Motivated by Nematic Liquid Crystal Alignment Visualization	10.1109/TVCG.2006.181	http://dx.doi.org/10.1109/TVCG.2006.181	1197	1204	4015482	data visualisation;eigenvalues and eigenfunctions;nematic liquid crystals;physics computing;tensors	eigenvalues;nematic liquid crystal alignment tensor visualization;superellipsoid-based real symmetric traceless tensor glyphs	Computer graphics;Crystalline materials;Crystallization;Eigenvalues and eigenfunctions;Liquid crystal displays;Liquid crystals;Shape;Symmetric matrices;Tensile stress;Visualization	nematic liquid crystals;scientific visualization;symmetric traceless tensor;tensor visualization	A glyph-based method for visualizing the nematic liquid crystal alignment tensor is introduced. Unlike previous approaches, the glyph is based upon physically-linked metrics, not offsets of the eigenvalues. These metrics, combined with a set of superellipsoid shapes, communicate both the strength of the crystal's uniaxial alignment and the amount of biaxiality. With small modifications, our approach can visualize any real symmetric traceless tensor	Jankun-Kelly, T.J.;Ketan Mehta	Dept. of Comput. Sci. & Eng., Mississippi State Univ., MS|c|;	37399870300;37823708900
	InfoVis+SciVis	Sept.-Oct. 2006	High-Quality Extraction of Isosurfaces from Regular and Irregular Grids	10.1109/TVCG.2006.149	http://dx.doi.org/10.1109/TVCG.2006.149	1205	1212	4015483	computational geometry;data visualisation;feature extraction;image reconstruction;mesh generation;surface fitting	Marching Cubes algorithm;high-quality isosurface extraction;irregular grids;minimal guidance field;regular grids;sampling conditions;surface reconstruction	Graphics;Isosurfaces;Mesh generation;Pervasive computing;Pipelines;Robustness;Sampling methods;Smoothing methods;Surface reconstruction;Visualization	Advancing Front;Curvature;Isosurface Extraction	Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets	Schreiner, J.;Silva, C.T.	SCI Inst., Utah Univ., Salt Lake City, UT|c|;	37840129300;37275249200
	InfoVis+SciVis	Sept.-Oct. 2006	Mesh Layouts for Block-Based Caches	10.1109/TVCG.2006.162	http://dx.doi.org/10.1109/TVCG.2006.162	1213	1220	4015484	cache storage;computational geometry;data visualisation;interactive systems;mesh generation	block fetching;block-based caches;cache-aware layouts;cache-oblivious layouts;computer architectures;geometric processing algorithms;interactive visualization;isosurface extraction;mesh layouts;uncached data element;unstructured meshes;view-dependent rendering;volume meshes	Application software;Computer architecture;Data mining;Data visualization;Delay;Isosurfaces;Optimizing compilers;Pattern matching;Spatial coherence;Strips	Mesh and graph layouts;cache-aware and cache-oblivious layouts;data locality.;metrics for cache coherence	Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy	Yoon, S.-E.;Lindstrom, P.	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;	37279394100;37269320000
	InfoVis+SciVis	Sept.-Oct. 2006	Out-of-Core Remeshing of Large Polygonal Meshes	10.1109/TVCG.2006.169	http://dx.doi.org/10.1109/TVCG.2006.169	1221	1228	4015485	computational geometry;data compression;mesh generation;solid modelling;surface fitting	MAPS remesher;large input surface meshes;large polygonal meshes;out-of-core remeshing;semiregular surface representations;shape compression	Approximation algorithms;Computational modeling;Computer applications;Data structures;Data visualization;Medical simulation;Mesh generation;Sampling methods;Shape;Surface fitting	Out-of-core algorithm;semi-regular remeshing;shape compression	We propose an out-of-core method for creating semi-regular surface representations from large input surface meshes. Our approach is based on a streaming implementation of the MAPS remesher of Lee et al. Our remeshing procedure consists of two stages. First, a simplification process is used to obtain the base domain. During simplification, we maintain the mapping information between the input and the simplified meshes. The second stage of remeshing uses the mapping information to produce samples of the output semi-regular mesh. The out-of-core operation of our method is enabled by the synchronous streaming of a simplified mesh and the mapping information stored at the original vertices. The synchronicity of two streaming buffers is maintained using a specially designed write strategy for each buffer. Experimental results demonstrate the remeshing performance of the proposed method, as well as other applications that use the created mapping between the simplified and the original surface representations	Minsu Ahn;Guskov, I.;Seungyong Lee	Pohang Univ. of Sci. & Technol.|c|;;	37588185500;37326465500;37281130900
	InfoVis+SciVis	Sept.-Oct. 2006	Interactive Point-Based Rendering of Higher-Order Tetrahedral Data	10.1109/TVCG.2006.154	http://dx.doi.org/10.1109/TVCG.2006.154	1229	1236	4015486	computational geometry;data visualisation;interactive systems;mesh generation;rendering (computer graphics)	adaptively sampling points;computational simulations;higher-order tetrahedral data;interactive point-based rendering;memory consumption;order-independent point rendering method;point-based visualization system;tetrahedral volume meshes	Computer graphics;Cost function;Data visualization;Electric shock;Finite element methods;Moment methods;Performance loss;Piecewise linear techniques;Sampling methods;Sorting	Interactive large higher-order tetrahedral volume visualization;point-based visualization.	Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates	Zhou, Y.;Garland, M.	Dept. of Comput. Sci., Illinois Univ., Urbana, IL|c|;	37273640900;37272036400
	InfoVis+SciVis	Sept.-Oct. 2006	Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization	10.1109/TVCG.2006.115	http://dx.doi.org/10.1109/TVCG.2006.115	1237	1244	4015487	biological techniques;biology computing;data visualisation;molecular biophysics;molecular configurations;proteins;rendering (computer graphics);solid modelling	3D shapes;GPU accelerated procedural impostors;ambient occlusion;ball-and-stick rendering;edge cueing;proteins;real time molecular visualization enhancement;space-fill rendering	Acceleration;Chemicals;Data visualization;Image databases;Inspection;Proteins;Rendering (computer graphics);Shape;Software systems;Visual databases	Ambient Occlusion;Molecular Visualization;Real Time Rendering		Tarini, M.;Cignoni, P.;Montani, C.	Universita dell''Insubria, Varese|c|;;	37591264000;37265783400;37265786500
	InfoVis+SciVis	Sept.-Oct. 2006	Fast and Efficient Compression of Floating-Point Data	10.1109/TVCG.2006.143	http://dx.doi.org/10.1109/TVCG.2006.143	1245	1250	4015488	data compression;data visualisation;floating point arithmetic;mathematics computing	I/O bandwidth;data visualization;data-dependent prediction;online floating-point data compression;plug-in scheme;scientific simulation codes	Analytical models;Bandwidth;Data compression;Data visualization;Entropy;File systems;Image coding;Large-scale systems;Predictive models;Throughput	High throughput;fast entropy coding;file compaction for I/O efficiency;large scale simulation and visualization.;lossless compression;predictive coding;range coder	Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data	Lindstrom, P.;Isenburg, M.	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;	37269320000;37281897600
	InfoVis+SciVis	Sept.-Oct. 2006	Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data	10.1109/TVCG.2006.195	http://dx.doi.org/10.1109/TVCG.2006.195	1251	1258	4015489	data visualisation;feature extraction;interactive systems;medical image processing;microscopy	attribute calculation;confocal microscopy data;feature extraction;interactive visualization;large data collection analysis;large data collection visualization;microscopic images	Automatic control;Biomedical measurements;Data analysis;Data visualization;Feature extraction;Feedback;Inspection;Microscopy;Monitoring;Testing	Biomedical visualization;features in volume data sets;large data set visualization. Author 1:	"In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with ""visual summaries"" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed"	de Leeuw, W.;Verschure, P.J.	Swammerdam Inst. for Life Sci.|c|;	;37340174000
	InfoVis+SciVis	Sept.-Oct. 2006	On Histograms and Isosurface Statistics	10.1109/TVCG.2006.168	http://dx.doi.org/10.1109/TVCG.2006.168	1259	1266	4015490	data visualisation;interpolation;mathematics computing;statistical analysis;surface fitting	histograms;isosurface statistics;nearest neighbour interpolation;spatial function distributions	Biomedical imaging;Data visualization;Filters;Histograms;Image reconstruction;Interpolation;Isosurfaces;Spatial resolution;Statistical distributions;Statistics	histograms;isosurface statistics;isosurfaces	In this paper, we show that histograms represent spatial function distributions with a nearest neighbour interpolation. We confirm that this results in systematic underrepresentation of transitional features of the data, and provide new insight why this occurs. We further show that isosurface statistics, which use higher quality interpolation, give better representations of the function distribution. We also use our experimentally collected isosurface statistics to resolve some questions as to the formal complexity of isosurfaces	Carr, H.	Univ. Coll. Dublin|c|	37282624500
	InfoVis+SciVis	Sept.-Oct. 2006	Interactive Point-based Isosurface Exploration and High-quality Rendering	10.1109/TVCG.2006.153	http://dx.doi.org/10.1109/TVCG.2006.153	1267	1274	4015491	computer graphic equipment;data visualisation;edge detection;feature extraction;interactive systems;interpolation;rendering (computer graphics);surface fitting	GPU-based hardware-accelerated rendering;edge kernel method;edge splatting;high-quality rendering;interactive point-based isosurface exploration system;point-based isosurface extraction;point-based isosurface visualization;trilinear interpolation	Acceleration;Data mining;Data visualization;Graphics;Hardware;Interpolation;Isosurfaces;Kernel;Rendering (computer graphics);Shape	GPU acceleration.;Isosurface;hardware acceleration;isosurface extraction;point-based visualization	We present an efficient point-based isosurface exploration system with high quality rendering. Our system incorporates two point-based isosurface extraction and visualization methods: edge splatting and the edge kernel method. In a volume, two neighboring voxels define an edge. The intersection points between the active edges and the isosurface are used for exact isosurface representation. The point generation is incorporated in the GPU-based hardware-accelerated rendering, thus avoiding any overhead when changing the isovalue in the exploration. We call this method edge splatting. In order to generate high quality isosurface rendering regardless of the volume resolution and the view, we introduce an edge kernel method. The edge kernel upsamples the isosurface by subdividing every active cell of the volume data. Enough sample points are generated to preserve the exact shape of the isosurface defined by the trilinear interpolation of the volume data. By employing these two methods, we can achieve interactive isosurface exploration with high quality rendering	Zhang, H.;Kaufman, A.	Stony Brook Univ., NY|c|;	37280794900;37268052800
	InfoVis+SciVis	Sept.-Oct. 2006	Using Difference Intervals for Time-Varying Isosurface Visualization	10.1109/TVCG.2006.188	http://dx.doi.org/10.1109/TVCG.2006.188	1275	1282	4015492	computational geometry;data compression;data visualisation;feature extraction;interactive systems;rendering (computer graphics);surface fitting	difference intervals;isosurface geometry;isosurface information extraction;out-of-core time-varying isosurface visualization;point-based previewing technique;span space extraction techniques;temporal compression;time-varying dataset interactive visualization;video encoding techniques	Bandwidth;Computational fluid dynamics;Computational modeling;Data analysis;Data mining;Data visualization;Encoding;Geometry;Isosurfaces;Workstations	Isosurface;out-of-core;point-based rendering;span space;time-varying	We present a novel approach to out-of-core time-varying isosurface visualization. We attempt to interactively visualize time-varying datasets which are too large to fit into main memory using a technique which is dramatically different from existing algorithms. Inspired by video encoding techniques, we examine the data differences between time steps to extract isosurface information. We exploit span space extraction techniques to retrieve operations necessary to update isosurface geometry from neighboring time steps. Because only the changes between time steps need to be retrieved from disk, I/O bandwidth requirements are minimized. We apply temporal compression to further reduce disk access and employ a point-based previewing technique that is refined in idle interaction cycles. Our experiments on computational simulation data indicate that this method is an extremely viable solution to large time-varying isosurface visualization. Our work advances the state-of-the-art by enabling all isosurfaces to be represented by a compact set of operations	Waters, K.W.;Co, C.S.;Joy, K.I.	Inst. for Data Anal. & Visualization, California Univ., Davis, CA|c|;;	37823091200;37828723800;37267811400
	InfoVis+SciVis	Sept.-Oct. 2006	Isosurface Extraction and Spatial Filtering using Persistent Octree (POT)	10.1109/TVCG.2006.157	http://dx.doi.org/10.1109/TVCG.2006.157	1283	1290	4015493	data visualisation;database indexing;feature extraction;octrees;spatial data structures	4D isocontour slicing;Richtmyer-Meshkov instability dataset;branch-on-need octree;hybrid data structure;isosurface extraction;persistent octree;spatial filtering	Acceleration;Active filters;Data mining;Data structures;Data visualization;Filtering;Indexing;Isosurfaces;Ray tracing;Tree data structures	indexing.;isosurface extraction;scientific visualization	We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset	Shi, Q.;JaJa, J.	Dept. of Electr. & Comput. Eng., Maryland Univ., College Park, MD|c|;	37333454000;37276261200
	InfoVis+SciVis	Sept.-Oct. 2006	Scalable Data Servers for Large Multivariate Volume Visualization	10.1109/TVCG.2006.175	http://dx.doi.org/10.1109/TVCG.2006.175	1291	1298	4015494	data visualisation;file servers;spatial data structures	multivariate time-varying dataset;multivariate volume visualization;parallel data servers;scalable data servers;spatial data structures	Astrophysics;Computational modeling;Computer networks;Concurrent computing;Data processing;Data visualization;Network servers;Parallel processing;Pipelines;Time varying systems	Parallel and distributed volume visualization;large data set visualization;multi-variate visualization;volume visualization.	Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets	Glatter, M.;Mollenhour, C.;Huang, J.;Gao, J.	Tennessee Univ., TN|c|;;;	37828700000;37828698800;37281262900;37279695300
	InfoVis+SciVis	Sept.-Oct. 2006	Distributed Shared Memory for Roaming Large Volumes	10.1109/TVCG.2006.135	http://dx.doi.org/10.1109/TVCG.2006.135	1299	1306	4015495	cache storage;distributed shared memory systems;paged storage;rendering (computer graphics);workstation clusters	cluster-based volume rendering system;data caching;distributed graphics processing;distributed shared memory;gigabit Ethernet network interface;optimal volume roaming;pipelined sort-last rendering algorithm	Acceleration;Aggregates;Clustering algorithms;Data visualization;Ethernet networks;Graphics;Network interfaces;Probes;Real time systems;Rendering (computer graphics)	Large volumes;distributed shared memory;graphics cluster.;graphics hardware;hardware-accelerated volume visualization;hierarchical caching;out-of-core;parallel rendering;volume roaming	We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming	Castanie, L.;Mion, C.;Cavin, X.;Levy, B.	ALICE Group, INRIA, Lorraine|c|;;;	37565750700;37550851600;37442790400;37554667100
	InfoVis+SciVis	Sept.-Oct. 2006	Progressive Volume Rendering of Large Unstructured Grids	10.1109/TVCG.2006.171	http://dx.doi.org/10.1109/TVCG.2006.171	1307	1314	4015496	client-server systems;grid computing;rendering (computer graphics)	client-server architecture;real-time rendering;remote server;tetrahedral mesh;unstructured grids;volume rendering	Computational modeling;Data visualization;Displays;Geometry;Graphics;Hardware;Image storage;Portable computers;Quality management;Rendering (computer graphics)	Client-Server;Large Unstructured Grids;Level-of-Detail;Progressive Rendering;Volume Rendering	We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations	Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT|c|;;;	37426872800;37565304300;38262213600;37275249200
	InfoVis+SciVis	Sept.-Oct. 2006	Representing Higher-Order Singularities in Vector Fields on Piecewise Linear Surfaces	10.1109/TVCG.2006.173	http://dx.doi.org/10.1109/TVCG.2006.173	1315	1322	4015497	computational complexity;computational geometry;data visualisation;graph theory;interpolation;vectors	Nielson side-vertex scheme;arbitrary triangulated surface;facet graph;higher-order singularity representation;interpolation scheme;piecewise linear surfaces;vector fields	Computational fluid dynamics;Computational modeling;Convolution;Data structures;Data visualization;Integral equations;Interpolation;Piecewise linear techniques;Topology;Vectors	GPU;higher-order singularities;line integral convolution;vector field visualization	"Accurately representing higher-order singularities of vector fields defined on piecewise linear surfaces is a non-trivial problem. In this work, we introduce a concise yet complete interpolation scheme of vector fields on arbitrary triangulated surfaces. The scheme enables arbitrary singularities to be represented at vertices. The representation can be considered as a facet-based ""encoding"" of vector fields on piecewise linear surfaces. The vector field is described in polar coordinates over each facet, with a facet edge being chosen as the reference to define the angle. An integer called the period jump is associated to each edge of the triangulation to remove the ambiguity when interpolating the direction of the vector field between two facets that share an edge. To interpolate the vector field, we first linearly interpolate the angle of rotation of the vectors along the edges of the facet graph. Then, we use a variant of Nielson's side-vertex scheme to interpolate the vector field over the entire surface. With our representation, we remove the bound imposed on the complexity of singularities that a vertex can represent by its connectivity. This bound is a limitation generally exists in vertex-based linear schemes. Furthermore, using our data structure, the index of a vertex of a vector field can be combinatorily determined"	Li, W.-C.;Vallet, B.;Ray, N.;Levy, B.	INRIA-Alice|c|;;;	37558024300;37828763300;37831619000;37554667100
	InfoVis+SciVis	Sept.-Oct. 2006	Techniques for the Visualization of Topological Defect Behavior in Nematic Liquid Crystals	10.1109/TVCG.2006.182	http://dx.doi.org/10.1109/TVCG.2006.182	1323	1328	4015498	data visualisation;digital simulation;nematic liquid crystals;physics computing;tensors	continuous second-order tensor field;molecular simulation analyzing;nematic liquid crystals;physics lab;topological defect behavior;visualization technique	Biological system modeling;Computational modeling;Crystallization;Data visualization;Liquid crystal devices;Liquid crystal displays;Liquid crystals;Numerical simulation;Shape;Tensile stress	Case Studies;Liquid Crystals;Molecular Modeling;Tensor Visualization		Slavin, V.A.;Loriot, G.;Laidlaw, D.H.	;;	37282588800;37282584100;37275712600
	InfoVis+SciVis	Sept.-Oct. 2006	Diffusion Tensor Visualization with Glyph Packing	10.1109/TVCG.2006.134	http://dx.doi.org/10.1109/TVCG.2006.134	1329	1336	4015499	biomedical MRI;brain;data visualisation;medical image processing;mesh generation;tensors;tumours	anisotropic mesh generation;brain tumor;diffusion tensor visualization;fiber tractography;glyph packing;patient DT-MRI scan;surface modeling	Anisotropic magnetoresistance;Convolution;Data visualization;Diffusion tensor imaging;Laboratories;Mesh generation;Potential energy;Sampling methods;Shape measurement;Tensile stress	Diffusion tensor;anisotropic sampling;fiber tractography;glyphs;particle systems	A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor	Kindlmann, G.;Westin, C.-F.	Dept. of Radiol., Harvard Med. Sch., Boston, MA|c|;	37282742400;37294318400
	InfoVis+SciVis	Sept.-Oct. 2006	Extensions of the Zwart-Powell Box Spline for Volumetric Data Reconstruction on the Cartesian Lattice	10.1109/TVCG.2006.141	http://dx.doi.org/10.1109/TVCG.2006.141	1337	1344	4015500	Fourier analysis;computational geometry;interpolation;sampling methods;splines (mathematics)	Cartesian lattice;Fourier domain analysis;Zwart-Powell box spline;tricubic B-spline;volumetric data reconstruction	Convolution;Design methodology;Frequency;Interpolation;Kernel;Lattices;Reconstruction algorithms;Sampling methods;Spline;Tensile stress	Volumetric data interpolation;box splines;reconstruction		Entezari, A.;Mo&#x0308;ller, T.	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC|c|;	37268675600;37275858700
	InfoVis+SciVis	Sept.-Oct. 2006	A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering	10.1109/TVCG.2006.110	http://dx.doi.org/10.1109/TVCG.2006.110	1345	1352	4015501	computational geometry;computer graphic equipment;grid computing;pipeline processing;rendering (computer graphics)	GPU tetrahedral grid rendering;feed-forward pipeline;geometry construction;graphics hardware	Computational geometry;Computer graphics;Feedforward systems;Hardware;Personal communication networks;Pipelines;Plastics;Rendering (computer graphics);Sampling methods;Visualization	Direct volume rendering;programmable graphics hardware;unstructured grids	Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes	Georgii, J.;Westermann, R.	Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;	37828702100;37444424000
	InfoVis+SciVis	Sept.-Oct. 2006	A Spectral Analysis of Function Composition and its Implications for Sampling in Direct Volume Visualization	10.1109/TVCG.2006.113	http://dx.doi.org/10.1109/TVCG.2006.113	1353	1360	4015502	Fourier analysis;data visualisation;rendering (computer graphics);signal sampling;spectral analysis	direct volume visualization;multidimensional transfer functions;pre-integrated volume rendering;sampling method;spectral analysis	Adaptive signal processing;Frequency;Image sampling;Optical signal processing;Rendering (computer graphics);Sampling methods;Signal sampling;Spectral analysis;Transfer functions;Visualization	Fourier transform;adaptive sampling.;signal processing;transfer function;volume rendering	In this paper we investigate the effects of function composition in the form g(f(x)) = h(x) by means of a spectral analysis of h. We decompose the spectral description of h(x) into a scalar product of the spectral description of g(x) and a term that solely depends on f(x) and that is independent of g(x). We then use the method of stationary phase to derive the essential maximum frequency of g(f(x)) bounding the main portion of the energy of its spectrum. This limit is the product of the maximum frequency of g(x) and the maximum derivative of f(x). This leads to a proper sampling of the composition h of the two functions g and f. We apply our theoretical results to a fundamental open problem in volume rendering - the proper sampling of the rendering integral after the application of a transfer function. In particular, we demonstrate how the sampling criterion can be incorporated in adaptive ray integration, visualization with multi-dimensional transfer functions, and pre-integrated volume rendering	Bergner, S.;Moller, T.;Weiskopf, D.;Muraki, D.J.	GrUVi-Lab, Simon Fraser Univ., Burnaby, BC|c|;;;	37418878100;37275858700;38470313000;37836983300
