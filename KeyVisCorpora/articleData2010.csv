Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis+SciVis	Nov.-Dec. 2010	Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation	10.1109/TVCG.2010.187	http://dx.doi.org/10.1109/TVCG.2010.187	1487	1494	5613490	gradient methods;interpolation;lighting;rendering (computer graphics);table lookup	Blinn Phong illumination model;gradient filtering;lookup tables;nonlinear gradient interpolation;nonphotorealistic illumination model;preintegrated volume rendering;shading	Computational modeling;Equations;Interpolation;Lighting;Mathematical model;Niobium;Rendering (computer graphics)	direct volume rendering;gradient interpolation;pre-integration	Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.	Guetat, A.;Ancel, A.;Marchesin, S.;Dischler, J.-M.	;;;	37590980200;37590983400;37284319100;37284320600
	InfoVis+SciVis	Nov.-Dec. 2010	Gradient Estimation Revitalized	10.1109/TVCG.2010.160	http://dx.doi.org/10.1109/TVCG.2010.160	1495	1504	5613491	Fourier analysis;computational complexity;gradient methods;rendering (computer graphics)	Fourier domain derivative error kernel;body centered cubic lattices;computational efficiency;gradient estimation revitalized;gradient reconstruction quality;optimal gradient estimation filters;regular lattice;scalar point samples;volume rendering	Estimation;Image reconstruction;Interpolation;Kernel;Lattices;Spline	Approximation;Body Centered Cubic Lattice;Derivative;Frequency Error Kernel;Gradient;Interpolation;Lattice;Reconstruction;Sampling	We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.	Alim, U.;Moller, T.;Condat, L.	Simon Fraser Univ., Burnaby, BC, Canada|c|;;	37402559800;37275858700;37294569700
	InfoVis+SciVis	Nov.-Dec. 2010	Direct Interval Volume Visualization	10.1109/TVCG.2010.145	http://dx.doi.org/10.1109/TVCG.2010.145	1505	1514	5613492	data visualisation;parallel processing;pattern classification;rendering (computer graphics)	CUDA;direct interval volume visualization;direct volume rendering;generalized isosurfaces;interval volume rendering;isosurface rendering;parallel processing;ray integration;scale-invariant opacity;scale-invariant rendering;spatial ordering;visual classification	Isosurfaces;Mathematical model;Polynomials;Rendering (computer graphics);Transfer functions	direct volume rendering;interval volume;isosurface;preintegration;ray casting;scale-invariant opacity	We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.	Ament, M.;Weiskopf, D.;Carr, H.	VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;	37393968500;37268045000;37282624500
	InfoVis+SciVis	Nov.-Dec. 2010	VDVR: Verifiable Volume Visualization of Projection-Based Data	10.1109/TVCG.2010.211	http://dx.doi.org/10.1109/TVCG.2010.211	1515	1524	5613493	computerised tomography;data visualisation;rendering (computer graphics);solid modelling	X-ray projection;blurring;computed tomography reconstruction;locality-optimized representation;mixed resolution volume representation;projection-based data;rendering;space-efficient representation;trilinear interpolation;verifiable volume visualization;volume data generation process;volume visualization pipeline	Computed tomography;Data visualization;Frequency domain analysis;Image reconstruction;Interpolation;Pipelines;Rendering (computer graphics)	Direct volume rendering;computed tomography;filtered back-projection;verifiable visualization	Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.	Ziyi Zheng;Wei Xu;Mueller, K.	Center of Visual Comput., Stony Brook Univ., Stony Brook, NY, USA|c|;;	37599599100;37597172500;37273119700
	InfoVis+SciVis	Nov.-Dec. 2010	Fast High-Quality Volume Ray Casting with Virtual Samplings	10.1109/TVCG.2010.155	http://dx.doi.org/10.1109/TVCG.2010.155	1525	1532	5613494	computer graphic equipment;coprocessors;rendering (computer graphics);splines (mathematics);transfer functions	cubic spline curve;cubic texture filtering;direct volume rendering frameworks;fast high-quality volume ray casting algorithm;high-order convolution filter;higher order reconstruction filter;interactive rendering;polynomial function;programmable GPU;transfer function;virtual samplings;volume scalar smooth reconstruction	Filtering;Image reconstruction;Interpolation;Polynomials;Rendering (computer graphics);Spline;Transfer functions	GPU;curve interpolation.;direct volume rendering;high quality	Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.	Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong Gil Shin;Bohyoung Kim	Seoul Nat. Univ., Seoul, South Korea|c|;;;;;	37600709600;37599808200;37422552700;37277951300;37366743500;37594632900
	InfoVis+SciVis	Nov.-Dec. 2010	Efficient High-Quality Volume Rendering of SPH Data	10.1109/TVCG.2010.148	http://dx.doi.org/10.1109/TVCG.2010.148	1533	1540	5613495	coprocessors;hydrodynamics;rendering (computer graphics)	GPU;complex order-dependent resampling;fluid rendering;particle resampling;particle voxelization;smoothed particle hydrodynamics;view-space discretization;volume rendering	Adaptation model;Graphics processing unit;Interpolation;Kernel;Rendering (computer graphics);Slabs;Three dimensional displays	GPU resampling;Particle visualization;ray-casting;volume rendering	High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.	Fraedrich, R.;Auer, S.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mu&#x0308;nchen, Germany|c|;;	37590979700;37411079300;37444424000
	InfoVis+SciVis	Nov.-Dec. 2010	Fast, Memory-Efficient Cell Location in Unstructured Grids for Visualization	10.1109/TVCG.2010.156	http://dx.doi.org/10.1109/TVCG.2010.156	1541	1550	5613496	computational geometry;data visualisation;interpolation;tree data structures	associated construction algorithm;complex geometries;data structure;interpolation problem;memory-efficient cell location;spatial subdivision schemes;unstructured grids;visualization techniques	Arrays;Data visualization;Indexes;Interpolation;Octrees	cell location;interpolation;unstructured grids;vector field visualization	Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.	Garth, C.;Joy, K.I.	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;	37282573700;37267811400
	InfoVis+SciVis	Nov.-Dec. 2010	Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data	10.1109/TVCG.2010.215	http://dx.doi.org/10.1109/TVCG.2010.215	1551	1559	5613497	computational complexity;data visualisation;interactive systems;rendering (computer graphics);transfer functions	data exploration;data set complexity;deferred interaction;interactivity;proxy images;rendering algorithm;transfer function exploration;visualization;volume data	Attenuation;Cameras;Image color analysis;Lighting;Rendering (computer graphics);Three dimensional displays;Transfer functions	deferred interaction;image-based rendering;volume distortion camera;volume visualization	Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.	Tikhonova, A.;Correa, C.;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;	37404049100;37282925900;37275869400
	InfoVis+SciVis	Nov.-Dec. 2010	Interactive Vector Field Feature Identification	10.1109/TVCG.2010.170	http://dx.doi.org/10.1109/TVCG.2010.170	1560	1568	5613498	data visualisation;vectors	diverse feature types;feature based visualizations;feature exploration;interactive exploration;interactive vector field feature identification;simultaneous identification;user specified feature templates;vector field data;vector field points	Aerospace electronics;Data visualization;Feature extraction;Linear systems;Painting;Vectors;Visualization	data clustering;feature classification;high-dimensional data;user interaction;vector field	We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.	Daniels II, Joel;Anderson, E.W.;Nonato, L.G.;Silva, C.T.	Sch. of Comput. & Sci. Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	37602531100;37592852700;37590974800;37275249200
	InfoVis+SciVis	Nov.-Dec. 2010	Interactive Separating Streak Surfaces	10.1109/TVCG.2010.169	http://dx.doi.org/10.1109/TVCG.2010.169	1569	1577	5613499	data visualisation;feature extraction;interactive systems;solid modelling	3D unsteady flow exploration;GPU;Lagrangian coherent structure;feature extraction;finite time Lyapunov exponent;interactive technique;particle density;particle trajectory;real-time visualization;ridges;seeding structure;semantic separable surface;separation profile;separation surface;streak surface;visual analysis	Feature extraction;Graphics processing unit;Pixel;Skeleton;Surface reconstruction;Three dimensional displays	GPUs;Unsteady flow visualization;feature extraction;streak surface generation	Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.	Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.	Comput. Graphics & Visualization group, Tech. Univ. Munchen, Mu&#x0308;nchen, Germany|c|;;;	37606419000;37587634700;37266875400;37444424000
	InfoVis+SciVis	Nov.-Dec. 2010	View-Dependent Streamlines for 3D Vector Fields	10.1109/TVCG.2010.212	http://dx.doi.org/10.1109/TVCG.2010.212	1578	1586	5613500	data visualisation;graphical user interfaces;vectors	3D vector fields;GPU implementation;data space;feature search;proper visualization;self-occlusion;user intervention;view-dependent streamlines	Entropy;Measurement;Rendering (computer graphics);Streaming media;Three dimensional displays;Tiles;Visualization	Streamlines;Vector fields;View-dependent.	This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.	Marchesin, S.;Cheng-Kai Chen;Ho, C.;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;;	37284319100;37406743400;37599717800;37275869400
	InfoVis+SciVis	Nov.-Dec. 2010	Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots	10.1109/TVCG.2010.218	http://dx.doi.org/10.1109/TVCG.2010.218	1587	1594	5613501	computational geometry;curve fitting;data visualisation;flow simulation;rendering (computer graphics)	computer room airflow simulation;data analysis;dense geometry;flow trajectory visualization;groundwater simulation;linked information visualization;locality-based rendering;manipulatable curve plot;multifield visualization;particle path;particle trajectory;similarity plot;visual exploration;warped curve plot	Context;Data visualization;Geometry;Image color analysis;Rendering (computer graphics);Solids;Trajectory	coordinated linked views;flow visualization;focus+context visualization;multi-field visualization	In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.	Jones, C.;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;	37598134900;37275869400
	InfoVis+SciVis	Nov.-Dec. 2010	Superquadric Glyphs for Symmetric Second-Order Tensors	10.1109/TVCG.2010.199	http://dx.doi.org/10.1109/TVCG.2010.199	1595	1604	5613502	computational geometry;data visualisation;tensors	biomedical studies;feature extraction methods;image analysis;positive definite tensors;rate-of-deformation tensors;scientific studies;superquadric glyphs;superquadric shape space;symmetric second order tensors;tensor glyph;tensor shape;traceless tensors;visualization techniques	Data visualization;Eigenvalues and eigenfunctions;Geometry;Image color analysis;Shape;Tensile stress;Visualization	Geometry Tensors;Glyph Design;Rate-of-Deformation Tensors;Stress Tensors;Tensor Glyphs	Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.	Schultz, T.;Kindlmann, G.L.	Comput. Sci. Dept., Univ. of Chicago, Chicago, IL, USA|c|;	38264158700;38265362700
	InfoVis+SciVis	Nov.-Dec. 2010	TanGeoMS: Tangible Geospatial Modeling System	10.1109/TVCG.2010.202	http://dx.doi.org/10.1109/TVCG.2010.202	1605	1612	5613503	data visualisation;geographic information systems;terrain mapping;user interfaces	TanGeoMS;barrier islands;geospatial information system;landscape rehabilitation;military training areas;physical terrain model;runoff management;storm surge;tangible geospatial modeling visualization system;tangible user interface;terrain data;watershed	Analytical models;Computational modeling;Data models;Geospatial analysis;Solid modeling;Surface topography	collaborative visualization;geographic/geospatial visualization;human-computer interaction;tangible user interface;terrain visualization;visualization system	We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.	Tateosian, L.;Mitasova, H.;Harmon, B.;Fogleman, B.;Weaver, K.;Harmon, R.	North Carolina State Univ., Raleigh, NC, USA|c|;;;;;	37550412000;37564680200;37603853300;37589580700;37603897600;37425778300
	InfoVis+SciVis	Nov.-Dec. 2010	FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces	10.1109/TVCG.2010.157	http://dx.doi.org/10.1109/TVCG.2010.157	1613	1622	5613504	data visualisation;interactive systems;natural sciences computing	3D scientific visualization spaces;FI3D;astronomy;brain fiber tracts;data manipulations;direct touch data exploration;direct touch interaction;mouse based interaction;physics	Aerospace electronics;Data visualization;Mice;Navigation;Solid modeling;Space exploration;Three dimensional displays	3D navigation and exploration;Direct-touch interaction;evaluation;illustrative visualization;wall displays	We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.	Lingyun Yu;Svetachov, P.;Isenberg, P.;Everts, M.H.;Isenberg, T.	Univ. of Groningen, Groningen, Netherlands|c|;;;;	37593898200;37591151000;37591317800;37591149600;37297057400
	InfoVis+SciVis	Nov.-Dec. 2010	A Scalable Distributed Paradigm for Multi-User Interaction with Tiled Rear Projection Display Walls	10.1109/TVCG.2010.128	http://dx.doi.org/10.1109/TVCG.2010.128	1623	1632	5613505	data visualisation;gesture recognition;human computer interaction;image registration;large screen displays;optical projectors	application scalability;application specific modules;distributed registration algorithms;distributed self-registration;emergency management system;gesture-based interface;laser-based user interface;map visualization;misregistrations;multiple interaction modality;multiple projectors;multiprojector display walls;multiuser interaction;radially cascading geometric registration technique;scalable distributed paradigm;specially augmented QR codes;tiled rear projection display walls;virtual bulletin board;virtual graffiti	Algorithm design and analysis;Arrays;Cameras;History;Servers;Tracking	Distributed algorithms;Gesture-Based Interaction;Human-Computer Interaction;Multi-user interaction;Tiled Displays	We present the first distributed paradigm for multiple users to interact simultaneously with large tiled rear projection display walls. Unlike earlier works, our paradigm allows easy scalability across different applications, interaction modalities, displays and users. The novelty of the design lies in its distributed nature allowing well-compartmented, application independent, and application specific modules. This enables adapting to different 2D applications and interaction modalities easily by changing a few application specific modules. We demonstrate four challenging 2D applications on a nine projector display to demonstrate the application scalability of our method: map visualization, virtual graffiti, virtual bulletin board and an emergency management system. We demonstrate the scalability of our method to multiple interaction modalities by showing both gesture-based and laser-based user interfaces. Finally, we improve earlier distributed methods to register multiple projectors. Previous works need multiple patterns to identify the neighbors, the configuration of the display and the registration across multiple projectors in logarithmic time with respect to the number of projectors in the display. We propose a new approach that achieves this using a single pattern based on specially augmented QR codes in constant time. Further, previous distributed registration algorithms are prone to large misregistrations. We propose a novel radially cascading geometric registration technique that yields significantly better accuracy. Thus, our improvements allow a significantly more efficient and accurate technique for distributed self-registration of multi-projector display walls.	Roman, P.;Lazarov, M.;Majumder, A.	Comput. Sci. Dept., Univ. of Calif ornia, Irvine, CA, USA|c|;;	37605184700;37541336800;38477161700
	InfoVis+SciVis	Nov.-Dec. 2010	Projector Placement Planning for High Quality Visualizations on Real-World Colored Objects	10.1109/TVCG.2010.189	http://dx.doi.org/10.1109/TVCG.2010.189	1633	1641	5613506	data visualisation;image colour analysis;mobile computing	ad hoc projector placement;appearance editing image formation;color shifting;high quality visualizations;mobile visualization;projection-based visualization displays;projector light radiance;projector placement planning;real-world colored objects;ubiquitous visualization	Equations;Image color analysis;Linear systems;Mathematical model;Pixel;Planning;Visualization	Interaction Design;Mobile and Ubiquitous Visualization;large and High-resolution Displays	Many visualization applications benefit from displaying content on real-world objects rather than on a traditional display (e.g., a monitor). This type of visualization display is achieved by projecting precisely controlled illumination from multiple projectors onto the real-world colored objects. For such a task, the placement of the projectors is critical in assuring that the desired visualization is possible. Using ad hoc projector placement may cause some appearances to suffer from color shifting due to insufficient projector light radiance being exposed onto the physical surface. This leads to an incorrect appearance and ultimately to a false and potentially misleading visualization. In this paper, we present a framework to discover the optimal position and orientation of the projectors for such projection-based visualization displays. An optimal projector placement should be able to achieve the desired visualization with minimal projector light radiance. When determining optimal projector placement, object visibility, surface reflectance properties, and projector-surface distance and orientation need to be considered. We first formalize a theory for appearance editing image formation and construct a constrained linear system of equations that express when a desired novel appearance or visualization is possible given a geometric and surface reflectance model of the physical surface. Then, we show how to apply this constrained system in an adaptive search to efficiently discover the optimal projector placement which achieves the desired appearance. Constraints can be imposed on the maximum radiance allowed by the projectors and the projectors' placement to support specific goals of various visualization applications. We perform several real-world and simulated appearance edits and visualizations to demonstrate the improvement obtained by our discovered projector placement over ad hoc projector placement.	Law, A.J.;Aliaga, Daniel G.;Majumder, A.	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA|c|;;	37593749400;37270561900;37408075400
	VAST	25-26 Oct. 2010	Keynote address: How will big pictures emerge from a sea of [&#x2026;] biological data?	10.1109/VAST.2010.5652365	http://dx.doi.org/10.1109/VAST.2010.5652365	xiii	xiii	5652365	Internet;bioinformatics;data visualisation	Google maps;United States;biological data;biological information;biological interactions;biological research;biological sequences;biological structures;biological system;complex systems;nonlinear interactions;systems biology;systems-level analysis;tangled web;visualization			Every year since the article “How Will Big Pictures Emerge From a Sea of Biological Data?” appeared in Science, the question becomes more compelling. We are now accumulating information about biological sequences, structures, and interactions faster than we have the power to make sense of them. For hundreds of years prior to this, practical considerations coerced biological research into reductionism. There are simply too many components in a biological system for a biologist to examine the whole picture with the tools formerly available. Over the past decade this has rapidly changed as biological information has become cheap and plentiful due to the advent of high-throughput tools, making it possible for the frst time to ask questions on time and length scales that were previously intractable. The relaxation of the practical limitations on systems-level analysis has also brought a change in the philosophy of how we regard biology, moving towards a holistic method of research and interpretation. This places systems biology in stark contrast to traditional biological research, and for good reason. In the words of Denis Noble, “Systems biology is about putting together rather than taking apart, integration rather than reduction. It starts with what we have learned from the reductionist approach; and then it goes further.” This shift from reductionism is essential, for as we know from studying complex systems, the whole is greater than the sum of the parts. With this new approach we are able to explore scientifc territory that has previously been untouched due to physical impossibility and philosophical differences. The complexity of the tangled web of nonlinear interactions between genes, proteins, and the environment necessitates the development of simplifed models to illuminate biological functions. Merely generating networks of interactions is not enough, providing us with far too much information in a single view without emphasizin- the important features of the map. When we use Google maps and look at a picture of the United States it doesn't show us every city, we would never see Evanston, Illinois being shown at that level of detail. Only large and recognizable cities are shown to help us orient the map. Once we zoom in other smaller cities and features become visible, giving us more relevant information in a manner that is usable. Simply generating networks without any type of analysis or visualization is akin to showing a map of the United States with every state, city, and town marked on it. In my talk, I will describe the advances we have made in developing new visualization methods and the challenges still remaining.	Amaral, L.A.N.		37603965400
	VAST	25-26 Oct. 2010	DimStiller: Workflows for dimensional analysis and reduction	10.1109/VAST.2010.5652392	http://dx.doi.org/10.1109/VAST.2010.5652392	3	10	5652392	collections of physical data;data analysis;data reduction;data visualisation;pipeline processing	DimStiller;data tables;dimensionality analysis;dimensionality reduction;operator controls;pipeline processing;visual feedback;workflows	Aerospace electronics;Algorithm design and analysis;Correlation;Image color analysis;Noise;Pipelines;Visualization		DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.	Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Mo&#x0308;ller, T.	Univ. of British Columbia, Vancouver, BC, Canada|c|;;;;;	37587716200;37349490300;37589529600;37275861300;37418878100;37275858700
	VAST	25-26 Oct. 2010	Visual exploration of classification models for risk assessment	10.1109/VAST.2010.5652398	http://dx.doi.org/10.1109/VAST.2010.5652398	11	18	5652398	data analysis;data visualisation;decision making;image classification;learning (artificial intelligence);risk management	classification model;classifier performance;data classification;data element;data visualization;decision making;expert knowledge;forensic psychiatry domain;interactive 2D visualization;interactive performance curve;interactive visual exploration;linked visualization;machine learning;multidimensional data;risk assessment;visual analytics framework;visual exploration	Context;Data models;Data visualization;Forensics;Image color analysis;Risk management;Visualization	Classification;Decision Boundary Visualization;Interactive Visual Exploration;Multi-dimensional Space;Visual Analytics	In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier's performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach.	Migut, M.;Worring, M.	Intell. Syst. Lab. Amsterdam, Univ. of Amsterdam, Amsterdam, Netherlands|c|;	37589528300;37267865600
	VAST	25-26 Oct. 2010	Improving the visual analysis of high-dimensional datasets using quality measures	10.1109/VAST.2010.5652433	http://dx.doi.org/10.1109/VAST.2010.5652433	19	26	5652433	data analysis;data reduction;data visualisation;information retrieval	Radviz;automatic reduction techniques;high-dimensional datasets;information content;modern visualization methods;pixel-oriented displays;quality measures;structural differences;table lenses;visual analysis	Clustering algorithms;Data visualization;Image color analysis;Lenses;Noise;Pixel;Visualization	H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval;I.3.3 [Computer Graphics]: Picture/Image Generation	Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.	Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.	Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;	37603943800;37546817000;37601992200;37266875400;37273816400
	VAST	25-26 Oct. 2010	iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction	10.1109/VAST.2010.5652443	http://dx.doi.org/10.1109/VAST.2010.5652443	27	34	5652443	data analysis;data reduction;data visualisation;face recognition;image classification;interactive systems;pattern clustering;visual databases	associated cluster label;cluster centroid;facial image data;heat map;high dimensional data;iVisClassifier;interactive visual analytics system;linear discriminant analysis;pairwise distance;supervised dimension reduction	Clustering algorithms;Data visualization;Image color analysis;Pixel;Principal component analysis;Space heating	H.5.2 [INFORMATION INTERFACES AND PRESENTATION]: User Interfaces-Theory and methods	We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.	Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park	Sch. of Comput. Sci. & Eng., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	37602784600;37599320600;37592890600;37277119500
	VAST	25-26 Oct. 2010	Finding and visualizing relevant subspaces for clustering high-dimensional astronomical data using connected morphological operators	10.1109/VAST.2010.5652450	http://dx.doi.org/10.1109/VAST.2010.5652450	35	42	5652450	data visualisation;graphical user interfaces;pattern clustering;spatial data structures;visual databases	catalogues;connected morphological operators;data clustering;data representation;data sets;data visualization;discrete image space;graphical user interface;grid-based density field;high-dimensional astronomical data;image data;local maxima;modern astronomical surveys;parametric space;subspaces;visualization toolkits	Data visualization;Estimation;Noise;Principal component analysis;Shape;Smoothing methods;Visualization	Subspace finding;astronomical data;clustering high-dimensional data;connected morphological operators;visual exploration	Data sets in astronomy are growing to enormous sizes. Modern astronomical surveys provide not only image data but also catalogues of millions of objects (stars, galaxies), each object with hundreds of associated parameters. Exploration of this very high-dimensional data space poses a huge challenge. Subspace clustering is one among several approaches which have been proposed for this purpose in recent years. However, many clustering algorithms require the user to set a large number of parameters without any guidelines. Some methods also do not provide a concise summary of the datasets, or, if they do, they lack additional important information such as the number of clusters present or the significance of the clusters. In this paper, we propose a method for ranking subspaces for clustering which overcomes many of the above limitations. First we carry out a transformation from parametric space to discrete image space where the data are represented by a grid-based density field. Then we apply so-called connected morphological operators on this density field of astronomical objects that provides visual support for the analysis of the important subspaces. Clusters in subspaces correspond to high-intensity regions in the density image. The importance of a cluster is measured by a new quality criterion based on the dynamics of local maxima of the density. Connected operators are able to extract such regions with an indication of the number of clusters present. The subspaces are visualized during computation of the quality measure, so that the user can interact with the system to improve the results. In the result stage, we use three visualization toolkits linked within a graphical user interface so that the user can perform an in-depth exploration of the ranked subspaces. Evaluation based on synthetic as well as real astronomical datasets demonstrates the power of the new method. We recover various known astronomical relations directly from the data with little or no a pri- - ori assumptions. Hence, our method holds good prospects for discovering new relations as well.	Ferdosi, B.J.;Buddelmeijer, H.;Trager, S.;Wilkinson, M.H.F.;Roerdink, J.B.T.M.	Johann Bernoulli Inst. for Math. & Comput. Sci., Univ. of Groningen, Groningen, Netherlands|c|;;;;	37589434200;37589433700;37589433500;37279238300;37279298200
	VAST	25-26 Oct. 2010	Flow-based scatterplots for sensitivity analysis	10.1109/VAST.2010.5652460	http://dx.doi.org/10.1109/VAST.2010.5652460	43	50	5652460	data visualisation;pattern clustering;sensitivity analysis	2D scatterplots;complex correlations;flow-based scatterplots;flow-field analysis;high-dimensional data;information loss;multidimensional data Visualization;sensitivity analysis	Complexity theory;Correlation;Data visualization;Navigation;Sensitivity analysis;Visualization	Data Transformations;Model Fitting;Principal Component Analysis;Uncertainty	Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.	Yu-Hsuan Chan;Correa, C.;Kwan-Liu Ma	Univ. of California at Davis, Davis, CA, USA|c|;;	37593323300;37282925900;37275869400
	VAST	25-26 Oct. 2010	Anomaly detection in GPS data based on visual analytics	10.1109/VAST.2010.5652467	http://dx.doi.org/10.1109/VAST.2010.5652467	51	58	5652467	Global Positioning System;data analysis;data flow analysis;data visualisation;graphical user interfaces;human computer interaction;information retrieval;learning (artificial intelligence);visual databases	GPS Visual Analytics System;anomaly detection;conditional random field model;data driven modeling;domain specific expertise;high level intelligence;human computer interaction;information extraction;interactive user interface;machine learning;real time data behavior;visualization	Data models;Data visualization;Global Positioning System;Histograms;Humans;Machine learning;Training	Feature evaluation and selection;H.1.2 [Models and Principles]: User/Machine Systems-Human information processing;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphics user interfaces;I.5.2 [Pattern Recognition]: Design Methodology-Pattern analysis	Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.	Zicheng Liao;Yizhou Yu;Baoquan Chen	Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA|c|;;	37591746700;37578164900;37600013700
	VAST	25-26 Oct. 2010	Discovering bits of place histories from people&#39;s activity traces	10.1109/VAST.2010.5652478	http://dx.doi.org/10.1109/VAST.2010.5652478	59	66	5652478	Internet;history;mobile computing	combine geocomputations;computer processable data;discovering bits;integrated analysis;interactive geovisualizations;mobile phone operators;people activity traces;photo sharing web sites;place histories;statistical methods;thematic components	Correlation;Databases;Games;Mobile handsets;Shape;Time series analysis;Visual analytics	event detection;geovisualization;scalable visualization;spatio-temporal data;time series analysis	Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.	Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.	Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;	37283047100;37283047700;37545515700;37279597900;37589346900
	VAST	25-26 Oct. 2010	A visual analytics approach to model learning	10.1109/VAST.2010.5652484	http://dx.doi.org/10.1109/VAST.2010.5652484	67	74	5652484	data mining;data visualisation;hidden Markov models;human computer interaction;knowledge representation;learning (artificial intelligence)	Hidden Markov Model;assistive visualization system;feature vector;individual clusters;labelling;model initialization phase;model learning;sequence segmentation task;visual analytics	Analytical models;Computational modeling;Data models;Hidden Markov models;Image segmentation;Layout;Visualization	Data Clustering;Human-Computer Interaction;Visual Knowledge Discovery;Visual Knowledge Representation	The process of learning models from raw data typically requires a substantial amount of user input during the model initialization phase. We present an assistive visualization system which greatly reduces the load on the users and makes the process of model initialization and refinement more efficient, problem-driven, and engaging. Utilizing a sequence segmentation task with a Hidden Markov Model as an example, we assign each token in the sequence a feature vector based on its various properties within the sequence. These vectors are then clustered according to similarity, generating a layout of the individual tokens in form of a node link diagram where the length of the links is determined by the feature vector similarity. Users may then tune the weights of the feature vector components to improve the segmentation, which is visualized as a better separation of the clusters. Also, as individual clusters represent different classes, the user can now work at the cluster level to define token classes, instead of labelling one entry at time. Inconsistent entries visually identify themselves by locating at the periphery of clusters, and the user then helps refine the model by resolving these inconsistencies. Our system therefore makes efficient use of the knowledge of its users, only requesting user assistance for non-trivial data items. It so allows users to visually analyse data at a higher, more abstract level, improving scalability.	Garg, S.;Ramakrishnan, I.V.;Mueller, K.	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	37592970300;37284911300;37273119700
	VAST	25-26 Oct. 2010	Multidimensional data dissection using attribute relationship graphs	10.1109/VAST.2010.5652520	http://dx.doi.org/10.1109/VAST.2010.5652520	75	82	5652520	data visualisation;graph theory;program slicing;query processing	attribute relationship graphs;design strategies;manipulating;multidimensional data dissection;multigraph representation;queries;slicing;visual analysis tools;visual exploration	Awards activities;Data visualization;Encoding;Layout;Motion pictures;Pipelines;Visualization	D.2.2 [Software Engineering]: Design Tools and Techniques-[User Interfaces];H.2.3 [Information Systems]: Database Management-[Languages];H.5.2 [Information Systems]: Information Interfaces and Presentation-[User Interfaces]	Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools.	Weaver, C.	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|	37564883300
	VAST	25-26 Oct. 2010	Visual market sector analysis for financial time series data	10.1109/VAST.2010.5652530	http://dx.doi.org/10.1109/VAST.2010.5652530	83	90	5652530	data analysis;data visualisation;financial data processing;pattern clustering;stock markets;time series;user interfaces	characteristic graphs;data cluster;interactive visual analysis;market mechanism;market sector;stock market;time series data	Clustering algorithms;Data visualization;Pixel;Real time systems;Stock markets;Time series analysis;Visualization	Explorative Analysis;Financial Information Visualization;Time Series Clustering;Time Series Data;Visual Analytics	The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.	Ziegler, H.;Jenny, M.;Gruse, T.;Keim, D.A.	Univ. of Konstanz, Konstanz, Germany|c|;;;	37606028000;37589560900;37589560700;37283138700
	VAST	25-26 Oct. 2010	Two-stage framework for a topology-based projection and visualization of classified document collections	10.1109/VAST.2010.5652940	http://dx.doi.org/10.1109/VAST.2010.5652940	91	98	5652940	classification;computational geometry;data visualisation;document handling;information resources	blogs;books;classified document collections;daily newspapers;electronic textual information;high dimensional information space;information source;patent collections;private messages;publications;tf-idf document-term weighting method;topology-based projection;visualization	Clouds;Context;Data visualization;Electronic mail;Layout;Optimization;Topology	H.5.2 [INFORMATION INTERFACES AND PRESENTATION]: User Interfaces-Theory and methods;I.5.3 [Pattern Recognition]: Clustering-Algorithms	During the last decades, electronic textual information has become the world's largest and most important information source. Daily newspapers, books, scientific and governmental publications, blogs and private messages have grown into a wellspring of endless information and knowledge. Since neither existing nor new information can be read in its entirety, we rely increasingly on computers to extract and visualize meaningful or interesting topics and documents from this huge information reservoir. In this paper, we extend, improve and combine existing individual approaches into an overall framework that supports topologi-cal analysis of high dimensional document point clouds given by the well-known tf-idf document-term weighting method. We show that traditional distance-based approaches fail in very high dimensional spaces, and we describe an improved two-stage method for topology-based projections from the original high dimensional information space to both two dimensional (2-D) and three dimensional (3-D) visualizations. To demonstrate the accuracy and usability of this framework, we compare it to methods introduced recently and apply it to complex document and patent collections.	Oesterling, P.;Scheuermann, G.;Teresniak, S.;Heyer, G.;Koch, S.;Ertl, T.;Weber, G.H.	Univ. of Leipzig, Leipzig, Germany|c|;;;;;;	37403135200;37282574800;37591211600;37591211200;37593029700;37268023800;37411444100
	VAST	25-26 Oct. 2010	Understanding text corpora with multiple facets	10.1109/VAST.2010.5652931	http://dx.doi.org/10.1109/VAST.2010.5652931	99	106	5652931	data models;data visualisation;text analysis;user interfaces	data facets;data model;text analysis;text corpora;text visualization;visual analysis;visual interaction method	Correlation;Data mining;Data models;Data visualization;Layout;Navigation;Visualization	multi-facet data visualization;text visualization	Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.	Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.	IBM Res. - China, Beijing, China|c|;;;;;	37287511900;37396839900;37406039100;37597343100;37604004300;37399569300
	VAST	25-26 Oct. 2010	VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis	10.1109/VAST.2010.5652932	http://dx.doi.org/10.1109/VAST.2010.5652932	107	114	5652932	Internet;data analysis;data visualisation;graph theory;groupware	VizCept;Web based visual analytics system;collaborative analysis;intelligence data analysis;keyword search;personal graph layout;synchronous collaborative construction;textual intelligence dataset	Collaboration;Data visualization;Keyword search;Layout;Servers;Text analysis;Visual analytics	Collaborative visualization;intelligence analysis;text and document data	In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.	Haeyong Chung;Seungwon Yang;Massjouni, N.;Andrews, C.;Kanna, R.;North, C.	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;	37597408500;37598427300;37591135300;37587847300;37591136300;37419565900
	VAST	25-26 Oct. 2010	Diamonds in the rough: Social media visual analytics for journalistic inquiry	10.1109/VAST.2010.5652922	http://dx.doi.org/10.1109/VAST.2010.5652922	115	122	5652922	content management;information retrieval;social networking (online);text analysis;user interfaces	Facebook;Twitter;Vox Civitas;journalist;social media;text analysis;visual analytic tool	Aggregates;Classification algorithms;Context;Filtering;Media;Twitter;Visual analytics	Computational Journalism;Computer Assisted Reporting;Sensemaking;Social Media	Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.	Diakopoulos, N.;Naaman, M.;Kivran-Swaine, F.	;;	37591165700;38359768900;38276630800
	VAST	25-26 Oct. 2010	Visual readability analysis: How to make your writings easier to read	10.1109/VAST.2010.5652926	http://dx.doi.org/10.1109/VAST.2010.5652926	123	130	5652926	data visualisation;text analysis	candidate readability feature;document draft version;document logical layout;document physical layout;semiautomatic feature selection approach;sentence readability;visual analysis tool;visual readability analysis;visual representation accounting	Complexity theory;Correlation;Image color analysis;Length measurement;Navigation;Visualization;Vocabulary	I.5.2 [Pattern Recognition]: Design Methodology-Feature evaluation and selection;I.7.5 [Document and Text Processing]: Document Capture-Document Analysis	We present a tool that is specifically designed to support a writer in revising a draft-version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we therefore discuss a semi-automatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. The user can choose different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case-studies are presented that show the wide range of applicability of our tool.	Oelke, D.;Spretke, D.;Stoffel, A.;Keim, D.A.	Univ. of Konstanz, Konstanz, Germany|c|;;;	37591207400;37601354600;37592880100;37283138700
	VAST	25-26 Oct. 2010	NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks	10.1109/VAST.2010.5652910	http://dx.doi.org/10.1109/VAST.2010.5652910	131	138	5652910	business communication;business data processing;computer networks;data visualisation;fault tolerant computing	NetClinic;administrators;automated fault diagnosis;automatic diagnostic tools;enterprise networks;interactive visualization;operational computer network;sensemaking strategies	Cognition;Electronic mail;Layout;Radiation detectors;Semantics;Servers;Visualization	Information Visualization;Network Diagnosis;Semantic Graph Layout;Sensemaking;Visual Analytics	Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.	Zhicheng Liu;Bongshin Lee;Kandula, S.;Mahajan, R.	;;;	37592993600;37293389400;37591286400;37603074200
	VAST	25-26 Oct. 2010	Geo-historical context support for information foraging and sensemaking: Conceptual model, implementation, and assessment	10.1109/VAST.2010.5652895	http://dx.doi.org/10.1109/VAST.2010.5652895	139	146	5652895	cognition;geographic information systems;inference mechanisms;mobile computing;user interfaces	context discovery application;context-aware computing;context-dependent activities;crisis management;document foraging;geo-historical context support;humanitarian relief;information foraging;sensemaking;visual analytics tools;visual interfaces;visually-enabled reasoning;web-based tool	Cognition;Computational modeling;Context;Context modeling;Data models;Ontologies;Semantics	context;foraging;geographic information retrieval;mapping;sensemaking;text analysis	Information foraging and sensemaking with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated adaptation of the system to meet user needs for applications such as mobile location-based services where information about the location, the user, and the user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sensemaking, the user is likely to take an active role in foraging for the contextual information needed to support sensemaking in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytical reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we pay particular attention to document foraging to support construction of the geographic and historical context within which monitoring and sensemaking can be carried out. Specifically, we present the concept of geo-historical context (GHC) and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application, a web-based tool that supports document foraging and sensemaking.	Tomaszewski, B.;MacEachren, A.M.	Dept. of Inf. Sci. & Technol., Rochester Inst. of Technol., Rochester, NY, USA|c|;	37591184300;37374699000
	VAST	25-26 Oct. 2010	Real-time aggregation of Wikipedia data for visual analytics	10.1109/VAST.2010.5652896	http://dx.doi.org/10.1109/VAST.2010.5652896	147	154	5652896	Web services;application program interfaces;data visualisation;query processing	French Wikipedia;Web Service;WikiReactive;Wikipedia API;Wikipedia articles;Wikipedia data;Wikipedia skins;collaborative social process;copyright infringements;encyclopedic knowledge;participatory design sessions;real-time aggregation;visual analytics	Data visualization;Databases;Electronic publishing;Encyclopedias;Internet;Measurement	Database Management [H.2.1]: Logical Design-Schema and subschema;Database Management [H.2.4]: System-Query processing;Information Storage and Retrieval [H.3.5]: Online Information Services-Web-based services	Wikipedia has been built to gather encyclopedic knowledge using a collaborative social process that has proved its effectiveness. However, the workload required for raising the quality and increasing the coverage of Wikipedia is exhausting the community. Based on several participatory design sessions with active Wikipedia contributors (a.k.a. Wikipedians), we have collected a set of measures related to Wikipedia activity that, if available and visualized effectively, could spare a lot of monitoring time to these Wikipedians, allowing them to focus on quality and coverage of Wikipedia instead of spending their time navigating heavily to track vandals and copyright infringements. However, most of these measures cannot be computed on the fly using the available Wikipedia API. Therefore, we have designed an open architecture called WikiReactive to compute incrementally and maintain several aggregated measures on the French Wikipedia. This aggregated data is available as a Web Service and can be used to overlay information on Wikipedia articles through Wikipedia Skins or for new services for Wikipedians or people studying Wikipedia. This article describes the architecture, its performance and some of its uses.	Boukhelifa, N.;Chevalier, F.;Fekete, J.	;;	37325862800;37395495900;37407972900
	VAST	25-26 Oct. 2010	Click2Annotate: Automated Insight Externalization with rich semantics	10.1109/VAST.2010.5652885	http://dx.doi.org/10.1109/VAST.2010.5652885	155	162	5652885	data mining;data visualisation;decision making;information retrieval;problem solving;user interfaces	Click2Annotate;decision making;insight browsing;insight externalization;insight management activity;insight retrieval;problem solving	Automation;Book reviews;Compounds;Context;Mice;Prototypes;Semantics	Annotation;Decision Making;Insight Management;Multidimensional Visualization;Visual Analytics	Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.	Yang Chen;Barlowe, S.;Jing Yang	Dept. of Comput. Sci., UNC Charlotte, Charlotte, NC, USA|c|;;	37600587200;37591128900;37292632600
	VAST	25-26 Oct. 2010	Interactive querying of temporal data using a comic strip metaphor	10.1109/VAST.2010.5652890	http://dx.doi.org/10.1109/VAST.2010.5652890	163	170	5652890	data analysis;data visualisation;pattern recognition;query processing	VizPattern;comic strip metaphor;data analysis;interactive querying;static visualization;temporal data;temporal pattern;visual analysis	Data analysis;Data visualization;Pain;Stomach;Strips;Time series analysis;Visualization	H.3.3 [Information Systems]: Information Search and Retrieval-Query formulation;H.5.2 [Information Interfaces and Presentation]: User Interface-User-centered design	Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.	Jing Jin;Szekely, P.	Inf. Sci. Inst., Univ. of Southern California, Los Angeles, CA, USA|c|;	37600357600;37591247400
	VAST	25-26 Oct. 2010	A closer look at note taking in the co-located collaborative visual analytics process	10.1109/VAST.2010.5652879	http://dx.doi.org/10.1109/VAST.2010.5652879	171	178	5652879	business data processing;data analysis;data visualisation;interactive devices;recording	analysis process;co-located collaborative visual analytics process;collaborative data analysis;collaborative visual analytic tool;large interactive wall;note taking;record keeping;tabletop display	Business;Collaboration;Data visualization;Marketing and sales;Software;Visual analytics	collaboration;history;note taking;provenance;recording;tabletop;wall display	This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.	Mahyar, N.;Sarvghad, A.;Tory, M.	Univ. of Victoria, Victoria, BC, Canada|c|;;	37591344800;37591344300;37275861300
	VAST	25-26 Oct. 2010	An exploratory study of co-located collaborative visual analytics around a tabletop display	10.1109/VAST.2010.5652880	http://dx.doi.org/10.1109/VAST.2010.5652880	179	186	5652880	computer displays;data analysis;data visualisation;groupware;microcomputers;problem solving	collaborative visual analysis;colocated collaboration;digital document;digital tabletop display;interview data;problem solving;system log;visual analytics	Collaboration;Context;Data visualization;Image color analysis;Problem-solving;Video coding;Visual analytics	K.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces	Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.	Isenberg, P.;Fisher, D.;Morris, M.R.;Inkpen, K.	;;;	37591317800;37542391000;37600344900;37562971500
	VAST	25-26 Oct. 2010	Helping users recall their reasoning process	10.1109/VAST.2010.5653598	http://dx.doi.org/10.1109/VAST.2010.5653598	187	194	5653598	data analysis;data mining;data visualisation;inference mechanisms	interaction log;knowledge discovery;memory aid;reasoning process;users recall;visual analysis	Cognition;Data visualization;Encoding;Heating;Interviews;Pharmaceuticals;Visualization	Visual analytics;reasoning process;visualization	The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.	Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	37601288800;37601289000;37606064200;37601287300;37592409400
	VAST	25-26 Oct. 2010	Comparing different levels of interaction constraints for deriving visual problem isomorphs	10.1109/VAST.2010.5653599	http://dx.doi.org/10.1109/VAST.2010.5653599	195	202	5653599	cognition;constraint handling;data analysis;data visualisation;problem solving;psychology	cognitive science;interaction constraints;manual manipulation;number scrabble;problem solving;visual analytics;visual problem isomorphs;visual representations	Cognition;Computers;Games;Problem-solving;Time factors;Visualization	Interaction;Problem Solving;Visual Isomorph	Interaction and manual manipulation have been shown in the cognitive science literature to play a critical role in problem solving. Given different types of interactions or constraints on interactions, a problem can appear to have different degrees of difficulty. While this relationship between interaction and problem solving has been well studied in the cognitive science literatures, the visual analytics community has yet to exploit this understanding for analytical problem solving. In this paper, we hypothesize that constraints on interactions and constraints encoded in visual representations can lead to strategies of varying effectiveness during problem solving. To test our hypothesis, we conducted a user study in which participants were given different levels of interaction constraints when solving a simple math game called Number Scrabble. Number Scrabble is known to have an optimal visual problem isomorph, and the goal of this study is to learn if and how the participants could derive the isomorph and to analyze the strategies that the participants utilize in solving the problem. Our results indicate that constraints on interactions do affect problem solving, and that while the optimal visual isomorph is difficult to derive, certain interaction constraints can lead to a higher chance of deriving the isomorph.	Wenwen Dou;Ziemkiewicz, C.;Harrison, L.;Dong Hyun Jeong;Ryan, R.;Ribarsky, W.;Xiaoyu Wang;Chang, R.	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;;;;	37606064200;37548028800;37546111900;37400451800;37603814100;37300425000;37601069300;37592409400
	VAST	25-26 Oct. 2010	Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction	10.1109/VAST.2010.5653587	http://dx.doi.org/10.1109/VAST.2010.5653587	203	210	5653587	cognition;data analysis;data visualisation;human factors;psychometric testing	extraversion;interactive visualization;menu-driven web table;multiple procedural learning tasks;neuroticism;personal interaction equation;personality factors;psychometric measures;visual analytics interface interaction	Atmospheric measurements;Cognition;Computers;Equations;Particle measurements;Visual analytics	cognition and perception theory;embodied cognition;visual analytics;visualization taxonomies and models	These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.	Green, T.M.;Fisher, Brian	Sch. of Interactive Arts + Technol., Simon Fraser Univ., Surrey, BC, Canada|c|;	37403562900;37267458000
	VAST	25-26 Oct. 2010	Poster: Dynamic time transformation for interpreting clusters of trajectories with space-time cube	10.1109/VAST.2010.5653580	http://dx.doi.org/10.1109/VAST.2010.5653580	213	214	5653580	data visualisation;pattern clustering;visual databases	absolute time references;dynamic time transformation;relative positions;space-time cube;temporal cycles;trajectory clusters;visual interpretation	Clutter;Data visualization;Image color analysis;Tracking;Trajectory;Visual analytics		We propose a set of techniques that support visual interpretation of trajectory clusters by transforming absolute time references into relative positions within temporal cycles or with respect to the starting and/or ending times of the trajectories. We demonstrate the work of the approach on a real data set about individual movement over one year.	Andrienko, G.;Andrienko, N.	;	37283047100;37283047700
	VAST	25-26 Oct. 2010	Interactive visual analysis of multiobjective optimizations	10.1109/VAST.2010.5651694	http://dx.doi.org/10.1109/VAST.2010.5651694	215	216	5651694	data analysis;data visualisation;optimisation	automatic algorithm;data attribute;domain expert;interactive visual analysis;multiobjective optimization;multirun simulation data;multivariate visualization	Context;Data visualization;Engines;Load modeling;Optimization;Visual analytics	H.1.2 [Models and Principles]: User/Machine Systems-Human factors;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Interaction Styles	Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design.	Berger, W.;Piringer, H.	VRVis Res. Center, Vienna, Austria|c|;	37546977900;37282562500
	VAST	25-26 Oct. 2010	Cluster correspondence views for enhanced analysis of SOM displays	10.1109/VAST.2010.5651676	http://dx.doi.org/10.1109/VAST.2010.5651676	217	218	5651676	data analysis;data mining;pattern clustering;self-organising feature maps	SOM displays;grid structure;self-organizing map;visual cluster analysis system;visual mappings	Algorithm design and analysis;Clustering algorithms;Clustering methods;Data visualization;Image color analysis;Trajectory;Visualization	H.4 [Information Systems]: Information Systems Applications;I.3.6 [Computing Methodologies]: Methodology and Techniques	The Self-Organizing Map (SOM) algorithm is a popular and widely used cluster algorithm. Its constraint to organize clusters on a grid structure makes it very amenable to visualization. On the other hand, the grid constraint may lead to reduced cluster accuracy and reliability, compared to other clustering methods not implementing this restriction. We propose a visual cluster analysis system that allows to validate the output of the SOM algorithm by comparison with alternative clustering methods. Specifically, visual mappings overlaying alternative clustering results onto the SOM are proposed. We apply our system on an example data set, and outline main analytical use cases.	Bernard, J.;von Landesberger, T.;Bremm, S.;Schreck, T.	Interactive Graphics Syst. Group, Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;;	37606179600;37586276100;37586274500;37282557600
	VAST	25-26 Oct. 2010	Visualization of temporal relationships within coordinated views	10.1109/VAST.2010.5651617	http://dx.doi.org/10.1109/VAST.2010.5651617	219	220	5651617	command and control systems;constraint handling;data visualisation;decision making;interactive systems;temporal reasoning	command and control;coordinated view;decision maker;interaction method;temporal constraint;temporal display;temporal relationship;visualization method	Cognition;Command and control systems;Decision making;Geospatial analysis;Information filters;Time factors;Visualization	temporal relationships;temporal visualization	In command and control (C2) environments, decision makers must rapidly understand and address key temporal relationships that exist between critical tasks as conditions fluctuate. However, traditional temporal displays, such as mission timelines, fail to support user understanding of and reasoning about critical relationships. We have developed visualization methods to compactly and effectively convey key temporal constraints. In this paper, we present examples of our visualization approach and describe how we are exploring interaction methods within an integrated visualization workspace to support user awareness of temporal constraints.	Dudzic, S.;Godwin, J.A.;Kilgore, R.M.	;;	37586314000;37593027200;37603789200
	VAST	25-26 Oct. 2010	Conveying network features in geospatial battlespace displays	10.1109/VAST.2010.5651192	http://dx.doi.org/10.1109/VAST.2010.5651192	221	222	5651192	data visualisation;geographic information systems;military computing	battlespace network visualization techniques;cross-domain situation awareness;cyber domains;decision-making;geospatial battlespace displays;health information;meta-information;mission planning;modern air operations center;visualization IEEE toolkit;warfighters	Color;Context;Geospatial analysis;Jamming;Planning;Rendering (computer graphics);Visualization		Advanced battlespace network visualization techniques are required within the modern Air Operations Center (AOC) to improve cross-domain situation awareness and to support planning and decision-making. We present a visualization toolkit to address this need that supports the integration of network health and status information and meta-information with other traditional AOC information resources and activities across air, space, and cyber domains. Applications include the development of battlespace visualization technologies that will improve warfighters' decision-making response time and provide enhanced flexibility for mission planning by efficiently revealing affordances for leveraging, disrupting, or enhancing network connectivity.	Godwin, J.A.;Kilgore, R.M.	;	37593027200;37603789200
	VAST	25-26 Oct. 2010	ALIDA: Using machine learning for intent discernment in visual analytics interfaces	10.1109/VAST.2010.5650854	http://dx.doi.org/10.1109/VAST.2010.5650854	223	224	5650854	cognition;data analysis;data visualisation;decision making;human computer interaction;learning (artificial intelligence);multi-agent systems;rendering (computer graphics);transfer functions	ALIDA;active learning intent discerning agent;analytic process;cognition model;decision making;human computer interaction;interactive visualization prototype;machine learning;scientific gateway;transfer function design;visual analytics interface;volume rendering	Cognition;Data visualization;History;Humans;Rendering (computer graphics);Transfer functions;Visual analytics	artificial intelligence;cognition;intent discernment;volume rendering	In this paper, we introduce ALIDA, an Active Learning Intent Discerning Agent for visual analytics interfaces. As users interact with and explore data in a visual analytics environment they are each developing their own unique analytic process. The goal of ALIDA is to observe and record the human-computer interactions and utilize these observations as a means of supporting user exploration; ALIDA does this by using interaction to make decision about user interest. As such, ALIDA is designed to track the decision history (interactions) of a user. This history is then utilized to enhance the user's decision-making process by allowing the user to return to previously visited search states, as well as providing suggestions of other search states that may be of interest based on past exploration modalities. The agent passes these suggestions (or decisions) back to an interactive visualization prototype, and these suggestions are used to guide the user, either by suggesting searches or changes to the visualization view. Current work has tested ALIDA under the exploration of homonyms for users wishing to explore word linkages within a dictionary. Ongoing work includes using ALIDA to guide users in transfer function design for volume rendering within scientific gateways.	Green, T.M.;Maciejewski, R.;DiPaola, S.	;;	37403562900;37396008400;37326092700
	VAST	25-26 Oct. 2010	Enhancing text-based chat with visuals for hazardous weather decision making	10.1109/VAST.2010.5650815	http://dx.doi.org/10.1109/VAST.2010.5650815	225	226	5650815	emergency services;geophysics computing;groupware;information dissemination;meteorological radar;weather forecasting	NWSChat2;National Weather Service forecasters;common shared radar map;hazardous weather decision making;information dissemination;media members;storm tracker;text based chat enhancing;visual chat application;weather emergencies	Communities;Media;Pins;Storms;Visualization;Weather forecasting	Collaboration;coordinated multiple views;emergency response;hazardous weather;instant messaging	We created a visual chat application for use during hazardous weather events. The application, NWSChat2, allows National Weather Service forecasters, media members, and storm trackers to communicate with each other, basing their conversation on a common shared radar map of the storm. Users can additionally annotate the map with `pins' or draw notes with a stylus. These annotations are automatically shared with all other users. The collaborative nature of NWSChat2 makes it well-suited for disseminating information to all users during weather emergencies.	Gutman, M.;Eosco, G.;Zappa, M.;Weaver, C.	Sch. of Comput. Sci., Univ. of Oklahoma, Norman, OK, USA|c|;;;	37587979100;37594341400;37594207000;37564883300
	VAST	25-26 Oct. 2010	Visual analysis of frequent patterns in large time series	10.1109/VAST.2010.5650766	http://dx.doi.org/10.1109/VAST.2010.5650766	227	228	5650766	data analysis;data mining;data visualisation;pattern recognition;time series	colored rectangle;data center cooling;motif distortion;multivariate time series;oil well production;pattern detection;real world data set;temporal data mining;visual analysis;visual analytics	Data mining;Layout;Merging;Petroleum;Production;Time series analysis;Visual analytics		The detection of previously unknown, frequently occurring patterns in time series, often called motifs, has been recognized as an important task. To find these motifs, we use an advanced temporal data mining algorithm. Since our algorithm usually finds hundreds of motifs, we need to analyze and access the discovered motifs. For this purpose, we introduce three novel visual analytics methods: (1) motif layout, using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs in a multivariate time series, (2) motif distortion, for enlarging or shrinking motifs as appropriate for easy analysis and (3) motif merging, to combine a number of identical adjacent motif instances without cluttering the display. We have applied and evaluated our methods using two real-world data sets: data center cooling and oil well production.	Hao, M.C.;Marwah, M.;Janetzko, H.;Keim, D.A.;Sharma, R.;Patnaik, D.;Ramakrishnan, N.	;;;;;;	37274264300;37419093700;37594026300;37283138700;37276219200;37593035500;37273204200
	VAST	25-26 Oct. 2010	Visually representing geo-temporal differences	10.1109/VAST.2010.5652951	http://dx.doi.org/10.1109/VAST.2010.5652951	229	230	5652951	data structures;data visualisation;geographic information systems	GTdiff;geo-temporal differences;geospatial-temporal elements;pair-wise differences;visual approach;visual representation	Electronic mail;Geography;Geospatial analysis;Image color analysis;Java;Visualization	H.5.2 [Information Systems]: Information Interfaces and Presentation-User Interfaces;I.3.6 [Computing Methodologies]: Computer Graphics-Methodology and Techniques	Data sets that contain geospatial and temporal elements can be challenging to analyze. In particular, it can be difficult to determine how the data have changed over spatial and temporal ranges. In this poster, we present a visual approach for representing the pair-wise differences between geographically and temporally binned data. In addition to providing a novel method for visualizing such geo-temporal differences, GTdiff provides a high degree of interactivity that supports the exploration and analysis of the data.	Hoeber, O.;Wilson, G.;Harding, S.;Enguehard, R.;Devillers, R.	;;;;	37565349100;37595914500;37266745700;37591138200;37570903200
	VAST	25-26 Oct. 2010	A continuous analysis process between desktop and collaborative visual analytics environments	10.1109/VAST.2010.5652958	http://dx.doi.org/10.1109/VAST.2010.5652958	231	232	5652958	data visualisation;groupware;interactive systems	collaborative visual analytics;continuous analysis process;intelligence analysts;interactive visual tools;mirroring system;single user desktop system	Collaboration;Collaborative work;Mice;Rendering (computer graphics);Switches;Visual analytics		Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment.	Dong Hyun Jeong;Suma, E.;Butkiewicz, T.;Ribarsky, W.;Chang, R.	Univ. of the District of Columbia, Washington, DC, USA|c|;;;;	37400451800;37297278600;37591215700;37300425000;37592409400
	VAST	25-26 Oct. 2010	EmailTime: Visual analytics of emails	10.1109/VAST.2010.5652968	http://dx.doi.org/10.1109/VAST.2010.5652968	233	234	5652968	electronic mail	EmailTime;communication patterns;email correspondence;email dataset;interactively portrays;interpersonal networks;visual analysis;visual analytics	Color;Electronic mail;Frequency measurement;Receivers;Switches;Visual analytics	Email;Email Correspondents;EmailTime;Enron;Visual Analysis	Although the discovery and analysis of communication patterns in large and complex email datasets are difficult tasks, they can be a valuable source of information. This paper presents EmailTime's capabilities through several examples. EmailTime is a visual analysis of email correspondence patterns over the course of time that interactively portrays personal and interpersonal networks using the correspondence in the email dataset. We suggest that integrating both statistics and visualizations in order to display information about the email datasets may simplify its evaluation.	Joorabchi, M.E.;Ji-Dong Yim;Shaw, C.D.	;;	37598481900;37605674700;37358198200
	VAST	25-26 Oct. 2010	Enron case study: Analysis of email behavior using EmailTime	10.1109/VAST.2010.5649905	http://dx.doi.org/10.1109/VAST.2010.5649905	235	236	5649905	behavioural sciences computing;data mining;electronic mail;organisational aspects;user interfaces	EmailTime;Enron;email;user behavior	Benchmark testing;Electronic mail;Indexes;Receivers;Time measurement;Visualization	Case Study;Email;EmailTime;Enron;Visual Analysis	This paper presents a case study with Enron email dataset to explore the behaviors of email users within different organizational positions. We defined email behavior as the email activity level of people regarding a series of measured metrics e.g. sent and received emails, numbers of email addresses, etc. These metrics were calculated through EmailTime, a visual analysis tool of email correspondence over the course of time. Results showed specific patterns in the email datasets of different organizational positions.	Joorabchi, M.E.;Ji-Dong Yim;Joorabchi, M.E.;Shaw, C.D.	Simon Fraser Univ., Burnaby, BC, Canada|c|;;;	37598481900;37605674700;37598482000;37358198200
	VAST	25-26 Oct. 2010	Large-scale neuroanatomical visualization using a manifold embedding approach	10.1109/VAST.2010.5652532	http://dx.doi.org/10.1109/VAST.2010.5652532	237	238	5652532	data mining;data visualisation;image resolution;magnetic resonance imaging;medical image processing;neurophysiology;solid modelling	Large scale performance;MRI image;data interactive visualization;data mining;data processing;data projection scheme;data storage availability;graphical processing;manifold embedding approach;multiresolution representation;neuroanatomical visualization;parallelized pipeline workflow;remote server;scale complexity;specific atlas space;standard format;triangular mesh cortical surface;user defined search criteria;visual query interface	Brain;Data visualization;Face;Feature extraction;Informatics;Neuroimaging;Three dimensional displays	I.3 [Computer Graphics]: Three-Dimensional Graphics and Realism;I.3.3 [Viewing Algorithms];I.3.8 [Applications]	We present a unified framework for data processing, mining and interactive visualization of large-scale neuroanatomical databases. The input data is assumed to lie in a specific atlas space, or simply exist as a separate collection. Users can specify their own atlas for comparative analyses. The original data exist as MRI images in standard formats. It is uploaded to a remote server and processed offline by a parallelized pipeline workflow. This workflow transforms the data to represent it as both volumetric and triangular mesh cortical surfaces. We use multiresolution representations to scale complexity to data storage availability as well as graphical processing performance. Our workflow implements predefined metrics for clustering and classification, and data projection schemes to aid in visualization. Additionally the system provides a visual query interface for performing selection requests based on user-defined search criteria.	Joshi, S.H.;Bowman, I.;Van Horn, J.D.	Dept. of Neurology, Univ. of California, Los Angeles, CA, USA|c|;;	37288595800;37603001800;37589311500
	VAST	25-26 Oct. 2010	Combining statistical independence testing, visual attribute selection and automated analysis to find relevant attributes for classification	10.1109/VAST.2010.5654445	http://dx.doi.org/10.1109/VAST.2010.5654445	239	240	5654445	attribute grammars;data analysis;pattern classification	attributes subset finding;automated analysis;classifier function;iterative strategy;statistical independence testing;visual attribute selection	Clustering methods;Data visualization;Electronic mail;Testing;USA Councils;Visualization	Data Clustering;Data Filtering;Dimensionality Reduction;High-Dimensional Data	We present an iterative strategy for finding a relevant subset of attributes for the purpose of classification in high-dimensional, heterogeneous data sets. The attribute subset is used for the construction of a classifier function. In order to cope with the challenge of scalability, the analysis is split into an overview of all attributes and a detailed analysis of small groups of attributes. The overview provides generic information on statistical dependencies between attributes. With this information the user can select groups of attributes and an analytical method for their detailed analysis. The detailed analysis involves the identification of redundant attributes (via classification or regression) and the creation of summarizing attributes (via clustering or dimension reduction). Our strategy does not prescribe specific analytical methods. Instead, we recursively combine the results of different methods to find or generate a subset of attributes to use for classification.	May, T.;Davey, J.;Kohlhammer, J.	Fraunhofer Inst. for Comput. Graphics Res., Darmstadt, Germany|c|;;	37603783600;37603822500;37449689200
	VAST	25-26 Oct. 2010	Visual tools for dynamic analysis of complex situations	10.1109/VAST.2010.5654451	http://dx.doi.org/10.1109/VAST.2010.5654451	241	242	5654451	computer animation;data visualisation;interactive systems	dynamic complex situation analysis;information visualization;interactive interface;line graph animation;simulation framework;surface graph animation;visual analysis;visual tools	Data models;Image color analysis;Psychology;Radio frequency;Synchronization;Visualization	2D1/2 animation;Information visualization;interaction;line & surface graph animation;synchronization	This paper presents an interactive interface synchronized with a simulation framework for exploring complex scenarios. This interface exploits visual analysis for facilitating the understanding of complex situation by human users.	Mokhtari, M.;Boivin, E.;Laurendeau, D.;Girardin, M.	Syst. of Syst. Sect., Defence R&D Canada, Quebec City, QC, Canada|c|;;;	37593942300;37283610000;37269074000;37593467200
	VAST	25-26 Oct. 2010	Data representation and exploration with Geometric Wavelets	10.1109/VAST.2010.5653822	http://dx.doi.org/10.1109/VAST.2010.5653822	243	244	5653822	computational geometry;data visualisation	anomaly detection;data compression;data representation;geometric wavelets;interactive visualization;speeding methods development	Data visualization;Dictionaries;Graphical user interfaces;Manifolds;Pixel;Principal component analysis;Wavelet analysis	H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphical user interfaces (GUI);I.5.1 [Pattern Recognition]: Models-Geometric	Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development.	Monson, E.E.;Guangliang Chen;Brady, R.;Maggioni, M.	;;;	37597529800;37403718100;38179702200;37395814700
	VAST	25-26 Oct. 2010	Poster: Translating cross-filtered queries into questions	10.1109/VAST.2010.5650251	http://dx.doi.org/10.1109/VAST.2010.5650251	245	246	5650251	data analysis;data visualisation;information filtering;natural languages;query processing;question answering (information retrieval)	Internet movie database;coordinated multiple views;cross-filtered visualization;interaction sequences;learning;multidimensional data;natural language;query-to-question translation;query-to-question user interface;visual analysis tools;visual exploration;visual log;visual state interpretation	Data visualization;Encoding;Internet;Motion pictures;Natural languages;Visualization;Weaving	Coordinated multiple views;cross-filtered queries;interaction states;natural language generation;visual provenance	Complex combinations of coordinated multiple views are increasingly used to design tools for highly interactive visual exploration and analysis of multidimensional data. While complex coordination patterns provide substantial utility through expressive querying, they also exhibit usability problems for users when learning required interaction sequences, recalling past queries, and interpreting visual states. As visual analysis tools grow more sophisticated, there is a growing need to make them more understandable as well. Our long-term goal is to exploit natural language familiarity and literacy to directly facilitate individual and collaborative use of visual analysis tools. In this poster, we present work in progress on an automatically generated query-to-question user interface to translate interactive states during visual analysis into an accompanying visual log of formatted text. Our effort currently focuses on a symmetric and thus relatively simple coordination pattern: cross-filtered views. We describe our current thinking about query-to-question translation in a typical cross-filtered visualization of movies, people, and genres in the Internet Movie Database.	Nafari, M.;Weaver, C.	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|;	37593329400;37564883300
	VAST	25-26 Oct. 2010	ProDV &#x2014; A case study in delivering visual analytics	10.1109/VAST.2010.5650219	http://dx.doi.org/10.1109/VAST.2010.5650219	247	248	5650219	data analysis;data visualisation;interactive systems;software architecture;user interfaces;visual programming	ProDV;collaborative analysis;performance metrics;visual analytics system;visual programming	Analytical models;Communities;Data models;Data visualization;Training;Visual analytics	Visualization system and toolkit design	We present a custom visual analytics system developed in conjunction with the test and evaluation community of the US Army. We designed and implemented a visual programming environment for configuring a variety of interactive visual analysis capabilities. Our abstraction of the visualization process is based on insights gained from interviews conducted with expert users. We show that this model allowed analysts to implement multiple visual analysis capabilities for network performance, anomalous sensor activity, and engagement results. Long-term interaction with expert users led to development of several custom visual analysis techniques. We have conducted training sessions with expert users, and are working to evaluate the success of our work based on performance metrics captured in a semi-automated fashion during these training sessions. We have also integrated collaborative analysis features such as annotations and shared content.	Overby, D.;Keyser, J.;Wall, J.	Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX, USA|c|;;	37586886600;37282588300;38225331100
	VAST	25-26 Oct. 2010	A Visual Analytics approach to identifying protein structural constraints	10.1109/VAST.2010.5650199	http://dx.doi.org/10.1109/VAST.2010.5650199	249	250	5650199	bioinformatics;data analysis;data visualisation;molecular biophysics;proteins	MAVL;StickWRLD;correlated protein mutations;fine grained computational simulation;pattern visualization;protein folding;protein structures;protein synthesis;statistical protein sequence information analysis;vector subtuples;visual analytics	Clouds;Correlation;Protein engineering;Protein sequence;Visual analytics	Bioinformatics;Clustering Classification and Association Rules;Interactive Data Exploration	Predicting protein structures has long been a grand-challenge problem. Fine-grained computational simulation of folding events from a protein's synthesis to its final stable structure remains computationally intractable. Therefore, methods which derive constraints from other sources are attractive. To date, constraints derived from known structures have proven to be highly successful. However, these cannot be applied to molecules with no identifiable neighbors having already-determined structures. For such molecules, structural constraints must be derived in other ways. One popular approach has been the statistical analysis of large families of proteins, with the hope that residues that “change together” (co-evolve) imply that those residues are in contact. Unfortunately, despite repeated attempts to use this data to deduce structural constraints, this approach has met with minimal success. The consensus of current literature concludes that there is simply too little information contained within the correlated mutations of many protein families to reliably and generally predict structural constraints. Recent work in my laboratory challenges this conclusion. For some time we have been developing methods (MAVL/StickWRLD) to visualize the pattern of co-evolved mutations within sequence families. While our analysis of individual correlations agrees with the literature consensus, we have recently discovered that the visualized pattern of correlations is highly suggestive of structural relationships. In our preliminary test cases, human researchers can unambiguously determine many positive structural constraints by visual analysis of statistical sequence information alone, often with no training on interpretation of the visualization results. Herein we report the visualization design that supports this Visual Analytics approach to identifying high-confidence hypotheses about protein folding from protein sequence, and illustrate preliminary results from th- - is research. Our approach entails a higher-dimensional extension of parallel coordinates which illuminates distant shared sub-tuples of the vectors representing each protein sequence when these sub-tuples occur with an over abundance compared to expectations. It simultaneously eliminates all representations of tuples which occur with frequency near the expected norm. The result is a minimally-occluded representation of outlier, and only outlier co-occurrences within the sequence families.	Ray, W.C.	Res. Inst., Ohio State Univ. Biophys. Program, Columbus, OH, USA|c|	37270070300
	VAST	25-26 Oct. 2010	A radial visualization tool for depicting hierarchically structured video content	10.1109/VAST.2010.5650177	http://dx.doi.org/10.1109/VAST.2010.5650177	251	252	5650177	data analysis;data structures;data visualisation;feature extraction;video retrieval	automatic video segmentation technique;depicting hierarchically structured video content;key frame extraction;radial visualization tool;visual analysis	Data visualization;Detectors;Image segmentation;Layout;Motion segmentation;Video sequences;Visualization		The visual analysis of video content is an important research topic due to the huge amount of video data that is generated every day. Annotating this data will become a major problem since the amount of videos further increases. With this work we introduce a system that combines a visualization tool with automatic video segmentation techniques and a characteristic key-frame extraction. A summary of the content of a whole video in one view is realized. Furthermore, the user can interactively browse through the video via our visualization interface to get more detailed information. The system is adapted to two application scenarios and a third application is discussed for future work.	Ruppert, T.;Kohlhammer, J.	Fraunhofer Inst. for Comput. Graphics Res. (IGD), Darmstadt, Germany|c|;	37593423500;37449689200
	VAST	25-26 Oct. 2010	Adapting Daniel and Wood&#39;s modeling approach to interactive visual analytics	10.1109/VAST.2010.5649831	http://dx.doi.org/10.1109/VAST.2010.5649831	253	254	5649831	data analysis;data visualisation;graphical user interfaces	human-in-the-loop model;interactive linear modeling system;interactive visual analytics;visual interface	Adaptation model;Analytical models;Data models;Data visualization;Mathematical model;Predictive models;Visual analytics	H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphical user interfaces	This poster describes our progress in developing an interactive linear modeling system that supports the modeling approach described by Daniel and Wood. Our visual interface permits analysts to build sets of possible models and then creates appropriate visualizations to permit human-in-the-loop model comparison and selection.	Talbot, J.;Hanrahan, P.	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;	37604514900;37349803800
	VAST	25-26 Oct. 2010	VAST 2010 Challenge: Arms dealings and pandemics	10.1109/VAST.2010.5649054	http://dx.doi.org/10.1109/VAST.2010.5649054	263	264	5649054	bioinformatics;data analysis;medical administrative data processing;weapons	VAST 2010 challenge;arms dealings;bioinformatics;dangerous viral mutations;death records;genetic data;grand challenge;hospital admission;intelligence analysis;interactive visualizations;minichallenge;pandemics;text reports		contest;evaluation;human information interaction;metrics;sense making;visual analytics		Grinstein, G.;Konecni, S.;Scholtz, J.;Whiting, M.;Plaisant, C.	Univ. of Massachusetts Lowell, Lowell, MA, USA|c|;;;;	37360588500;37590124000;37283026800;37268671300;37357067600
