Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis+SciVis	Nov.-Dec. 2009	ABySS-Explorer: Visualizing Genome Sequence Assemblies	10.1109/TVCG.2009.116	http://dx.doi.org/10.1109/TVCG.2009.116	881	888	5290690	DNA;bioinformatics;data visualisation;genomics;interactive systems	ABySS-Explorer;DNA sequence data;bioinformatics visualization;genome assembly process;genome sequence assemblies;genome sequencing projects;interactive graph display;pen-and-paper based analysis tasks;user feedback;visualization tools	Assembly;Bioinformatics;Data visualization;Displays;Encoding;Feedback;Genomics;Inspection;Large-scale systems;Sequences	Bioinformatics visualization;DNA sequence;design study;genome assembly	One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.	Nielsen, C.B.;Jackman, S.D.;Birol, I.;Jones, S.J.M.	Genome Sci. Centre, BC Cancer Agency, Vancouver, BC, Canada|c|;;;	38112559500;38108815200;37278695500;37570599800
	InfoVis+SciVis	Nov.-Dec. 2009	Constructing Overview + Detail Dendrogram-Matrix Views	10.1109/TVCG.2009.130	http://dx.doi.org/10.1109/TVCG.2009.130	889	896	5290691	data structures;matrix algebra;pattern clustering	clustering hierarchy;data abstraction quality;data exploration;dendrogram-matrix views;detail view dendrogram;overview dendrogram;pattern identification;reorderable matrix	Binary trees;Cervical cancer;Data mining;Data visualization;Demography;Displays;Geography;Multidimensional systems;Scalability;Statistics	Dendrogram;compound graphs;data abstraction quality metrics;hierarchical clusters;reorderable matrix	A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.	Jin Chen;MacEachren, A.M.;Peuquet, D.J.	Dept. of Geogr., Pennsylvania State Univ., University Park, PA, USA|c|;;	37859000800;37374699000;37830095400
	InfoVis+SciVis	Nov.-Dec. 2009	MizBee: A Multiscale Synteny Browser	10.1109/TVCG.2009.167	http://dx.doi.org/10.1109/TVCG.2009.167	897	904	5290692	biology computing;data structures;data visualisation;genomics	MizBee;biological data abstraction;chromosome;comparative genomics;data visualization;dsyntenic blocks;genome;multiscale synteny browser	Bioinformatics;Biological cells;Biological information theory;Data analysis;Data visualization;Encoding;Evolution (biology);Genomics;Marine animals;Taxonomy	Information visualization;bioinformatics;design study;synteny.	In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.	Meyer, M.;Munzner, T.;Pfister, H.	Harvard Univ., Cambridge, MA, USA|c|;;	37564728700;37349490300;37275698100
	InfoVis+SciVis	Nov.-Dec. 2009	GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories	10.1109/TVCG.2009.146	http://dx.doi.org/10.1109/TVCG.2009.146	905	912	5290693	Internet;biology computing;data structures;genetics;user interfaces	GeneShelf;Web-based visual interface;bar charts;large gene expression time-series data repositories;public databases;static data representations	Bioinformatics;Databases;Displays;Gene expression;Genetics;Injuries;Mice;Rats;Spinal cord;Time series analysis	animation;augmented timeline;bioinformatics visualization;gene expression profiling;zoomable grid	A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.	Bohyoung Kim;Bongshin Lee;Knoblach, S.;Hoffman, E.;Jinwook Seo	Seoul Nat. Univ., Seoul, South Korea|c|;;;;	37594632900;37293389400;38108809200;37272368200;37422552700
	InfoVis+SciVis	Nov.-Dec. 2009	Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps	10.1109/TVCG.2009.182	http://dx.doi.org/10.1109/TVCG.2009.182	913	920	5290694	biology computing;biosensors;colour graphics;data loggers;data visualisation	Alzheimer transgenic mice;colors intensity;distinct colors;geographic monitoring;growth ring maps;hierarchical clustering;map distortions;mobile phone capacity planning;multidimensional scaling;nonoverlapping pixels;packet tracing;sensor logs spatiotemporal analysis;spatial data;visualization technique	Animal behavior;Data analysis;Data mining;Data visualization;Humans;Mice;Monitoring;Multidimensional systems;Navigation;Spatiotemporal phenomena	animal behavior;dense pixel displays;spatiotemporal visualization;visual analytics	Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.	Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.	Univ. of Konstanz, Konstanz, Germany|c|;;;	37392085400;37392086200;37594026300;37283138700
	InfoVis+SciVis	Nov.-Dec. 2009	A Nested Model for Visualization Design and Validation	10.1109/TVCG.2009.111	http://dx.doi.org/10.1109/TVCG.2009.111	921	928	5290695	data visualisation	domain characterization;nested process model;visual encoding;visualization design	Algorithm design and analysis;Concrete;Coupled mode analysis;Data visualization;Diseases;Electronic mail;Encoding;Process design;Vocabulary;Writing	Models;design;evaluation.;frameworks	We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.	Munzner, T.	Univ. of British Columbia, Vancouver, BC, Canada|c|	37349490300
	InfoVis+SciVis	Nov.-Dec. 2009	Conjunctive Visual Forms	10.1109/TVCG.2009.129	http://dx.doi.org/10.1109/TVCG.2009.129	929	936	5290696	data visualisation;query processing	boolean logic;conjunctive visual form model;heterogeneous multidimensional queries;multidimensional data visual exploration;visual representation	Boolean functions;Computer Society;Computer simulation;Data mining;Data visualization;Instruments;Intelligent sensors;Multidimensional systems;Predictive models;Visual analytics	Boolean query;brushing;conjunctive normal form;exploratory visualization;multiple views;visual abstraction.	Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.	Weaver, C.	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|	37564883300
	InfoVis+SciVis	Nov.-Dec. 2009	Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations	10.1109/TVCG.2009.151	http://dx.doi.org/10.1109/TVCG.2009.151	937	944	5290697	biology computing;data visualisation;graph theory;interactive systems	NAViGaTOR;biological networks;interaction techniques;interactive graph visualization;lasso selection;network visualizations;selecting subgraphs;software package;usability study	Bioinformatics;Biology computing;Displays;Keyboards;Layout;Mice;Navigation;Software packages;Usability;Visualization	biological networks;hotbox;interactive graph drawing;marking menus;network layout;radial menus	We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.	McGuffin, M.J.;Jurisica, I.	Ecole de Technol. Super., Montreal, QC, Canada|c|;	37403234300;37353445900
	InfoVis+SciVis	Nov.-Dec. 2009	ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity	10.1109/TVCG.2009.117	http://dx.doi.org/10.1109/TVCG.2009.117	945	952	5290698	computational complexity;data mining;graph theory	ActiviTree;Web searching;algorithmic search mechanisms;complex event-based temporal data;computational complexity;event-based data;graph similarity;interactive visual data mining;interactive visual sequence exploration	Computational complexity;Data mining;Frequency;History;Information analysis;Marketing and sales;Medical services;Medical treatment;Predictive models;Urban planning	event-based data;graph similarity;interactive visual exploration;node similarity;sequence identification	The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.	Vrotsou, K.;Johansson, J.;Cooper, M.	Linkoping Univ., Linkoping, Sweden|c|;;	37939017400;37273045500;37268765000
	InfoVis+SciVis	Nov.-Dec. 2009	&#x0201C;Search, Show Context, Expand on Demand&#x0201D;: Supporting Large Graph Exploration with Degree-of-Interest	10.1109/TVCG.2009.108	http://dx.doi.org/10.1109/TVCG.2009.108	953	960	5290699	citation analysis;data visualisation;graph theory;mathematics computing	contextual subgraph;dense online database;graph visualization;immediate context graph;large graph database;large graph exploration;legal citation	Context modeling;Data analysis;Data visualization;Hardware;Information analysis;Law;Legal factors;Mobile computing;Tree graphs;Visual databases	Graph visualization;degree of interest;focus+context;legal citation networks;network visualization	A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.	van Ham, F.;Perer, A.	IBM-ILOG Res., Gentilly, France|c|;	37326291000;37294938400
	InfoVis+SciVis	Nov.-Dec. 2009	A Comparison of User-Generated and Automatic Graph Layouts	10.1109/TVCG.2009.109	http://dx.doi.org/10.1109/TVCG.2009.109	961	968	5290700	graph theory;social networking (online);user interfaces	automatic graph layouts;circular automatic layouts;desktop computer;mouse interaction;multitouch interaction;orthogonal automatic layouts;physics-based layout;tabletop display;user-generated layouts	Algorithm design and analysis;Automatic control;Computer displays;Design optimization;Human factors;Mice;Social network services;Sorting	Graph layout;automatic layout algorithms;graph-drawing aesthetics;network layout;user-generated layout	The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.	Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.	;;;;;;	37326161000;37293389400;37542391000;38108819900;37591317800;37448060300;37419565900
	InfoVis+SciVis	Nov.-Dec. 2009	Smooth Graphs for Visual Exploration of Higher-Order State Transitions	10.1109/TVCG.2009.181	http://dx.doi.org/10.1109/TVCG.2009.181	969	976	5290701	biology computing;graph theory;splines (mathematics);time series	biological data;higher-order state transitions;large observational time series;smooth graphs;splines;state sequences;state-graph exploration methods	Clustering algorithms;Data visualization;Frequency	Biological data;Graph drawing;State transitions;Time series	In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.	Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.	Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;	37550793100;37373834100;38110391600;37335785800;37267247900;37295045800
	InfoVis+SciVis	Nov.-Dec. 2009	Configuring Hierarchical Layouts to Address Research Questions	10.1109/TVCG.2009.128	http://dx.doi.org/10.1109/TVCG.2009.128	977	984	5290702	data visualisation;geography;temporal databases;visual databases	cognitive load;dimensional stacking;hierarchical displays;hierarchical layouts;multivariate datasets;research questions;space-filling rectangular layouts	Containers;Displays;Facial animation;Graphics;Guidelines;Layout;Marketing and sales;Shape;Stacking;Visualization	Geovisualization;exploratory;guidelines;hierarchical;layout;notation.	We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.	Slingsby, A.;Dykes, J.;Wood, J.	Dept. of Inf. Sci., City Univ. London, London, UK|c|;;	37590960700;37605079900;37399045100
	InfoVis+SciVis	Nov.-Dec. 2009	Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos	10.1109/TVCG.2009.201	http://dx.doi.org/10.1109/TVCG.2009.201	985	992	5290703	Galois fields;data analysis;data visualisation;human computer interaction;indexing;social networking (online)	Hasse diagram;content fusion process;eliciting relations;formal concept analysis;indexing new photos;information visualization;object Galois sub-hierarchy;social photos;visualization strategy	Digital cameras;Displays;Facebook;Indexing;Navigation;Scalability;Social network services;Tagging;Testing;Visualization	Galois sub-hierarchy.;Hasse Diagram;Information visualization;formal concept analysis;indexation;social photos	Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.	Crampes, M.;de Oliveira-Kumar, J.;Ranwez, S.;Villerd, J.	LGI2P/EMA Res. Center, France|c|;;;	38108840900;38108840700;38108835500;37697469600
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics	10.1109/TVCG.2009.153	http://dx.doi.org/10.1109/TVCG.2009.153	993	1000	5290704	data reduction;data visualisation;interactive systems	interactive dimensionality reduction;multivariate data sets;multivariate visualization technique;quality metrics;user-defined combinations	Data analysis;Data visualization;Displays;Humans;Lenses;Monitoring;Product development;Scattering;Weight control	Information Visualization;Multidimensional Scaling;Parallel Coordinates;Scatterplots	Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.	Johansson, S.;Johansson, J.	Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden|c|;	37924876400;37273045500
	InfoVis+SciVis	Nov.-Dec. 2009	Scattering Points in Parallel Coordinates	10.1109/TVCG.2009.179	http://dx.doi.org/10.1109/TVCG.2009.179	1001	1008	5290705	data visualisation	GPU;data selection;data visualization;dimensional incremental multidimensional scaling;multidimensional scaling;parallel coordinates;scattering points;visual analysis tasks	Acceleration;Concurrent computing;Data visualization;Explosions;Interference;Multidimensional systems;Performance analysis;Scattering;System performance	Dimensionality reduction;interactivity;quality metrics;variable ordering.	In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.	Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu	Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;;	37403856700;37411096400;37397293900;37405368200;37272637300
	InfoVis+SciVis	Nov.-Dec. 2009	Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations	10.1109/TVCG.2009.122	http://dx.doi.org/10.1109/TVCG.2009.122	1009	1016	5290706	data visualisation;set theory	Bubble sets;data relationship;data sets;data visualization;isocontours;primary data relation;set cluster continuity;set relation	Air conditioning;Cognitive science;Data visualization;Scattering;Social network services;Tree graphs	clustering;graph visualization;spatial layout;tree visualization	While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.	Collins, C.;Penn, G.;Carpendale, S.	Univ. of Toronto, Toronto, ON, Canada|c|;;	37669874100;37830217600;37285000100
	InfoVis+SciVis	Nov.-Dec. 2009	FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries	10.1109/TVCG.2009.145	http://dx.doi.org/10.1109/TVCG.2009.145	1017	1024	5290707	air traffic;data visualisation;query processing	FromDaDy;aircraft trajectories;iterative queries;multidimensional data exploration;pick and drop operation;trajectory visualization tool;visual analysis	Aerospace control;Aerospace safety;Air safety;Air traffic control;Aircraft;Data mining;Data visualization;Multidimensional systems;Railway safety;Uncertainty	direct manipulation;iterative exploration;trajectories;visualization	When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.	Hurter, C.;Tissoires, B.;Conversy, S.	DSNA, DTI R&D, ENAC, Toulouse, France|c|;;	38017336200;38108818800;38017080200
	InfoVis+SciVis	Nov.-Dec. 2009	SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data	10.1109/TVCG.2009.180	http://dx.doi.org/10.1109/TVCG.2009.180	1025	1032	5290708	data analysis;data visualisation;time series;travel industry	SellTrend;airline travel purchase requests;categorical event sequences;historical trend analysis;inter-attribute visual analysis;multi-variate temporal event sequences;temporal transaction data analysis;time series visualization	Books;Cities and towns;Companies;Data analysis;Data visualization;Failure analysis;Feedback;Information analysis;Logistics;Time series analysis	categorical data;information visualization;investigative analysis;multiple attributes;multiple views;time series data;transaction analysis	We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.	Zhicheng Liu;Stasko, J.;Sullivan, T.	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	37592993600;37267736900;38106606100
	InfoVis+SciVis	Nov.-Dec. 2009	Comparing Dot and Landscape Spatializations for Visual Memory Differences	10.1109/TVCG.2009.127	http://dx.doi.org/10.1109/TVCG.2009.127	1033	1040	5290709	data visualisation;document handling	2D landscapes;3D landscapes;document collections;dot displays;dot spatializations;geographic metaphor;landscape spatializations;nonspatial data;spatialization displays;spatialization interfaces;visual memory differences	Automobiles;Data visualization;Design methodology;Psychology;Software systems;Surface fitting;Surface topography;Three dimensional displays;Two dimensional displays;Uncertainty	Information interfaces and presentation;evaluation / methodology;landscape visualization.;screen design;software psychology;user / machine systems	Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.	Tory, M.;Swindells, C.;Dreezer, R.	Univ. of Victoria, Victoria, BC, Canada|c|;;	37275861300;37267462600;38108876200
	InfoVis+SciVis	Nov.-Dec. 2009	Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data	10.1109/TVCG.2009.143	http://dx.doi.org/10.1109/TVCG.2009.143	1041	1048	5290710	cartography;data visualisation;user interfaces	county-to-county migration data;geographic space;integrated interactive visualization framework;interactive flow mapping;large spatial interaction data;multivariate clustering;multivariate visualization;spatially constrained graph partitioning method;weighted location-to-location network	Data mining;Data visualization;Decision making;Demography;Diseases;Earth;Humans;Multidimensional systems;Transportation;Urban planning	contiguity constraints;coordinated views;data mining;flow mapping;graph partitioning;hierarchical clustering;multidimensional visualization;spatial interaction	Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.	Diansheng Guo	Dept. of Geogr., Univ. of South Carolina, Columbia, SC, USA|c|	37669399300
	InfoVis+SciVis	Nov.-Dec. 2009	Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison	10.1109/TVCG.2009.187	http://dx.doi.org/10.1109/TVCG.2009.187	1049	1056	5290711	data visualisation;human computer interaction	interactive visualization technique;temporal categorical searching;temporal ordering;temporal summaries	Aggregates;Collaborative work;Data analysis;Data visualization;Displays;Event detection;Filters;History;Performance analysis;Springs	Human-computer interaction;Information Visualization;Interaction design;temporal categorical data visualization	When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records.	Wang, T.D.;Plaisant, C.;Spring, N.;Roseman, D.;Marchand, G.;Mukherjee, V.;Smith, M.	Dept. of Comput. Sci., Univ. of Maryland at Coll. Park, College Park, MD, USA|c|;;;;;;	38006054000;37283026800;38180636700;38113224400;38113939800;38111007700;37654306800
	InfoVis+SciVis	Nov.-Dec. 2009	ResultMaps: Visualization for Search Interfaces	10.1109/TVCG.2009.176	http://dx.doi.org/10.1109/TVCG.2009.176	1057	1064	5290712	data visualisation;digital libraries;query processing;search engines;trees (mathematics);user interfaces	ResultMap system;digital repositories;hierarchical treemap representations;online search interfaces;query string-driven digital library search engines;repository search visualization	Visualization	Treemap;digital library;digital repository;evaluation;infovis;search engine;search visualization;user studies	Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.	Clarkson, E.;Desai, K.;Foley, J.D.	Georgia Tech, Atlanta, GA, USA|c|;;	37296656400;38101559100;37286177900
	InfoVis+SciVis	Nov.-Dec. 2009	Lark: Coordinating Co-located Collaboration with Information Visualization	10.1109/TVCG.2009.162	http://dx.doi.org/10.1109/TVCG.2009.162	1065	1072	5290713	data analysis;data visualisation;touch sensitive screens	Lark;colocated collaboration;data analysis;information visualization;integrated meta-visualization;multitouch displays;scoped interaction;spatial flexibility;temporal flexibility	Collaboration;Collaborative work;Concurrent computing;Data analysis;Data visualization;Displays;Information analysis;Pipelines;Switches	Co-located work;Collaboration;Coordination;Information visualization;Meta-visualization;Workspace awareness	Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.	Tobiasz, M.;Isenberg, P.;Carpendale, S.	Univ. of Calgary, Calgary, AB, Canada|c|;;	37680420900;37591317800;37285000100
	InfoVis+SciVis	Nov.-Dec. 2009	The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation	10.1109/TVCG.2009.188	http://dx.doi.org/10.1109/TVCG.2009.188	1073	1080	5290714	data analysis;data visualisation;statistical analysis	data analysis;group annotation;knowledge sharing;statistical analysis;suboptimal visualization;synchronous collaborative information visualization;synchronous group knowledge work	Collaboration;Collaborative work;Data analysis;Data visualization;Information analysis;Knowledge management;Optimal control;Particle measurements;Productivity;Statistical analysis	Collaborative and Distributed Visualization;Laboratory Studies;Visual Knowledge Representation;experiment;group work;knowledge sharing;synchronous situated collaboration	A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a- - nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.	Bresciani, S.;Eppler, M.J.	Univ. of Lugano, Lugano, Switzerland|c|;	37546982400;38473544100
	InfoVis+SciVis	Nov.-Dec. 2009	Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards	10.1109/TVCG.2009.148	http://dx.doi.org/10.1109/TVCG.2009.148	1081	1088	5290715	Internet;data analysis;data visualisation;social networking (online)	Dashiki;Web information ecology;Web information ecosystem;Wiki-based visualization dashboards;coordinating interaction;dashboard pages;public Web site;social data analysis;wiki-like syntax	Application software;Collaborative software;Data analysis;Data visualization;Ecosystems;Environmental factors;Eyes;Feeds;Pipelines;Web page design	collaboration;dashboards;social data analysis;social software;visual analytics.;visualization;web;wikis	We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web's information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews.	McKeon, M.	IBM Research|c|	37542455400
	InfoVis+SciVis	Nov.-Dec. 2009	SpicyNodes: Radial Layout Authoring for the General Public	10.1109/TVCG.2009.183	http://dx.doi.org/10.1109/TVCG.2009.183	1089	1096	5290716	authoring systems;data visualisation;trees (mathematics)	GUI authoring tools;SpicyNodes;XML-based API;force-directed layouts;geometric layout;graph structures;information-visualization technology;radial layout authoring;radial tree layouts	Art;Catalogs;Graphical user interfaces;Information management;Portals;Semantic Web;Social network services;Software libraries;Tree graphs;Visualization	Trees and network visualization;focus+context;hierarchy visualization;human-computer interaction;information visualization;interaction;radial tree layout	Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.	Douma, M.;Ligierko, G.;Ancuta, O.;Gritsai, P.;Liu, S.	;;;;	38108824400;38108821200;38108821300;38108819800;38107258600
	InfoVis+SciVis	Nov.-Dec. 2009	code_swarm: A Design Study in Organic Software Visualization	10.1109/TVCG.2009.123	http://dx.doi.org/10.1109/TVCG.2009.123	1097	1104	5290717	data visualisation;public domain software;software maintenance;video signal processing	code_swarm;design methodology;open source information visualization practice;organic information design;organic information visualization technique;organic software visualization;software development evolution;software development history;software visualization videos	Animation;Application software;Data visualization;Design methodology;History;Humans;Open source software;Programming;Software quality;Videos	Software visualization;organic information visualization;software development history and evolution.	In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.	Ogawa, M.;Kwan-Liu Ma	VIDI Lab., Univ. of California, Davis, CA, USA|c|;	37287357700;37275869400
	InfoVis+SciVis	Nov.-Dec. 2009	Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations	10.1109/TVCG.2009.191	http://dx.doi.org/10.1109/TVCG.2009.191	1105	1112	5290718	abstract data types;coprocessors;data visualisation;visual programming	GPU shader languages;drag-and-drop interface;high-level abstract data type;image-space operation;information visualization;low-level floating-point model;visual programming environment	Computer buffers;Computer graphics;Computer industry;Data visualization;Displays;Image resolution;Pipelines;Programming environments;Toy industry;Tree graphs	GPU-acceleration;high-performance visualization;interaction;shader programming	Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.	McDonnel, B.;Elmqvist, N.	Purdue Univ., West Lafayette, IN, USA|c|;	37590945700;37295438200
	InfoVis+SciVis	Nov.-Dec. 2009	A Multi-Threading Architecture to Support Interactive Visual Exploration	10.1109/TVCG.2009.110	http://dx.doi.org/10.1109/TVCG.2009.110	1113	1120	5290719	data visualisation;multi-threading;software architecture;user interfaces	VISPLORE;continuous user interaction;information visualizations;interactive visual exploration;multi-threading architecture;visual feedback	Communication system control;Concurrent computing;Data visualization;Delay;Feedback;Frequency synchronization;Interactive systems;Manipulator dynamics;Navigation	Information visualization architecture;continuous interaction;layer;multi-threading;preview	During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.	Piringer, H.;Tominski, C.;Muigg, P.;Berger, W.	VRVis Res. Center, Vienna, Austria|c|;;;	37282562500;37283236000;37546620600;37546977900
	InfoVis+SciVis	Nov.-Dec. 2009	Protovis: A Graphical Toolkit for Visualization	10.1109/TVCG.2009.174	http://dx.doi.org/10.1109/TVCG.2009.174	1121	1128	5290720	application program interfaces;data visualisation;rendering (computer graphics)	Protovis;data visualization;graphical visualization toolkit;high-level visualization systems;low-level graphical systems;rendering API;vector-based drawing programs	Computer science;Costs;Data processing;Data visualization;Domain specific languages;Encoding;Graphics;Rendering (computer graphics);Software tools;User interfaces	2D graphics.;Information visualization;toolkits;user interfaces	Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.	Bostock, M.;Heer, J.	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;	37591067400;37550791300
	InfoVis+SciVis	Nov.-Dec. 2009	Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing	10.1109/TVCG.2009.196	http://dx.doi.org/10.1109/TVCG.2009.196	1129	1136	5290721	application program interfaces;data visualisation;message passing	Gantt chart;MPI Profiling;information visualization;interprocess communication;large-scale parallel computing;parallel processes;parallel systems;program execution;program profiling;visual analysis	Computational modeling;Delay;Laboratories;Large-scale systems;Message passing;Parallel processing;Scalability;Supercomputers;US Department of Energy;Visualization	Information Visualization;MPI Profiling;Scalability	In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.	Muelder, C.;Gygi, F.;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;	37299311900;37399379400;37275869400
	InfoVis+SciVis	Nov.-Dec. 2009	Participatory Visualization with Wordle	10.1109/TVCG.2009.171	http://dx.doi.org/10.1109/TVCG.2009.171	1137	1144	5290722	Web sites;data analysis;data visualisation;text analysis	Web-based tool;Wordle;Wordle layouts;tag-cloud-like displays;text visualisation	Visualization	Visualization;educational visualization;memory;participatory culture;social data analysis;tag cloud;text	We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.	Viegas, F.B.;Wattenberg, M.;Feinberg, J.	IBM Res., Hawthorne, CA, USA|c|;;	37681355300;37550759700;38102505300
	InfoVis+SciVis	Nov.-Dec. 2009	Document Cards: A Top Trumps Visualization for Documents	10.1109/TVCG.2009.139	http://dx.doi.org/10.1109/TVCG.2009.139	1145	1152	5290723	data mining;data visualisation;document image processing	IEEE InfoVis publications;advanced text mining;compact visualization;display devices;document cards;document structure extraction;image color histogram;semi-semantic image weighting;top trumps document visualization	Displays;Feeds;Histograms;Image databases;Operating systems;Pipelines;Search engines;Text mining;Visualization	content extraction;document collection browsing;document visualization;visual summary	Finding suitable, less space consuming views for a document's main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document's key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the IEEE InfoVis publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images.	Strobelt, H.;Oelke, D.;Rohrdantz, C.;Stoffel, A.;Keim, D.A.;Deussen, O.	Univ. of Konstanz, Konstanz, Germany|c|;;;;;	38108845300;37591207400;37601356700;37592880100;37283138700;37266781000
	InfoVis+SciVis	Nov.-Dec. 2009	Visualizing the Intellectual Structure with Paper-Reference Matrices	10.1109/TVCG.2009.202	http://dx.doi.org/10.1109/TVCG.2009.202	1153	1160	5290724	Java;astronomical surveys;astronomy computing;citation analysis;data visualisation;network theory (graphs);pattern clustering;scientific information systems;trees (mathematics)	FP-tree;Java-based prototype system;SDSS;Sloan Digital Sky Survey;author analysis;co-citation relationship;co-cited unit;information source;information visualization;intellectual structure visualization;node-link network visualization;paper-reference matrix;reference analysis;reference-reference matrix;scientific domain analysis;tightly-knit cluster;visual analysis	Chaos;Data visualization;Information analysis;Information science;Java;Joining processes;Libraries;Prototypes;Testing;Tree data structures	Co-citation;FP-tree;Intellectual Structure;Paper-reference Matrix	Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.	Jian Zhang;Chen, C.;Jiexun Li	Drexel Univ., Philadelphia, PA, USA|c|;;	38108288000;37280749300;37676324000
	InfoVis+SciVis	Nov.-Dec. 2009	Exemplar-based Visualization of Large Document Corpus (InfoVis2009-1115)	10.1109/TVCG.2009.140	http://dx.doi.org/10.1109/TVCG.2009.140	1161	1168	5290725	biology computing;data visualisation;iterative methods;optimisation	exemplar-based visualization;iterative optimization;large document corpus;matrix approximation;parameter embedding;text corpus;text visualization	Computer science;Data visualization;Drugs;Indexing;Large-scale systems;Matrix decomposition;Multidimensional systems;Principal component analysis;Text mining;Web sites	Exemplar;large-scale document visualization;multidimensional projection.	With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.	Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua	Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;;	37965966100;37900114200;37290589700;37285799200
	InfoVis+SciVis	Nov.-Dec. 2009	Mapping Text with Phrase Nets	10.1109/TVCG.2009.165	http://dx.doi.org/10.1109/TVCG.2009.165	1169	1176	5290726	data visualisation;text analysis	phrase nets;text mapping;user-specified relation;visual overviews	Books;Computer network reliability;Displays;Natural language processing;Pattern analysis;Pattern matching;Speech;Tag clouds;Turning;Visualization	Text visualization;natural language processing;semantic net;tag cloud	We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.	van Ham, F.;Wattenberg, M.;Viegas, F.B.	;;	37326291000;37550759700;37681355300
	InfoVis+SciVis	Nov.-Dec. 2009	Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees	10.1109/TVCG.2009.163	http://dx.doi.org/10.1109/TVCG.2009.163	1177	1184	5290727	computational complexity;data visualisation;graph theory;mesh generation	Reeb graphs;contour trees;loop surgery;mechanical design pressure analysis;scalar function;time complexity;volumetric meshes	Algorithm design and analysis;Data mining;Data visualization;Isosurfaces;Level set;Scalability;Stress;Surgery;Topology;Tree graphs	Reeb graph;isosurfaces;scalar field topology;topological simplification		Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	37298870300;37870001700;38113906300;37284312600
	InfoVis+SciVis	Nov.-Dec. 2009	Applying Manifold Learning to Plotting Approximate Contour Trees	10.1109/TVCG.2009.119	http://dx.doi.org/10.1109/TVCG.2009.119	1185	1192	5290728	computer graphics;data analysis;edge detection	contour tree;dimensionality reduction scheme;high-dimensional data samples;isosurfaces;large-scale datasets;manifold learning;plotting approximation;segmentation capability;single-valued function;time-varying volumes	Biochemistry;Data analysis;Data mining;Data visualization;Feature extraction;Isosurfaces;Large-scale systems;Physics;Scattering;Software algorithms	Contour trees;high-dimensional data analysis;manifold learning;time-varying volumes	A contour tree is a powerful tool for delineating the topological evolution of isosurfaces of a single-valued function, and thus has been frequently used as a means of extracting features from volumes and their time-varying behaviors. Several sophisticated algorithms have been proposed for constructing contour trees while they often complicate the software implementation especially for higher-dimensional cases such as time-varying volumes. This paper presents a simple yet effective approach to plotting in 3D space, approximate contour trees from a set of scattered samples embedded in the high-dimensional space. Our main idea is to take advantage of manifold learning so that we can elongate the distribution of high-dimensional data samples to embed it into a low-dimensional space while respecting its local proximity of sample points. The contribution of this paper lies in the introduction of new distance metrics to manifold learning, which allows us to reformulate existing algorithms as a variant of currently available dimensionality reduction scheme. Efficient reduction of data sizes together with segmentation capability is also developed to equip our approach with a coarse-to-fine analysis even for large-scale datasets. Examples are provided to demonstrate that our proposed scheme can successfully traverse the features of volumes and their temporal behaviors through the constructed contour trees.	Takahashi, S.;Fujishiro, I.;Okada, M.	Univ. of Tokyo, Tokyo, Japan|c|;;	37280401000;37282596600;37280787900
	InfoVis+SciVis	Nov.-Dec. 2009	Intrinsic Geometric Scale Space by Shape Diffusion	10.1109/TVCG.2009.159	http://dx.doi.org/10.1109/TVCG.2009.159	1193	1200	5290729	computer graphics;feature extraction;image matching;image representation	3D surface shapes;Ricci flow;axiomatic causality property;feature-based shape representation;global shape representations;intrinsic geometric scale space;multiscale shape representation;salient geometric feature detection;scale-dependent saliency;shape diffusion	Computer vision;Data mining;Feature extraction;Geometry;Noise robustness;Noise shaping;Shape;Smoothing methods;Solid modeling;Surface treatment	Riemannian manifolds;Scale space;feature extraction;geometric flow	This paper formalizes a novel, intrinsic geometric scale space (IGSS) of 3D surface shapes. The intrinsic geometry of a surface is diffused by means of the Ricci flow for the generation of a geometric scale space. We rigorously prove that this multiscale shape representation satisfies the axiomatic causality property. Within the theoretical framework, we further present a feature-based shape representation derived from IGSS processing, which is shown to be theoretically plausible and practically effective. By integrating the concept of scale-dependent saliency into the shape description, this representation is not only highly descriptive of the local structures, but also exhibits several desired characteristics of global shape representations, such as being compact, robust to noise and computationally efficient. We demonstrate the capabilities of our approach through salient geometric feature detection and highly discriminative matching of 3D scans.	Guangyu Zou;Jing Hua;Zhaoqiang Lai;Xianfeng Gu;Ming Dong	Wayne State Univ., Detroit, MI, USA|c|;;;;	37301933100;37285799200;37868989800;37276603700;37290589700
	InfoVis+SciVis	Nov.-Dec. 2009	Multi-Scale Surface Descriptors	10.1109/TVCG.2009.168	http://dx.doi.org/10.1109/TVCG.2009.168	1201	1208	5290730	approximation theory;curve fitting;data visualisation;image matching;mesh generation;rendering (computer graphics);shape recognition;statistical analysis;surface fitting	anisotropy;data visualization;differential curvature;infinitesimal neighborhood;local shape descriptor;multiscale surface mesh descriptor;protein surface analysis;quadratic surface fitting;shape matching;statistical approximation;stylized rendering	Anisotropic magnetoresistance;Application software;Computational efficiency;Data analysis;Data visualization;Mathematics;Mesh generation;Proteins;Shape;Surface fitting	Curvature;descriptors;npr;shape matching.;stylized rendering	Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.	Cipriano, G.;Phillips, G.N.;Gleicher, M.	Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA|c|;;	37882969500;37604175600;37282585700
	InfoVis+SciVis	Nov.-Dec. 2009	A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets	10.1109/TVCG.2009.114	http://dx.doi.org/10.1109/TVCG.2009.114	1209	1218	5290731	data visualisation	ANOVA;counting task;data surface;data visualization;error rate;errorbars;glyphs;search task;surface color-mapping;uncertainty visualization	Analysis of variance;Data acquisition;Data engineering;Data visualization;Error analysis;Pipelines;Quality assurance;Uncertainty	User study;uncertainty visualization	Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.	Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.	Geosystems Res. Inst., Mississippi State Univ., Starkville, MS, USA|c|;;;;	37567906800;37277708500;38100000900;37411386700;37282559500
	InfoVis+SciVis	Nov.-Dec. 2009	Comparing 3D Vector Field Visualization Methods: A User Study	10.1109/TVCG.2009.126	http://dx.doi.org/10.1109/TVCG.2009.126	1219	1226	5290732	data visualisation	3D vector field visualization methods;integral curve;monoscopic viewing;stereo lines;stereoscopic viewing;swirling movement	Blood flow;Computer science;Data visualization;Design for experiments;Surface texture;Testing	3D vector fields;lines;stereoscopic and monoscopic viewing;tubes;user study;visualization	In a user study comparing four visualization methods for three-dimensional vector data, participants used visualizations from each method to perform five simple but representative tasks: 1) determining whether a given point was a critical point, 2) determining the type of a critical point, 3) determining whether an integral curve would advect through two points, 4) determining whether swirling movement is present at a point, and 5) determining whether the vector field is moving faster at one point than another. The visualization methods were line and tube representations of integral curves with both monoscopic and stereoscopic viewing. While participants reported a preference for stereo lines, quantitative results showed performance among the tasks varied by method. Users performed all tasks better with methods that: 1) gave a clear representation with no perceived occlusion, 2) clearly visualized curve speed and direction information, and 3) provided fewer rich 3D cues (e.g., shading, polygonal arrows, overlap cues, and surface textures). These results provide quantitative support for anecdotal evidence on visualization methods. The tasks and testing framework also give a basis for comparing other visualization methods, for creating more effective methods, and for defining additional tasks to explore further the tradeoffs among the methods.	Forsberg, A.;Jian Chen;Laidlaw, D.H.	Comput. Sci. Dept., Brown Univ., RI, USA|c|;;	37612088000;38107662400;37275712600
	InfoVis+SciVis	Nov.-Dec. 2009	Verifiable Visualization for Isosurface Extraction	10.1109/TVCG.2009.194	http://dx.doi.org/10.1109/TVCG.2009.194	1227	1234	5290733	image coding;image representation	convergence rate;isosurface extraction codes;isosurface features;visual representations	Computational modeling;Convergence;Data mining;Data visualization;Heart;Isosurfaces;Mathematical model;Numerical simulation;Pipelines;Scientific computing	Isosurface Extraction;Marching Cubes;V&V;Verification	Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.	Etiene, T.;Scheidegger, C.;Nonato, L.G.;Kirby, R.M.;Silva, C.T.	Sch. of Comput. & Sci. Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;	37829389700;37550809300;37590974800;37275716100;37275249200
	InfoVis+SciVis	Nov.-Dec. 2009	Curve-Centric Volume Reformation for Comparative Visualization	10.1109/TVCG.2009.136	http://dx.doi.org/10.1109/TVCG.2009.136	1235	1242	5290734	computational geometry;data visualisation	arc-length parameterized data visualizations;compelling comparative visualizations;curve-centric volume reformation;radial-ray casting;volume deformation	Current measurement;Data analysis;Data visualization;Drilling;Geometry;Hydrocarbon reservoirs;Inspection;Petroleum;Production;Shape	Comparative Visualization;Curve-Centric-Reformation;Radial Ray-Casting;Volume Deformation	We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.	Lampe, O.D.;Correa, C.;Kwan-Liu Ma;Hauser, H.	CMR AS, Univ. of Bergen, Bergen, Norway|c|;;;	37842366200;37282925900;37275869400;37274158800
	InfoVis+SciVis	Nov.-Dec. 2009	Predictor-Corrector Schemes for Visualization ofSmoothed Particle Hydrodynamics Data	10.1109/TVCG.2009.173	http://dx.doi.org/10.1109/TVCG.2009.173	1243	1250	5290735	data visualisation;flow visualisation;hydrodynamics;interpolation;physics computing;predictor-corrector methods	Lagrangian coherent structures;basic trilinear interpolant;interpolation method;isosurfaces;predictor-corrector schemes;smoothed particle hydrodynamics data visualization;vortex core line extraction	Computational fluid dynamics;Computational modeling;Data mining;Data visualization;Hydrodynamics;Interpolation;Isosurfaces;Kernel;Lagrangian functions;Software algorithms	Smoothed particle hydrodynamics;feature extraction;flow visualization;unsteady flow;vortex core lines	In this paper we present a method for vortex core line extraction which operates directly on the smoothed particle hydrodynamics (SPH) representation and, by this, generates smoother and more (spatially and temporally) coherent results in an efficient way. The underlying predictor-corrector scheme is general enough to be applied to other line-type features and it is extendable to the extraction of surfaces such as isosurfaces or Lagrangian coherent structures. The proposed method exploits temporal coherence to speed up computation for subsequent time steps. We show how the predictor-corrector formulation can be specialized for several variants of vortex core line definitions including two recent unsteady extensions, and we contribute a theoretical and practical comparison of these. In particular, we reveal a close relation between unsteady extensions of Fuchs et al. and Weinkauf et al. and we give a proof of the Galilean invariance of the latter. When visualizing SPH data, there is the possibility to use the same interpolation method for visualization as has been used for the simulation. This is different from the case of finite volume simulation results, where it is not possible to recover from the results the spatial interpolation that was used during the simulation. Such data are typically interpolated using the basic trilinear interpolant, and if smoothness is required, some artificial processing is added. In SPH data, however, the smoothing kernels are specified from the simulation, and they provide an exact and smooth interpolation of data or gradients at arbitrary points in the domain.	Schindler, B.;Fuchs, R.;Biddiscombe, J.;Peikert, R.	Inst. of Visual Comput., ETH Zurich, Zurich, Switzerland|c|;;;	38102461400;38099765400;37948935700;37282541100
	InfoVis+SciVis	Nov.-Dec. 2009	Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets	10.1109/TVCG.2009.142	http://dx.doi.org/10.1109/TVCG.2009.142	1251	1258	5290736	astronomy computing;cosmology;dark matter;data visualisation;rendering (computer graphics);vector quantisation	GPU;brick-based page-tree;coarse particle distribution;fine-grain view-frustum culling;graphics subsystem;hierarchical quantization scheme;large-scale cosmological datasets;large-scale particle-based cosmological simulations;logarithmically encoded floating point value;particle-based cosmological dark-matter simulation;scalable rendering;subpixel screen space error;vector quantization;visually continuous level-of-detail particle representation	Acceleration;Analytical models;Computational modeling;Data visualization;Geometry;Graphics;Large-scale systems;Rendering (computer graphics);Scalability;Vector quantization	Cosmology;Particle Visualization;Scalability	In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.	Fraedrich, R.;Schneider, J.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;	37590979700;37560044500;37444424000
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Streak Surface Visualization on the GPU	10.1109/TVCG.2009.154	http://dx.doi.org/10.1109/TVCG.2009.154	1259	1266	5290737	coprocessors;flow visualisation;image representation;mesh generation;physics computing;rendering (computer graphics)	GPU;adaptive surface representation;interactive streak surface visualization;numerical particle integration;particle-based surface representation;patch-based surface representation;quadrilateral surface patches;surface quality;surface rendering;surface triangulation;triangle mesh;visual quality	Bandwidth;Computational complexity;Computer graphics;Hydrogen;Monitoring;Shape;Streaming media;Video sequences;Visualization	GPUs;Unsteady flow visualization;streak surface generation	In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.	Burger, K.;Ferstl, F.;Theisel, H.;Westermann, R.	Comput. Graphics & Visualization group, Tech. Univ. Munchen, Munich, Germany|c|;;;	;37606419000;37266875400;37444424000
	InfoVis+SciVis	Nov.-Dec. 2009	Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets	10.1109/TVCG.2009.190	http://dx.doi.org/10.1109/TVCG.2009.190	1267	1274	5290738	data visualisation;flow visualisation;rendering (computer graphics)	flow visualization;large time-varying data sets;rendering;streak surface;surface adaptation;surface advection;time surface	Algorithm design and analysis;Approximation algorithms;Concurrent computing;Data analysis;Data visualization;Surface texture	3D vector field visualization;flow visualization;surface extraction.;time and streak surfaces;time-varying	Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.	Krishnan, H.;Garth, C.;Joy, K.I.	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;	37866882400;37282573700;37267811400
	InfoVis+SciVis	Nov.-Dec. 2009	Hue-Preserving Color Blending	10.1109/TVCG.2009.150	http://dx.doi.org/10.1109/TVCG.2009.150	1275	1282	5290739	colour graphics;data visualisation;rendering (computer graphics)	achromatic compositing;chromatic compositing;hue-preserving color blending;image overlay;nominal data visualization;perception-guided compositing operator;transparency rendering;visual characteristics;visual labeling;volume rendering;volume visualization	Biomedical imaging;Brightness;Computed tomography;Data visualization;Displays;Histograms;Labeling;Magnetic resonance imaging;Rendering (computer graphics);Transfer functions	color blending;illustrative visualization;image compositing;perceptual transparency;volume rendering	We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.	Chuang, J.;Weiskopf, D.;Moller, T.	Simon Fraser Univ., Burnaby, BC, Canada|c|;;	38100482200;37268045000;37275858700
	InfoVis+SciVis	Nov.-Dec. 2009	Perception-Based Transparency Optimization for Direct Volume Rendering	10.1109/TVCG.2009.172	http://dx.doi.org/10.1109/TVCG.2009.172	1283	1290	5290740	rendering (computer graphics);user interfaces	auto-correction method;direct volume rendered images;intuitive user interaction process;perception-based transparency optimization;psychological principles;visual quality	Image enhancement;Image quality;Image resolution;Psychology;Rendering (computer graphics);Robustness;Shape measurement;Transfer functions;Visual perception;Visualization	Direct volume rendering;image enhancement;layer perception.	The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.	Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;	37401176900;37407308300;37306814700;37279188600;37272637300
	InfoVis+SciVis	Nov.-Dec. 2009	A Physiologically-based Model for Simulation of Color Vision Deficiency	10.1109/TVCG.2009.113	http://dx.doi.org/10.1109/TVCG.2009.113	1291	1298	5290741	biology computing;data visualisation;image colour analysis;visual perception	anomalous trichromacy;color vision deficiency simulation;dichromacy;electrophysiological studies;human color vision;physiologically-based model	Biological cells;Data visualization;Electrophysiology;Feedback;Humans;Photoreceptors;Proteins;Retina;Testing	Anomalous Trichromacy;Color Perception;Dichromacy.;Models of Color Vision;Simulation of Color Vision Deficiency	Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.	Machado, Gustavo M.;Oliveira, M.M.;Fernandes, Leandro A.F.	UFRGS, Porto Alegre, Brazil|c|;;	38221364200;37554064200;37349793000
	InfoVis+SciVis	Nov.-Dec. 2009	Depth-Dependent Halos: Illustrative Rendering of Dense Line Data	10.1109/TVCG.2009.138	http://dx.doi.org/10.1109/TVCG.2009.138	1299	1306	5290742	data visualisation;rendering (computer graphics)	dense line data;depth-dependent halos;fluid flow simulations;gas flow simulations;illustrative DTI fiber tract visualizations;illustrative rendering;interactive frame rates;line width attenuation;mathematics;neurosurgery;sparse line rendering;tractography	Attenuation;Biomedical imaging;Data visualization;Diffusion tensor imaging;Fluid flow;Mathematics;Medical simulation;Optical fiber communication;Rendering (computer graphics);Shape	DTI;GPU technique.;Illustrative rendering and visualization;NPR;black-and-white rendering;dense line data	We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.	Everts, M.H.;Bekker, H.;Roerdink, J.B.T.M.;Isenberg, T.	Univ. of Groningen, Groningen, Netherlands|c|;;;	37591149600;38105196000;37279298200;37297057400
	InfoVis+SciVis	Nov.-Dec. 2009	Markerless View-Independent Registration of Multiple Distorted Projectors on Extruded Surfaces Using an Uncalibrated Camera	10.1109/TVCG.2009.166	http://dx.doi.org/10.1109/TVCG.2009.166	1307	1316	5290743	computer displays;coprocessors;data visualisation;image registration;image sensors	geometrically register multiple projectors;graphical processing unit;markerless view-independent registration;multiple distorted projectors;nonlinear geometric distortions;uncalibrated camera	Biomedical imaging;Calibration;Cameras;Joining processes;Large screen displays;Lenses;Nonlinear distortion;Shape;Three dimensional displays;Visualization	Calibration;Multi-Projector Displays;Registration;Tiled Displays	In this paper, we present the first algorithm to geometrically register multiple projectors in a view-independent manner (i.e. wallpapered) on a common type of curved surface, vertically extruded surface, using an uncalibrated camera without attaching any obtrusive markers to the display screen. Further, it can also tolerate large non-linear geometric distortions in the projectors as is common when mounting short throw lenses to allow a compact set-up. Our registration achieves sub-pixel accuracy on a large number of different vertically extruded surfaces and the image correction to achieve this registration can be run in real time on the GPU. This simple markerless registration has the potential to have a large impact on easy set-up and maintenance of large curved multi-projector displays, common for visualization, edutainment, training and simulation applications.	Sajadi, B.;Majumder, A.	Comput. Sci. Dept., Univ. of California, Irvine, Irvine, CA, USA|c|;	37391937200;38477161700
	InfoVis+SciVis	Nov.-Dec. 2009	Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing	10.1109/TVCG.2009.124	http://dx.doi.org/10.1109/TVCG.2009.124	1317	1326	5290744	computer graphics;coprocessors;display devices;image colour analysis;optical projectors	3D color gamut;GPU;chromaticity gamuts;color morphing algorithm;color seamlessness;constrained gamut morphing;multi-projector displays	Brightness;Calibration;Computer displays;Computer science;Dynamic range;Fresnel reflection;Geometrical optics;Optical filters;Optical saturation;Three dimensional displays	Color Calibration;Multi-Projector Displays;Tiled Displays.	Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.	Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.	Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;	37391937200;37541336800;37271691400;37408075400
	InfoVis+SciVis	Nov.-Dec. 2009	Visual Human+Machine Learning	10.1109/TVCG.2009.199	http://dx.doi.org/10.1109/TVCG.2009.199	1327	1334	5290745	data mining;data visualisation;evolutionary computation;fuzzy logic;learning (artificial intelligence);rendering (computer graphics);search problems;user interfaces	GPU implementation;automatic hypothesis generation;evolutionary search algorithm;fuzzy logic formalization;heuristic search algorithm;interactive visual analysis;knowledge-based analysis;machine learning;pattern recognition;superior reasoning;visual human;volume rendering	Fuzzy logic;Heuristic algorithms;Humans;Information analysis;Joining processes;Machine learning;Machine learning algorithms;Multidimensional systems;Pattern recognition;Visualization	Computer-assisted Multivariate Data Exploration;Curse of Dimensionality;Genetic Algorithm;Interactive Visual Analysis;Knowledge Discovery;Multiple Competing Hypotheses;Predictive Analysis;Volumetric Data	In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.	Fuchs, R.;Waser, J.;Groller, M.E.	ETH Zurich, Zurich, Switzerland|c|;;	38099765400;38111592300;37282552200
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Visual Optimization and Analysis for RFID Benchmarking	10.1109/TVCG.2009.156	http://dx.doi.org/10.1109/TVCG.2009.156	1335	1342	5290746	data visualisation;optimisation;radiofrequency identification	3D spatial viewer;RFID benchmarking;aGate;data visualization;interactive visual optimization;orientation plots;parallel coordinate plots;radiofrequency identification;visual history mechanism	Data analysis;Data engineering;Data visualization;History;Instruments;Multidimensional systems;Performance analysis;RFID tags;Radio frequency;Radiofrequency identification	RFID;Visual analytics;Visualization	Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.	Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;	37407308300;37406959900;37272637300;37403856700;37275216500
	InfoVis+SciVis	Nov.-Dec. 2009	A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete	10.1109/TVCG.2009.115	http://dx.doi.org/10.1109/TVCG.2009.115	1343	1350	5290747	cast iron;computerised tomography;mechanical engineering computing;nondestructive testing;reinforced concrete;rendering (computer graphics);transfer functions	2D metallographic samples;ISO standard 945-1;ductile cast irons microstructure;mechanical stress;nondestructive testing;particle roundness;steel fibre reinforced sprayed concrete;transfer functions;volume visualization	Buildings;Concrete;Iron;Nondestructive testing;Optical fiber testing;Spraying;Steel;Stress;Transfer functions;Visualization	Direction Visualization;Multi-Dimensional Transfer Functions;Non-Destructive Testing;Volume Rendering	This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.	Fritz, L.;Hadwiger, M.;Geier, G.;Pittino, G.;Groller, E.	VRVis Res. Center, Vienna, Austria|c|;;;;	37865385300;37394809600;37869963700;38108759900;37284271200
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces	10.1109/TVCG.2009.155	http://dx.doi.org/10.1109/TVCG.2009.155	1351	1358	5290748	automobile industry;data analysis;data visualisation;electrohydrodynamics;interactive systems;lubrication	automotive industry;complex scientific data;computational simulation;data surfaces;elastohydrodynamic lubrication;interactive visual analysis;meteorological multi-run simulation data case	Aggregates;Automotive engineering;Cognition;Collaborative work;Computational modeling;Context modeling;Data engineering;Data visualization;Lubrication;Meteorology	coordinated multiple views;family of surfaces;interactive visual analysis;multidimensional multivariate data	The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.	Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.	VRVis Res. Center, Vienna, Austria|c|;;;	38220979200;37272650400;38246833000;37274158800
	InfoVis+SciVis	Nov.-Dec. 2009	Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data	10.1109/TVCG.2009.200	http://dx.doi.org/10.1109/TVCG.2009.200	1359	1366	5290749	computational complexity;data visualisation;user interfaces	data exploration;data visualization;linear time complexity;multivariate time-varying data;spatial distributions;temporal trend relationships;trend sequence clustering;user interfaces	Algorithm design and analysis;Clustering algorithms;Data mining;Data visualization;Displays;Hurricanes;Temperature;Testing;User interfaces;Wind	SUBDTW;trend sequence;trend sequence clustering	We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.	Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;	37403060100;37279493500
	InfoVis+SciVis	Nov.-Dec. 2009	Isosurface Extraction and View-Dependent Filtering from Time-Varying Fields Using Persistent Time-Octree (PTOT)	10.1109/TVCG.2009.160	http://dx.doi.org/10.1109/TVCG.2009.160	1367	1374	5290750	data visualisation;octrees	4D isocontour slicing;branch-on-need octree;isosurface extraction;persistent time-octree indexing structure;state-of-the-art programmable GPU;time-varying fields;view-dependent filtering	Concurrent computing;Costs;Data mining;Data structures;Filtering algorithms;Indexing;Isosurfaces;Runtime;Steady-state;Time domain analysis	Isosurface extraction;out-of-core methods;persistent data structure;time-varying fields;view-dependent filtering	We develop a new algorithm for isosurface extraction and view-dependent filtering from large time-varying fields, by using a novel persistent time-octree (PTOT) indexing structure. Previously, the persistent octree (POT) was proposed to perform isosurface extraction and view-dependent filtering, which combines the advantages of the interval tree (for optimal searches of active cells) and of the branch-on-need octree (BONO, for view-dependent filtering), but it only works for steady-state(i.e., single time step) data. For time-varying fields, a 4D version of POT, 4D-POT, was proposed for 4D isocontour slicing, where slicing on the time domain gives all active cells in the queried timestep and isovalue. However, such slicing is not output sensitive and thus the searching is sub-optimal. Moreover, it was not known how to support view-dependent filtering in addition to time-domain slicing.In this paper, we develop a novel persistent time-octree (PTOT) indexing structure, which has the advantages of POT and performs 4D isocontour slicing on the time domain with an output-sensitive and optimal searching. In addition, when we query the same iso value q over m consecutive time steps, there is no additional searching overhead (except for reporting the additional active cells) compared to querying just the first time step. Such searching performance for finding active cells is asymptotically optimal, with asymptotically optimal space and preprocessing time as well. Moreover, our PTOT supports view-dependent filtering in addition to time-domain slicing. We propose a simple and effective out-of-core scheme, where we integrate our PTOT with implicit occluders, batched occlusion queries and batched CUDA computing tasks, so that we can greatly reduce the I/O cost as well as increase the amount of data being concurrently computed in GPU.This results in an efficient algorithm for isosurface extraction with view-dependent filtering utilizing a state-of-the-art programmable GPU for ti me-varying fields larger than main memory. Our experiments on datasets as large as 192 GB (with 4 GB per time step) having no more than 870 MB of memory footprint in both preprocessing and run-time phases demonstrate the efficacy of our new technique.	Cong Wang;Yi-Jen Chiang	CSE Dept, Polytech. Inst. of New York Univ., Brooklyn, NY, USA|c|;	38107165200;37288235400
	InfoVis+SciVis	Nov.-Dec. 2009	Visual Exploration of Climate Variability Changes Using Wavelet Analysis	10.1109/TVCG.2009.197	http://dx.doi.org/10.1109/TVCG.2009.197	1375	1382	5290751	climatology;data visualisation;geophysics computing;wavelet transforms	ECHAM5/MPI-OM;El Nino southern oscillation phenomenon;IPCC AR4 simulations;climate variability changes;frequency domain;multiyear oscillations;visual exploration;wavelet analysis	Data analysis;Data visualization;Environmental factors;Fluctuations;Frequency;Ocean temperature;Sea level;Sea surface;Time series analysis;Wavelet analysis	El Nino;Wavelet analysis;climate variability change visualization;multivariate data;time-dependent data	Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.	Janicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.	Univ. of Leipzig, Leipzig, Germany|c|;;;	37393638200;37869987100;38108879000;37282574800
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data	10.1109/TVCG.2009.152	http://dx.doi.org/10.1109/TVCG.2009.152	1383	1390	5290752	biology computing;biomechanics;data visualisation;image motion analysis	biomechanical motion data;biplane fluoroscopy;complex 3D motions;high-speed imaging technologies;interactive coordinated multiple-view visualization;multi-dimensional data analysis;spatial analysis	Animals;Bioinformatics;Data analysis;Data visualization;High-resolution imaging;Humans;Legged locomotion;Motion analysis;Sequences;Space technology	Scientific visualization;biomechanics;coordinated multiple views;information visualization	We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.	Keefe, Daniel F.;Ewert, M.;Ribarsky, W.;Chang, R.	Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA|c|;;;	37267356000;38108838100;37300425000;37592409400
	InfoVis+SciVis	Nov.-Dec. 2009	Interactive Visualization of Molecular Surface Dynamics	10.1109/TVCG.2009.157	http://dx.doi.org/10.1109/TVCG.2009.157	1391	1398	5290753	biology computing;data visualisation;interactive systems;molecular biophysics;probability;proteins;rendering (computer graphics)	GPU ray casting technique;interactive visualization techniques;molecular dynamics simulations;molecular surface dynamics;protein flexibility;protein solvent excluded surface;rendering quality;spatial probability density;time-dependent protein data;visual complexity	Acceleration;Analytical models;Casting;Data visualization;Medical simulation;Pharmaceuticals;Proteins;Shape;Solvents;Surface impedance	GPU;Isosurfaces;Molecular Visualization;Point-based Data;Ray Casting;Surface Extraction;Time-varying Data	Molecular dynamics simulations of proteins play a growing role in various fields such as pharmaceutical, biochemical and medical research. Accordingly, the need for high quality visualization of these protein systems raises. Highly interactive visualization techniques are especially needed for the analysis of time-dependent molecular simulations. Beside various other molecular representations the surface representations are of high importance for these applications. So far, users had to accept a trade-off between rendering quality and performance - particularly when visualizing trajectories of time-dependent protein data. We present a new approach for visualizing the solvent excluded surface of proteins using a GPU ray casting technique and thus achieving interactive frame rates even for long protein trajectories where conventional methods based on precomputation are not applicable. Furthermore, we propose a semantic simplification of the raw protein data to reduce the visual complexity of the surface and thereby accelerate the rendering without impeding perception of the protein's basic shape. We also demonstrate the application of our solvent excluded surface method to visualize the spatial probability density for the protein atoms over the whole period of the trajectory in one frame, providing a qualitative analysis of the protein flexibility.	Krone, M.;Bidmon, K.;Ertl, T.	Visualization Res. Center VISUS, Univ. Stuttgart, Stuttgart, Germany|c|;;	37885145500;37282594900;37268023800
	InfoVis+SciVis	Nov.-Dec. 2009	Stress Tensor Field Visualization for Implant Planning in Orthopedics	10.1109/TVCG.2009.184	http://dx.doi.org/10.1109/TVCG.2009.184	1399	1406	5290754	biomechanics;bone;data visualisation;medical diagnostic computing;orthopaedics;physiological models;planning;prosthetics;rendering (computer graphics);stress analysis;surgery;tensors	GPU;bone;computational steering environment;focus+context approach;hip joint replacement planning;implant planning;normal stress;orthopedics;physiological stress distribution;shear stress;simulated replacement surgery;spatial context information;stress analysis;stress tensor field visualization;volume rendering	Bones;Computational modeling;Data visualization;Humans;Implants;Information analysis;Orthopedic surgery;Prosthetics;Surges;Tensile stress	Biomedical Visualization;Comparative Visualization;GPU Techniques;Implant Planning;Stress Tensor Fields	We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.	Dick, C.;Georgii, J.;Burgkart, R.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;;	38013954900;37828702100;37281609100;37444424000
	InfoVis+SciVis	Nov.-Dec. 2009	Visual Exploration of Nasal Airflow	10.1109/TVCG.2009.198	http://dx.doi.org/10.1109/TVCG.2009.198	1407	1414	5290755	biomedical imaging;data analysis;data visualisation;flow visualisation;interactive systems;medical computing;rendering (computer graphics);time series	complex nasal anatomy;information visualization technique;medical imaging;nasal airflow visual exploration;nasal breathing;physiological nasal breathing;rhinologists;rhinomanometry;spatio-temporal airflow characteristics;therapeutic interventions;time series visualization;unstructured grid multivolume rendering;visual inspection	Analytical models;Anatomy;Biomedical imaging;Humans;Humidity;Immune system;Inspection;Medical simulation;Temperature;Visualization	Flow visualization;exploratory data analysis;interactive visual analysis of scientific data;interactive visualFlow visualization;time-dependent data.	Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.	Zachow, S.;Muigg, P.;Hildebrandt, T.;Doleisch, H.;Hege, H.-C.	Zuse Inst. Berlin (ZIB), Berlin, Germany|c|;;;;	37681640300;37546620600;38192658400;37546620400;37282272000
	InfoVis+SciVis	Nov.-Dec. 2009	Sampling and Visualizing Creases with Scale-Space Particles	10.1109/TVCG.2009.177	http://dx.doi.org/10.1109/TVCG.2009.177	1415	1424	5290756	data visualisation;image sampling;image segmentation;interpolation;medical image processing;splines (mathematics)	complex three-dimensional branching structure;computer vision;image resolution;implicit surface sampling;lung CT;mesh generation;particle-image energy;scale-space particles;scale-space theory;shape analysis;spline-based interpolation	Anatomical structure;Biomedical imaging;Computer vision;Data visualization;Image resolution;Image sampling;Mesh generation;Sampling methods;Shape;Spline	Crease Features;Diffusion Tensor MRI;Lung CT;Particle Systems;Ridge and Valley Detection	Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.	Kindlmann, G.L.;Estepar, R.S.J.;Smith, S.M.;Westin, C.-F.	Dept. of Comput. Sci., Univ. of Chicago, Chicago, IL, USA|c|;;;	37282742400;37829931900;38183671700;37294318400
	InfoVis+SciVis	Nov.-Dec. 2009	Volume Illustration of Muscle from Diffusion Tensor Images	10.1109/TVCG.2009.203	http://dx.doi.org/10.1109/TVCG.2009.203	1425	1432	5290757	image texture;medical image processing;tensors;vectors	diffusion tensor image;diffusion tensor imaging;example-based texture synthesis technique;fibrous structures;medical illustration;muscle volume illustration;solid texture synthesis algorithm	Biomedical imaging;Computed tomography;Data visualization;Diffusion tensor imaging;Heart;Magnetic resonance imaging;Muscles;Shape;Solid modeling;Tensile stress	Diffusion Tensor Image;Illustrative Visualization;Muscle;Solid Texture Synthesis	Medical illustration has demonstrated its effectiveness to depict salient anatomical features while hiding the irrelevant details. Current solutions are ineffective for visualizing fibrous structures such as muscle, because typical datasets (CT or MRI) do not contain directional details. In this paper, we introduce a new muscle illustration approach that leverages diffusion tensor imaging (DTI) data and example-based texture synthesis techniques. Beginning with a volumetric diffusion tensor image, we reformulate it into a scalar field and an auxiliary guidance vector field to represent the structure and orientation of a muscle bundle. A muscle mask derived from the input diffusion tensor image is used to classify the muscle structure. The guidance vector field is further refined to remove noise and clarify structure. To simulate the internal appearance of the muscle, we propose a new two-dimensional example based solid texture synthesis algorithm that builds a solid texture constrained by the guidance vector field. Illustrating the constructed scalar field and solid texture efficiently highlights the global appearance of the muscle as well as the local shape and structure of the muscle fibers in an illustrative fashion. We have applied the proposed approach to five example datasets (four pig hearts and a pig leg), demonstrating plausible illustration and expressiveness.	Wei Chen;Zhicheng Yan;Song Zhang;Crow, J.A.;Ebert, D.S.;McLaughlin, R.M.;Mullins, K.B.;Cooper, R.;Zi'ang Ding;Jun Liao	State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;;;	37279188600;38103982100;37277708500;38108843800;38472155800;38109676900;38108596500;37398897600;37833873400;38101476700
	InfoVis+SciVis	Nov.-Dec. 2009	A Novel Interface for Interactive Exploration of DTI Fibers	10.1109/TVCG.2009.112	http://dx.doi.org/10.1109/TVCG.2009.112	1433	1440	5290758	biology computing;biomedical MRI;data visualisation	2D representation;3D visualization;DTI fibers;biological speciments;cluttering;fiber tracts anatomical complexity;interactive exploration;occlusion;visual exploration;visualization optimization	Biological tissues;Computer science;Diffusion tensor imaging;Grasping;Magnetic field measurement;Magnetic resonance imaging;Rendering (computer graphics);Tensile stress;Velocity measurement;Visualization	Diffusion Tensor Imaging;Fiber Clustering;Fibers;Visualization Interface	Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user's workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.	Wei Chen;Zi'ang Ding;Song Zhang;MacKay-Brandt, A.;Correia, S.;Huamin Qu;Crow, J.A.;Tate, D.F.;Zhicheng Yan;Qunsheng Peng	State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;;;	37279188600;38104793000;37277708500;38108827300;37629889400;37272637300;38108843800;37642222600;38103982100;37272758500
	InfoVis+SciVis	Nov.-Dec. 2009	Parameter Sensitivity Visualization for DTI Fiber Tracking	10.1109/TVCG.2009.170	http://dx.doi.org/10.1109/TVCG.2009.170	1441	1448	5290759	biomedical MRI;brain;data visualisation;medical image processing	DTI fiber tracking;diffusion tensor imaging;living brain;parameter sensitivity visualization;white matter structures	Anisotropic magnetoresistance;Data visualization;Diffusion tensor imaging;Ischemic pain;Magnetic field measurement;Magnetic resonance;Magnetic resonance imaging;Stability;Tensile stress;Uncertainty	Diffusion Tensor Imaging;Fiber Tracking;Parameter Sensitivity;Stopping Criteria;Uncertainty Visualization	Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.	Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romeny, B.	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;	38108879500;37282551500;37428377700;38180036400
	InfoVis+SciVis	Nov.-Dec. 2009	Exploring 3D DTI Fiber Tracts with Linked 2D Representations	10.1109/TVCG.2009.141	http://dx.doi.org/10.1109/TVCG.2009.141	1449	1456	5290760	biology computing;biomedical MRI;brain;data visualisation	3D DTI fiber tracts;anecdotal evaluation;brain anatomical structures;brain functional structures;diffusion tensor magnetic resonance imaging;hierarchical clustering tree;linked 2D representations;two-dimensional representations;visual exploration paradigm	Acceleration;Brain modeling;Data visualization;Diffusion tensor imaging;Muscles;Navigation;Neurofeedback;Streaming media;Tensile stress;Transmission line matrix methods	DTI fiber tracts;coloring;embedding;interaction	We present a visual exploration paradigm that facilitates navigation through complex fiber tracts by combining traditional 3D model viewing with lower dimensional representations. To this end, we create standard streamtube models along with two two-dimensional representations, an embedding in the plane and a hierarchical clustering tree, for a given set of fiber tracts. We then link these three representations using both interaction and color obtained by embedding fiber tracts into a perceptually uniform color space. We describe an anecdotal evaluation with neuroscientists to assess the usefulness of our method in exploring anatomical and functional structures in the brain. Expert feedback indicates that, while a standalone clinical use of the proposed method would require anatomical landmarks in the lower dimensional representations, the approach would be particularly useful in accelerating tract bundle selection. Results also suggest that combining traditional 3D model viewing with lower dimensional representations can ease navigation through the complex fiber tract models, improving exploration of the connectivity in the brain.	Jianu, R.;Demiralp, C.;Laidlaw, D.H.	Brown Univ., Providence, RI, USA|c|;;	37887934300;38201834500;37275712600
	InfoVis+SciVis	Nov.-Dec. 2009	Coloring 3D Line Fields Using Boy&#x02019;s Real Projective Plane Immersion	10.1109/TVCG.2009.125	http://dx.doi.org/10.1109/TVCG.2009.125	1457	1464	5290761	biodiffusion;biomedical MRI;brain;computational geometry;data visualisation;image colour analysis;medical image processing	3D line field coloring;Boy's surface real projective plane immersion;DTI brain data set visualization;RP2;diffusion tensor magnetic resonance imaging;double curve;measure zero set	Biomedical engineering;Biomedical imaging;Computer vision;Data engineering;Data visualization;Diffusion tensor imaging;Magnetic field measurement;Materials science and technology;Physics;Tensile stress	DTI.;Line field;colormapping;orientation;real projective plane;tensor field	We introduce a new method for coloring 3D line fields and show results from its application in visualizing orientation in DTI brain data sets. The method uses Boy's surface, an immersion of RP2 in 3D. This coloring method is smooth and one-to-one except on a set of measure zero, the double curve of Boy's surface.	Demiralp, C.;Hughes, J.F.;Laidlaw, D.H.	Brown Univ., Providence, RI, USA|c|;;	38201834500;38246811200;37275712600
	InfoVis+SciVis	12-13 Oct. 2009	Interactive visual clustering of large collections of trajectories	10.1109/VAST.2009.5332584	http://dx.doi.org/10.1109/VAST.2009.5332584	3	10	5332584	data visualisation;interactive systems;pattern clustering	computationally intensive clustering algorithms;data clustering;interactive visual clustering;interactive visual interface	Clustering algorithms;Clustering methods;Data visualization;Functional analysis;Humans;Information analysis;Information systems;Joining processes;Scalability;Spatiotemporal phenomena	Spatio-temporal data;classification;clustering;geovisualization;movement data;scalable visualization;trajectories	One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.	Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.	Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;;	37283047100;37283047700;37670571400;37669195900;37394413600;37268539100
	InfoVis+SciVis	12-13 Oct. 2009	Proximity-based visualization of movement trace data	10.1109/VAST.2009.5332593	http://dx.doi.org/10.1109/VAST.2009.5332593	11	18	5332593	data visualisation;video cameras	motion sensor;proximity-based visualization;video camera	Availability;Cameras;Concrete;Data visualization;Hazards;Motion analysis;Multidimensional systems;Pattern analysis;Principal component analysis;Visual analytics	Spatio-temporal visualization;linked views;movement patterns;principal component analysis;proximity;temporal trajectories	The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.	Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;;	37597152500;37299311900;37282925900;37275869400
	InfoVis+SciVis	12-13 Oct. 2009	Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates	10.1109/VAST.2009.5332586	http://dx.doi.org/10.1109/VAST.2009.5332586	19	26	5332586	data visualisation;geophysics computing;regression analysis;storms;visual databases	correlation analysis;descriptive statistical calculation;hurricane trends analysis;interactive multivariate representations;interactive parallel coordinates;interactive visual analysis capabilities;multidimensional data explorer;statistical regression	Computer interfaces;Data analysis;Data visualization;Hurricanes;Multidimensional systems;Performance analysis;Physics computing;Regression analysis;Statistical analysis;Weather forecasting	Climate study;correlation;interaction;multivariate data;regression;statistical analysis;visual analytics	This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system's utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.	Steed, C.A.;Swan, J.E.;Jankun-Kelly, T.J.;Fitzpatrick, P.J.	Naval Res. Lab., Orlando, FL, USA|c|;;;	37396434400;37295140400;37399870300;37267202400
	InfoVis+SciVis	12-13 Oct. 2009	Finding comparable temporal categorical records: A similarity measure with an interactive visualization	10.1109/VAST.2009.5332595	http://dx.doi.org/10.1109/VAST.2009.5332595	27	34	5332595	data visualisation;information retrieval;interactive systems;temporal databases;time series;very large databases	M&M measure;Match & Mismatch measure;Similan;interactive search tool;interactive visualization tool;large databases;numerical time series;parameters customization;similarity measure;temporal categorical databases;temporal categorical records	Educational institutions;Feedback;Medical services;Particle measurements;Testing;Time measurement;Transportation;Usability;Visual databases;Visualization	M&M Measure;Similan;Similarity Search;Temporal Categorical Records	An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher's intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M&M (Match & Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M&M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M&M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M&M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants.	Wongsuphasawat, K.	Dept. of Comput. Sci. & Human-Comput. Interaction Lab., Univ. of Maryland, College Park, MD, USA|c|	37670523200
	InfoVis+SciVis	12-13 Oct. 2009	A visual analytics system for radio frequency fingerprinting-based localization	10.1109/VAST.2009.5332596	http://dx.doi.org/10.1109/VAST.2009.5332596	35	42	5332596	data analysis;data visualisation;graphical user interfaces;indoor radio;radio direction-finding	computational data analysis;graphical user interface;interactive visualisation;reliable radio frequency fingerprinting-based localization;ubiquitous indoor positioning system;visual analytics system	Debugging;Electronic mail;Fingerprint recognition;Global Positioning System;RF signals;Radio frequency;Receivers;Satellite broadcasting;Signal generators;Visual analytics	D.2.5 [Testing and Debugging]: Debugging aids—;H.5.2 [User Interfaces]: Graphical user interfaces (GUI)—	Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user's current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system.	Yi Han;Stuntebeck, E.P.;Stasko, J.T.;Abowd, G.D.	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	37677711000;37670091600;37267736900;38261901100
	InfoVis+SciVis	12-13 Oct. 2009	Geovisual analytics for self-organizing network data	10.1109/VAST.2009.5332610	http://dx.doi.org/10.1109/VAST.2009.5332610	43	50	5332610	Internet;cellular radio;data visualisation;self-organising feature maps;telecommunication computing;telecommunication network management	Ericsson;Web-enabled geovisual analytics approach;automatic algorithms;automatic neighbor relations algorithm;cellular radio network management;selforganizing network data	Algorithm design and analysis;Data analysis;Data visualization;Filtering;Information analysis;Large-scale systems;Pattern analysis;Self-organizing networks;Testing;Visual analytics	Geovisual analytics;geospatial data sets;multi-dimensional;multi-layer;self-organizing network;time-varying;visualization	Cellular radio networks are continually growing in both node count and complexity. It therefore becomes more difficult to manage the networks and necessary to use time and cost effective automatic algorithms to organize the networks neighbor cell relations. There have been a number of attempts to develop such automatic algorithms. Network operators, however, may not trust them because they need to have an understanding of their behavior and of their reliability and performance, which is not easily perceived. This paper presents a novel Web-enabled geovisual analytics approach to exploration and understanding of self-organizing network data related to cells and neighbor cell relations. A demonstrator and case study are presented in this paper, developed in close collaboration with the Swedish telecom company Ericsson and based on large multivariate, time-varying and geospatial data provided by the company. It allows the operators to follow, interact with and analyze the evolution of a self-organizing network and enhance their understanding of how an automatic algorithm configures locally-unique physical cell identities and organizes neighbor cell relations of the network. The geovisual analytics tool is tested with a self-organizing network that is operated by the automatic neighbor relations (ANR) algorithm. The demonstrator has been tested with positive results by a group of domain experts from Ericsson and will be tested in production.	Ho Van Quan;Astrom, T.;Jern, M.	Dept. of Sci. & Technol., Linkoping Univ., Linkoping, Sweden|c|;;	;37669906900;37283245900
	InfoVis+SciVis	12-13 Oct. 2009	A framework for uncertainty-aware visual analytics	10.1109/VAST.2009.5332611	http://dx.doi.org/10.1109/VAST.2009.5332611	51	58	5332611	data visualisation;decision making;statistical analysis	data collections;data transformations;decision making;numerous statistical tools;uncertainty-aware visual analytics	Blogs;Data analysis;Data visualization;Decision making;Humans;Principal component analysis;Sampling methods;Statistical analysis;Uncertainty;Visual analytics	Data Transformations;Model Fitting;Principal Component Analysis;Uncertainty	Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.	Correa, C.;Yu-Hsuan Chan;Kwan-Liu Ma	Univ. of California at Davis, Davis, CA, USA|c|;;	37282925900;37593323300;37275869400
	InfoVis+SciVis	12-13 Oct. 2009	Combining automated analysis and visualization techniques for effective exploration of high-dimensional data	10.1109/VAST.2009.5332628	http://dx.doi.org/10.1109/VAST.2009.5332628	59	66	5332628	data analysis;data visualisation;information retrieval	automated analysis techniques;automated visualization techniques;interactive data analysis;lower-dimensional representations;nonclass-based parallel coordinates visualizations;nonclass-based scatterplots coordinates visualizations	Business;Coordinate measuring machines;Data mining;Data visualization;Displays;Image retrieval;Image storage;Information retrieval;Scattering;Visual analytics	H.3.3 [Information Storage and Retrieval];Information Search and Retrieval I.3.3 [Computer Graphics];Picture/Image Generation	Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.	Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;	37590724000;37603943800;37546817000;37669961800;37266875400;37273816400;37283138700
	InfoVis+SciVis	12-13 Oct. 2009	Two-stage framework for visualization of clustered high dimensional data	10.1109/VAST.2009.5332629	http://dx.doi.org/10.1109/VAST.2009.5332629	67	74	5332629	data visualisation;pattern clustering;principal component analysis	2D visualization;high dimensional clustered data;linear discriminant analysis;principal component analysis;reduced dimensional data;supervised dimension reduction	Algorithm design and analysis;Data visualization;Drives;Educational institutions;Information analysis;Laboratories;Linear discriminant analysis;Principal component analysis;Scattering;Visual analytics	2D projection;clustered data;dimension reduction;generalized singular value decomposition;linear discriminant analysis;orthogonal centroid method;principal component analysis;regularization	In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets.	Jaegul Choo;Bohn, S.;Haesun Park	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	37602784600;37648561300;37277119500
	InfoVis+SciVis	12-13 Oct. 2009	Model space visualization for multivariate linear trend discovery	10.1109/VAST.2009.5333431	http://dx.doi.org/10.1109/VAST.2009.5333431	75	82	5333431	data mining;data visualisation	data space;domain knowledge;linear pattern discovery;model space visualization;multivariate linear trend discovery	Computer science;Data analysis;Data mining;Data visualization;Extraterrestrial phenomena;Navigation;Pattern analysis;Predictive models;Scattering;User interfaces	Knowledge Discovery;model space visualization;multivariate linear model construction;visual analysis	Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.	Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.	Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;	37668783300;37268441700;37279217900
	InfoVis+SciVis	12-13 Oct. 2009	LSAView: A tool for visual exploration of latent semantic modeling	10.1109/VAST.2009.5333428	http://dx.doi.org/10.1109/VAST.2009.5333428	83	90	5333428	data visualisation	LSA model;LSAView;automated processing;impact analysis;latent semantic analysis;latent semantic modeling;linked matrix-graph views;problem solving;rank parameter;scaling parameter;unstructured text data;visual exploration	Application software;Cities and towns;Data analysis;Laboratories;Layout;Matrix decomposition;Natural languages;Problem-solving;USA Councils;Visual analytics	Applications I.2.7 [Computing Methodologies]: Natural Language Processing;I.3.8 [Computing Methodologies]: Computer Graphics;Text analysis	Latent Semantic Analysis (LSA) is a commonly-used method for automated processing, modeling, and analysis of unstructured text data. One of the biggest challenges in using LSA is determining the appropriate model parameters to use for different data domains and types of analyses. Although automated methods have been developed to make rank and scaling parameter choices, these approaches often make choices with respect to noise in the data, without an understanding of how those choices impact analysis and problem solving. Further, no tools currently exist to explore the relationships between an LSA model and analysis methods. Our work focuses on how parameter choices impact analysis and problem solving. In this paper, we present LSAView, a system for interactively exploring parameter choices for LSA models. We illustrate the use of LSAView's small multiple views, linked matrix-graph views, and data views to analyze parameter selection and application in the context of graph layout and clustering.	Crossno, P.J.;Dunlavy, D.M.;Shead, T.M.	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;	37282576500;37673263800;37681611000
	InfoVis+SciVis	12-13 Oct. 2009	Parallel Tag Clouds to explore and analyze faceted text corpora	10.1109/VAST.2009.5333443	http://dx.doi.org/10.1109/VAST.2009.5333443	91	98	5333443	data mining;data visualisation;text analysis	faceted text corpora;graphical element;parallel coordinate;parallel tag cloud;text mining	Tag clouds	Text visualization;corpus visualization;information retrieval;tag clouds;text mining	Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.	Collins, C.;Viegas, F.B.;Wattenberg, M.	Univ. of Toronto, Toronto, ON, Canada|c|;;	37669874100;37681355300;37550759700
	InfoVis+SciVis	12-13 Oct. 2009	Describing story evolution from dynamic information streams	10.1109/VAST.2009.5333437	http://dx.doi.org/10.1109/VAST.2009.5333437	99	106	5333437	data visualisation;information analysis;information filtering;portals	dynamic information streaming;fundamental visual representation;information analysis;information portals;visual analytics system	Data models;Graphics;Image analysis;Indexing;Information analysis;Joining processes;Laboratories;Portals;Streaming media;Visual analytics	H.3.1 [Content Analysis and Indexing]: Abstracting methods—;H.3.3 [Information Search and Retrieval]: Information Filtering—;H.3.7 [Digital Libraries]: User Issues—;I.3.3 [Computer Graphics]: Picture/Image Generation—	Sources of streaming information, such as news syndicates, publish information continuously. Information portals and news aggregators list the latest information from around the world enabling information consumers to easily identify events in the past 24 hours. The volume and velocity of these streams causes information from prior days to quickly vanish despite its utility in providing an informative context for interpreting new information. Few capabilities exist to support an individual attempting to identify or understand trends and changes from streaming information over time. The burden of retaining prior information and integrating with the new is left to the skills, determination, and discipline of each individual. In this paper we present a visual analytics system for linking essential content from information streams over time into dynamic stories that develop and change over multiple days. We describe particular challenges to the analysis of streaming information and present a fundamental visual representation for showing story change and evolution over time.	Rose, S.;Butner, S.;Cowley, W.;Gregory, M.;Walker, J.	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;	37434158300;38179762500;37672002300;37285562300;37671797700
	InfoVis+SciVis	12-13 Oct. 2009	What&#39;s being said near &#x201C;Martha&#x201D;? Exploring name entities in literary text collections	10.1109/VAST.2009.5333248	http://dx.doi.org/10.1109/VAST.2009.5333248	107	114	5333248	data visualisation;information filtering;linguistics;text analysis;user interfaces;vocabulary	POSvis;automatic entity extraction;character analysis;humanities scholar;literary analysis;literary text collection;name entity;part-of-speech filtering;self-organizing graph;text analysis;user interface;vocabulary;word clouds;word usage	Books;Filters;Graphical user interfaces;Sections;Speech;Tag clouds;Text analysis;User interfaces;Visual analytics;Vocabulary	Design;Experimentation;Human Factors;Visual Analytics	A common task in literary analysis is to study characters in a novel or collection. Automatic entity extraction, text analysis and effective user interfaces facilitate character analysis. Using our interface, called POSvis, the scholar uses word clouds and self-organizing graphs to review vocabulary, to filter by part of speech, and to explore the network of characters located near characters under review. Further, visualizations show word usages within an analysis window (i.e. a book chapter), which can be compared with a reference window (i.e. the whole book). We describe the interface and report on an early case study with a humanities scholar.	Vuillemot, R.;Clement, T.;Plaisant, C.;Kumar, A.	Univ. de Lyon, Lyon, France|c|;;;	37681739300;37299421200;37283026800;37676118300
	InfoVis+SciVis	12-13 Oct. 2009	VAST contest dataset use in education	10.1109/VAST.2009.5333245	http://dx.doi.org/10.1109/VAST.2009.5333245	115	122	5333245	data visualisation;educational technology;information analysis	IEEE visual analytics science and technology;VAST;education;evaluation metrics;information analysts	Application software;Computer science;Computer science education;Data visualization;Educational institutions;Educational technology;Government;Information analysis;Laboratories;Visual analytics	education;evaluation;synthetic data	The IEEE Visual Analytics Science and Technology (VAST) Symposium has held a contest each year since its inception in 2006. These events are designed to provide visual analytics researchers and developers with analytic challenges similar to those encountered by professional information analysts. The VAST contest has had an extended life outside of the symposium, however, as materials are being used in universities and other educational settings, either to help teachers of visual analytics-related classes or for student projects. We describe how we develop VAST contest datasets that results in products that can be used in different settings and review some specific examples of the adoption of the VAST contest materials in the classroom. The examples are drawn from graduate and undergraduate courses at Virginia Tech and from the Visual Analytics ldquoSummer Camprdquo run by the National Visualization and Analytics Center in 2008. We finish with a brief discussion on evaluation metrics for education.	Whiting, M.A.;North, C.;Endert, A.;Scholtz, J.;Haack, J.;Varley, C.;Thomas, J.	;;;;;;	37357067600;37419565900;37681759500;37268671300;37267550400;37678660700;37273308900
	InfoVis+SciVis	12-13 Oct. 2009	Connecting the dots in visual analysis	10.1109/VAST.2009.5333023	http://dx.doi.org/10.1109/VAST.2009.5333023	123	130	5333023	information filtering;information retrieval	Harvest system;Web based visual analytic system;collaborative analysis task;connecting-the-dots process;context based retrieval algorithm;datasets exploration;recommendation feature;visual analysis	Algorithm design and analysis;Collaboration;Context modeling;Data visualization;Heuristic algorithms;Information analysis;Information retrieval;Joining processes;Tag clouds;Visual analytics	H.3.3 [Information Search and Retrieval]—Retrieval models	During visual analysis, users must often connect insights discovered at various points of time. This process is often called ldquoconnecting the dots.rdquo When analysts interactively explore complex datasets over multiple sessions, they may uncover a large number of findings. As a result, it is often difficult for them to recall the past insights, views and concepts that are most relevant to their current line of inquiry. This challenge is even more difficult during collaborative analysis tasks where they need to find connections between their own discoveries and insights found by others. In this paper, we describe a context-based retrieval algorithm to identify notes, views and concepts from users' past analyses that are most relevant to a view or a note based on their line of inquiry. We then describe a related notes recommendation feature that surfaces the most relevant items to the user as they work based on this algorithm. We have implemented this recommendation feature in HARVEST, a Web based visual analytic system. We evaluate the related notes recommendation feature of HARVEST through a case study and discuss the implications of our approach.	Shrinivasan, Y.B.;Gotz, D.;Jie Lu	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;	37681468200;37601397400;37674897500
	InfoVis+SciVis	12-13 Oct. 2009	Capturing and supporting the analysis process	10.1109/VAST.2009.5333020	http://dx.doi.org/10.1109/VAST.2009.5333020	131	138	5333020	authoring languages;data visualisation;graph theory	CzSaw-visual analytics system;dependency graph;document collection;script language;scripting-driven propagation system;user history navigation channel;visual analytics tool;visual representation;visualization	Art;Data visualization;Failure analysis;Graphical user interfaces;History;Information analysis;Logic;Navigation;Pattern analysis;Visual analytics	Analysis Process;Sense-making;Visual Analytics;Visual History	Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw's approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses.	Kadivar, N.;Chen, V.;Dunsmuir, D.;Lee, E.;Qian, C.;Dill, J.;Shaw, C.;Woodbury, R.	Sch. of Interactive Arts & Technol., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;;	37681588600;38182637400;37601085600;37596074400;37595662900;38349149300;37358198200;38181028300
	InfoVis+SciVis	12-13 Oct. 2009	Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study	10.1109/VAST.2009.5333878	http://dx.doi.org/10.1109/VAST.2009.5333878	139	146	5333878	data visualisation;interactive systems	Jigsaw system;interactive visualization;investigative analysis;investigative sensemaking exercise;simulated intelligence analysis task;visual analytics system	Collaborative tools;Collaborative work;Control systems;Data analysis;Data visualization;Electronic mail;Guidelines;Information analysis;Performance analysis;Visual analytics		Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.	Youn-ah Kang;Gorg, C.;Stasko, J.	GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	37673524700;37428446300;37267736900
	InfoVis+SciVis	12-13 Oct. 2009	A multi-level middle-out cross-zooming approach for large graph analytics	10.1109/VAST.2009.5333880	http://dx.doi.org/10.1109/VAST.2009.5333880	147	154	5333880	data visualisation;human computer interaction	GreenHornet system prototype;bottom-up approach;human-visualization interface;information visualization;multilevel middle-out cross-zooming approach;top-down approach;working graph analytics model	Data visualization;Humans;Information analysis;Laboratories;Pattern analysis;Prototypes;Space technology;System testing;Visual analytics;Visual databases	Graph analytics;information visualization	This paper presents a working graph analytics model that embraces the strengths of the traditional top-down and bottom-up approaches with a resilient crossover concept to exploit the vast middle-ground information overlooked by the two extreme analytical approaches. Our graph analytics model is co-developed by users and researchers, who carefully studied the functional requirements that reflect the critical thinking and interaction pattern of a real-life intelligence analyst. To evaluate the model, we implement a system prototype, known as GreenHornet, which allows our analysts to test the theory in practice, identify the technological and usage-related gaps in the model, and then adapt the new technology in their work space. The paper describes the implementation of GreenHornet and compares its strengths and weaknesses against the other prevailing models and tools.	Pak Chung Wong;Mackey, P.;Cook, K.A.;Rohrer, R.M.;Foote, H.;Whiting, M.A.	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;;	37280665600;37550755900;37564931700;37682743100;37372586800;37357067600
	InfoVis+SciVis	12-13 Oct. 2009	Visual analysis of graphs with multiple connected components	10.1109/VAST.2009.5333893	http://dx.doi.org/10.1109/VAST.2009.5333893	155	162	5333893	data visualisation;directed graphs;interactive systems;mathematics computing;pattern clustering;self-organising feature maps	SOM algorithm;graph clustering;interactive feature selection;interactive visualization analysis;multiple connected component;self-organizing-map algorithm;shareholder network analysis problem;task-tailored data;topology descriptor;weighted directed graph data set	Clustering algorithms;Data analysis;Data structures;Data visualization;Displays;Graphics;Image retrieval;Information retrieval;Topology;User interfaces	Clustering H.5.2 [User Interfaces]: Graphical user interfaces (GUI);E.1 [Data Structures]: Graphs and Networks;Picture/Image Generation;[H.3.3]: Information Search and Retrieval;[I.3.3]: COMPUTER GRAPHICS	In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types.	von Landesberger, T.;Gorner, M.;Schreck, T.	Interactive Graphics Syst. Group, Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;	37586276100;37683615400;37282557600
	InfoVis+SciVis	12-13 Oct. 2009	MassVis: Visual analysis of protein complexes using mass spectrometry	10.1109/VAST.2009.5333895	http://dx.doi.org/10.1109/VAST.2009.5333895	163	170	5333895	biology computing;cellular biophysics;mass spectroscopy;pattern clustering;proteins	MassVis;cell biology;mass spectrometry;protein complexes;putative complexes;tandem mass spectrometry;two-dimensional gel techniques;unsupervised clustering;user interaction;visual analysis tool	Biology computing;Data visualization;Electrokinetics;Humans;Information analysis;Laboratories;Mass spectroscopy;Proteins;Proteomics;Scattering	correlation analysis;information visualization;interactome;mass spectrometry;proteomics;visual analysis	Protein complexes are formed when two or more proteins non-covalently interact to form a larger three dimensional structure with specific biological function. Understanding the composition of such complexes is vital to understanding cell biology at the molecular level. MassVis is a visual analysis tool designed to assist the interpretation of data from a new workflow for detecting the composition of such protein complexes in biological samples. The data generated by the laboratory workflow naturally lends itself to a scatter plot visualization. However, characteristics of this data give rise to some unique aspects not typical of a standard scatter plot. We are able to take the output from tandem mass spectrometry and render the data in such a way that it mimics more traditional two-dimensional gel techniques and at the same time reveals the correlated behavior indicative of protein complexes. By computationally measuring these correlated patterns in the data, membership in putative complexes can be inferred. User interactions are provided to support both an interactive discovery mode as well as an unsupervised clustering of likely complexes. The specific analysis tasks led us to design a unique arrangement of item selection and coordinated detail views in order to simultaneously view different aspects of the selected item.	Kincaid, R.;Dejgaard, K.	;	37587984100;37681886500
	InfoVis+SciVis	12-13 Oct. 2009	Using projection and 2D plots to visually reveal genetic mechanisms of complex human disorders	10.1109/VAST.2009.5333917	http://dx.doi.org/10.1109/VAST.2009.5333917	171	178	5333917	data visualisation;diseases;genetics;medical computing;statistical analysis	2D plots;complex human disorders;gene mapping;genetic likelihood space;genetic mechanism visualization;human disease genes;human genome;multidimensional data projection;multidimensional scalar field;radial projection;statistical method	Bioinformatics;Data visualization;Diseases;Genetics;Genomics;Humans;Multidimensional systems;Performance analysis;Space exploration;Statistical analysis	Autism;LD analysis;Linkage Analysis;Linkage disequilibrium;Multidimensional data;PPL;PPLD;Posterior Probability of Linkage;Visualization	Gene mapping is a statistical method used to localize human disease genes to particular regions of the human genome. When performing such analysis, a genetic likelihood space is generated and sampled, which results in a multidimensional scalar field. Researchers are interested in exploring this likelihood space through the use of visualization. Previous efforts at visualizing this space, though, were slow and cumbersome, only showing a small portion of the space at a time, thus requiring the user to keep a mental picture of several views. We have developed a new technique that displays much more data at once by projecting the multidimensional data into several 2D plots. One plot is created for each parameter that shows the change along that parameter. A radial projection is used to create another plot that provides an overview of the high dimensional surface from the perspective of a single point. Linking and brushing between all the plots are used to determine relationships between parameters. We demonstrate our techniques on real world autism data, showing how to visually examine features of the high dimensional space.	Nouanesengsy, B.;Sang-Cheol Seok;Han-Wei Shen;Vieland, V.J.	Battelle Center for Math. Med., Ohio State Univ., Columbus, OH, USA|c|;;;	37570501300;37667195400;37279493500;37681642300
	InfoVis+SciVis	12-13 Oct. 2009	SpRay: A visual analytics approach for gene expression data	10.1109/VAST.2009.5333911	http://dx.doi.org/10.1109/VAST.2009.5333911	179	186	5333911	bioinformatics;genetics;statistical analysis	SpRay;bioinformatics applications;high-dimensional datasets;multidimensional gene expression datasets;parallel coordinates;statistical methods;visual analytics approach;visual exploration	Application software;Bioinformatics;Computer graphics;Data analysis;Data visualization;Gene expression;Spraying;Statistical analysis;Terminology;Visual analytics	Visual analytics;bioinformatics;gene expression experiments;large-scale microarray;microarray data	We present a new application, SpRay, designed for the visual exploration of gene expression data. It is based on an extension and adaption of parallel coordinates to support the visual exploration of large and high-dimensional datasets. In particular, we investigate the visual analysis of gene expression data as generated by micro-array experiments; We combine refined visual exploration with statistical methods to a visual analytics approach that proved to be particularly successful in this application domain. We will demonstrate the usefulness on several multidimensional gene expression datasets from different bioinformatics applications.	Dietzsch, J.;Heinrich, J.;Nieselt, K.;Bartz, D.	ZBIT, Univ. of Tubingen, Tubingen, Germany|c|;;;	37662554400;37665271000;37681805000;37448237300
	InfoVis+SciVis	12-13 Oct. 2009	Visual opinion analysis of customer feedback data	10.1109/VAST.2009.5333919	http://dx.doi.org/10.1109/VAST.2009.5333919	187	194	5333919	Internet;Web sites;customer satisfaction;data visualisation	Web sites;customer feedback data;customer satisfaction;discrimination-based technique;high-dimensional feature vectors;interactive circular correlation map;product reviews;real-world online stores;reverse-distance-weighting method;visual opinion analysis	Customer satisfaction;Customer service;Data visualization;Feedback;Information resources;Laboratories;Manufacturing;Pattern analysis;Text analysis;Visual analytics	Attribute Extraction;Visual Document Analysis;Visual Opinion Analysis;Visual Sentiment Analysis	Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.	Oelke, D.;Ming Hao;Rohrdantz, C.;Keim, D.A.;Dayal, U.;Haug, L.;Janetzko, H.	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;	37591207400;37274264300;37601356700;37283138700;37275646700;37681663300;37594026300
	InfoVis+SciVis	12-13 Oct. 2009	FinVis: Applied visual analytics for personal financial planning	10.1109/VAST.2009.5333920	http://dx.doi.org/10.1109/VAST.2009.5333920	195	202	5333920	data visualisation;decision making;financial management;investment	FinVis software;applied visual analytics tool;financial data;financial decision-making;inter-temporal data;personal financial planning;portfolio diversification	Application software;Data analysis;Decision making;Displays;Finance;Financial management;Instruments;Investments;Portfolios;Visual analytics	Casual Information Visualization;economic decision-making;personal finance;visual analytics;visualization of risk	FinVis is a visual analytics tool that allows the non-expert casual user to interpret the return, risk and correlation aspects of financial data and make personal finance decisions. This interactive exploratory tool helps the casual decision-maker quickly choose between various financial portfolio options and view possible outcomes. FinVis allows for exploration of inter-temporal data to analyze outcomes of short-term or long-term investment decisions. FinVis helps the user overcome cognitive limitations and understand the impact of correlation between financial instruments in order to reap the benefits of portfolio diversification. Because this software is accessible by non-expert users, decision-makers from the general population can benefit greatly from using FinVis in practical applications. We quantify the value of FinVis using experimental economics methods and find that subjects using the FinVis software make better financial portfolio decisions as compared to subjects using a tabular version with the same information. We also find that FinVis engages the user, which results in greater exploration of the dataset and increased learning as compared to a tabular display. Further, participants using FinVis reported increased confidence in financial decision-making and noted that they were likely to use this tool in practical application.	Rudolph, S.;Savikhin, A.;Ebert, D.S.	Purdue Univ. Regional Visualization & Analytics Center (PURVAC), West Lafayette, IN, USA|c|;;	37396006000;37681662800;38472156400
	InfoVis+SciVis	12-13 Oct. 2009	Iterative integration of visual insights during patent search and analysis	10.1109/VAST.2009.5333564	http://dx.doi.org/10.1109/VAST.2009.5333564	203	210	5333564	information analysis;information retrieval;patents	PatViz;complex query languages;economic factor;globalized markets;interactive analysis;iterative integration;iterative query refinement;patent document retrieval;patent information analysis;patent information retrieval;patent material;patent search;visual analytics system;visual insight;visual query module;visual query representation	Companies;Database languages;Environmental economics;Information analysis;Information retrieval;Intellectual property;Interactive systems;Iterative methods;Visual analytics;Visualization	Patent retrieval;information visualization;multiple coordinated views;visual analytics	Patents are an important economic factor in todays globalized markets. Therefore, the analysis of patent information has become an inevitable task for a variety of interest groups. The retrieval of relevant patent information is an integral part of almost every patent analysis scenario. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. With `PatViz', a new system for interactive analysis of patent information has been developed to leverage iterative query refinement. PatViz supports users in building complex queries visually and in exploring patent result sets interactively. Thereby, the visual query module introduces an abstraction layer that provides uniform access to different retrieval systems and relieves users of the burden to learn different complex query languages. By establishing an integrated environment it allows for interactive reintegration of insights gained from visual result set exploration into the visual query representation. We expect that the approach we have taken is also suitable to improve iterative query refinement in other Visual Analytics systems.	Koch, S.;Bosch, H.;Giereth, M.;Ertl, T.	Visualization & Interactive Syst. Group, Univ. Stuttgart, Stuttgart, Germany|c|;;;	37593029700;37683989300;37681276000;37268023800
	InfoVis+SciVis	12-13 Oct. 2009	Analysis of community-contributed space- and time-referenced data (example of flickr and panoramio photos)	10.1109/VAST.2009.5333472	http://dx.doi.org/10.1109/VAST.2009.5333472	213	214	5333472	image processing	flickr;geographical space;panoramio photos;space-referenced data;spatio-temporal events;time-referenced data	Advertising;Cities and towns;Clustering algorithms;Earth;Humans;Mobile handsets;Pattern analysis;Spatiotemporal phenomena;Trajectory;Visualization		Space- and time-referenced data published on the Web by general people can be viewed in a dual way: as independent spatio-temporal events and as trajectories of people in the geographical space. These two views suppose different approaches to the analysis, which can yield different kinds of valuable knowledge about places and about people. We define possible types of analysis tasks related to the two views of the data and present several analysis methods appropriate for these tasks. The methods are suited to large amounts of the data.	Andrienko, G.;Andrienko, N.;Bak, P.;Kisilevich, S.;Keim, D.	Fraunhofer Inst. IAIS, Univ. of Bonn, Bonn, Germany|c|;;;;	37283047100;37283047700;37392085400;37392087800;37283138700
	InfoVis+SciVis	12-13 Oct. 2009	Interactive poster: A proposal for sharing user requirements for visual analytic tools	10.1109/VAST.2009.5333474	http://dx.doi.org/10.1109/VAST.2009.5333474	215	216	5333474	data mining;data visualisation;software tools;user interfaces	user requirement sharing;user-centered evaluation;visual analytic tools	Best practices;Information analysis;Law enforcement;Medical services;Personnel;Proposals;Social network services;User interfaces;Visual analytics;Visualization	user requirements;user-centered evaluation;visual analytics	Although many in the community have advocated user-centered evaluations for visual analytic environments, a significant barrier exists. The users targeted by the visual analytics community (law enforcement personnel, professional information analysts, financial analysts, health care analysts, etc.) are often inaccessible to researchers. These analysts are extremely busy and their work environments and data are often classified or at least confidential. Furthermore, their tasks often last weeks or even months. It is simply not feasible to do such long-term observations to understand their jobs. How then can we hope to gather enough information about the diverse user populations to understand their needs? Some researchers, including the author, have been successful in getting access to specific end-users. A reasonable approach, therefore, would be to find a way to share user information. This work outlines a proposal for developing a handbook of user profiles for use by researchers, developers, and evaluators.	Scholtz, J.	Pacific Northwest Nat. Lab., Rockaway Beach, OR, USA|c|	37268671300
	InfoVis+SciVis	12-13 Oct. 2009	Working memory load as a novel tool for evaluating visual analytics	10.1109/VAST.2009.5333468	http://dx.doi.org/10.1109/VAST.2009.5333468	217	218	5333468	user interfaces	cognitive resources;criterion validation;evaluation criterion;human cognition;visual analytics;working memory load	Cognition;Data analysis;Data visualization;Feedback;Humans;Laboratories;Process design;Testing;Uncertainty;Visual analytics	Visual analytics;cognitive load;evaluation	The current visual analytics literature highlights design and evaluation processes that are highly variable and situation dependent, which raises at least two broad challenges. First, lack of a standardized evaluation criterion leads to costly re-designs for each task and specific user community. Second, this inadequacy in criterion validation raises significant uncertainty regarding visualization outputs and their related decisions, which may be especially troubling in high consequence environments like those of the intelligence community. As an attempt to standardize the ldquoapples and orangesrdquo of the extant situation, we propose the creation of standardized evaluation tools using general principles of human cognition. Theoretically, visual analytics enables the user to see information in a way that should attenuate the user's memory load and increase the user's task-available cognitive resources. By using general cognitive abilities like available working memory resources as our dependent measures, we propose to develop standardized evaluative capabilities that can be generalized across contexts, tasks, and user communities.	Dornburg, C.C.;Matzen, L.E.;Bauer, T.L.;McNamara, L.A.	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;	37681577100;37681577000;37665492000;37681575600
	InfoVis+SciVis	12-13 Oct. 2009	Comparing two interface tools in performing visual analytics tasks	10.1109/VAST.2009.5333469	http://dx.doi.org/10.1109/VAST.2009.5333469	219	220	5333469	data visualisation;graphical user interfaces	captured coarse-grained interactive behaviors;completion times;floating text-based menu;genomic visualization;interactive icon;interface tools;task errors;visual analytics	Art;Bioinformatics;Cognition;Data visualization;Genomics;Humans;Organisms;Performance analysis;Phylogeny;Visual analytics		In visual analytics, menu systems are commonly adopted as supporting tools because of the complex nature of data. However, it is still unknown how much the interaction implicit to the interface impacts the performance of visual analysis. To show the effectiveness of two interface tools, one a floating text-based menu (Floating Menu) and the other a more interactive iconic tool (Interactive-Icon), we evaluated the use and human performance of both tools within one highly interactive visual analytics system. We asked participants to answer similarly constructed, straightforward questions in a genomic visualization, first with one tool, and then the other. During task performance we tracked completion times, task errors, and captured coarse-grained interactive behaviors. Based on the participants accuracy, speed, behaviors and post-task qualitative feedback, we observed that although the Interactive-Icon tool supports continuous interactions, task-oriented user evaluation did not find a significant difference between the two tools because there is a familiarity effect on the performance of solving the task questions with using Floating-Menu interface tool.	Dong Hyun Jeong;Green, T.M.;Ribarsky, W.;Chang, R.	Charlotte Visualization Center, UNC Charlotte, Charlotte, NC, USA|c|;;;	37400451800;37403562900;37300425000;37592409400
	InfoVis+SciVis	12-13 Oct. 2009	A scalable architecture for visual data exploration	10.1109/VAST.2009.5333451	http://dx.doi.org/10.1109/VAST.2009.5333451	221	222	5333451	computer displays;data visualisation;graphical user interfaces;security;visual databases	component-based visualization architecture;coordinated multiple views;data layer;data set dimensionality reduction;defense security;geospatial event databases;homeland security;intelligence analysts;massive data stores;multi-monitor tiled display;parallel coordinates;principal components plots;scalable architecture;single laptop screen;visual data exploration	Data analysis;Data visualization;Displays;Information analysis;Laboratories;Principal component analysis;Risk analysis;Scalability;Terrorism;Visual analytics	Coordiated Multiple Views;Ultrascale Visualization;Visual Analytics	Intelligence analysts in the areas of defense and homeland security are now faced with the difficult problem of discerning the relevant details amidst massive data stores. We propose a component-based visualization architecture that is built specifically to encourage the flexible exploration of geospatial event databases. The proposed system is designed to deploy on a variety of display layouts, from a single laptop screen to a multi-monitor tiled-display. By utilizing a combination of parallel coordinates, principal components plots, and other data views, analysts may reduce the dimensionality of a data set to its most salient features. Of particular value to our target applications are understanding correlations between data layers, both within a single view and across multiple views. Our proposed system aims to address the limited scalability associated with coordinated multiple views (CMVs) through the implementation of an efficient core application which is extensible by the end-user.	Decker, J.;Godwin, A.;Livingston, M.A.;Royle, D.	;;;	37681593700;37593027200;37300434300;37678970200
	InfoVis+SciVis	12-13 Oct. 2009	Interactive visual analysis of location reporting patterns	10.1109/VAST.2009.5333453	http://dx.doi.org/10.1109/VAST.2009.5333453	223	224	5333453	data visualisation;interactive systems;very large databases	color coding;interactive visual analysis;large time-series dataset;location reporting pattern	Automotive engineering;Computer science;Data analysis;Design engineering;Failure analysis;Pattern analysis;Sensor systems;Time series analysis;Vehicles;Visualization		Interactive visualization methods are often used to aid in the analysis of large datasets. We present a novel interactive visualization technique designed specifically for the analysis of location reporting patterns within large time-series datasets. We use a set of triangles with color coding to indicate the time between location reports. This allows reporting patterns (expected and unexpected) to be easily discerned during interactive analysis. We discuss the details of our method and describe evaluation both from expert opinion and from a user study.	Overby, D.;Keyser, J.;Wall, J.	Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX, USA|c|;;	37586886600;37282588300;38225331100
	InfoVis+SciVis	12-13 Oct. 2009	Reordered tilebars for visual text exploration	10.1109/VAST.2009.5333436	http://dx.doi.org/10.1109/VAST.2009.5333436	225	226	5333436	graphical user interfaces;information retrieval;text analysis;visual databases	TileBars;barycenter heuristic;bigraph crossing minimization;distribution information;full-text documents;query terms;visual presentation;visual text exploration	Bars;Bipartite graph;Frequency;Navigation;Ontologies;Pattern analysis;Prototypes;Smoothing methods;User interfaces;Visual analytics	Graphical user interfaces;H.5.2 [Information interfaces and presentation]: User Interfaces	The classic TileBars paradigm has been used to show distribution information of query terms in full-text documents. However, when the number of query terms becomes large, it is not an easy task for users to comprehend their distribution within certain parts of a document. In this paper, we present a novel approach to improve the visual presentation of TileBars, in which barycenter heuristic for bigraph crossing minimization is used to reorder TileBars elements. The reordered TileBars can be demonstrated to provide users with better focus and navigation while exploring text documents.	VinhTuan Thai;Handschuh, S.	Digital Enterprise Res. Inst., Nat. Univ. of Ireland, Galway, Ireland|c|;	37667058500;37661704100
	InfoVis+SciVis	12-13 Oct. 2009	Visual knowledge exploration and discovery from different points of view	10.1109/VAST.2009.5333438	http://dx.doi.org/10.1109/VAST.2009.5333438	227	228	5333438	data mining;data visualisation;decision making;information retrieval;ontologies (artificial intelligence)	decision making;domain ontologies;heterogeneous data analysis;interactive graph visualisation;knowledge retrieval;knowledge-intensive organisations;visual knowledge discovery;visual knowledge exploration	Assembly systems;Bicycles;Computer science;Decision making;Failure analysis;Information analysis;Information retrieval;Ontologies;Project management;Visualization	H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical user interfaces (GUI);K.6.1 [Management of Computing and Information Systems]: Project and People Management—Life Cycle	Complex scenario analysis requires the exploration of multiple hypotheses and supporting evidence for each argument posed. Knowledge-intensive organisations typically analyse large amounts of inter-related, heterogeneous data to retrieve the knowledge this contains and use it to support effective decision-making. We demonstrate the use of interactive graph visualisation to support hierarchical, task-driven, hypothesis investigation. The visual investigative analysis is guided by task and domain ontologies used to capture the structure of the investigation process and the experience gained and knowledge created in previous, related investigations.	Dadzie, A.-S.;Petrelli, D.	Dept. of Inf. Studies, Univ. of Sheffield, Sheffield, UK|c|;	37681297400;37681293700
	InfoVis+SciVis	12-13 Oct. 2009	Poster: Visual prediction of time series	10.1109/VAST.2009.5333420	http://dx.doi.org/10.1109/VAST.2009.5333420	229	230	5333420	data visualisation;smoothing methods;time series	multiscaling technique;smoothing technique;time series prediction methods;visual analysis techniques;weighted average technique	Energy consumption;History;Humans;Marketing and sales;Pattern analysis;Pipelines;Prediction methods;Smoothing methods;Supply chains;Time series analysis		Many well-known time series prediction methods have been used daily by analysts making decisions. To reach a good prediction, we introduce several new visual analysis techniques of smoothing, multi-scaling, and weighted average with the involvement of human expert knowledge. We combine them into a well-fitted method to perform prediction. We have applied this approach to predict resource consumption in data center for next day planning.	Hao, M.C.;Janetzko, H.;Sharma, R.K.;Dayal, U.;Keim, D.A.;Castellanos, M.	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;	37274264300;37594026300;37276219200;38319940200;37283138700;37270303500
	InfoVis+SciVis	12-13 Oct. 2009	ProcessLine: Visualizing time-series data in process industry	10.1109/VAST.2009.5333421	http://dx.doi.org/10.1109/VAST.2009.5333421	231	232	5333421	brewing industry;data visualisation;production engineering computing;time series	ProcessLine;beer industry production data;interactive visualization tool;process industry;production process;time-series data visualization	Beverage industry;Data analysis;Data visualization;Logistics;Manufacturing industries;Manufacturing processes;Production;Testing;Time series analysis;Visual analytics	Business visualization;Time-series data;Visual analytics;Visual design	In modern process industry, it is often difficult to analyze a manufacture process due to its numerous time-series data. Analysts wish to not only interpret the evolution of data over time in a working procedure, but also examine the changes in the whole production process through time. To meet such analytic requirements, we have developed ProcessLine, an interactive visualization tool for a large amount of time-series data in process industry. The data are displayed in a fisheye timeline. ProcessLine provides good overviews for the whole production process and details for the focused working procedure. A preliminary user study using beer industry production data has shown that the tool is effective.	Xiongfei Luo;Hongan Wang;Feng Tian;Wei Liu;Dongxing Teng;Guozhong Dai	Chinese Acad. of Sci., Grad. Univ., Beijing, China|c|;;;;;	37670411800;37280094700;37668467300;37656059500;37553445200;37274248100
	InfoVis+SciVis	12-13 Oct. 2009	Articulate: a conversational interface for visual analytics	10.1109/VAST.2009.5333099	http://dx.doi.org/10.1109/VAST.2009.5333099	233	234	5333099	data visualisation;natural language processing;speech-based user interfaces	articulate;conversational user interface;heuristics;natural language processing;semiautomated visual analytic model;visualization tools	Data visualization;Electronic mail;Graphics;Laboratories;Natural language processing;Natural languages;Speech recognition;Sun;User interfaces;Visual analytics	Graphical user interfaces;H.5.2 [Information Interfaces and Presentation]: User Interfaces	While many visualization tools exist that offer sophisticated functions for charting complex data, they still expect users to possess a high degree of expertise in wielding the tools to create an effective visualization. This poster presents Articulate, an attempt at a semi-automated visual analytic model that is guided by a conversational user interface. The goal is to relieve the user of the physical burden of having to directly craft a visualization through the manipulation of a complex user-interface, by instead being able to verbally articulate what the user wants to see, and then using natural language processing and heuristics to semi-automatically create a suitable visualization.	Yiwen Sun;Leigh, J.;Johnson, A.;Chau, D.	Electron. Visualization Lab., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;;	37633211900;37284238900;37270146700;37682410500
	InfoVis+SciVis	12-13 Oct. 2009	BEADS: High dimensional data cluster visualization	10.1109/VAST.2009.5333417	http://dx.doi.org/10.1109/VAST.2009.5333417	235	236	5333417	data visualisation;pattern clustering	2D shape representation;BEADS;beads shape identification;cluster division component;cluster shape composition;high dimensional data cluster visualization;shape 2-D representation	Clustering algorithms;Computer displays;Data engineering;Data visualization;Image representation;Partitioning algorithms;Shape;Testing		In this poster paper, we present BEADS, a high dimensional data cluster visualization by having a 2-D representation of shape and spread of the cluster. The Cluster Division component, the Bead Shape Identification and Cluster Shape Composition form the core of the system. BEADS visualization consists of a 2-D plot, standard 2-D shapes which are used as metaphors to represent corresponding high-dimensional shapes of beads. The final resulting images convey the relative placement of beads with respect to the cluster center, the shape of the beads. We give a textual summary of the beads and their 2-D placement on the Beads plot in tabular format along with the image.	Vadapalli, S.;Karlapalem, K.	Centre for Data Eng., Int. Inst. of Inf. Technol.-Hyderabad, Hyderabad, India|c|;	37681354900;37281960300
	InfoVis+SciVis	12-13 Oct. 2009	Interactive poster: Interactive multiobjective optimization - a new application area for visual analytics	10.1109/VAST.2009.5333081	http://dx.doi.org/10.1109/VAST.2009.5333081	237	238	5333081	decision making;optimisation;problem solving;user interfaces	complex problem solving;expert decision maker;interactive multiobjective optimization;multiple criteria decision making;user interface development;visual analytics	Analytical models;Collaboration;Constraint optimization;Decision making;Information analysis;Iterative methods;Mathematical model;Problem-solving;User interfaces;Visual analytics	Interactive multiobjective optimization;information visualization;interaction design;visual analytics	The poster introduces interactive multiobjective optimization (IMO) as a field offering new application possibilities and challenges for visual analytics (VA), and aims at inspiring collaboration between the two fields. Our aim is to collect new ideas in order to be able to utilize VA techniques more effectively in our user interface development. Simulation-based IMO methods are developed for complex problem solving, where the expert decision maker (analyst) should be supported during the iterative process of eliciting preference information and examining the resulting output data. IMO is a subfield of multiple criteria decision making (MCDM). In simulation-based IMO, the optimization task is formulated in a mathematical model containing several conflicting objectives and constraints depending on decision variables. While using IMO methods the analyst progressively provides preference information in order to find the most satisfactory compromise between the conflicting objectives. In the poster, the implementations of two new IMO methods are used as examples to demonstrate concrete challenges of interaction design. One of them is described in this summary.	Tarkkanen, S.;Miettinen, K.;Hakanen, J.	Dept. of Math. Inf. Technol., Univ. of Jyvaskyla, Jyvaskyla, Finland|c|;;	37681626500;37546691200;37681627000
	InfoVis+SciVis	12-13 Oct. 2009	Poster: Icexplorer: Studying Great Lakes Ice cover	10.1109/VAST.2009.5333082	http://dx.doi.org/10.1109/VAST.2009.5333082	239	240	5333082	data analysis;data visualisation;geophysics computing;glaciology;ice;lakes	IceXplorer;Lake Erie;advancing scientific research;automated data analysis;great lakes ice atlas;great lakes ice cover;interaction technique;visualization technique	Animation;Data analysis;Data visualization;Educational institutions;Histograms;Ice;Information systems;Lakes;Solids;User interfaces	Earth and atmospheric sciences H.4.3 [Information systems applications]: Communications Applications;Graphical user interfaces, Interaction styles;Information browsers H.5.2 [Information interfaces and presentation]: User interfaces;J.2 [Physical sciences and engineering]	IceXplorer is a tool for analyzing variations in ice cover on Lake Erie. It enhances the data and pre-packaged analysis currently available in the great lakes ice atlas and serves as an example of a small, focused application where simple but carefully-chosen visualizations, interaction techniques, and automated data analysis are combined to create an effective tool for advancing scientific research.	Bridgeman, S.	Hobart & William Smith Colleges, Hobart, IN, USA|c|	37683002000
	InfoVis+SciVis	12-13 Oct. 2009	VAST 2009 challenge: An insider threat	10.1109/VAST.2009.5334454	http://dx.doi.org/10.1109/VAST.2009.5334454			5334454	data visualisation;graphical user interfaces	VAST 2009 challenge;cyber analytics;geospatial information;human information interaction;network traffic data;security video;social network;visual analytics	Computer network management;Computer security;Data security;Information analysis;Information security;National security;Social network services;Telecommunication traffic;Visual analytics	contest;evaluation;human information interaction;metrics;sense making;visual analytics		Grinstein, G.	Univ. of Massachusetts, Lowell, MA, USA|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Timeline analysis of undercover activities VAST 2009 traffic mini challenge award: Good analytical technique	10.1109/VAST.2009.5334460	http://dx.doi.org/10.1109/VAST.2009.5334460			5334460	data mining;data visualisation;telecommunication traffic	Timeliner;badge;network traffic data;timeline analysis;undercover activities;visualization tool	Visual analytics	H.1.2 [Information Systems]: User/Machine Systems—Human information processing;H.2.8 [Database Management]: Database Applications—Data mining	Our visualization tool for the VAST 2009 traffic mini challenge, Timeliner, visualizes badge and network traffic data together in a single timeline. The two views of per-employee and per-day with various filtering interactions enable users to analyze easily employees activities at a particular moment of interest as well as their general daily patterns. Using Timeliner, we present several hypotheses for the task at hand and their validation processes, which reveals various aspects of the data.	Jaegul Choo	Georgia Inst. of Technol., Atlanta, GA, USA|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Solving the traffic and flitter challenges with tulip	10.1109/VAST.2009.5334456	http://dx.doi.org/10.1109/VAST.2009.5334456			5334456	business communication;computational geometry;data visualisation;encoding;graph theory;graphical user interfaces;query processing;social networking (online);time series	2009 VAST contest;Tulip graph drawing software;badge traffic;candidate network traffic;embassy leak;employee suspicious transmission;flitter challenge;geospatial challenge;graph visualization system;social network;time series encoding;traffic challenge;visual query generator interface	Computer interfaces;Computer networks;Encoding;Information systems;Social network services;Software algorithms;Telecommunication traffic;Visualization	F.2.2 [Theory of Computation]: Nonnumerical Algorithms and Problems—Pattern matching;H.5.0 [Information Systems]: Information Interfaces and Presentation—General	We present our visualization systems and findings for the badge and network traffic as well as the social network and geospatial challenges of the 2009 VAST contest. The summary starts by presenting an overview of our time series encoding of badge information and network traffic. Our findings suggest that employee 30 may be of interest. In the second part of the paper, we describe our system for finding subgraphs in the social network subject to degree constraints. Subsequently, we present our most likely candidate network which is similar to scenario B.	Simonetto, P.	LaBRI, Univ. de Bordeaux I, Bordeaux, France|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Palantir: A visualization platform for real-world analysis	10.1109/VAST.2009.5334462	http://dx.doi.org/10.1109/VAST.2009.5334462			5334462	data visualisation;information analysis;ontologies (artificial intelligence)	Palantir;financial analysts;information analysis;visualization platform	Bayesian methods;Collaboration;Data visualization;Filtering;Graphical user interfaces;Information systems;Ontologies;Space missions;Visual analytics	Palantir;VAST 2009;collaboration;data integration;visual analytics	Palantir is an analytic platform currently used worldwide by both governmental and financial analysts. This paper provides a brief overview of the platform, examines our 2009 IEEE VAST Challenge submission, and highlights several key analytic and visualization features we used in our analysis.	Wright, B.	Palantir Technol., Palo Alto, CA, USA|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Combining iterative analytical reasoning and software development using the visualization language Processing	10.1109/VAST.2009.5334463	http://dx.doi.org/10.1109/VAST.2009.5334463			5334463	data mining;data visualisation;program visualisation;visual languages	Processing;customized software development;iterative analytical reasoning;programming language;visualization language	Computer languages;Data visualization;Object oriented modeling;Programming;Software tools;Telecommunication traffic;Traffic control;Visual analytics	D.2.3 [Coding Tools and Techniques]: Object-oriented programming;H.1.2 [User/Machine Systems]: Visual Analytics	Processing is a very powerful visualization language which combines software concepts with principles of visual form and interaction. Artists, designers and architects use it but it is also a very effective programming language in the area of visual analytics. In the following contribution Processing is utilized in order to visually analyze data provided by IEEE VAST 2009 Mini Challenge Badge and Network Traffic. The applied process is iterative and each stage of the analytical reasoning process is accompanied by customized software development. The visual model, the process and the technical solution will be briefly introduced.			
	InfoVis+SciVis	12-13 Oct. 2009	Integrative visual analytics for suspicious behavior detection	10.1109/VAST.2009.5334430	http://dx.doi.org/10.1109/VAST.2009.5334430			5334430	data mining;data visualisation;graphical user interfaces;video surveillance	geospatial attributes;heterogeneous data;integrative visual analytics;network traffic;social network;suspicious behavior detection;video surveillance data	Data analysis;Data mining;Data visualization;Graphical user interfaces;Information analysis;Information resources;Pattern analysis;Telecommunication traffic;Visual analytics	H.5.2 [Information Interfaces & Presentations]: User Interfaces - Graphical User Interfaces (GUI);I.3.6 [Methodology and Techniques]: Interaction Techniques	In the VAST Challenge 2009 suspicious behavior had to be detected applying visual analytics to heterogeneous data, such as network traffic, social network enriched with geo-spatial attributes, and finally video surveillance data. This paper describes some of the awarded parts from our solution entry.	Bak, P.	Univ. of Konstanz, Konstanz, Germany|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Detecting and analyzing relationships among anomalies	10.1109/VAST.2009.5334426	http://dx.doi.org/10.1109/VAST.2009.5334426			5334426	data analysis;data visualisation;telecommunication traffic	HRL anomaly analysis tool;IEEE VAST Challenge 2009;alibi table;network traffic;network visualization;processing badge	Data structures;Data visualization;Graphical user interfaces;Gunshot detection systems;Information analysis;Intelligent networks;Leak detection;Social network services;Telecommunication traffic	Anomaly analysis;VAST 2009;information visualization;intelligence analysis;social network analysis	The HRL anomaly analysis tool was developed as part of the IEEE VAST Challenge 2009. One of the tasks involved processing badge and network traffic in order to detect and identify a fictitious embassy employee suspected of leaking information. The tool is designed to assist an analyst in detecting, analyzing, and visualizing anomalies and their relationships. Two key visualizations in our submission present how we identified the suspicious traffic using network visualization and how subsequently we connected that activity to an employee using an alibi table.			
	InfoVis+SciVis	12-13 Oct. 2009	VIDI surveillance - embassy monitoring and oversight system	10.1109/VAST.2009.5333950	http://dx.doi.org/10.1109/VAST.2009.5333950			5333950	IP networks;access control;security;video surveillance	IP event monitoring;IP usage timeline visualization;VIDI surveillance;classified area intrusion;embassy monitoring;oversight system;suspicious IP activity	Cameras;Computer security;Packaging;Robustness;Software packages;Surveillance;Visualization		We hypothesized that potential spies would try to use other employees' terminals in order to not draw attention to themselves. We define one type of suspicious activity as IP use on a terminal when the owner is inside the classified area. We created a timeline visualization of IP usage, overlaid with classified area entrances and exits. The vertical axis divides the timelines into 31 rows, one for each day of the month. The horizontal axis represents the time of day from early morning to late evening. A single employee's entire month is viewed all at once using this visualization. The employee being viewed can be changed using the arrow keys. Every IP event is represented by a vertical bar positioned at the exact time of its appearance. We color the IP events by port number, which is either intranet, HTTP, tomcat, or email, and size the bar based on the outgoing data size. Whenever an employee enters the classified area, a semi-transparent yellow region is drawn until that user exits the classified area. In rare cases when the user double enters, the region is twice as opaque, and in the other rare case where a user leaves the exits without entering, a red region is drawn until the next time the employee enters. The legend key and office diagram showing the current selected employee, highlighted in red, can be seen in the top left-hand corner.	Jones, C.;Ogawa, M.;Shearer, J.;Tikhonova, A.	VIDI Group, Univ. of California, Davis, CA, USA|c|;;;	37598134900;37287357700;38181769500;37404049100
	InfoVis+SciVis	12-13 Oct. 2009	VIScover: Visualizing, exploring, and analysing structured data	10.1109/VAST.2009.5333946	http://dx.doi.org/10.1109/VAST.2009.5333946			5333946	data analysis;data structures;data visualisation	VIScover system;data visualization;geospatial data set;intelligent data processing;interlinked data;semantic technology;social network;structured data analysis	Computer interfaces;Data analysis;Data processing;Data visualization;Displays;Information retrieval;Intelligent structures;OWL;Ontologies;Social network services	H.3.3 [Information Systems]: Information Storage And Retrieval—Information Search and Retrieval H.5.2 [Information Interfaces And Presentation]: User Interfaces—;I.2.4 [Computing Methodologies]: Artificial Intelligence—Knowledge Representation Formalisms and Methods	Today's challenging task in intelligent data processing is not to store large volumes of interlinked data but to visualize, explore, and understand its explicit or implicit relationships. Our solution to this is the VIScover system. VIScover combines semantic technologies with interactive exploration and visualization techniques able to analyze large volumes of structured data. We briefly describe our VIScover system and show its potential using the example of the VAST 2009 social network and geospatial data set.	Liebig, T.	derivo GmbH, Ulm Univ., Ulm, Germany|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Visualization of uncertainty and analysis of geographical data	10.1109/VAST.2009.5333965	http://dx.doi.org/10.1109/VAST.2009.5333965			5333965	data visualisation;geographic information systems;social networking (online);uncertainty handling	Flitter social network;criminal structure;geographic analysis;geographical data analysis;geographical data visualization;uncertainty hannot dling	Cities and towns;Data analysis;Data visualization;Databases;Electronic mail;Geography;Informatics;Performance analysis;Social network services		A team of five worked on this challenge to identify a possible criminal structure within the Flitter social network. Initially we worked on the problem individually, deliberately not sharing any data, results or conclusions. This maximised the chances of spotting any blunders, unjustified assumptions or inferences and allowed us to triangulate any common conclusions. After an agreed period we shared our results demonstrating the visualization applications we had built and the reasoning behind our conclusions. This sharing of assumptions encouraged us to incorporate uncertainty in our visualization approaches as it became clear that there was a number of possible interpretations of the rules and assumptions governing the challenge. This summary of the work emphasises one of those applications detailing the geographic analysis and uncertainty handling of the network data.	Wood, J.	Sch. of Inf., City Univ. London, London, UK|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Multiple step social structure analysis with Cytoscape	10.1109/VAST.2009.5333961	http://dx.doi.org/10.1109/VAST.2009.5333961			5333961	biology computing;data visualisation;public domain software	Cytoscape;VAST 2009 Flitter Mini Challenge;graph data;interaction network analysis tool;multiple step social structure analysis;open source tool	Biological interactions;Data visualization;Social network services;Statistical analysis;Statistics;Visual analytics	Cytoscape;Social Networks	Cytoscape is a popular open source tool for biologists to visualize interaction networks. We find that it offers most of the desired functionality for visual analytics on graph data to guide us in the identification of the underlying social structure. We demonstrate its utility in the identification of the social structure in the VAST 2009 Flitter Mini Challenge.	Hao Zhou	Dept. of Stat., Univ. of Michigan, Ann Arbor, MI, USA|c|	
	InfoVis+SciVis	12-13 Oct. 2009	EAKOS: VAST 2009	10.1109/VAST.2009.5333967	http://dx.doi.org/10.1109/VAST.2009.5333967			5333967	social networking (online)	EAKOS;VAST 2009 Flitter mini challenge award;competing hypothesis;geospatial relationships;social networks	Cities and towns;Data visualization;Information analysis;Information systems;Intrusion detection;Social network services;Visual analytics;Web services	Visual analytics;geovisualization;information visualization;investigative analysis	In this article, I describe the tools and techniques used to generate competing hypotheses for the VAST 2009 Flitter mini challenge. I will describe how I approached solving the social networks and the importance of the geospatial relationships to determine that ldquoSocial Structure Form Ardquo was the best matching social network.			
	InfoVis+SciVis	12-13 Oct. 2009	Visualized subgraph search	10.1109/VAST.2009.5333968	http://dx.doi.org/10.1109/VAST.2009.5333968			5333968	data visualisation;graphical user interfaces;query formulation	GUI;browsing system;visualized subgraph search	Automation;Cities and towns;Computer networks;Data mining;Data visualization;Database languages;Graphical user interfaces;User interfaces;Visual analytics;Web search	Heterogeneous Graph Visualization;Visual Analytics	We present a visually supported search and browsing system for network-type data, especially a novel module for subgraph search with a GUI to define subgraphs for queries. We describe how this prototype was applied for the Vast Challenge 2009, Flitter Mini Challenge.	Erdos, D.	Data Min. & Web Search Group, Hungarian Acad. of Sci., Budapest, Hungary|c|	
	InfoVis+SciVis	12-13 Oct. 2009	Innovative filtering techniques and customized analytics tools	10.1109/VAST.2009.5334300	http://dx.doi.org/10.1109/VAST.2009.5334300			5334300	information filtering	collaborative analytic process;customized analytics tools;heterogeneous synthetic data sets;innovative filtering techniques;queryable models;rapid prototyping	Collaboration;Data visualization;Information analysis;Information filtering;Information filters;Interactive systems;Network servers;Social network services;Telecommunication traffic	H.5.2 [Information Interfaces and Presentation]: User Interfaces—GUI;I.2.10 [Artificial Intelligence]: Vision and Scene Understanding—Video Analysis	The VAST 2009 Challenge consisted of three heterogeneous synthetic data sets organized into separate mini-challenges with minimal correspondence information. The challenge task was the identification of a suspected data theft from cyber and real-world traces. The grand challenge required integrating the findings from the mini challenges into a plausible, consistent scenario. A mixture of linked, customized tools based on queryable models and rapid prototyping as well as generic analysis tools (developed in-house) helped us correctly solve all of the mini challenges. A collaborative analytic process was employed to reconstruct the scenario and to propose the correct steps for the reliable identification of the criminal organization based on activity traces of its members.	Bosch, H.	Visualization & Interactive Syst. Inst., Univ. Stuttgart, Stuttgart, Germany|c|	
	InfoVis+SciVis	12-13 Oct. 2009	VAST 2009 Traffic Mini Challenge: Intuitive analytic information presentation	10.1109/VAST.2009.5334301	http://dx.doi.org/10.1109/VAST.2009.5334301			5334301	Internet;computer animation;data analysis;data visualisation;image colour analysis;telecommunication traffic	VAST 2009;Web-access entries;animated visualization;badge and network traffic tool;color-based flagging;color-coded alerts;intuitive analytic information presentation;traffic mini visualization challenge	Data analysis;Data engineering;Data visualization;Electronic mail;Information analysis;Information technology;Telecommunication traffic		As a solution to the VAST 2009 Traffic Mini Visualization Challenge, we built the Badge and Network Traffic (BNT) tool to create animations of the events taking place in the embassy. Using the embassy layout, the prox-card and web-access entries and their time-stamps, we animated color-based flagging of events. The BNT tool highlights logical anomalies occuring in the badge and network traffic data with color-coded alerts. Prior to the animated visualization, the tool analyzes data with respect to various aspects using (i) the amount of data transfers, (ii) destination IPs access patterns, (iii) employee's browsing patterns and (iv) employee's entry log into the restricted area. Any abnormality noticed is immediately reported to the user in the form of plots. In this presentation, we list out the various analyses performed and how they were utilized in the visualization. A few screenshots of the tool are provided to illustrate our analytic information presentation.	Agrawal, S.	Centre for Data Eng., Int. Inst. of Inf. Technol., Hyderabad, India|c|	
	InfoVis+SciVis				http://dx.doi.org/			5332485					As a solution to the VAST 2009 Traffic Mini Visualization Challenge, we built the Badge and Network Traffic (BNT) tool to create animations of the events taking place in the embassy. Using the embassy layout, the prox-card and web-access entries and their time-stamps, we animated color-based flagging of events. The BNT tool highlights logical anomalies occuring in the badge and network traffic data with color-coded alerts. Prior to the animated visualization, the tool analyzes data with respect to various aspects using (i) the amount of data transfers, (ii) destination IPs access patterns, (iii) employee's browsing patterns and (iv) employee's entry log into the restricted area. Any abnormality noticed is immediately reported to the user in the form of plots. In this presentation, we list out the various analyses performed and how they were utilized in the visualization. A few screenshots of the tool are provided to illustrate our analytic information presentation.			
	InfoVis+SciVis	12-13 Oct. 2009	Merging visual analysis with automated reasoning: Using Prajna to solve the traffic challenge	10.1109/VAST.2009.5332481	http://dx.doi.org/10.1109/VAST.2009.5332481			5332481	Internet;Java;data visualisation;inference mechanisms;knowledge representation;sensor fusion	Internet traffic;Prajna Project;automated reasoning;data fusion;knowledge representation;open-source Java toolkit;semantic reasoning;visual analysis	Application software;Information analysis;Information filtering;Information filters;Internet;Knowledge representation;Pattern analysis;Workstations	Information Visualization;Knowledge Representation;Semantic Reasoning;Software Toolkit	The Internet traffic challenge required the development of a custom application to analyze internet traffic patterns coupled with building access records. To solve this challenge, the author applied the Prajna Project, an open-source Java toolkit designed to provide various capabilities for visualization, knowledge representation, semantic reasoning, and data fusion. By applying some of the capabilities of Prajna to this challenge, the author could quickly develop a custom application for visual analysis. The author determined that he could solve some of the analytical components of this challenge using automated reasoning techniques. Prajna includes interfaces to incorporate automated reasoners into visual applications. By blending the automated reasoning processes with visual analysis, the author could design a flexible, useful application to solve this challenge.	Swing, E.	Vision Syst. & Technol., Inc., NJ, USA|c|	
