Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	VAST+InfoVis+SciVis	Dec. 2013	VIS 2013 Capstone Speaker: Information Visualization: Challenges and Opportunities	10.1109/TVCG.2013.216	http://dx.doi.org/10.1109/TVCG.2013.216	xxviii	xxviii	6634140	data analysis;data visualisation	abstract data interaction;abstract data visualization;information visualization			Summary form only given. In the past decades many new techniques have been developed to visualize and interact with abstract data, but also, many challenges remain. In my talk I will reflect on how to make progress in our field: how to identify interesting problems and next how to find effective solutions. I will begin with an attempt to identify characteristics of interesting problems, and discuss windows of opportunity for data, tasks, and users. Some problems have been solved, some are too hard to deal with, what is the range we should aim at? And what impact can be obtained? Next, I discuss strategies and approaches for finding novel solutions, such as combining existing approaches and finding inspiration in other disciplines, including art and design. This talk is based on lessons we learned while developing new techniques, and will be illustrated with a variety of cases and demos from our group at TU/e, showing successes and failures.			
	VAST+InfoVis+SciVis	Dec. 2013	A Partition-Based Framework for Building and Validating Regression Models	10.1109/TVCG.2013.125	http://dx.doi.org/10.1109/TVCG.2013.125	1962	1971	6634169	data visualisation;mathematics computing;regression analysis;solid modelling	application domains;domain knowledge;energy sector deployment;feature subset selection;five-dimensional model;input variable selection process;natural gas consumption;partition-based framework;regression model building;relevance quantification;relevance visualization;variable interaction;variable structure;variable transformation	Complexity theory;Computational modeling;Feature extraction;Frequency-domain analysis;Modeling;Regression analysis	Complexity theory;Computational modeling;Feature extraction;Frequency-domain analysis;Modeling;Regression;Regression analysis;data partitioning;feature selection;guided visualization;model building;visual knowledge discovery	Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.			
	VAST+InfoVis+SciVis	Dec. 2013	Decision Exploration Lab: A Visual Analytics Solution for Decision Management	10.1109/TVCG.2013.146	http://dx.doi.org/10.1109/TVCG.2013.146	1972	1981	6634184	business data processing;data visualisation;decision support systems;expert systems;ontologies (artificial intelligence)	ODM;artificial intelligence;business domain;business logic;decision exploration lab;decision logic;expert system;ontologies;operational decision management;visual analytics solution	Analytical models;Data visualization;Decision making;Statistical analysis;Visual analytics	Analytical models;Data visualization;Decision making;Decision support systems;Model validation and Analysis;Multivariate statistics;Program Analysis;Statistical analysis;Visual analytics	We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.	Broeksema, B.	IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations	10.1109/TVCG.2013.219	http://dx.doi.org/10.1109/TVCG.2013.219	1982	1991	6634172	data analysis;data visualisation;history;painting;walls	Vis4Heritage;degradation area scales;degradation pattern discovery;grotto wall painting degradations;grotto wall protection;historic cultural icons;multidimensional visualization techniques;multiscale analytic;nature environment;renowned World Heritage site;visual analytics approach;visual analytics framework	Correlation;Cultural differences;Data visualization;Painting;Visual analytics	Correlation;Cultural Heritage;Cultural differences;Data visualization;Degradation;Painting;Visual Analytics;Visual analytics;Wall Paintings	For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.	Jiawan Zhang	Sch. of Comput. Software & Inf. Technol., Tianjin Univ., Tianjin, China|c|	
	VAST+InfoVis+SciVis	Dec. 2013	UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization	10.1109/TVCG.2013.212	http://dx.doi.org/10.1109/TVCG.2013.212	1992	2001	6634167	data analysis;data visualisation;interactive systems;matrix decomposition;text analysis	UTOPIAN;flexible visual analytics system;latent Dirichlet allocation;probabilistic graphical modeling;real-world document corpuses;reliable visual analytics system;semisupervised formulation;text document collection analysis;topic modeling method;topic modeling techniques;user feedback;user-driven manner;user-driven topic modeling based on interactive nonnegative matrix factorization;visual text analytics	Analytical models;Computational modeling;Context modeling;Interactive states;Visual analytics	Analytical models;Computational modeling;Context modeling;Interactive states;Latent dirichlet allocation;Visual analytics;interactive clustering;nonnegative matrix factorization;text analytics;topic modeling;visual analytics	Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.	Jaegul Choo	Georgia Inst. of Technol., Atlanta, GA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies	10.1109/TVCG.2013.162	http://dx.doi.org/10.1109/TVCG.2013.162	2002	2011	6634160	computational complexity;data visualisation;text analysis;trees (mathematics);user interfaces;vocabulary	HierarchicalTopic;computational algorithm;hierarchical topic structure;interactive visual interface;interactive visualizations;text collections;text corpora;textual collections;topic groups;topic hierarchy;topic rose tree;topic-based text summarization methods;topic-based visualizations;user feedback;user interactions;visual analytics system;vocabulary	Algorithm design and analysis;Analytical models;Computational modeling;Text mining;Visual analytics;Vocabulary	Algorithm design and analysis;Analytical models;Computational modeling;Hierarchical topic representation;Text mining;Visual analytics;Vocabulary;rose tree;topic modeling;visual analytics	Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.	Wenwen Dou	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Analysis of Topic Competition on Social Media	10.1109/TVCG.2013.221	http://dx.doi.org/10.1109/TVCG.2013.221	2012	2021	6634134	data visualisation;social networking (online)	2012 United States presidential election;Occupy Wall Street movement;ThemeRiver;Tweets;information diffusion process;metaphoric interpretation;opinion leaders;public agenda;public attention competition;social aspects;social media;storyline style visualization;timeline visualization;topic competition model;topic competitiveness;topical aspects;visual analysis techniques;visual design	Data visualization;Mathematical model;Recruitment;Social network services;Visual analytics	Data visualization;Mathematical model;Recruitment;Social media visuaization;Social network services;Visual analytics;agenda-setting;information diffusion;information propagation;topic competition	How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.	Panpan Xu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|	
	VAST+InfoVis+SciVis	Dec. 2013	ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided Filtering	10.1109/TVCG.2013.186	http://dx.doi.org/10.1109/TVCG.2013.186	2022	2031	6634195	decision making;emergency management;information filtering;information filters;meta data;pattern classification;query processing;social networking (online);statistical distributions	ScatterBlogs2;Twitter;co-occurrence statistical distribution;decision making;emergency management scenarios;message retrieval;metadata restrictions;microblog feeds;microblog message real-time monitoring;microblog posts;query creation;situational awareness;supervised classification;task-tailored message filters;term statistical distribution;time-critical tasks;user-defined keyword queries;user-guided filtering	Blogs;Information retrieval;Labeling;Real-time systems;Social network services;Spatiotemporal phenomena;Twitter	Blogs;Information retrieval;Labeling;Microblog analysis;Real-time systems;Social network services;Spatiotemporal phenomena;Twitter;filter construction;information visualization;live monitoring;query construction;social media monitoring;text analytics;text classification;visual analytics	The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.	Bosch, H.	Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists	10.1109/TVCG.2013.223	http://dx.doi.org/10.1109/TVCG.2013.223	2032	2041	6634091	data visualisation;network theory (graphs);pattern recognition;social networking (online);social sciences computing	PNLB;coauthorship pattern analysis;formative design process;mSNA;multimodal social network analysis;network metrics;organization asymmetric relations;parallel node-link bands;social science;visual analytics tools;visual representation	Complexity theory;Data visualization;Design methodology;Social network services;User centered design;Visual analytics	Complexity theory;Data visualization;Design methodology;Design study;Social network services;User centered design;Visual analytics;interaction;multimodal graphs;node-link diagrams;qualitative evaluation;user-centered design	Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.	Ghani, S.	Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Explainers: Expert Explorations with Crafted Projections	10.1109/TVCG.2013.157	http://dx.doi.org/10.1109/TVCG.2013.157	2042	2051	6634124	data visualisation;learning (artificial intelligence);optimisation	crafted projection function;expert exploration;explainers;high-dimensional data;machine learning optimization framework;user-specified annotation	Cities and towns;Optimization;Quantization (signal);Support vector machines;Text mining	Cities and towns;High-dimensional spaces;Optimization;Quantization (signal);Support vector machines;Text mining;exploration;support vector machines	This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.	Gleicher, M.	Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Semantics of Directly Manipulating Spatializations	10.1109/TVCG.2013.188	http://dx.doi.org/10.1109/TVCG.2013.188	2052	2059	6634115	data visualisation;statistical analysis;user interfaces	V2PI interactions;algorithmic input;alternative structures;decisive interactions;domain knowledge;high-dimensional data visualization;manipulating spatializations;parameter tweaking;parametric projection algorithms;sophisticated weighting scheme;statistical model;unmoved data points;user interactions;visual to parametric interaction	Algorithm design and analysis;Cognitive science;Data visualization;Mathematical model;Semantics	Algorithm design and analysis;Cognitive science;Data visualization;Mathematical model;Semantics;Visual to parametric interaction;statistical models;visual analytics	When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.			
	VAST+InfoVis+SciVis	Dec. 2013	SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space	10.1109/TVCG.2013.190	http://dx.doi.org/10.1109/TVCG.2013.190	2060	2069	6634118	data visualisation;user interfaces	N-D polygon;SketchPadN-D;WYDIWYG editing;WYDIWYG sculpting;What You Draw Is What You Get;data cleaning;data density;direct data generation activity;high-dimensional data visualization;immersive data generation activity;interactive data editing;probability density functions	Data visualization;Image color analysis;Shape analysis	Data visualization;Image color analysis;N-D navigation;Shape analysis;Synthetic data generation;data acquisition and management;data editing;high-dimensional data;interaction;multiple views;multivariate data;parallel coordinates;scatterplot;user interface		Bing Wang	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System	10.1109/TVCG.2013.220	http://dx.doi.org/10.1109/TVCG.2013.220	2070	2079	6634154	data analysis;data visualisation;query processing	attribute relationship graph;binary conjunctive relationships;conjunctive interdimensional relationships;conjunctive intradimensional relationships;cross-filtering;digital humanities;higher-order conjunctive relationships;hypergraph query system;multidimensional data analysis;query expressiveness;query specification;visual analysis;visual exploration;visual querying systems	Data analysis;Data visualization;Database languages;Marine vehicles;Semantics;Visual analytics	Data analysis;Data visualization;Database languages;Graph search;Marine vehicles;Semantics;Visual analytics;attribute relationship graphs;digital humanities;graph query language;higher-order conjunctive queries;multidimensional data;multivariate data analysis;visual query language	Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.	Shadoan, R.	Akashic Labs. LLC, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets	10.1109/TVCG.2013.167	http://dx.doi.org/10.1109/TVCG.2013.167	2080	2089	6634163	data integration;data visualisation	PivotSlice interactive visualization technique;data exploration;direct manipulation metaphor;explicit relational references;explicit relations;faceted browsing;faceted dataset;graphical interaction history;implicit relations;information visualization;live search;multifocus multiscale tabular view;online data integration;sensemaking process;smoothly animated visual state transitions;visual exploration process	Data visualization;Faceted searches;Information filters;Market research	Data visualization;Faceted browsing;Faceted searches;Information filters;Market research;dynamic query;information visualization;interaction;network exploration;visual analytics	Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.	Jian Zhao	Univ. of Toronto, Toronto, ON, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	VAICo: Visual Analysis for Image Comparison	10.1109/TVCG.2013.213	http://dx.doi.org/10.1109/TVCG.2013.213	2090	2099	6634107	Internet;data visualisation;interactive systems;pattern clustering	VAICo;cluster analysis techniques;comparative visualization tools;contextual information;image comparison;image difference visualization;image similarity visualization;interactive Web application;subtle variation analysis;visual analysis	Data visualization;Image color analysis;Image segmentation;Shape analysis;Visual analytics	Comparative visualization;Data visualization;Image color analysis;Image segmentation;Shape analysis;Visual analytics;focus+context visualization;image set comparison	Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.	Schmidt, J.	Vienna Univ. of Technol., Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Open-Box Spectral Clustering: Applications to Medical Image Analysis	10.1109/TVCG.2013.181	http://dx.doi.org/10.1109/TVCG.2013.181	2100	2108	6634089	biomedical MRI;computerised tomography;data visualisation;graph theory;medical image processing;pattern clustering	3D image analysis;Laplacian graph type;brain MRI;chest CT;computerised tomography;distance measures;graph parameter;hierarchical clustering;magnetic resonance imaging;medical image analysis;open-box spectral clustering;segmentation protocols;three-dimensional data space;tuning parameters	Clustering;Data visualization;Eigenvalues and eigenfunctions;Image analysis;Image segmentation;Laplace equations;Three-dimensional displays	Clustering;Data visualization;Eigenvalues and eigenfunctions;Image analysis;Image segmentation;Laplace equations;Three-dimensional displays;high-dimensional embeddings;linked views;programming with example;spectral clustering	Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.	Schultz, T.	Univ. of Bonn, Bonn, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop	10.1109/TVCG.2013.207	http://dx.doi.org/10.1109/TVCG.2013.207	2109	2118	6634165	data analysis;data mining;data visualisation;learning (artificial intelligence);video retrieval	active learning;candidature search visualization;interactive browsing;knowledge discovery;machine learning concepts;parameter space visualization;search requirements;semantic annotation;sketch-based image search systems;sketch-based interface;sketch-based video search systems;sketch-based visual analytics loop;spatiotemporal attribute searching;sport video;training data;uncertain video search pipeline;visual analytics systems	Analytical models;Computational modeling;Data visualization;Machine learning;Multimedia communication;Visual analytics	Analytical models;Computational modeling;Data visualization;Machine learning;Multimedia communication;Visual analytics;data clustering;machine learning;multimedia visualization;visual knowledge discovery	Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.	Legg, P.A.	Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization	10.1109/TVCG.2013.168	http://dx.doi.org/10.1109/TVCG.2013.168	2119	2128	6634090	data analysis;data visualisation;image representation;information retrieval;spatial filters;video signal processing;video surveillance	action shot representation;action shot summarization;manual fast forward video browsing;movement detection;movements overall timeline;multipart visual representation;object movement path extraction;regions-of-interest;sViSIT;single action shot image;space-time cube;spatial filtering;surveillance video data interactive exploration;tasks time-to-completion;temporal filtering;trajectory visualization;video visual analytics system	Data visualization;Image segmentation;Interactive states;Navigation;Surveillance;Tracking;Visual analytics	Data visualization;Image segmentation;Interactive states;Navigation;Surveillance;Tracking;Video visual analytics;Visual analytics;surveillance video;video browsing and exploration;video summarization;video visualization	We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.	Meghdadi, A.H.	Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli	10.1109/TVCG.2013.194	http://dx.doi.org/10.1109/TVCG.2013.194	2129	2138	6634139	data analysis;data visualisation;image motion analysis;pattern clustering	animated graphics;attentional focus;attentional synchrony time sequence;density-based color mapping;dynamic stimuli;eye gaze;eye movement data analysis;eye-tracking data;eye-tracking visualization techniques;individual scan paths;motion-compensated heat maps;scan path trajectory;space-time cube visualization;space-time visual analytics method;spatial information;spatiotemporal data clustering;static 3D representation;temporal information;video;viewing behavior	Clustering algorithms;Context awareness;Data visualization;Space-time codes;Spatiotemporal phenomena;Tracking;Visual analytics	Clustering algorithms;Context awareness;Data visualization;Eye-tracking;Space-time codes;Spatiotemporal phenomena;Tracking;Visual analytics;dynamic areas of interest;motion-compensated heat map;space-time cube;spatiotemporal clustering	We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.	Kurzhals, K.	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	An Extensible Framework for Provenance in Human Terrain Visual Analytics	10.1109/TVCG.2013.132	http://dx.doi.org/10.1109/TVCG.2013.132	2139	2148	6634110	XML;data analysis;data visualisation;iterative methods;military computing;pattern classification;terrain mapping	HTA chain;HTVA;ProveML;XML-based extension;analogous features;analytic bookmarks;analytical interpretations;analytical process;analytical provenance;data analysis;data exploration;data provenance;defence analysts;human terrain visual analytics;intelligence analysts;intelligence community;iterative process;nonclassified data source;open provenance model;rapid prototyping;structured communication;structured workshops	Context awareness;Data visualization;Human factors;Terrain mapping;Visual analytics	Context awareness;Data visualization;Human factors;Human terrain analysis;Terrain mapping;Visual analytics;bookmarks;framework;narratives;provenance	We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.	Walker, R.	Middlesex Univ., London, UK|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips	10.1109/TVCG.2013.226	http://dx.doi.org/10.1109/TVCG.2013.226	2149	2158	6634127	data visualisation;decision making;query processing;rendering (computer graphics);spatiotemporal phenomena;traffic information systems	New York City taxi trips;adaptive level-of-detail rendering strategy;big spatio-temporal urban data;clutter-free visualization;data-driven analysis;economic activity;evidence-based decision making;evidence-based decision policies;geographical components;human behavior;mobility patterns;origin-destination queries;spatiotemporal queries;standard analytics;taxi trip visually query;temporal components;traffic engineers;urban data set;visual exploration;visual representations	Analytical models;Cities and towns;Data models;Data visualization;Mathematical model;Time factors;Visual analytics	Analytical models;Cities and towns;Data models;Data visualization;Mathematical model;NYC taxis;Spatio-temporal queries;Time factors;Visual analytics;urban data;visual exploration	As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.			
	VAST+InfoVis+SciVis	Dec. 2013	Visual Traffic Jam Analysis Based on Trajectory Data	10.1109/TVCG.2013.228	http://dx.doi.org/10.1109/TVCG.2013.228	2159	2168	6634174	Global Positioning System;data analysis;data visualisation;interactive systems;pattern matching;traffic information systems	Beijing;GPS trajectories;automatic traffic jam event detection;high-level traffic jam description;interactive system;road network;road segment;spatially related events;taxi GPS trajectories;temporally related events;traffic jam information extraction;traffic jam propagation graphs;traffic speed;trajectory data;trajectory matching;visual exploration;visual traffic jam analysis;visual urban traffic congestion analysis	Cities and towns;Data mining;Data visualization;Global Positioning System;Road traffic;Traffic control;Trajectory;Urban areas	Cities and towns;Data mining;Data visualization;Global Positioning System;Road traffic;Traffic control;Traffic visualization;Trajectory;Urban areas;traffic jam propagation	In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.	Zuchao Wang	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Space Transformation for Understanding Group Movement	10.1109/TVCG.2013.193	http://dx.doi.org/10.1109/TVCG.2013.193	2169	2178	6634194	behavioural sciences computing;computer graphics;zoology	abstract group space;animal ethology;geographical space;granularity level;group center position;group movement behaviors;group space reference system;individual position;individuals movement;space transformation;visual analytics;wild social animals	Behavioral science;Data models;Market research;Trajectory;Visual analytics	Behavioral science;Data models;Market research;Trajectory;Visual analytics;collective movement;movement data	We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.			
	VAST+InfoVis+SciVis	Dec. 2013	Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration	10.1109/TVCG.2013.224	http://dx.doi.org/10.1109/TVCG.2013.224	2179	2188	6634158	computational geometry;data analysis;data visualisation;pattern clustering	computational geometry;data analysis;distance-based spatial clustering;guided exploration;heuristic approach;interactive visualization;visual analytics;visual feedback	Clustering algorithms;Data visualization;Heuristic algorithms;Image color analysis;Noise measurement;Shape analysis;Visual analytics	Clustering algorithms;Data visualization;Heuristic algorithms;Heuristic-based spatial clustering;Image color analysis;Noise measurement;Shape analysis;Visual analytics;iInteractive visual clustering;k-order a-(alpha)-shapes	We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.	Packer, E.	IBM Res. Haifa Lab., Haifa, Israel|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Supporting Awareness through Collaborative Brushing and Linking of Tabular Data	10.1109/TVCG.2013.197	http://dx.doi.org/10.1109/TVCG.2013.197	2189	2197	6634130	data visualisation;groupware	awareness support;collaborative brushing;collaborative visualization activities;collaborative work;distributed collaborative visualization;fictitious collaborator;natural brushing actions;tabular data linking;tabular data set	Collaborative work;Context awareness;Data visualization	Collaboration;Collaborative work;Context awareness;Data visualization;attentionally ambient visualization;awareness;brushing and linking;linked views;user study	Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing & linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing & linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.	Hajizadeh, A.H.	Univ. of Victoria, Victoria, BC, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis	10.1109/TVCG.2013.164	http://dx.doi.org/10.1109/TVCG.2013.164	2198	2206	6634191	data analysis;groupware;information filtering;online front-ends;pattern clustering;sorting	color clustering with representative selection;crowd-assisted techniques;crowdsourced data analysis;crowdsourced explanations;embedded Web browser;explanation provenance expose;explanation-management interface;provenance information;redundancy explanation identification;response filtering;response sorting;source-review tasks;workers browsing behavior	Clustering algorithms;Data analysis;Image color analysis;Market research;Redundancy;Social network services	Clustering algorithms;Crowdsourcing;Data analysis;Image color analysis;Market research;Redundancy;Social Data Analysis;Social network services	We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.	Willett, W.	INRIA, Sophia-Antipolis, France|c|	
	VAST+InfoVis+SciVis	Dec. 2013	The Impact of Physical Navigation on Spatial Organization for Sensemaking	10.1109/TVCG.2013.205	http://dx.doi.org/10.1109/TVCG.2013.205	2207	2216	6634176	human computer interaction;virtual reality	high-resolution display;pan;physical navigation;physical workspace;sensemaking process;sensemaking space;spatial organization;spatial sensemaking techniques;user interaction;user navigation;virtual navigation;virtual workspace;zoom	Browsers;Image color analysis;Navigation;Visual analytics	Browsers;Image color analysis;Navigation;Sensemaking;Visual analytics;embodiment large;high-resolution displays;physical navigation;visual analytics	Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.	Andrews, C.	Middlebury Coll., USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design	10.1109/TVCG.2013.211	http://dx.doi.org/10.1109/TVCG.2013.211	2217	2226	6651935	cognition;data analysis;data visualisation;digital libraries;query processing	ACM digital library;INVISQUE;candidate influencers;cognitive needs;cognitive work;community of practice;design implications;freeform infinite canvas;inferences;interaction needs;interactive visual reasoning;interactive visual search and query environment;reasoning process;sense-making	Design methodology;Query processing;User interfaces;Visual analytics	Design methodology;Query processing;User interfaces;Visual analytics;analysis;dataframe mode;evaluation;interaction;interface design;reasoning;sense-making	This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.	Kodagoda, N.	Middlesex Univ., London, UK|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Temporal Event Sequence Simplification	10.1109/TVCG.2013.200	http://dx.doi.org/10.1109/TVCG.2013.200	2227	2236	6634100	data visualisation;medical information systems	EHR;electronic heath records;event records;temporal event sequence simplification;user-driven data simplifications;visual complexity	Complexity theory;Data mining;Data visualization;Electronic medical records;Market research	Complexity theory;Data mining;Data visualization;Electronic medical records;Event sequences;Market research;electronic heath records;simplification;temporal query	Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.	Monroe, M.	Univ. of Maryland, College Park, MD, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Analytics for Model Selection in Time Series Analysis	10.1109/TVCG.2013.222	http://dx.doi.org/10.1109/TVCG.2013.222	2237	2246	6634112	data analysis;data visualisation;iterative methods;mathematics computing;statistical analysis;time series	TiMoVA prototype;automated computation;domain experts;epidemiology;human judgement;interactive visual interfaces;iterative expert feedback;model selection tasks;statistical software tools;time series analysis;user experience;user stories;visual analytics process	Analytical models;Autoregressive processes;Data models;Mathematical model;Time series analysis	Analytical models;Autoregressive processes;Data models;Mathematical model;Time series analysis;Visual analytics;coordinated &amp;amp; multiple views;model selection;time series analysis;visual interaction	Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.	Bogl, M.	Vienna Univ. of Technol., Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data	10.1109/TVCG.2013.206	http://dx.doi.org/10.1109/TVCG.2013.206	2247	2256	6634096	data models;data visualisation;software libraries;time-domain analysis	TimeBench;application code;calendar granularity;data model;electronic health records;flat numerical data type;foundational data algorithms;foundational data structures;long-term developer study;medical insights;network traffic;software library;temporal foundations;time domain complexity;time-oriented data;visual analytics designs	Data models;Data structures;Data visualization;Time-domain analysis;Visual analytics	Data models;Data structures;Data visualization;Time-domain analysis;Visual Analytics;Visual analytics;information visualization;software infrastructure;temporal data;time;toolkits	Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.	Rind, A.	Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation	10.1109/TVCG.2013.178	http://dx.doi.org/10.1109/TVCG.2013.178	2257	2266	6634102	data visualisation;image motion analysis;image retrieval;image sequences;interactive systems;time series	MotionExplorer;animation;combination;data exploration;data navigation;data search;data visualization;drill-down functionality;exploratory analysis system;exploratory search system;hierarchical aggregation;human motion capture data;human motion sequences;interactive aggregation;interpolation;medicine;motion capture data collection;motion state analysis;motion state visualization;motion transition analysis;motion vector synthesis;multivariate time series data;query-by-example metaphor;sports;visual analysis;visual retrieval;visual summary	Data collection;Data visualization;Databases;Time series analysis;Visual analytics	Data collection;Data visualization;Databases;Time series analysis;Visual analytics;cluster glyph;data aggregation;exploratory search;motion capture data;multivariate time series	We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.	Bernard, J.	Fraunhofer Inst. for Comput. Graphics Res. Darmstadt, Darmstadt, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes	10.1109/TVCG.2013.198	http://dx.doi.org/10.1109/TVCG.2013.198	2267	2276	6634085	data analysis;data visualisation;graph theory;pattern clustering;telecommunication computing;wireless mesh networks	dynamic networks;edge groups;node groups;substructure discovery;supergraph visualization;temporal attribute clustering;temporal clustering;visual analysis;wireless mesh network	Current measurement;Image color analysis;Market research;Power system dynamics;Time measurement;Time series analysis	Current measurement;Dynamic networks;Image color analysis;Market research;Power system dynamics;Time measurement;Time series analysis;supergraph clustering;visualization	The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.	Hadlak, S.	Univ. of Rostock, Rostock, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	LineUp: Visual Analysis of Multi-Attribute Rankings	10.1109/TVCG.2013.173	http://dx.doi.org/10.1109/TVCG.2013.173	2277	2286	6634146	bar charts;data visualisation;interactive systems	LineUp;attribute combination;bar charts;interactive technique;item ranking;multiattribute rankings;multiattribute visualization technique;multiple heterogeneous attributes;ranking visualization;slope graphs;visual analysis;visual exploration tools	Data visualization;Encoding;Histograms;Rankings;Scalability	Data visualization;Encoding;Histograms;Ranking visualization;Rankings;Scalability;multi-attribute;multi-faceted;multifactorial;ranking;scoring;stacked bar charts	Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.	Gratzl, S.	Johannes Kepler Univ. Linz, Linz, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays	10.1109/TVCG.2013.122	http://dx.doi.org/10.1109/TVCG.2013.122	2287	2296	6634111	data visualisation;formal specification	absolute reference specification;application domains;categorical information;comparative visualization;explicit encoding;fixed reference category;formal model;numerical information;overlay encoding;relative reference specification;semantic ordering;small-multiple displays;structure-based comparison	Computational modeling;Data visualization;Displays;Encoding	Comparative visualization;Computational modeling;Data visualization;Displays;Encoding;categorical data;small-multiple displays;trellis displays	Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.	Kehrer, J.	VRVis Res. Center, Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Common Angle Plots as Perception-True Visualizations of Categorical Associations	10.1109/TVCG.2013.140	http://dx.doi.org/10.1109/TVCG.2013.140	2297	2305	6634157	data visualisation;distortion	Muller-Lyer type illusion;categorical associations;categorical data;categorical variables;common angle charts;common angle plots;data visualization;distortion;hammock plots;line width illusion;parallel sets;perception-true visualizations;perceptual illusions	Biochemistry;Biological cells;Data visualization;Parallel processing	Biochemistry;Biological cells;Data visualization;Linewidth illusion;Muller-Lyer illusion;Parallel processing;data visualization;hammock plots;high-dimensional displays;parallel sets	Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue.			
	VAST+InfoVis+SciVis	Dec. 2013	What Makes a Visualization Memorable?	10.1109/TVCG.2013.234	http://dx.doi.org/10.1109/TVCG.2013.234	2306	2315	6634103	data visualisation	Amazon;Mechanical Turk;data understanding;data-ink ratios;government reports;infographic sources;memorability scores;news media sites;scientific journals;visual densities;visualization community;visualization type	Data visualization;Encoding;Information technology;Taxonomy	Data visualization;Encoding;Information technology;Taxonomy;Visualization taxonomy;information visualization;memorability	An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.	Borkin, M.A.	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Perception of Average Value in Multiclass Scatterplots	10.1109/TVCG.2013.183	http://dx.doi.org/10.1109/TVCG.2013.183	2316	2325	6634120	data visualisation	average value perception;conflicting encodings;crowd-sourced participants;multiclass scatterplots;relative mean value judgement;salient encodings;scatterplots design;visual summarization task;visualization tasks	Color imaging;Encoding;Shape analysis;Visual systems	Color imaging;Encoding;Psychophysics;Shape analysis;Visual systems;information visualization;perceptual study	The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.	Gleicher, M.	Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation	10.1109/TVCG.2013.187	http://dx.doi.org/10.1109/TVCG.2013.187	2326	2335	6634178	data visualisation;mesh generation;pattern clustering	Delaunay triangulation;aspect ratio;optimization problem;quality measures;scale factor;scatter plot;two-dimensional data visualization	Approximation algorithms;Approximation methods;Atmospheric measurements;Data visualization;Market research;Particle measurements	Approximation algorithms;Approximation methods;Atmospheric measurements;Data visualization;Delaunay triangulation;Market research;Particle measurements;Scatter plot;aspect ratio	Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.	Fink, M.	Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale	10.1109/TVCG.2013.170	http://dx.doi.org/10.1109/TVCG.2013.170	2336	2345	6634121	computer displays;data visualisation	display size;focus-plus-context visualization technique;information space;information visualization techniques;interactive visualization;overview-plus-detail visualization technique;scale ratio;visualization usability;zoom level;zooming-for multiscale navigation visualization technique	Aerospace electronics;Data visualization;Interactive systems;Monitoring;Navigation	Aerospace electronics;Data visualization;Information visualization;Interactive systems;Monitoring;Navigation;experimental method;interaction techniques;multi-scale navigation;user studies	In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' p- rformance and to discuss differences between the two experimental approaches.	Jakobsen, M.R.	Univ. of Copenhagen, Copenhagen, Denmark|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Hybrid-Image Visualization for Large Viewing Environments	10.1109/TVCG.2013.163	http://dx.doi.org/10.1109/TVCG.2013.163	2346	2355	6634173	computer displays;data analysis;data visualisation	data analysis scenarios;design space;detail-in-context tasks;displays;full-screen visualizations;hybrid-image visualization;large-scale viewing environments;perception-based blending approach;static view;visual representations	Data visualization;Encoding;Frequency-domain analysis;Image color analysis	Data visualization;Encoding;Frequency-domain analysis;Image color analysis;Multi-scale;collaboration;hybrid images;large displays;visualization	We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.			
	VAST+InfoVis+SciVis	Dec. 2013	An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization	10.1109/TVCG.2013.130	http://dx.doi.org/10.1109/TVCG.2013.130	2356	2365	6634181	cartography;data visualisation;geographic information systems;interactive systems	GIScience;card sorting study;cognitive sophistication;empirically-derived taxonomy;expert interactive map users;functional taxonomy;geovisualization;information visualization;interaction operands;interaction primitives;interaction science;interactive cartography;interactive map designers;map-based visualization;objective sorting;operator sorting;user goals;visual analytics	Cartography;Geophysical measurements;Object recognition;Search problems	Cartography;Geophysical measurements;Object recognition;Science of interaction;Search problems;geovisualization;interaction primitives;interaction techniques;interactive maps	Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, & delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, & prescribe) and interaction operands (space-alone, attributes-in-space, & space-in-time; elementary & general). The operator sort suggested five enabling operators (import, export, save, edit, & annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, & calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.	Roth, R.E.	Univ. of Wisconsin-Madison, Madison, WI, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Design Space of Visualization Tasks	10.1109/TVCG.2013.120	http://dx.doi.org/10.1109/TVCG.2013.120	2366	2375	6634156	data visualisation	climate impact research;visual representations;visualization task descriptions;visualization task model;visualization task taxonomy;visualization tasks design space	Data visualization;Market research;Meteorology;Taxonomy	Data visualization;Market research;Meteorology;Task taxonomy;Taxonomy;climate impact research;design space;visualization recommendation	Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.	Schulz, H.-J.	Univ. of Rostock, Rostock, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Multi-Level Typology of Abstract Visualization Tasks	10.1109/TVCG.2013.124	http://dx.doi.org/10.1109/TVCG.2013.124	2376	2385	6634168	data visualisation;pattern classification	abstract visualization tasks;cartography;communications;domain-specific problems;extant classification systems;human-computer interaction;information retrieval;multilevel typology;visualization systems;visualization usage qualitative evaluation	Encoding;Modeling;Qualitative evaluations;Topology	Encoding;Modeling;Qualitative evaluations;Topology;Typology;qualitative evaluation;task and requirements analysis;visualization models	The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.			
	VAST+InfoVis+SciVis	Dec. 2013	Information Visualization and Proxemics: Design Opportunities and Empirical Findings	10.1109/TVCG.2013.166	http://dx.doi.org/10.1109/TVCG.2013.166	2386	2395	6634094	data visualisation;human computer interaction	high-resolution display;information visualization;interaction techniques;proxemics;spatial relations;visual representation	Data visualization;Encoding;Information filters;Navigation	Data visualization;Encoding;Information filters;Navigation;Proxemics;distance;information visualization;large displays;movement;orientation;user study;user tracking	People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.	Jakobsen, M.R.	Univ. of Copenhagen, Copenhagen, Denmark|c|	
	VAST+InfoVis+SciVis	Dec. 2013	An Interaction Model for Visualizations Beyond The Desktop	10.1109/TVCG.2013.134	http://dx.doi.org/10.1109/TVCG.2013.134	2396	2405	6634126	data visualisation;interactive systems;rendering (computer graphics)	beyond-desktop visualizations;conceptual models;conventional interactive visualization systems;design alternatives;instrumental interaction paradigm;interaction model;pipeline model;rendering;unconventional interactive visualization systems;visualization reference model	Data visualization;Pipelines;Rendering (computer graphics);Three-dimensional displays	Data visualization;Information visualization;Pipelines;Rendering (computer graphics);Three-dimensional displays;interaction model;notational system;physical visualization	We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.	Jansen, Y.	Inria & Univ. Paris Sud, Paris, France|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Deeper Understanding of Sequence in Narrative Visualization	10.1109/TVCG.2013.119	http://dx.doi.org/10.1109/TVCG.2013.119	2406	2415	6634182	cognition;data visualisation;graph theory;humanities;sequences	audience perspective;automatic effective sequence identification;global sequencing strategies;graph-driven approach;local transitions;narrative sequencing;narrative systems;professional narrative visualizations;qualitative analysis;slideshow-style presentations;user preferences;visualization sequence optimization;visualization set;visualization-to-visualization transitions	Data visualization;Encoding;Linear programming;Parallel processing;Sequential analysis	Data storytelling;Data visualization;Encoding;Linear programming;Parallel processing;Sequential analysis;narrative structure;narrative visualization	Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.			
	VAST+InfoVis+SciVis	Dec. 2013	SketchStory: Telling More Engaging Stories with Data through Freeform Sketching	10.1109/TVCG.2013.191	http://dx.doi.org/10.1109/TVCG.2013.191	2416	2425	6634113	computer animation;data visualisation;gesture recognition	Microsoft PowerPoint;SketchStory;data charts;data exploration;data-enabled digital whiteboard;freeform sketching;information visualization;narrative storytelling attributes;pen-and-touch interactions;presenter-provided example icon;sketch gestures;whiteboard animation	Animation;Data visualization;Filtering;Real-time systems;Rendering (computer graphics)	Animation;Data visualization;Filtering;Real-time systems;Rendering (computer graphics);Storytelling;data presentation;interaction;pen and touch;sketch;visualization	Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.			
	VAST+InfoVis+SciVis	Dec. 2013	Using Concrete Scales: A Practical Framework for Effective Visual Depiction of Complex Measures	10.1109/TVCG.2013.210	http://dx.doi.org/10.1109/TVCG.2013.210	2426	2435	6634143	cognition;data visualisation	communication settings;complex measures;concrete scales;decision-making settings;educational settings;extreme magnitude measures;graphic composition;graphic compositions;quantitative information;scale cognition mechanisms;unfamiliar unit measures;visual depiction;visual depictions;visual representations	Complexity theory;Computer graphics;Measurement	Complexity theory;Computer graphics;Concrete scale;Measurement;graphic composition;scale cognition;visual comparison;visual notation	From financial statistics to nutritional values, we are frequently exposed to quantitative information expressed in measures of either extreme magnitudes or unfamiliar units, or both. A common practice used to comprehend such complex measures is to relate, re-express, and compare them through visual depictions using magnitudes and units that are easier to grasp. Through this practice, we create a new graphic composition that we refer to as a concrete scale. To the best of our knowledge, there are no design guidelines that exist for concrete scales despite their common use in communication, educational, and decision-making settings. We attempt to fill this void by introducing a novel framework that would serve as a practical guide for their analysis and design. Informed by a thorough analysis of graphic compositions involving complex measures and an extensive literature review of scale cognition mechanisms, our framework outlines the design space of various measure relations-specifically relations involving the re-expression of complex measures to more familiar concepts-and their visual representations as graphic compositions.	Chevalier, F.	Univ. of Toronto & OCAD Univ., Toronto, ON, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	StoryFlow: Tracking the Evolution of Stories	10.1109/TVCG.2013.196	http://dx.doi.org/10.1109/TVCG.2013.196	2436	2445	6634164	data visualisation;humanities;optimisation	StoryFlow;continuous optimization;discrete method;discrete optimization;dynamic relationships;entities alignment;entities ordering;hybrid optimization approach;real-time interactions;story evolution;storyline layout;storyline visualizations	Heuristic algorithms;Layout;Motion pictures;Optimization;White spaces	Heuristic algorithms;Layout;Motion pictures;Optimization;Storylines;White spaces;level-of-detail;optimization;story-telling visualization;user interactions	Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.			
	VAST+InfoVis+SciVis	Dec. 2013	Visual Sedimentation	10.1109/TVCG.2013.227	http://dx.doi.org/10.1109/TVCG.2013.227	2446	2455	6634152	data visualisation	chronological order;data stream visualization;force model;metaphor design space;sedimentation process;visual sedimentation design metaphor	Data visualization;Design methodology;Real-time systems;Sediments	Data visualization;Design;Design methodology;Real-time systems;Sediments;data stream;dynamic data;dynamic visualization;information visualization;metaphor;real time	We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.			
	VAST+InfoVis+SciVis	Dec. 2013	Nanocubes for Real-Time Exploration of Spatiotemporal Datasets	10.1109/TVCG.2013.179	http://dx.doi.org/10.1109/TVCG.2013.179	2456	2465	6634137	data visualisation;query processing	aggregate query;data attributes;data cube aggregation operation;exact visualizations;heatmaps;hierarchical structure;histograms;location attribute;memory measurement;nanocube query;network bandwidth measurement;network latency;parallel coordinate plots;realtime spatiotemporal datasets exploration;relational databases;time attribute;timing measurement;user-interaction latency;visual encodings	Androids;Data visualization;Encoding;Humanoid robots;Nanostructured materials;Spatiotemporal phenomena	Androids;Data cube;Data visualization;Encoding;Humanoid robots;Nanostructured materials;Spatiotemporal phenomena;data structures;interactive exploration	Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.			
	VAST+InfoVis+SciVis	Dec. 2013	Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems	10.1109/TVCG.2013.233	http://dx.doi.org/10.1109/TVCG.2013.233	2466	2475	6634197	computer animation;data visualisation;distributed processing	animation visualization approach;automated localization technique;diff visualization approach;distributed systems;performance diagnosis;request-flow comparison technique;request-flow comparison visualization;side-by-side visualization approach;visualization techniques	Distributed processing;Human factors;Layout;Training	Distributed processing;Distributed systems;Human factors;Layout;Training;human factors;problem diagnosis;visualization	Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.			
	VAST+InfoVis+SciVis	Dec. 2013	Evaluation of Filesystem Provenance Visualization Tools	10.1109/TVCG.2013.155	http://dx.doi.org/10.1109/TVCG.2013.155	2476	2485	6634189	data visualisation;file organisation;gender issues;user interfaces	Orbiter;complex hierarchical structure;data exploration;filesystem provenance data;filesystem provenance visualization tools;high level summary;interactive radial based tree layout;node link based tool;node link diagram;quantitative evaluation;subjective measures;system activity;time based hierarchical node grouping method;user mental model;visual representation	Context awareness;Data visualization;Encoding;Layout	Context awareness;Data visualization;Encoding;Layout;Provenance data;gender differences;graph/network data;hierarchy data;quantitative evaluation	Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.	Borkin, M.A.	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visualizing Fuzzy Overlapping Communities in Networks	10.1109/TVCG.2013.232	http://dx.doi.org/10.1109/TVCG.2013.232	2486	2495	6634179	data visualisation;fuzzy set theory;graph theory	biological interactions;community structure;fuzzy community memberships;layout strategy;membership distribution;network topology;node color;node position;node-link diagrams;object attributes;real-world systems;social networking;visual mappings;visualization approach;visualizing fuzzy overlapping community;weighted undirected graphs	Communities;Data visualization;Fuzzy methods;Image color analysis;Layout;Uncertainty	Communities;Data visualization;Fuzzy methods;Image color analysis;Layout;Overlapping community visualization;Uncertainty;fuzzy clustering;graph visualization;uncertainty visualization	An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.	Vehlow, C.	VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Radial Sets: Interactive Visual Analysis of Large Overlapping Sets	10.1109/TVCG.2013.184	http://dx.doi.org/10.1109/TVCG.2013.184	2496	2505	6634104	data visualisation;interactive systems;query formulation	attribute distribution;attribute values;data tables;element-set membership matrix;frequency-based representations;interactive visual analysis;multivalued attributes;overlapping patterns;overlapping sets;radial sets;set-typed data;table entity membership;visual query formulation	Color imaging;Data visualization;Histograms;Interactive systems;Scalability	Color imaging;Data visualization;Histograms;Interactive systems;Multi-valued attributes;Scalability;overlapping sets;scalability;set-typed data;visualization technique	In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.	Alsallakh, B.	Vienna Univ. of Technol., Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	SoccerStories: A Kick-off for Visual Soccer Analysis	10.1109/TVCG.2013.192	http://dx.doi.org/10.1109/TVCG.2013.192	2506	2515	6634087	data analysis;data visualisation;sport	SoccerStories visualization interface;connected visualizations;game phase overview-detail interface;qualitative user studies;quantitative analysis;soccer data exploration;visual soccer analysis;word-sized graphics	Data visualization;Games;Layout;Navigation	Data visualization;Games;Layout;Navigation;Visual knowledge discovery;sport analytics;visual aggregation;visual knowledge representation	This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.	Perin, C.	INRIA, Univ. Paris-Sud, Paris, France|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Creative User-Centered Visualization Design for Energy Analysts and Modelers	10.1109/TVCG.2013.145	http://dx.doi.org/10.1109/TVCG.2013.145	2516	2525	6634166	data analysis;data visualisation;home automation;power engineering computing;smart meters;user centred design	creative user-centered visualization design;creativity techniques;data sculpting;data visualization;energy analysts;energy consumers;energy suppliers;smart home data analysis;smart meter technology;systematic visualization design;visualization development	Data models;Data visualization;Home appliances;Prototypes;Smart homes	Creativity techniques;Data models;Data visualization;Home appliances;Prototypes;Smart homes;data visualization;energy consumption;smart home;user-centered design	We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.	Goodwin, S.	giCentre, City Univ. London, London, UK|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization	10.1109/TVCG.2013.209	http://dx.doi.org/10.1109/TVCG.2013.209	2526	2535	6634088	commerce;data visualisation;interactive systems;market opportunities	business ecosystems;dotlink360;global networks;interactive visualization;interfirm relationships;market segments	Companies;Data visualization;Ecosystems;Interactive systems;Mobile communication	Business ecosystems;Companies;Data visualization;Ecosystems;Interactive systems;Mobile communication;design study;interaction;market research;network visualization;strategic analysis	Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.			
	VAST+InfoVis+SciVis	Dec. 2013	Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets	10.1109/TVCG.2013.154	http://dx.doi.org/10.1109/TVCG.2013.154	2536	2545	6634190	biology computing;data analysis;data visualisation	Entourage visualization technique;biological network;biological network complexity;biological pathway map visualization;biological pathway relationship;contextual subsets;experimental data visualization;pathway cross-talks	Bioinformatics;Biological system modeling;Context awareness;Data visualization;Drugs;Portals	Bioinformatics;Biological system modeling;Context awareness;Data visualization;Drugs;Pathway visualization;Portals;biological networks;biomolecular data;graphs;subsets	Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.	Lex, A.	Harvard Univ., Cambridge, MA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Variant View: Visualizing Sequence Variants in their Gene Context	10.1109/TVCG.2013.214	http://dx.doi.org/10.1109/TVCG.2013.214	2546	2555	6634170	DNA;bioinformatics;data visualisation;diseases;genomics	DNA sequence;biological context;data abstractions;disease;gene context;individual genome;information spaces;information-dense visual encoding;prevalent genome browsers;sequence variant visualization;standard reference genome;task abstractions;variant impact assessment;variant view tool	Bioinformatics;Browsers;Context awareness;Databases;Design methodology;Genomics;Sequential analysis	Bioinformatics;Browsers;Context awareness;Databases;Design methodology;Genomics;Information visualization;Sequential analysis;bioinformatics;design study;genetic variants	Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.			
	VAST+InfoVis+SciVis	Dec. 2013	DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation	10.1109/TVCG.2013.149	http://dx.doi.org/10.1109/TVCG.2013.149	2556	2565	6634116	computer animation;data visualisation;graph theory	DiffAni;animation;diff tiles;difference maps;dynamic graph;hybrid visualization	Animation;Computer graphics;Prototypes	Animation;Computer graphics;Dynamic networks;Prototypes;animation;difference map;evolution;hybrid visualization;taxonomy	Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.	Rufiange, S.	Ecole de Technol. Super., Montreal, QC, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView	10.1109/TVCG.2013.231	http://dx.doi.org/10.1109/TVCG.2013.231	2566	2575	6634101	data analysis;data visualisation	Department of Transportation;Federal Drug Administration;National Cancer Institute;Office of the Bursar;StemView dynamic hierarchy;TreeVersity2 dynamic hierarchy;US Federal Budget data;University of Maryland;Web based interactive data visualization tool;change visualization;data analysis;data attributes;eBay;space filling visualization;tree context;university student population data	Context awareness;Data visualization;Image color analysis;Topology	Context awareness;Data visualization;Image color analysis;Information visualization;Topology;tree comparison	To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.	Guerra-Gomez, J.	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs	10.1109/TVCG.2013.225	http://dx.doi.org/10.1109/TVCG.2013.225	2576	2585	6634198	bioinformatics;data compression;data visualisation	automated macromotif detection;biological data repository;candidate macro computation;data curation tasks;data repositories;glyph design;macro candidate identification;macro glyph;state transition information;visual compression;workflow graphs;workflow visualizations	Algorithm design and analysis;Biological system modeling;Data visualization;Semantics	Algorithm design and analysis;Biological system modeling;Data visualization;Semantics;Workflow visualization;glyph generation;glyph-based visualization;motif detection;state-transition-based algorithm	This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.	Maguire, E.	Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Automatic Layout of Structured Hierarchical Reports	10.1109/TVCG.2013.137	http://dx.doi.org/10.1109/TVCG.2013.137	2586	2595	6634099	data visualisation;user interfaces	domain-specific database applications;form-style visualization view;hand-designed database UI;horizontally constrained layout management algorithm;horizontally unconstrained table layouts;low-level presentation details;outline layouts;report-style visualization view;structured hierarchical data display;structured hierarchical reports;table-style visualization view;user interface	Data visualization;Layout;XML	Data visualization;Hierarchy data;Layout;XML;layout management;nested relations;tabular data	Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.	Bakke, E.	Comput. Sci. & Artificial Intell. Lab. (CSAIL), MIT, Cambridge, MA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Edge Compression Techniques for Visualization of Dense Directed Graphs	10.1109/TVCG.2013.151	http://dx.doi.org/10.1109/TVCG.2013.151	2596	2605	6634098	constraint handling;data compression;directed graphs	aggregate connectivity;constraint programming;dense directed graph visualisation;edge compression techniques;lossless compression;modular decomposition;power graph analysis;software dependency analysis	Computer graphics;Edge detection;Modular construction	Computer graphics;Directed graphs;Edge detection;Modular construction;modular decomposition;networks;power graph analysis	We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.			
	VAST+InfoVis+SciVis	Dec. 2013	GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data	10.1109/TVCG.2013.160	http://dx.doi.org/10.1109/TVCG.2013.160	2606	2614	6634192	data visualisation	GPLOM technique;Polaris system;SPLOM;Tableau system;barcharts;categorical variable visualization;continuous variable;generalized plot matrix;glyphs;heatmaps;multidimensional multivariate data visualization;parallel coordinates;scatterplot matrix;textual search feature	Data visualization;Prototypes;Visual databases	Data visualization;Multidimensional data;Prototypes;Visual databases;business intelligence;database visualization;databaseoverview;high-dimensional data;mdmv;parallel coordinates;relational data;scatterplot matrix;tabular data;user interfaces	Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.	Im, J.-F.	Ecole de Technol. Super., Montreal, QC, Canada|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Orthographic Star Coordinates	10.1109/TVCG.2013.182	http://dx.doi.org/10.1109/TVCG.2013.182	2615	2624	6634131	data analysis;data visualisation	2D visualization domain;3D visualization domain;affine projection;aspect ratio;coordinate axis;ellipse;grand tour;orthographic data tour sequence;orthographic interaction;orthographic projection;orthographic star coordinates;principle component tour;projection technique;repeated nonlinear optimization;scatterplot tour;sphere	Data visualization;Minimization;Nonlinear distortion;Principal component analysis;Three-dimensional displays	Data visualization;Minimization;Nonlinear distortion;Principal component analysis;Start plot;Three-dimensional displays;multivariate visualization;visual analytics	Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.	Lehmann, D.J.	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data	10.1109/TVCG.2013.150	http://dx.doi.org/10.1109/TVCG.2013.150	2625	2633	6634155	data analysis;data visualisation;merging;pattern clustering;trees (mathematics)	automation;brushing;data clusters;data correlation;dimension correlation;dimension projection matrix;dimension projection plot;dimension projection tree;high dimensional data;interactive subspace visual analysis;interactive subspace visual exploration;merging;scatterplot matrix;user interaction	Algorithm design and analysis;Clustering algorithms;Correlation;Data visualization;Image color analysis	Algorithm design and analysis;Clustering algorithms;Correlation;Data visualization;High dimensional data;Image color analysis;hierarchical visualization;matrix;sub-dimensional space;subspace;tree;user interaction	For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.	Xiaoru Yuan	Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices	10.1109/TVCG.2013.153	http://dx.doi.org/10.1109/TVCG.2013.153	2634	2643	6634128	data analysis;data visualisation;pattern clustering	2D scatterplot technique;DR exploration process;SPLOM;cluster separation;color-coded classes;data reduction;data visualization;dimension reduction technique;heatmap approach;high-dimensional data;interactive 3D Scatterplots;scatterplot matrices;visual encoding choices	Data analysis;Data visualization;Encoding;Principal component analysis;Three-dimensional displays	Data analysis;Data visualization;Dimensionality reduction;Encoding;Principal component analysis;Three-dimensional displays;quantitative study;scatterplots	To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.	Sedlmair, M.	Univ. of Vienna, Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visualization of Shape Motions in Shape Space	10.1109/TVCG.2013.230	http://dx.doi.org/10.1109/TVCG.2013.230	2644	2652	6634092	cardiology;data visualisation;medical diagnostic computing;pattern classification	2D surface manifold;3D heart motion disparity;3D heart motion similarity;abnormal human heart deformation;cardiac diagnostic methods;classification method;comparative visualization;deformation behavior visualization;dynamic object deformation analysis;geodesic distance;geometric point-of-view;heart motion sequence visualization;medial surface shape space;medial surfaces;motion data collection;normal human heart deformation;shape descriptors;shape motion visualization;visualization method	Atomic measurements;Biomedical monitoring;Cardiology;Data visualization;Heart;Level measurement;Shape analysis	Atomic measurements;Biomedical monitoring;Cardiology;Data visualization;Heart;Level measurement;Medial surface;Shape analysis;comparative visualization;left ventricle diagnosis;shape space	Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.	Taimouri, V.	Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Fast Blending Scheme for Molecular Surface Representation	10.1109/TVCG.2013.158	http://dx.doi.org/10.1109/TVCG.2013.158	2653	2662	6634161	Gaussian processes;biology computing;data visualisation;iterative methods;molecular biophysics;ray tracing;rendering (computer graphics)	GPU-based ray-casting algorithm;Gaussian model;Gaussian representation;SES model;fast blending scheme;implicit functions;iterative blending;molecular representation visualization;molecular surface representation;molecules interaction;qualitative comparison;quantitative comparison;rendering performance;surface visualization	Atomic measurements;Computational modeling;Mathematical model;Rendering (computer graphics);Solvents	Atomic measurements;Computational modeling;Mathematical model;Molecular visualization;Rendering (computer graphics);Solvents;geometry-based techniques;implicit surfaces	Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.	Parulek, J.	Dept. ofInformatics, Univ. of Bergen, Bergen, Norway|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Detecting Symmetry in Scalar Fields Using Augmented Extremum Graphs	10.1109/TVCG.2013.148	http://dx.doi.org/10.1109/TVCG.2013.148	2663	2672	6634095	computational geometry;data visualisation;graph theory	augmented extremum graph;cryo-electron microscopy dataset;data structure;geometric information;robust distance estimation;scalar field data visualization;symmetric pattern;symmetry detection;topological informaton	Computer graphics;Feature extraction;Geometry;Histograms;Robustness;Symmetric matrices	Computer graphics;Feature extraction;Geometry;Histograms;Morse decomposition;Robustness;Scalar field visualization;Symmetric matrices;data exploration;extremum graph;symmetry detection	Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.	Thomas, D.M.	Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy	10.1109/TVCG.2013.159	http://dx.doi.org/10.1109/TVCG.2013.159	2673	2682	6634177	diagnostic radiography;graphics processing units;image reconstruction;medical image processing;mesh generation;rendering (computer graphics)	3D anatomical information;3D anatomy geometric reconstruction;GPU-based approach;OpenGL implementation;SSIM model;X-ray attenuation;deformable tetrahedral meshes;graphics processing unit;image generation;optimization process;statistical shape and intensity model;tetrahedral mesh density;tetrahedral mesh shape;virtual X-ray projections rendering;virtual x-ray image	Attenuation;Deformable models;Graphics processing units;Image reconstruction;Shape analysis;Three-dimensional displays;X-ray imaging	Attenuation;Deformable models;Digitally reconstructed radiographs;GPU acceleration;Graphics processing units;Image reconstruction;Shape analysis;Three-dimensional displays;X-ray imaging;image registration;mesh deformation;statistical shape and intensity models;volume rendering	We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.	Ehlke, M.	Zuse Inst. Berlin, Berlin, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	An Information-Aware Framework for Exploring Multivariate Data Sets	10.1109/TVCG.2013.133	http://dx.doi.org/10.1109/TVCG.2013.133	2683	2692	6634187	data analysis;data models;data visualisation;entropy;graph theory;pattern classification	PCP;entropy;graph model;information based importance;information content measurement;information metrics;information theory;information-aware framework;multivariate data set exploration;mutual information;parallel coordinates plots;variable classification;variable interaction;variable isocontours;variable relationship analysis;variable representation;variable saliency;variable similarity;visualization research	Entropy;Information technology;Isosurfaces;Layout;Mutual information;Uncertainty	Entropy;Information technology;Information theory;Isosurfaces;Layout;Mutual information;Uncertainty;framework;isosurface;multivariate uncertainty	Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.	Biswas, A.	Gravity Group, Ohio State Univ., Columbus, OH, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform	10.1109/TVCG.2013.152	http://dx.doi.org/10.1109/TVCG.2013.152	2693	2702	6634159	computational complexity;data visualisation;discrete wavelet transforms;feature extraction;graphics processing units;image retrieval;parallel processing;performance evaluation;statistical analysis;tracking	DWT;WaveletSAT;axis-aligned region histograms;close query performance;data element scan;discrete wavelet transform algorithm;feature identification;feature tracking;grid origin;grid point;histogram computing;integral histogram approach;integral histograms;interactively histogram query;local statistical analysis;logarithmic time complexity;parallel GPU-based implementation;performance-efficient query;sparse representation;storage cost;storage-efficient query;summed area tables;visualization applications;wavelet coefficients	Discrete wavelet transforms;Histograms;Integral equations;Statistical analysis;Time complexity	Discrete wavelet transforms;Histograms;Integral equations;Statistical analysis;Time complexity;WaveletSAT;discrete wavelet transform;integral histograms	Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.	Teng-Yok Lee	Ohio State Univ., Columbus, OH, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging	10.1109/TVCG.2013.138	http://dx.doi.org/10.1109/TVCG.2013.138	2703	2712	6634123	Bayes methods;data visualisation;learning (artificial intelligence);statistical analysis;uncertainty handling	Bayesian model averaging framework;ensemble constituents;event-of-interest prediction;ground truth observations;numerical ensemble forecasting;predictive uncertainty characterization;predictive uncertainty visualization;statistical aggregate;visual strategy;visualization strategy	Bayes methods;Data visualization;Mathematical model;Numerical models;Predictive models	Bayes methods;Data visualization;Mathematical model;Numerical models;Predictive models;Uncertainty visualization;numerical ensembles;statistical visualization	Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.			
	VAST+InfoVis+SciVis	Dec. 2013	Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles	10.1109/TVCG.2013.143	http://dx.doi.org/10.1109/TVCG.2013.143	2713	2722	6634129	data visualisation;learning (artificial intelligence);statistical analysis;uncertainty handling	aggregate representations;average probability;center-outward ordering;computational fluid dynamics;confidence intervals;contour boxplots method;data depth notion;ensemble exploration;ensemble variability visualization;ensemble visualization;functional boxplots;mean;median;outliers;pointwise probability;robust statistics;simulation ensembles;uncertainty characterization;weather forecasting	Computational modeling;Data visualization;Numerical models;Shape analysis;Statistical analysis;Uncertainty;Weather forecasting	Boxplots;Computational modeling;Data visualization;Numerical models;Shape analysis;Statistical analysis;Uncertainty;Uncertainty visualization;Weather forecasting;band depth;ensemble visualization;order statistics	Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.	Whitaker, R.T.	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Uncertainty Quantification in Linear Interpolation for Isosurface Extraction	10.1109/TVCG.2013.208	http://dx.doi.org/10.1109/TVCG.2013.208	2723	2732	6634171	data visualisation;interpolation;statistical distributions	closed-form characterization;data uncertainty;isosurface extraction algorithm;isosurface extraction positional uncertainty;isosurface geometry;isosurface level crossings;level-crossing position;linear interpolation;positional uncertainty visualization;probability density function;random variable modeling;uniform distribution	Data models;Interpolation;Isosurfaces;Probability density function;Random variables;Uncertainty	Data models;Interpolation;Isosurfaces;Marching Cubes;Probability density function;Random variables;Uncertainty;Uncertainty quantification;isosurface extraction;linear interpolation	We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.	Athawale, T.	Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Coupled Ensemble Flow Line Advection and Analysis	10.1109/TVCG.2013.144	http://dx.doi.org/10.1109/TVCG.2013.144	2733	2742	6634188	data visualisation;flow visualisation;mechanical engineering computing;parallel processing	Lagrangian-based distance metric;MapReduce style;data visualization;ensemble flow line advection;ensemble flow line analysis;ensemble run simulations;ensemble simulations;parallelism;pathline analysis;pathline variation extraction;pathline variation visualization;variation field	Computational modeling;Data visualization;Scalability;Spatiotemporal phenomena;Uncertainty	Computational modeling;Data visualization;Ensemble analysis;Scalability;Spatiotemporal phenomena;Uncertainty;field line advection;parallel processing	Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.	Hanqi Guo	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles	10.1109/TVCG.2013.141	http://dx.doi.org/10.1109/TVCG.2013.141	2743	2752	6634122	computational fluid dynamics;data analysis;data visualisation;learning (artificial intelligence);mechanical engineering computing;pattern classification;principal component analysis	CFD ensembles;Lagrangian framework;Lagrangian neighborhoods;Lagrangian transport;classification space;comparative visual analysis;comparative visualization;computational fluid dynamics;data visualization;ensemble joint transport characteristics;ensemble visualization;individual flow divergence effect;parameter space;pathline integration;principal component analysis;scalar ensemble;time-varying vector fields;transport variance;uncertainty measurements;vector field	Computational modeling;Data visualization;Principal component analysis;Trajectory;Visual analytics	Computational modeling;Data visualization;Ensemble;Lagrangian;Principal component analysis;Trajectory;Visual analytics;comparison;flow field;principal components analysis;time-varying;variance;visualization	Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.	Hummel, M.	Univ. of Kaiserslautern, Kaiserslautern, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Adaptive Refinement of the Flow Map Using Sparse Samples	10.1109/TVCG.2013.128	http://dx.doi.org/10.1109/TVCG.2013.128	2753	2762	6634133	computational fluid dynamics;data visualisation;flow visualisation;mechanical engineering computing	Lagrangian flow visualization techniques;Sibson scattered data interpolation;adaptive flow map refinement;data reconstruction;flow definition;flow map reconstruction;geometric structures;massless particle transport;qualitative evaluation;quantitative evaluation;sparse samples;transient flow phenomenon	Approximation error;Image edge detection;Interpolation;Least squares approximations;Surface reconstruction;Trajectory	Approximation error;Image edge detection;Interpolation;Lagrangian flow visualization;Least squares approximations;Surface reconstruction;Trajectory;adaptive refinement;edge features;flow map;parallel reconstruction;scattered data interpolation;sparse sampling	We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.	Barakat, S.S.	Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Visualization of Morse Connection Graphs for Topologically Rich 2D Vector Fields	10.1109/TVCG.2013.229	http://dx.doi.org/10.1109/TVCG.2013.229	2763	2772	6634162	data visualisation;graph theory;vectors	MCG arcs;MCG nodes;MCG visual representation;Morse connection graph visualization;Morse sets;PC vector field;multiscale graph representations;periodic trajectories;piecewise constant vector field;stationary points;topological skeletons;topologically rich 2D vector fields	Computer graphics;Corporate acquisitions;Topology;Trajectory;Two dimensional displays	Computer graphics;Corporate acquisitions;Morse connection graph;Topology;Trajectory;Two dimensional displays;Vector field topology	Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.	Szymczak, A.	Colorado Sch. of Mines, Golden, CO, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates	10.1109/TVCG.2013.189	http://dx.doi.org/10.1109/TVCG.2013.189	2773	2782	6634153	biomedical MRI;blood flow measurement;feature extraction;graphics processing units;haemodynamics;medical image processing;vortices	3D flow measurement;4D PC-MRI acquisition;4D PC-MRI cardiac blood flow data;CVD;GPU;Tetralogy-of-Fallot pathology;aneurysm pathology;blood flow characteristics;cardiac blood flow;cardiovascular diseases;characteristic flow patterns;coarctations pathology;graphics processing unit;line predicates;magnetic resonance imaging;patient-specific hemodynamics;pulmonary artery;semiautomatic vortex extraction;vortex criterion;vortex flow extraction	Arteries;Biomedical monitoring;Blood flow;Cardiovascular system;Data mining;Heart;Pathology;Smoothing methods	4D PC-MRI;Arteries;Biomedical monitoring;Blood flow;Cardiovascular system;Data mining;Heart;Pathology;Smoothing methods;cardiac blood flow;hemodynamics;line predicates;vortex extraction	Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.			
	VAST+InfoVis+SciVis	Dec. 2013	Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles	10.1109/TVCG.2013.147	http://dx.doi.org/10.1109/TVCG.2013.147	2783	2791	6634138	CAD;computational fluid dynamics;data visualisation;digital simulation;drag;finite element analysis;user interfaces	CFD simulation;FEA simulation;as-direct-as-possible;as-rigid-as-possible shape manipulation;computationally-intensive simulations;creative design tasks;creative forward design;design spaces;direct manipulation;dragging design;in-place interactive ensemble visualization;inverse design strategy;medical device engineering;morphing arbitrary scalar fields output;multitouch input;parameterized models;physically based flame simulation;reshaping simulation outputs;simulation ensembles;simulation inputs;simulation-based engineering;tugging simulation output;tuning parameters;user drag operations;vacuum-assisted biopsy device;visual effects design;visual query;visual space	Biological system modeling;Computational modeling;Data models;Data visualization;Real-time systems	Biological system modeling;Computational modeling;Data models;Data visualization;Design;Real-time systems;direct manipulation;multi-touch;simulation	We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.	Coffey, D.	Univ. of Minnesota, Minneapolis, MN, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation	10.1109/TVCG.2013.123	http://dx.doi.org/10.1109/TVCG.2013.123	2792	2801	6634149	cameras;computer animation;computerised instrumentation;data visualisation;natural sciences computing;path planning	camera motion path planning;coherent animations;complex scientific visualizations;context-aware animation;dynamic multicriteria solver;force-directed routing algorithm;integrated camera motion design;interactive volume visualization system;path generation system;volume data animation	Animation;Cameras;Data visualization;Motion control;Rendering (computer graphics);Three-dimensional displays	Animation;Camera motion planning;Cameras;Data visualization;Motion control;Rendering (computer graphics);Three-dimensional displays;animation;visualization;volume rendering	We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.	Wei-Hsien Hsu	Univ. of California, Davis, Davis, CA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	A Lightweight Tangible 3D Interface for Interactive Visualization of Thin Fiber Structures	10.1109/TVCG.2013.121	http://dx.doi.org/10.1109/TVCG.2013.121	2802	2809	6651934	biological tissues;biology computing;cameras;data analysis;data visualisation;feature extraction;haptic interfaces;proteins;stereo image processing;virtual reality	3D bioimaging datasets;3D interactive visualization;bioimaging datasets;biophotonic experts;collagen fibers;commodity visualization technology;data exploration;depth sensing camera;fiber centerline extraction;fiber orientation;fiber orientation analysis;fish-tank stereposcopic virtual reality system;graphics community;interactive exploratory visualization system;interactive visualization;lightweight tangible 3D interface;low-cost 3D display;low-level algorithm;passive-haptic feedback;scientist desk;second-harmonic generation microscopy;small-scale gesture tracking;thin fiber structures;three-dimensional thin fiber data;visual data analysis;volumetric imaging	Data visualization;Microscopy;Three dimensional displays	3D interaction;Data visualization;Microscopy;Scientific visualization;Three dimensional displays;microscopy visualization;tangible interaction	We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.	Jackson, B.	Univ. of Minnesota, Minneapolis, MN, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities	10.1109/TVCG.2013.156	http://dx.doi.org/10.1109/TVCG.2013.156	2810	2817	6634097	computer based training;data visualisation	3D object orthographic projection;3D task learning;3D task mastering;MRT;dynamic visualization training approach;mental rotation test;static visualization training approach;user spatial abilities;visualization training programs	Animation;Atmospheric measurements;Design automation;Optimized production technology;Particle measurements;Spatial resolution	3D visualization;Animation;Atmospheric measurements;CAD.;Design automation;Optimized production technology;Particle measurements;Spatial ability;Spatial resolution;evaluation;orthographic projection;training	Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.			
	VAST+InfoVis+SciVis	Dec. 2013	A Systematic Review on the Practice of Evaluating Visualization	10.1109/TVCG.2013.126	http://dx.doi.org/10.1109/TVCG.2013.126	2818	2827	6634108	data visualisation;encoding	IEEE information visualization;IEEE visualization conference;coding scheme;domain-specific work practices;meta-level;requirements analyses;visual tools;visualization evaluation	Data visualization;Encoding;History;Mathematical model;Systematics	Data visualization;Encoding;Evaluation;History;Mathematical model;Systematics;information visualization;scientific visualization;systematic review;validation;visualization	We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.	Isenberg, T.	INRIA, Sophia-Antipolis, France|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Interactive Patient-Specific Vascular Modeling with Sweep Surfaces	10.1109/TVCG.2013.169	http://dx.doi.org/10.1109/TVCG.2013.169	2828	2837	6634086	data visualisation;diseases;haemodynamics;haemorheology;image segmentation;interactive systems;medical image processing	aneurysms;automatic segmentations;blood flow simulation pipelines;complex vascular free-form contours;geometric centerline descriptions;implicit sweep surfaces;interactive patient-specific vascular modeling;pathological structures;stenoses	Biomedical imaging;Computational modeling;Image segmentation;Interpolation;Splines (mathematics);Vascular structures	Biomedical imaging;Computational modeling;Image segmentation;Interpolation;Splines (mathematics);Surface modeling;Vascular structures;centerline-based modeling;vascular visualization	The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.	Kretschmer, J.	Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Area-Preservation Mapping using Optimal Mass Transport	10.1109/TVCG.2013.135	http://dx.doi.org/10.1109/TVCG.2013.135	2838	2847	6634117	Newton method;convex programming;data visualisation	Monge-Brenier theory;Monge-Kantorovich approach;Newton method;area weighting strategy;area-preservation flattening method;area-preservation mapping method;conformal mapping;convex optimization problem;graphics application;medical imaging application;optimal mass transport technique;visualization application	Area measurement;Conformal mapping;Convex functions;Shape analysis;Transportation	Area measurement;Area-preservation mapping;Conformal mapping;Convex functions;Monge-Brenier theory;Shape analysis;Transportation;optimal transport map;surface flattening;visualization and graphics applications				
	VAST+InfoVis+SciVis	Dec. 2013	Colon Flattening Using Heat Diffusion Riemannian Metric	10.1109/TVCG.2013.139	http://dx.doi.org/10.1109/TVCG.2013.139	2848	2857	6634145	Laplace equations;image registration;medical image processing;rendering (computer graphics)	Euclidean metric;Laplacian equation;colon flattening;colon registration pipeline;heat diffusion Riemannian metric;heat diffusion metric;integration step;shape-preserving;topological noise;virtual colonoscopy inspection;volume rendering	Biomedical measurement;Colonoscopy;Harmonic analysis;Heating;Volume rendering	Biomedical measurement;Colon flattening;Colonoscopy;Harmonic analysis;Heating;Volume rendering;heat diffusion;shape-preserving mapping;topological noise;virtual colonoscopy;volume rendering	We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.	Gurijala, K.C.	Stony Brook Univ., Stony Brook, NY, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Vessel Visualization using Curved Surface Reformation	10.1109/TVCG.2013.215	http://dx.doi.org/10.1109/TVCG.2013.215	2858	2867	6634141	data visualisation;diagnostic radiography;image reconstruction;medical image processing;rendering (computer graphics)	2D image space;3D lumina data query;CPR method;CSR technique;blood flow obstructions;centerline reformation;curved planar reformation method;curved surface reformation;radiological investigations;vascular disease analysis;vascular structure visualization;vessel lumen reconstruction;vessel lumina visualization;vessel visualization;visibility information;visual vessel wall calcification assessment	Data visualization;Radiology;Rendering (computer graphics);Surface treatment;Three-dimensional displays;Vascular structures	Data visualization;Radiology;Reformation;Rendering (computer graphics);Surface treatment;Three-dimensional displays;Vascular structures;surface approximation;volume rendering	Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.	Auzinger, T.	Vienna Univ. of Technol., Vienna, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data	10.1109/TVCG.2013.142	http://dx.doi.org/10.1109/TVCG.2013.142	2868	2877	6634132	biology computing;data analysis;data visualisation;electron microscopy;meta data;neurophysiology;query processing	ConnectomeExplorer application;EM data;EM volume querying;EM volume visualization;connectomics research;dynamically evaluated query specification;knowledge-based query algebra;large volumetric electron microscopy data;large volumetric neuroscience data;meta data;neuronal connectivity;neuronal data attributes;query-guided visual analysis;scalable volume visualization framework;segmentation volumes;visual query builder	Data visualization;Nerve fibers;Neuroscience;Query processing;Three-dimensional displays	Connectomics;Data visualization;Nerve fibers;Neuroscience;Query processing;Three-dimensional displays;neuroscience;petascale volume analysis;query algebra;visual knowledge discovery	This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.	Beyer, J.	King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|	
	VAST+InfoVis+SciVis	Dec. 2013	ManyVis: Multiple Applications in an Integrated Visualization Environment	10.1109/TVCG.2013.174	http://dx.doi.org/10.1109/TVCG.2013.174	2878	2885	6634144	application program interfaces;data visualisation;user interfaces;virtual reality	API level;ManyVis;SDK level;ad-hoc scripts;general toolkits;integrated visualization environment;user interfaces;virtual application	Data visualization;Graphical user interfaces;Image color analysis;Programming;Shape analysis	Data visualization;Graphical user interfaces;Image color analysis;Programming;Shape analysis;Visualization environments;integrated applications;linked views;macros	As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.	Rungta, A.	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Acuity-Driven Gigapixel Visualization	10.1109/TVCG.2013.127	http://dx.doi.org/10.1109/TVCG.2013.127	2886	2895	6634175	computer displays;data visualisation;image resolution;rendering (computer graphics)	acuity-driven gigapixel visualization;acuity-driven rendering optimizations;acuity-driven tessellation scheme;focus-and-context lenses;gigapixel displays;gigapixel image rendering scheme;head tracking information;image quality;reality deck immersive gigapixel display;search task performance;super-high resolution image data;tiled display walls;user navigation;user study;visual acuity formulation;visual exploration process	Context awareness;Data visualization;Image resolution;Lenses;Pixels;Rendering (computer graphics)	Context awareness;Data visualization;Gigapixel visualization;Image resolution;Lenses;Pixels;Reality Deck;Rendering (computer graphics);focus and context;gigapixel display;visual acuity	We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.	Papadopoulos, C.	Stony Brook Univ., Stony Brook, NY, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	An Exploration Framework to Identify and Track Movement of Cloud Systems	10.1109/TVCG.2013.131	http://dx.doi.org/10.1109/TVCG.2013.131	2896	2905	6634109	clouds;data analysis;data visualisation;geophysics computing	MJO envelope;MJO scale;Madden Julian Oscillation;Nakazawa cloud clusters;a priori knowledge;cloud system identification;cloud system movement tracking;cloud system movement visualization;computational topology;computer vision;data analysis;exploration framework	Brightness temperature;Clouds;Data visualization;Level set;Meteorology;Optical imaging;Tracking	Brightness temperature;Cloud clusters;Clouds;Data visualization;Level set;Meteorology;Optical imaging;Tracking;computational topology;split tree;tracking;weather and climate simulations	We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.	Doraiswamy, H.	Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data	10.1109/TVCG.2013.177	http://dx.doi.org/10.1109/TVCG.2013.177	2906	2915	6634106	aerospace components;aerospace industry;carbon fibre reinforced plastics;computerised tomography;data visualisation;heat conduction;infrared imaging;porosity;ultrasonic materials testing	CFRP nondestructive testing practitioners;CFRP specimens;MObject parameter space;MObjects visualization;active thermography;advanced visualization method;analysis path;carbon fiber reinforced polymers;color-coded homogeneity visualization;data visualization;heat conduction simulations;industrial 3D X-ray computed tomography data;industrial XCT data;interactive exploration;interactive selection;mean object sets;parallel arrangement;pore extraction;pore property;porosity determination;radial arrangement;representative pores;shape factor;ultrasonic calibration curves;visual linking approach;volume factor;volumetric datasets	Biomedical imaging;Data visualization;Three-dimensional displays;Transfer functions;X-ray tomography	3D X-Ray computed tomography;Biomedical imaging;Data visualization;MObjects;Three-dimensional displays;Transfer functions;X-ray tomography;carbon fiber reinforced polymers;parameter space analysis;porosity	This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.	Reh, A.	Univ. of Appl. Sci. Upper Austria, Wels, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data	10.1109/TVCG.2013.161	http://dx.doi.org/10.1109/TVCG.2013.161	2916	2925	6634119	biomedical MRI;data visualisation;geriatrics;iterative methods;least squares approximations;medical image processing;neurophysiology	GRACE;abstract visual representation;comparative visualization;design description;domain analysis;integrated spatial data;interactive visual comparison;interactive visualization techniques;iterated Tikhonov regularization algorithms;iterative design;magnetic resonance imaging volumes;mathematical analysis;medical imaging;neurologymobility connections;nonspatial data;nonspatial domain;nonspatial geriatric data;nonspatial geriatric research data;sparse partial least squares;spatial representation;visual analysis framework;visual comparison framework;visual integration	Algorithm design and analysis;Biomedical imaging;Brain modeling;Data visualization;Geriatrics;Rendering (computer graphics)	Algorithm design and analysis;Biomedical imaging;Brain modeling;Data visualization;Design studies;Geriatrics;Rendering (computer graphics);applications of visualization;high-dimensional data;integrating spatial and non-spatial datavisualization;methodology design;task and requirements analysis;visual comparison	We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.	Maries, A.	Dept. of Comput. Sci., Univ. of Pittsburgh, Pittsburgh, PA, USA|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data	10.1109/TVCG.2013.180	http://dx.doi.org/10.1109/TVCG.2013.180	2926	2935	6634151	data visualisation;filtering theory;random noise;real-time systems;rendering (computer graphics);transfer functions	3D volume visualization method;aliasing avoidance;color readability improvement;data attributes;error rates;high-frequency redistribution pattern;mapping function filtering;multivariate volumetric data visualization;noise-based volume rendering;opacity mapping function;opacity redistribution;predictable procedural noise;random-phase Gabor noise;regular transfer function;simultaneous real-time visualization;transparent region maintenance	Colored noise;Data visualization;Image color analysis;Rendering (computer graphics);Three-dimensional displays;Transfer functions	Colored noise;Data visualization;Image color analysis;Rendering (computer graphics);Three-dimensional displays;Transfer functions;Volume rendering;multi-variate data visualization;multi-volume rendering;scientific visualization	Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.	Khlebnikov, R.	Graz Univ. of Technol., Graz, Austria|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Ambient Volume Scattering	10.1109/TVCG.2013.129	http://dx.doi.org/10.1109/TVCG.2013.129	2936	2945	6634150	Monte Carlo methods;data visualisation;rendering (computer graphics);table lookup	GPU implementation;Monte-Carlo simulation;ambient volume scattering method;anisotropy parameter;data set visualization;direct volume rendering;exponential attenuation;extinction parameter;far-range scattering effects;full light transport problem;graphics processing unit;high-quality illumination;lighting conditions;local illumination;look-up table;material parameter;mesoscopic scales;phase function;preintegration method;ray sample point;rendering speed;spatial perception;spherical regions;translucency;viewing direction;viewpoint parameter;volumetric ambient occlusion	Computational modeling;Light sources;Lighting;Rendering (computer graphics);Scattering;Solid modeling;Transfer functions	Computational modeling;Direct volume rendering;Light sources;Lighting;Rendering (computer graphics);Scattering;Solid modeling;Transfer functions;ambient scattering;gradient-free shading;preintegrated light transport;volume illumination	We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.	Ament, M.	Univ. of Stuttgart, Stuttgart, Germany|c|	
	VAST+InfoVis+SciVis	Dec. 2013	Lighting Design for Globally Illuminated Volume Rendering	10.1109/TVCG.2013.172	http://dx.doi.org/10.1109/TVCG.2013.172	2946	2955	6634193	data visualisation;lighting;rendering (computer graphics)	automatic tone mapping operator;back light;depth perception;global light transportation;global shadow;globally illuminated volume rendering;graphics hardware;lighting design;local illumination;multiple scattering;realtime volume rendering;shading effects;shape perception;transfer-function dependent content;view dependent content;volume data visualization;volume visualization;volumetric features	Data visualization;Image color analysis;Light sources;Lighting;Rendering (computer graphics);Volume rendering	Data visualization;Global illumination;Image color analysis;Light sources;Lighting;Rendering (computer graphics);Volume rendering;lighting design;tone mapping;volume rendering	With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.	Yubo Zhang	Univ. of California, Davis, Davis, CA, USA|c|	
