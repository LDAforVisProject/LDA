Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis	21-21 Oct. 2003	IEEE Symposium on Information Visualization 2003 (IEEE Cat. No.03TH8714)	10.1109/INFVIS.2003.1249000	http://dx.doi.org/10.1109/INFVIS.2003.1249000			1249000	computer displays;data visualisation;graphs;hidden feature removal	computer displays;context;design studies;graphs;high dimensionality;linking;multiscale systems;occlusion;visualization evaluation	Computer displays;Visualization		The following topics are dealt with: computer displays; multiscaling; graphs; high dimensionality; occlusion; visualization evaluation; linking and design studies.			
	InfoVis	21-21 Oct. 2003	Thinking with visualization	10.1109/INFVIS.2003.1249001	http://dx.doi.org/10.1109/INFVIS.2003.1249001	3	3	1249001			Books;Cities and towns;Computer architecture;Computer science;Data visualization;Displays;Geographic Information Systems;Humans;Psychology;Software systems			Ware, C.	Data Visualization Research Lab|c|	37265850800
	InfoVis	21-21 Oct. 2003	Exploding the frame: designing for wall-size computer displays	10.1109/INFVIS.2003.1249002	http://dx.doi.org/10.1109/INFVIS.2003.1249002	7		1249002	computer displays;screens (display)	IMAX films;control design;data displays;data set representations;display walls;frameless screens;graphic design;high-resolution displays;image design;image visualization;interactive design;interface design;interface research;pervasive computing;tiled displays;visual images;visual interface;visual space;wall-size computer displays;wall-size digital displays	Computer displays;Computer science;Control design;Data visualization;Education;Educational institutions;Graphics;Large screen displays;Pervasive computing;Production		"High-resolution wall-size digital displays present significant new and different visual space to show and see imagery. The author has been working with two wall-size digital displays at Princeton University for five years and directing and producing IMAX films for a decade, and he has noted some unique design considerations for creating effective visual images when they are spread across entire walls. The author suggests these ""frameless"" screens - where images are so large we need to look around to see the entire field - need different ways of thinking about image design and visualization. Presenting such things as scale and detail take on new meaning when they can be displayed life-size and not shown in the context of one or many small frames such as we see everywhere. These design ideas will be of use for pervasive computing, interface research and design, interactive design, control design, representations of massive data sets, and creating effective displays of data for research and education."	Shedd, B.	Princeton Univ., NJ, USA|c|	37443178200
	InfoVis	21-21 Oct. 2003	Information esthetics: from MoMa to wall street	10.1109/INFVIS.2003.1249003	http://dx.doi.org/10.1109/INFVIS.2003.1249003	11	11	1249003			Art;Computer graphics;Data visualization;Decoding;Digital images;Displays;Guidelines;Knowledge acquisition;Pipelines;User interfaces			Paley, W.B.	Digital Image Design & Columbia University|c|	38202672400
	InfoVis	21-21 Oct. 2003	Smooth and efficient zooming and panning	10.1109/INFVIS.2003.1249004	http://dx.doi.org/10.1109/INFVIS.2003.1249004	15	23	1249004	computational geometry;computer animation;data visualisation;graphical user interfaces;image processing	2D information spaces;abstract visualization;animation speed;computational model;image visualization;inspection techniques;map visualization;navigation;optimal animations;panning;perceived velocity;scale space;scrolling;smooth animations;software engineering;user interfaces;zooming	Animation;Chromium;Cities and towns;Computational modeling;Computer graphics;Data visualization;Navigation;Software engineering;Switches;Uninterruptible power systems		Large 2D information spaces, such as maps, images, or abstract visualizations, require views at various level of detail: close ups to inspect details, overviews to maintain (literally) an overview. Users often switch between these views. We discuss how smooth animations from one view to another can be defined. To this end, a metric on the effect of simultaneous zooming and panning is defined, based on an estimate of the perceived velocity. Optimal is defined as smooth and efficient. Given the metric, these terms can be translated into a computational model, which is used to calculate an analytic solution for optimal animations. The model has two free parameters: animation speed and zoom/pan trade off. A user experiment to find good values for these is described.	van Wijk, J.J.;Nuij, W.A.A.	Dept. of Math. & Comput. Sci., Technische Universiteit Eindvohen, Netherlands|c|;	37267249200;38201799400
	InfoVis	21-21 Oct. 2003	A model of multi-scale perceptual organization in information graphics	10.1109/INFVIS.2003.1249005	http://dx.doi.org/10.1109/INFVIS.2003.1249005	23	30	1249005	computer displays;computer vision;data visualisation;graphical user interfaces;software tools	design aid;design methodology;formal model;grayscale image;human perception;information graphics;lattice structure;machine vision;multiple resolutions;multiscale perceptual organization;perceptual structure;scale space;screen design;software psychology;software tool;user interfaces;user/machine systems;visual displays;visual organization;visual structure	Collaboration;Design methodology;Displays;Graphics;Gray-scale;Guidelines;Humans;Image analysis;Software tools;Visualization		We propose a new method for assessing the perceptual organization of information graphics, based on the premise that the visual structure of an image should match the structure of the data it is intended to convey. The core of our method is a new formal model of one type of perceptual structure, based on classical machine vision techniques for analyzing an image at multiple resolutions. The model takes as input an arbitrary grayscale image and returns a lattice structure describing the visual organization of the image. We show how this model captures several aspects of traditional design aesthetics, and we describe a software tool that implements the model to help designers analyze and refine visual displays. Our emphasis here is on demonstrating the model's potential as a design aid rather than as a description of human perception, but given its initial promise we propose a variety of ways in which the model could be extended and validated.	Wattenberg, M.;Fisher, D.	Collaborative User Experience Group, IBM Res., White Plains, NY, USA|c|;	37550759700;37737355700
	InfoVis	21-21 Oct. 2003	Exploring high-D spaces with multiform matrices and small multiples	10.1109/INFVIS.2003.1249006	http://dx.doi.org/10.1109/INFVIS.2003.1249006	31	38	1249006	data analysis;data mining;data visualisation;geographic information systems;medical diagnostic computing;object-oriented programming;pattern recognition;visual databases	EDA;GeoVISTA Studio;bivariate maps;bivariate matrix;bivariate representation;bivarite small multiple plot;cancer diagnosis;component-based architecture;conditional entropy;default order;exploratory data analysis;geovisualization;high-dimensional data set;high-dimensional space exploration;information visualization;mortality data;multiform matrices;multiple display;multivariate data;risk factors;scatterplot matrices;scatterplot matrix;scatterplots;small multiples;space-filling displays;visual analysis	Cancer;Data analysis;Data visualization;Displays;Electronic design automation and methodology;Entropy;Filtering;Information analysis;Scattering;Space exploration		We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors.	MacEachren, A.;Hardisty, F.;Diansheng Guo;Lengerich, G.	Dept. of Geogr., Pennsylvania State Univ., University Park, VA, USA|c|;;;	37374699000;37945504200;38197945800;38202682500
	InfoVis	21-21 Oct. 2003	Design choices when architecting visualizations	10.1109/INFVIS.2003.1249007	http://dx.doi.org/10.1109/INFVIS.2003.1249007	41	48	1249007	data visualisation;meta data;software architecture;visual databases	Rivet;data access;data sets;data transformations;design tradeoffs;information systems;information visualization;internal data model;modular objects;semantic meta-data information;system architecture;visual decodings;visualization architecture;visualization system;visualization tool prototyping	Chromium;Data models;Data visualization;Displays;Encoding;Information analysis;Information systems;Polarization;Prototypes;User interfaces		In this paper, we focus on some of the key design decisions we faced during the process of architecting a visualization system and present some possible choices, with their associated advantages and disadvantages. We frame this discussion within the context of Rivet, our general visualization environment designed for rapidly prototyping interactive, exploratory visualization tools for analysis. As we designed increasingly sophisticated visualizations, we needed to refine Rivet in order to be able to create these richer displays for larger and more complex data sets. The design decisions we discuss in this paper include: the internal data model, data access, semantic meta-data information the visualization can use to create effective visual decodings, the need for data transformations in a visualization tool, modular objects for flexibility, and the tradeoff between simplicity and expressiveness when providing methods for creating visualizations.	Tang, D.;Stolte, C.;Bosche, R.	Stanford Univ., CA, USA|c|;;	37652594600;37442008700;37446738400
	InfoVis	21-21 Oct. 2003	Edgelens: an interactive method for managing edge congestion in graphs	10.1109/INFVIS.2003.1249008	http://dx.doi.org/10.1109/INFVIS.2003.1249008	51	58	1249008	air traffic;data visualisation;graphs	Edgelens;Web structures;airline routes;data sets;data visualization;distortion lens;electrical networks;graph edge congestion management;graph layout;graphs;individual edges;information visualization;interactive method;interactive visualization;interconnected nodes;navigation;telecommunication networks;visual information	Chromium;Cities and towns;Computer science;Data visualization;Layout;Lenses;Navigation;Power grids;Telecommunication congestion control;Telephony		An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person's focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph.	Wong, N.;Carpendale, S.;Greenberg, S.	Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;	38198657400;38268267400;37352792200
	InfoVis	21-21 Oct. 2003	MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes	10.1109/INFVIS.2003.1249009	http://dx.doi.org/10.1109/INFVIS.2003.1249009	59	66	1249009	data visualisation;trees (mathematics)	MoireGraphs;animated transitions;communicating topology;graph drawing;graphs;information visualization;level highlighting;node information;radial focus+context interaction;radial focus+context visualization;radial graph layout;radial rotation;tree visualization;visual information;visual nodes	Animation;Computer graphics;Computer science;Data visualization;Displays;Focusing;Geometry;Layout;Topology;Tree graphs		Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.	Jankun-Kelly, T.J.;Kwan-Liu Ma	Mississippi State Univ., Starkville, MS, USA|c|;	38198374100;37275869400
	InfoVis	21-21 Oct. 2003	Visualizing evolving networks: minimum spanning trees versus pathfinder networks	10.1109/INFVIS.2003.1249010	http://dx.doi.org/10.1109/INFVIS.2003.1249010	67	74	1249010	citation analysis;data visualisation;solid modelling;trees (mathematics)	MST;PFNET;botulinum toxin research;cocitation networks;complex networks;dynamical properties;evolving network visualization;growth animation;high-degree nodes;link reduction algorithms;minimum spanning trees;network evolution;pathfinder networks;scale-free networks;scientific publications;shortest paths;small-world networks;topological properties;ubiquitous computing;visualization assessment	Animation;Chaos;Citation analysis;Complex networks;Computer graphics;Computer networks;Data visualization;Educational institutions;Information science;Pervasive computing		Network evolution is an ubiquitous phenomenon in a wide variety of complex systems. There is an increasing interest in statistically modeling the evolution of complex networks such as small-world networks and scale-free networks. In this article, we address a practical issue concerning the visualizations of co-citation networks of scientific publications derived by two widely known link reduction algorithms, namely minimum spanning trees (MSTs) and pathfinder networks (PFNETs). Our primary goal is to identify the strengths and weaknesses of the two methods in fulfilling the need for visualizing evolving networks. Two criteria are derived for assessing visualizations of evolving networks in terms of topological properties and dynamical properties. We examine the animated visualization models of the evolution of botulinum toxin research in terms of its co-citation structure across a 58-year span (1945-2002). The results suggest that although high-degree nodes dominate the structure of MST models, such structures can be inadequate in depicting the essence of how the network evolves because MST removes potentially significant links from high-order shortest paths. In contrast, PFNET models clearly demonstrate their superiority in maintaining the cohesiveness of some of the most pivotal paths, which in turn make the growth animation more predictable and interpretable. We suggest that the design of visualization and modeling tools for network evolution should take the cohesiveness of critical paths into account.	Chen, C.;Morris, S.	Coll. of Inf. Sci. & Technol., Drexel Univ., Philadelphia, PA, USA|c|;	37280749300;37734723200
	InfoVis	21-21 Oct. 2003	A virtual workspace for hybrid multidimensional scaling algorithms	10.1109/INFVIS.2003.1249013	http://dx.doi.org/10.1109/INFVIS.2003.1249013	91	96	1249013	computational complexity;data structures;data visualisation;visual programming	HIVE;MDS;algorithmic architecture;computational complexity;data flows;data sets;data visualisation;data volume;hybrid algorithm;hybrid combinations;multidimensional data;multidimensional scaling;variable distribution;variable types;virtual workspace;visual programming	Chromium;Clustering algorithms;Computer architecture;Computer graphics;Data structures;Data visualization;Multidimensional systems;Pattern recognition;Springs;Visual databases		In visualising multidimensional data, it is well known that different types of algorithms to process them. Data sets might be distinguished according to volume, variable types and distribution, and each of these characteristics imposes constraints upon the choice of applicable algorithms for their visualization. Previous work has shown that a hybrid algorithmic approach can be successful in addressing the impact of data volume on the feasibility of multidimensional scaling (MDS). This suggests that hybrid combinations of appropriate algorithms might also successfully address other characteristics of data. This paper presents a system and framework in which a user can easily explore hybrid algorithms and the data flowing through them. Visual programming and a novel algorithmic architecture let the user semi-automatically define data flows and the co-ordination of multiple views.	Ross, G.;Chalmers, M.	Dept. of Comput. Sci., Glasgow Univ., UK|c|;	37282731400;37283487400
	InfoVis	21-21 Oct. 2003	Dynamic visualization of transient data streams	10.1109/INFVIS.2003.1249014	http://dx.doi.org/10.1109/INFVIS.2003.1249014	97	104	1249014	data mining;data visualisation;remote sensing;sensor fusion	adaptive visualization;data fusion;data fusion-based visualization;data stratification;data stratification-based visualization;dynamic visualization;incremental visualization;multidimensional scaling;neighboring data;newswires;remote sensing imagery;singular vectors;text visualization;transient data streams;visualization subspace	Computer graphics;Data analysis;Data visualization;Image databases;Multidimensional systems;Remote sensing;Scattering;Streaming media;Transient analysis;Visual databases		We introduce two dynamic visualization techniques using multidimensional scaling to analyze transient data streams such as newswires and remote sensing imagery. While the time-sensitive nature of these data streams requires immediate attention in many applications, the unpredictable and unbounded characteristics of this information can potentially overwhelm many scaling algorithms that require a full re-computation for every update. We present an adaptive visualization technique based on data stratification to ingest stream information adaptively when influx rate exceeds processing rate. We also describe an incremental visualization technique based on data fusion to project new information directly onto a visualization subspace spanned by the singular vectors of the previously processed neighboring data. The ultimate goal is to leverage the value of legacy and new information and minimize re-processing of the entire dataset in full resolution. We demonstrate these dynamic visualization results using a newswire corpus and a remote sensing imagery sequence.	Pak Chung Wong;Foote, H.;Adams, D.;Cowley, W.;Thomas, J.	PNNL, Richland, WA, USA|c|;;;;	38193849400;37372586800;38022952100;37672002300;37273308900
	InfoVis	21-21 Oct. 2003	Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets	10.1109/INFVIS.2003.1249015	http://dx.doi.org/10.1109/INFVIS.2003.1249015	105	112	1249015	data mining;data visualisation;graphical user interfaces;pattern clustering	DOSFA;data space navigation;dimension filtering;dimension hierarchies;dimension hierarchy manipulation;dimension management;dimension ordering;dimension spacing;dimensional management;high dimensional dataset exploration;high dimensional datasets;interactive hierarchical dimensions;multidimensional visualization;multidimensional visualizations;parallel coordinates;pixel-oriented techniques;star glyphs;visual exploration;visual interaction tools	Computer science;Data visualization;Displays;Face detection;Information filtering;Information filters;Multidimensional systems;Navigation;Stacking;Visual databases		Large number of dimensions not only cause clutter in multi-dimensional visualizations, but also make it difficult for users to navigate the data space. Effective dimension management, such as dimension ordering, spacing and filtering, is critical for visual exploration of such datasets. Dimension ordering and spacing explicitly reveal dimension relationships in arrangement-sensitive multidimensional visualization techniques, such as parallel coordinates, star glyphs, and pixel-oriented techniques. They facilitate the visual discovery of patterns within the data. Dimension filtering hides some of the dimensions to reduce clutter while preserving the major information of the dataset. In this paper, we propose an interactive hierarchical dimension ordering, spacing and filtering approach, called DOSFA. DOSFA is based on dimension hierarchies derived from similarities among dimensions. It is scalable multi-resolution approach making dimensional management a tractable task. On the one hand, it automatically generates default settings for dimension ordering, spacing and filtering. On the other hand, it allows users to efficiently control all aspects of this dimension management process via visual interaction tools for dimension hierarchy manipulation. A case study visualizing a dataset containing over 200 dimensions reveals high dimensional visualization techniques.	Jing Wang;Peng, W.;Ward, M.O.;Rundensteiner, E.A.	Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA|c|;;;	;37929204000;37268441700;37279217900
	InfoVis	21-21 Oct. 2003	Mapping nominal values to numbers for effective visualization	10.1109/INFVIS.2003.1249016	http://dx.doi.org/10.1109/INFVIS.2003.1249016	113	120	1249016	data compression;data visualisation;mathematics computing;software packages	DQC approach;XmdvTool package;classing step;clustering;correspondence analysis;data sets;data visualization;dimension reduction;distance step;distance-quantification-classing;nominal data;nominal value mapping;nominal variables;norminal values;numeric variables;quantification step;visual exploration displays;visualization tools	Chromium;Computer displays;Computer science;Data visualization;Information analysis;Mathematics;Packaging;Pattern analysis;Pattern recognition;Probability		Data sets with a large number of nominal variables, some with high cardinality, are becoming increasingly common and need to be explored. Unfortunately, most existing visual exploration displays are designed to handle numeric variables only. When importing data sets with nominal values into such visualization tools, most solutions to date are rather simplistic. Often, techniques that map nominal values to numbers do not assign order or spacing among the values in a manner that conveys semantic relationships. Moreover, displays designed for nominal variables usually cannot handle high cardinality variables well. This paper addresses the problem of how to display nominal variables in general-purpose visual exploration tools designed for numeric variables. Specifically, we investigate (1) how to assign order and spacing among the nominal values, and (2) how to reduce the number of distinct values to display. We propose that nominal variables be pre-processed using a distance-quantification-classing (DQC) approach before being imported into a visual exploration tool. In the distance step, we identify a set of independent dimensions that can be used to calculate the distance between nominal values. In the quantification step, we use the independent dimensions and the distance information to assign order and spacing among the nominal values. In the classing step, we use results from the previous steps to determine which values within a variable are similar to each other and thus can be grouped together. Each step in the DQC approach can be accomplished by a variety of techniques. We extended the XmdvTool package to incorporate this approach. We evaluated our approach on several data sets using a variety of evaluation measures.	Rosario, G.E.;Rundensteiner, E.A.;Brown, D.C.;Ward, M.O.	Dept. of Comput. Sci., Worcester Polytech. Inst., USA|c|;;;	38202898100;37279217900;38183230000;37268441700
	InfoVis	21-21 Oct. 2003	Intelligently resolving point occlusion	10.1109/INFVIS.2003.1249018	http://dx.doi.org/10.1109/INFVIS.2003.1249018	131	136	1249018	data visualisation;graphical user interfaces;hidden feature removal;jitter;learning (artificial intelligence);neural nets	RadViz;Smart Jittering algorithm;data density;data points;data sets;data visualization;identifiable points;information visualization;low-dimensional visualizations;multidimensional visualizations;neighboring records;neural network;neural networks;nonstandard visual attributes;point occlusion;polar coordinates;scatter plot;shading;transparency	Artificial neural networks;Chromium;Computer graphics;Computer science;Data visualization;Displays;Multidimensional systems;Neural networks;Scattering;User interfaces		Large and high-dimensional data sets mapped to low-dimensional visualizations often result in perceptual ambiguities. One such ambiguity is overlap or occlusion that occurs when the number of records exceeds the number of unique locations in the presentation or when there exist two or more records that map to the same location. To lessen the affect of occlusion, non-standard visual attributes (i.e. shading and/or transparency) are applied, or such records may be remapped to a corresponding jittered location. The resulting mapping efficiently portrays the crowding of records but fails to provide the insight into the relationship between the neighboring records. We introduce a new interactive technique that intelligibly organizes overlapped points, a neural network-based smart jittering algorithm. We demonstrate this technique on a scatter plot, the most widely used visualization. The algorithm can be applied to other one, two, and multi-dimensional visualizations which represent data as points, including 3-dimensional scatter plots, RadViz, polar coordinates.	Trutschl, M.;Grinstein, G.;Cvek, U.	LSU Comput. Sci., LSU Health Sci. Center, Shreveport, LA, USA|c|;;	37546988100;37360588500;37546985400
	InfoVis	21-21 Oct. 2003	Constant density displays using diversity sampling	10.1109/INFVIS.2003.1249019	http://dx.doi.org/10.1109/INFVIS.2003.1249019	137	144	1249019	computer displays;data visualisation;graphical user interfaces;hidden feature removal	Informedia Digital Video Library;constant density algorithms;constant density displays;diversity sampling;global density;graphical objects;greedy algorithm;human factors;image display;information visualization;keyframe occlusion;query results;representative keyframes;user interface	Computer displays;Computer science;Greedy algorithms;Image retrieval;Information retrieval;Sampling methods;Software libraries;Tree graphs;User interfaces;Visualization		The Informedia Digital Video Library user interface summarizes query results with a collage of representative keyframes. We present a user study in which keyframe occlusion caused difficulties. To use the screen space most efficiently to display images, both occlusion and wasted whitespace should be minimized. Thus optimal choices will tend toward constant density displays. However, previous constant density algorithms are based on global density, which leads to occlusion and empty space if the density is not uniform. We introduce an algorithm that considers the layout of individual objects and avoids occlusion altogether. Efficiency concerns are important for dynamic summaries of the Informedia Digital Video Library, which has hundreds of thousands of shots. Posting multiple queries that take into account parameters of the visualization as well as the original query reduces the amount of work required. This greedy algorithm is then compared to an optimal one. The approach is also applicable to visualizations containing complex graphical objects other than images, such as text, icons, or trees.	Derthick, M.;Christel, M.G.;Hauptmann, A.G.;Wactlar, H.D.	Human-Comput. Interaction Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;	37444609500;37284685200;38478161300;37279681600
	InfoVis	21-21 Oct. 2003	Empirical comparison of dynamic query sliders and brushing histograms	10.1109/INFVIS.2003.1249020	http://dx.doi.org/10.1109/INFVIS.2003.1249020	147	153	1249020	data visualisation;graphical user interfaces;information filters;query formulation	DataMaps;brushing histograms;brushing interaction;complex trend evaluation;dynamic queries;dynamic query sliders;filter data;geographic data visualization;information exploration;information visualization;multidimensional visualization;query formulation;real-time visual display;usability study	Data visualization;Displays;Histograms;Information filtering;Information filters;Information retrieval;Manipulator dynamics;Multidimensional systems;User interfaces;Visual databases		Dynamic queries facilitate rapid exploration of information by real-time visual display of both query formulation and results. Dynamic query sliders are linked to the main visualization to filter data. A common alternative to dynamic queries is to link several simple visualizations, such as histograms, to the main visualization with a brushing interaction strategy. Selecting data in the histograms highlights that data in the main visualization. We compare these two approaches in an empirical experiment on DataMaps, a geographic data visualization tool. Dynamic query sliders resulted in better performance for simple range tasks, while brushing histograms was better for complex trend evaluation and attribute relation tasks. Participants preferred brushing histograms for understanding relationships between attributes and the rich information they provided.	Qing Li;North, C.	Dept. of Comput. Sci., Virginia Polytech. Inst & State Univ., Blacksburg, VA, USA|c|;	38199879300;37419565900
	InfoVis	21-21 Oct. 2003	An experimental evaluation of continuous semantic zooming in program	10.1109/INFVIS.2003.1249021	http://dx.doi.org/10.1109/INFVIS.2003.1249021	155	162	1249021	data visualisation;graphical user interfaces;program visualisation;reverse engineering	continuous semantic zooming;flat zooming;human subjects testing;program representation;program visualization;user understanding;visual program languages;visual programs	Chromium;Electronic mail;High performance computing;Humans;Programming environments;Programming profession;Psychology;Testing;User interfaces;Visualization		This paper presents the results of an experiment aimed at investigating how different methods of viewing visual programs affect users' understanding. The first two methods used traditional flat and semantic zooming models of program representation; the third is a new representation that uses semantic zooming combined with blending and proximity. The results of several search tasks performed by approximately 80 participants showed that the new method resulted in both faster and more accurate searches than the other methods.	Summers, K.L.;Goldsmith, T.E.;Caudell, T.P.	Center for High Performance Comput., New Mexico Univ., Albuquerque, NM, USA|c|;;	38026709000;38202832700;37297193300
	InfoVis	21-21 Oct. 2003	Conveying shape with texture: an experimental investigation of the impact of texture type on shape categorization judgments	10.1109/INFVIS.2003.1249022	http://dx.doi.org/10.1109/INFVIS.2003.1249022	163	170	1249022	data visualisation;image texture	anisotropic pattern;arbitrary smoothly curving shape;boundary masked quadric surface patches;concave;controlled observer experiment;convex;cylindrical shape;elliptical shape;experimental investigation;flat shape;head-on viewpoint;hyperbolic shape;isotropic pattern;nonprincipal direction;oblique viewpoint;observer judgments;oriented energy;orthographic projection conditions;perspective projection;principal direction texture pattern conditions;shape categorization judgments;shape category;shape conveyance;shape orientation;shape perception;shape type;texture type;visualization research	Anisotropic magnetoresistance;Chromium;Computer displays;Computer graphics;Data visualization;Geometry;Material properties;Probes;Shape control;Surface texture		As visualization researchers, we are interested in gaining a better understanding of how to effectively use texture to facilitate shape perception. If we could design the ideal texture pattern to apply to an arbitrary smoothly curving shape to be most accurately and effectively perceived, what would the characteristics of that texture pattern be? In this paper we describe the results of a comprehensive controlled observer experiment intended to yield insight into that question. Here, we report the results of a new study comparing the relative accuracy of observers' judgments of shape type (elliptical, cylindrical, hyperbolic or flat) and shape orientation (convex, concave, both, or neither) for local views of boundary masked quadric surface patches under six different principal direction texture pattern conditions plus two texture conditions (an isotropic pattern and a non-principal direction oriented anisotropic pattern), under both perspective and orthographic projection conditions and from both head-on and oblique viewpoints. Our results confirm the hypothesis that accurate shape perception is facilitated to a statistically significantly greater extent by some principal direction texture patterns than by others. Specifically, we found that, for both views, under conditions of perspective projection, participants more often correctly identified the shape category and the shape orientation when the surface was textured with the pattern that contained oriented energy along both the first and second principal directions only than in the case of any other texture condition. Patterns containing markings following only one of the principal directions, or containing information along other directions in addition to the principal directions yielded poorer performance overall.	Kim, S.;Hagh-Shenas, H.;Interrante, V.	Minnesota Univ., Minneapolis, MN, USA|c|;;	37963203000;38201808500;37282637800
	InfoVis	21-21 Oct. 2003	Coordinated graph and scatter-plot views for the visual exploration of microarray time-series data	10.1109/INFVIS.2003.1249023	http://dx.doi.org/10.1109/INFVIS.2003.1249023	173	180	1249023	data acquisition;data visualisation;query formulation;time series;user interfaces	bioinformatics;biological phenomena investigation;data acquisition;disease diagnosis;disease prevention;disease treatment;graph view;information visualization techniques;microarray experimentation;microarray time-course experiment;microarray time-series data;microarrays;multiple views;requirements analysis;scatter-plot view;time graph data representation;visual exploration;visual queries	Biology computing;Chromium;Data acquisition;Data visualization;Diseases;Displays;Information analysis;Scattering;Time series analysis;User interfaces		Microarrays are relatively new, high-throughput data acquisition technology for investigating biological phenomena at the micro-level. One of the more common procedures for microarray experimentation is that of the microarray time-course experiment. The product of microarray time-course experiment is time-series data, which subject to proper analysis has the potential to have significant impact on the diagnosis, treatment, and prevention of diseases. While existing information visualization techniques go some way to making microarray time-series data more manageable, requirements analysis has revealed significant limitations. The main finding was that users were unable to uncover and quantify common changes in value over a specified time-period. This paper describes a novel technique that provides this functionality by allowing the user to visually formulate and modify measurable queries with separate time-period and condition components. These visual queries are supported by the combination of a traditional value against time graph representation of the data with a complementary scatter-plot representation of a specified time-period. The multiple views of the visualization are coordinated so that the user can formulate and modify queries with rapid reversible display of query results in the traditional value against time graph format.	Craig, P.;Kennedy, J.	Sch. of Comput., Napier Univ., Edinburgh, UK|c|;	37325492100;37334180100
	InfoVis	21-21 Oct. 2003	Compound brushing [dynamic data visualization]	10.1109/INFVIS.2003.1249024	http://dx.doi.org/10.1109/INFVIS.2003.1249024	181	188	1249024	data visualisation;graphical user interfaces;visual programming	brushing techniques;compound brushing;device;dynamic data visualization;dynamic graphics;dynamic query;higraphs;renderer;selection;transformation;visual programming tool	Brushes;Chromium;Data visualization;Dynamic programming;Graphics;Rendering (computer graphics);Scattering;Shape;Synthetic aperture sonar;Utility programs		This paper proposes a conceptual model called compound brushing for modeling the brushing techniques used in dynamic data visualization. In this approach, brushing techniques are modeled as higraphs with five types of basic entities: data, selection, device, renderer, and transformation. Using this model, a flexible visual programming tool is designed not only to configure/control various common types of brushing techniques currently used in dynamic data visualization, but also to investigate new brushing techniques.	Hong Chen	SAS Inst. Inc., Cary, NC, USA|c|	38201292600
	InfoVis	21-21 Oct. 2003	Causality visualization using animated growing polygons	10.1109/INFVIS.2003.1249025	http://dx.doi.org/10.1109/INFVIS.2003.1249025	189	196	1249025	computer animation;concurrent engineering;data visualisation;graphical user interfaces;software engineering	Hasse diagram visualization;animated growing polygons;causal relations;causality visualization;color coded segments;dynamic execution;graphical representation;information flow;information visualization;interactive animation;interactive systems;partitioned polygons;subjective user ratings	Animation;Chromium;Color;Humans;Information analysis;Information systems;Software engineering;Software testing;Usability;Visualization		We present Growing Polygons, a novel visualization technique for the graphical representation of causal relations and information flow in a system of interacting processes. Using this method, individual processes are displayed as partitioned polygons with color-coded segments showing dependencies to other processes. The entire visualization is also animated to communicate the dynamic execution of the system to the user. The results from a comparative user study of the method show that the Growing Polygons technique is significantly more efficient than the traditional Hasse diagram visualization for analysis tasks related to deducing information flow in a system for both small and large executions. Furthermore, our findings indicate that the correctness when solving causality tasks is significantly improved using our method. In addition, the subjective ratings of the users rank the method as superior in all regards, including usability, efficiency, and enjoyability.	Elmqvist, N.;Tsigas, P.	Dept. of Comput. Sci., Chalmers Univ. of Technol., Goteborg, Sweden|c|;	37295438200;37295439000
	InfoVis	21-21 Oct. 2003	Visualization of large-scale customer satisfaction surveys using a parallel coordinate tree	10.1109/INFVIS.2003.1249026	http://dx.doi.org/10.1109/INFVIS.2003.1249026	197	201	1249026	customer satisfaction;data visualisation;graphical user interfaces;marketing data processing;multidimensional systems;parallel programming;tree data structures	customer satisfaction surveys;data visualization;distortion-oriented focus+context techniques;human factors;human resources management;market research;measurement tool;multidimensional analysis;parallel coordinate tree;tree structure representation	Customer satisfaction;Data visualization;Demography;Encoding;Government;Large-scale systems;Quality management;Rail transportation;USA Councils;Vehicles		Satisfaction surveys are an important measurement tool in fields such as market research or human resources management. Serious studies consist of numerous questions and contain answers from large population samples. Aggregation on both sides, the questions asked as well as the answers received, turns the multidimensional problem into a complex system of interleaved hierarchies. Traditional ways of presenting the results are limited to one-dimensional charts and cross-tables. We developed a visualization method called the Parallel Coordinate Tree that combines multidimensional analysis with a tree structure representation. Distortion-oriented focus+context techniques are used to facilitate interaction with the visualization. In this paper we present a design study of a commercial application that we built, using this method to analyze and communicate results from large-scale customer satisfaction surveys.	Brodbeck, D.;Girardin, L.	Macrofocus GmbH, Zurich, Switzerland|c|;	37611663700;38202075100
	InfoVis	21-21 Oct. 2003	FundExplorer: supporting the diversification of mutual fund portfolios using context treemaps	10.1109/INFVIS.2003.1249027	http://dx.doi.org/10.1109/INFVIS.2003.1249027	203	208	1249027	data visualisation;financial data processing;investment;stock markets;tree data structures	FundExplorer;context treemaps;distorted treemap;diversification support;equity mutual fund;financial data;financial instrument;fund visualization systems;information visualization;investment visualization;mutual fund portfolios;portfolio diversification;stock market;stock visualization systems;stocks investment	Chromium;Data visualization;Educational institutions;Financial management;Information systems;Instruments;Investments;Mutual funds;Portfolios;Stock markets		An equity mutual fund is a financial instrument that invests in a set of stocks. Any two different funds may partially invest in some of the same stocks, thus overlap is common. Portfolio diversification aims at spreading an investment over many different stocks in search of greater returns. Helping people with portfolio diversification is challenging because it requires informing them about both their current portfolio of stocks held through funds and the other stocks in the market not invested in yet. Current stock/fund visualization systems either waste screen real estate and visualization of all data points. We have developed a system called FundExplorer that implements a distorted treemap to visualize both the amount of money invested in a person's fund portfolio and the context of remaining market stocks. The FundExplorer system enables people to interactively explore diversification possibilities with their portfolios.	Csallner, C.;Handte, M.;Lehmann, O.;Stasko, J.	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	37540651600;38467650200;38197720100;37267736900
	InfoVis	21-21 Oct. 2003	Thread Arcs: an email thread visualization	10.1109/INFVIS.2003.1249028	http://dx.doi.org/10.1109/INFVIS.2003.1249028	211	218	1249028	data visualisation;electronic mail;graphical user interfaces;tree data structures	Thread Arcs;branching tree structure;conversational thread;electronic mail;email client;email thread visualization;information visualization;interactive visualization;message chronology;mixed-model visualization;user interfaces	Chromium;Collaboration;Disk recording;Electronic mail;Prototypes;Testing;Tree data structures;User interfaces;Visualization;Yarn		This paper describes Thread Arcs, a novel interactive visualization technique designed to help people use threads found in email. Thread Arcs combine the chronology of messages with the branching tree structure of a conversational thread in a mixed-model visualization by Venolia and Neustaedter (2003) that is stable and compact. By quickly scanning and interacting with Thread Arcs, people can see various attributes of conversations and find relevant messages in them easily. We tested this technique against other visualization techniques with users' own email in a functional prototype email client. Thread Arcs proved an excellent match for the types of threads found in users' email for the qualities users wanted in small-scale visualizations.	Kerr, B.		38203152100
	InfoVis	21-21 Oct. 2003	Using multilevel call matrices in large software projects	10.1109/INFVIS.2003.1249030	http://dx.doi.org/10.1109/INFVIS.2003.1249030	227	232	1249030	data visualisation;graphical user interfaces;medical information systems;program visualisation;screens (display);software architecture	Philips Medical Systems;graph structures;large software projects;matrix visualizations;multilevel call matrices;multilevel visualizations;node link diagrams;recursive structure;software architecture;software visualization;visual aids	Biomedical imaging;Chromium;Computer science;Mathematics;Programming profession;Project management;Software architecture;Software engineering;Software systems;Visualization		Traditionally, node link diagrams are the prime choice when it comes to visualizing software architectures. However, node link diagrams often fall short when used to visualize large graph structures. In this paper we investigate the use of call matrices as visual aids in the management of large software projects. We argue that call matrices have a number of advantages over traditional node link diagrams when the main object of interest is the link instead of the node. Matrix visualizations can provide stable and crisp layouts of large graphs and are inherently well suited for large multilevel visualizations because of their recursive structure. We discuss a number of visualization issues, using a very large software project currently under development at Philips Medical Systems as a running example.	van Ham, F.	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|	37326291000
	InfoVis	21-21 Oct. 2003	Between aesthetics and utility: designing ambient information visualizations	10.1109/INFVIS.2003.1249031	http://dx.doi.org/10.1109/INFVIS.2003.1249031	233	240	1249031	art;computer displays;data visualisation;information use;large screen displays;multimedia systems;vehicles	aesthetics;ambient displays;ambient information visualizations;bus departure times;calm technology;design constraint;dynamic information;information visualization;informative art;modern abstract artist;nondesktop spaces;real-time visualization;valuable information;visual art	Application software;Art;Chromium;Computer displays;Data communication;Data visualization;Humans;Multimedia computing;Multimedia systems;Web page design		Unlike traditional information visualization, ambient information visualizations reside in the environment of the user rather than on the screen of a desktop computer. Currently, most dynamic information that is displayed in public places consists of text and numbers. We argue that information visualization can be employed to make such dynamic data more useful and appealing. However, visualizations intended for non-desktop spaces will have to both provide valuable information and present an attractive addition to the environment - they must strike a balance between aesthetical appeal and usefulness. To explore this, we designed a real-time visualization of bus departure times and deployed it in a public space, with about 300 potential users. To make the presentation more visually appealing, we took inspiration from a modern abstract artist. The visualization was designed in two passes. First, we did a preliminary version that was presented to and discussed with prospective users. Based on their input, we did a final design. We discuss the lessons learned in designing this and previous ambient information visualizations, including how visual art can be used as a design constraint, and how the choice of information and the placement of the display affect the visualization.	Skog, T.;Ljungblad, S.;Holmquist, L.E.	Future Applications Lab, Viktoria Inst., Goteborg, Sweden|c|;;	38202116700;37296143000;37296141000
	SciVis	24-24 Oct. 2003	IEEE Visualization 2003 (IEEE Cat. No.03CH37496)	10.1109/VISUAL.2003.1250348	http://dx.doi.org/10.1109/VISUAL.2003.1250348			1250348	data visualisation;digital simulation;feature extraction;haptic interfaces;image reconstruction;image segmentation;medical computing;rendering (computer graphics)	biological visualization;feature analysis;flow visualization;haptics;hardware-assisted volume rendering;image segmentation;implicit surfaces;information visualization;isosurfaces;large data visualization;medical visualization;medicinal visualization;mesh simplification;physical simulation;sample-based rendering;scientific data visualization;shading perception;shape perception;terrain-dependent method;transfer functions;view-dependent method;visualization softwares;volume reconstruction;volume rendering acceleration;volumetric techniques	Books;Computer graphics;IEEE catalog;IEEE services;Libraries;Permission;Visualization		The following topics are dealt with: medical visualization; isosurfaces; implicit surfaces; flow visualization; terrains and view-dependent methods; segmentation and feature analysis; haptics and physical simulation; hardware-assisted volume rendering; volume rendering acceleration; shading and shape perception; volume reconstruction; volumetric techniques; sample-based rendering; mesh simplification; transfer functions; information visualization; scientific and large data visualization; visualization in medicine and biology; and visualization software.			
	SciVis	24-24 Oct. 2003	The visualization market: open source vs. commercial approaches	10.1109/VISUAL.2003.1250350	http://dx.doi.org/10.1109/VISUAL.2003.1250350	21	24	1250350			Application software;Business;Cost function;Environmental economics;Laboratories;Licenses;Marketing and sales;Open source software;Software libraries;Visualization					
	SciVis	24-24 Oct. 2003	Exploring curved anatomic structures with surface sections	10.1109/VISUAL.2003.1250351	http://dx.doi.org/10.1109/VISUAL.2003.1250351	27	34	1250351	computerised tomography;data visualisation;feature extraction;medical computing	3D image;3D volume;anatomic structures;curved cross-sections;curved sections;data visualization;free form surfaces;interactive flattening;interactive specification;planar sections;surface extraction;surface sections;tubular structures;volume images	Anatomy;Biomedical imaging;Colon;Education;Feedback;Java;Navigation;Visualization		The extraction of planar sections from volume images is the most commonly used technique for inspecting and visualizing anatomic structures. We propose to generalize the concept of planar section to the extraction of curved cross-sections (free form surfaces). Compared with planar slices, curved cross-sections may easily follow the trajectory of tubular structures and organs such as the aorta or the colon. They may be extracted from a 3D volume, displayed as a 3D view and possibly flattened. Flattening of curved cross-sections allows to inspect spatially complex relationship between anatomic structures and their neighborhood. They also allow to carry out measurements along a specific orientation. For the purpose of facilitating the interactive specification of free form surfaces, users may navigate in real time within the body and select the slices on which the surface control points will be positioned. Immediate feedback is provided by displaying boundary curves as cylindrical markers within a 3D view composed of anatomic organs, planar slices and possibly free form surface sections. Extraction of curved surface sections is an additional service that is available online as a Java applet (http://visiblehuman.epfl.ch). It may be used as an advanced tool for exploring and teaching anatomy.	Saroul, L.;Gerlach, S.	Ecole Polytechnique Federale de Lausanne, Switzerland|c|;	;37415825900
	SciVis	24-24 Oct. 2003	Psychophysical scaling of a cardiovascular information display	10.1109/VISUAL.2003.1250352	http://dx.doi.org/10.1109/VISUAL.2003.1250352	35	42	1250352	cardiovascular system;data visualisation;medical computing;patient monitoring;surgery;user interfaces	anesthesia;cardiovascular health;cardiovascular information display;cardiovascular visualization;human information processing;just noticeable differences;patent vital sign monitor;patient physiology;patient vital sign phenomena;psychophysical scaling	Cardiology;Displays;History;Humans;Information processing;Object detection;Physiology;Psychology;Shape;Visualization		A new method was developed to increase the saliency of changing variables in a cardiovascular visualization for use by anesthesiologists in the operating room (OR). Clinically meaningful changes in patient physiology were identified and then mapped to the inherent psychophysical properties of the visualization. A long history of psychophysical research has provided an understanding of the parameters within which the human information processing system is able to detect changes in the size, shape and color of visual objects (Gescheider, 1976, Spence, 1990, and Baird, 1970). These detection thresholds are known as just noticeable differences (JNDs) which characterize the amount of change in an object's attribute that is recognizable 50% of the time. A prototype version of the display has been demonstrated to facilitate anesthesiologist's performance while reducing cognitive workload during simulated cardiac events (Agutter et al., 2002). In order to further improve the utility of the new cardiovascular visualization, the clinically relevant changes in cardiovascular variables are mapped to noticeable perceptual changes in the representational elements of the display. The results of the method described in this paper are used to merge information from the psychophysical properties of the cardiovascular visualization, with clinically relevant changes in the patient's cardiovascular physiology as measured by the clinical meaningfulness questionnaire. The result of this combination will create a visualization that is sensitive to changes in the cardiovascular health of the patient and communicates this information to the user in a meaningful, salient and intuitive manner.	Albert, R.;Syroid, N.;Zhang, Y.;Agutter, J.;Drews, F.;Strayer, D.;Hutchinson, G.;Westenskow, Dwayne	Appl. Med. Visualizations, West Valley, UT, USA|c|;;;;;;;	38202614000;37725245800;38200661900;37442679500;37281841200;37726237200;37430681500;37293901500
	SciVis	24-24 Oct. 2003	Advanced curved planar reformation: flattening of vascular structures	10.1109/VISUAL.2003.1250353	http://dx.doi.org/10.1109/VISUAL.2003.1250353	43	50	1250353	angiocardiography;blood vessels;cardiovascular system;computerised tomography;data visualisation;medical image processing;rendering (computer graphics)	computed tomography angiography;curved planar reformation;feature perception;helical spiral;medical visualization;spatial coherence;vascular structures;vascular tree;vascular visualization;vessel analysis;vessel visualization;vessel volume	Angiography;Arteries;Biomedical imaging;Computed tomography;Data visualization;Displays;Magnetic resonance imaging;Medical diagnostic imaging;Spatial coherence;Tree graphs		Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.	Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;	37282727500;37267822600;37282581000;37282552200
	SciVis	24-24 Oct. 2003	Counting cases in marching cubes: toward a generic algorithm for producing substitopes	10.1109/VISUAL.2003.1250354	http://dx.doi.org/10.1109/VISUAL.2003.1250354	51	58	1250354	algorithm theory;combinatorial mathematics;computational geometry;group theory	cases counting;computational group theory;contour meshing;generic algorithm;geometric substitution;interval volumes;isosurface;marching cubes;polytopes;separating surfaces;substitopes;visualization techniques	Algorithm design and analysis;Bones;Computer aided software engineering;Data visualization;Isosurfaces;Lesions;Level set;Software algorithms;Software systems;Taxonomy		"We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitution of polytopes). We demonstrate the method using a software system (""GAP"") for computational group theory. The case-counts are organized into a table that provides taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculation confirms previously reported case-counts for large dimensions that are too large to check by hand, and predicts the number of cases that will arise in algorithms that have not yet been invented."	Banks, D.C.;Linton, S.	Florida State Univ., Gainesville, FL, USA|c|;	37356983700;37646706300
	SciVis	24-24 Oct. 2003	MC*: star functions for marching cubes	10.1109/VISUAL.2003.1250355	http://dx.doi.org/10.1109/VISUAL.2003.1250355	59	66	1250355	Gaussian processes;approximation theory;computational geometry;interpolation;mesh generation;solid modelling	Gaussian curvature;approximation methods;constrained smoothing;interpolation methods;isosurface parameterization;local surface properties;marching cubes;mean curvature;single valued functions;star functions;triangular mesh	Approximation methods;Chromium;Computer graphics;Interpolation;Isosurfaces;Lattices;Mesh generation;Smoothing methods;Solid modeling;Topology		We describe a modification of the widely used marching cubes method that leads to the useful property that the resulting isosurfaces are locally single valued functions. This implies that conventional interpolation and approximation methods can be used to locally represent the surface. These representations can be used for computing approximations for local surface properties. We utilize this possibility in order to develop algorithms for locally approximating Gaussian and mean curvature, methods for constrained smoothing of isosurface, and techniques for the parameterization of isosurfaces.	Nielson, G.M.	Arizona State Univ., Tempe, AZ, USA|c|	37283754100
	SciVis	24-24 Oct. 2003	Extraction of topologically simple isosurfaces from volume datasets	10.1109/VISUAL.2003.1250356	http://dx.doi.org/10.1109/VISUAL.2003.1250356	67	74	1250356	computational geometry;data visualisation;solid modelling;topology	3D geometry acquisition;CT scans;data visualization;isosurfaces;polygonal models;topological complexity;topology;volume datasets	Arm;Computed tomography;Computer graphics;Geometry;Isosurfaces;Pipelines;Reconstruction algorithms;Solid modeling;Topology;Visualization		There are numerous algorithms in graphics and visualization whose performance is known to decay as the topological complexity of the input increases. On the other hand, the standard pipeline for 3D geometry acquisition often produces 3D models that are topologically more complex than their real forms. We present a simple and efficient algorithm that allows us to simplify the topology of an isosurface by alternating the values of some number of voxels. Its utility and performance are demonstrated on several examples, including signed distance functions from polygonal models and CT scans.	Szymczak, A.;Vanderhyde, J.	Georgia Tech, USA|c|;	37330183900;38198915600
	SciVis	24-24 Oct. 2003	Interactive deformation and visualization of level set surfaces using graphics hardware	10.1109/VISUAL.2003.1250357	http://dx.doi.org/10.1109/VISUAL.2003.1250357	75	82	1250357	computational geometry;data visualisation;image segmentation;rendering (computer graphics)	GPU-based solution;deformable models;graphics hardware;graphics processor;image rendering;image segmentation;interactive deformation;isosurfaces;level-set methods;message passing;region-of-interest specifier;sparse texture format;streaming computation;surface processing;surface reconstruction;volume visualization	Data visualization;Deformable models;Graphics;Hardware;Image segmentation;Isosurfaces;Level set;Rendering (computer graphics);Scientific computing;Surface reconstruction		Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization for applications such as segmentation, surface processing, and surface reconstruction. Their usefulness has been limited, however, by their high computational cost and reliance on significant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based on algorithms for solving and visualizing level-set solutions at interactive rates. Our efficient GPU-based solution relies on packing the level-set isosurface data into a dynamic, sparse texture format. As the level set moves, this sparse data structure is updated via a novel GPU to CPU message passing scheme. When the level-set solver is integrated with a real-time volume renderer operating on the same packed format, a user can visualize and steer the deformable level-set surface as it evolves. In addition, the resulting isosurface can serve as a region-of-interest specifier for the volume renderer. This paper demonstrates the capabilities of this technology for interactive volume visualization and segmentation.	Lefohn, A.E.;Kniss, J.M.;Hansen, C.D.;Whitaker, R.T.	Sch. of Comput. & Imaging Inst., Utah Univ., Salt Lake, UT, USA|c|;;;	38198885000;37324263400;37266777200;37267322600
	SciVis	24-24 Oct. 2003	Signed distance transform using graphics hardware	10.1109/VISUAL.2003.1250358	http://dx.doi.org/10.1109/VISUAL.2003.1250358	83	90	1250358	algorithm theory;computational geometry;data visualisation;image segmentation;rendering (computer graphics)	Cartesian grid;Euclidean distance;GPU-based algorithms;Voronoi diagram;data visualization;deformable isosurfaces;distance field;fragment program;graphics hardware;graphics processor;grid points;image rendering;linear complexity;nonlinear interpolation;polyhedron;scalar valued function;scan conversion;signed distance transform;triangle meshes	Chromium;Computational geometry;Computer graphics;Euclidean distance;Grid computing;Hardware;Image converters;Image generation;Interpolation;Solid modeling		This paper presents a signed distance transform algorithm using graphics hardware, which computes the scalar valued function of the Euclidean distance to a given manifold of co-dimension one. If the manifold is closed and orientable, the distance has a negative sign on one side of the manifold and a positive sign on the other. Triangle meshes are considered for the representation of a two-dimensional manifold and the distance function is sampled on a regular Cartesian grid. In order to achieve linear complexity in the number of grid points, to each primitive we assign a simple polyhedron enclosing its Voronoi cell. Voronoi cells are known to contain exactly all points that lay closest to its corresponding primitive. Thus, the distance to the primitive only has to be computed for grid points inside its polyhedron. Although Voronoi cells partition space, the polyhedrons enclosing these cells do overlap. In regions where these overlaps occur, the minimum of all computed distances is assigned to a grid point. In order to speed up computations, points inside each polyhedron are determined by scan conversion of grid slices using graphics hardware. For this task, a fragment program is used to perform the nonlinear interpolation and minimization of distance values.	Sigg, C.;Peikert, R.;Gross, Markus	Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;;	37565783800;37282541100;37275694700
	SciVis	24-24 Oct. 2003	Piecewise C1 continuous surface reconstruction of noisy point clouds via local implicit quadric regression	10.1109/VISUAL.2003.1250359	http://dx.doi.org/10.1109/VISUAL.2003.1250359	91	98	1250359	computational geometry;image reconstruction;solid modelling;surface reconstruction	Piecewise C1;Shepard method;computer graphics;continuous surface reconstruction;flatter surface areas;local implicit quadric regression;moving least squares;noisy point clouds;pseudosigned distance field;quadric fields;solid modeling;surface fitting;surface representation;topology	Chromium;Clouds;Computer graphics;Computer science;Computer vision;Image reconstruction;Least squares methods;Sampling methods;Surface fitting;Surface reconstruction			Hui Xie;Wang, J.;Jing Hua;Hong Qin;Kaufman, A.	Dept. of Comput. Sci., Stony Brook univrsity, NY, USA|c|;;;;	38198809000;37280545800;38197026500;38199415900;37268052800
	SciVis	24-24 Oct. 2003	Feature-sensitive subdivision and isosurface reconstruction	10.1109/VISUAL.2003.1250360	http://dx.doi.org/10.1109/VISUAL.2003.1250360	99	106	1250360	Boolean algebra;computational geometry;feature extraction;image reconstruction;solid modelling	Boolean operations;directed distance fields;dual contouring algorithm;feature-sensitive subdivision;geometric operations;implicit modeling;isosurface reconstruction;marching cubes;polygonization;surface extraction	Computer graphics;Computer vision;Image edge detection;Image reconstruction;Isosurfaces;Mesh generation;Reconstruction algorithms;Solid modeling;Surface reconstruction;Vehicles		We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.	Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.	North Carolina Univ., Chapel Hill, NC, USA|c|;;;	37267825100;37275776600;38185529300;37267825600
	SciVis	24-24 Oct. 2003	A texture-based framework for spacetime-coherent visualization of time-dependent vector fields	10.1109/VISUAL.2003.1250361	http://dx.doi.org/10.1109/VISUAL.2003.1250361	107	114	1250361	data visualisation;flow visualisation;image processing	Lagrangian-Eulerian advection;dynamic LIC;graphics hardware;hardware acceleration;image quality;image-based flow visualization;spacetime-coherent visualization;spatial correlation;temporal coherence;texture advection;texture-based discretization;time evolution;time-dependent vector fields;unsteady flow LIC;unsteady flow advection-convolution	Aerodynamics;Computer graphics;Convolution;Hardware;Image quality;Information technology;Interactive systems;Lagrangian functions;Spatial coherence;Visualization		We propose unsteady flow advection-convolution (UFAC) as a novel visualization approach for unsteady flows. It performs time evolution governed by pathlines, but builds spatial correlation according to instantaneous streamlines whose spatial extent is controlled by the flow unsteadiness. UFAC is derived from a generic framework that provides spacetime-coherent dense representations of time dependent-vector fields by a two-step process: 1) construction of continuous trajectories in spacetime for temporal coherence; and 2) convolution along another set of paths through the above spacetime for spatially correlated patterns. Within the framework, known visualization techniques-such as Lagrangian-Eulerian advection, image-based flow visualization, unsteady flow LIC, and dynamic LIC-can be reproduced, often with better image quality, higher performance, or increased flexibility of the visualization style. Finally, we present a texture-based discretization of the framework and its interactive implementation on graphics hardware, which allows the user to gradually balance visualization speed against quality.	Weiskopf, D.;Erlebacher, G.;Ertl, T.	Inst. of Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;	38470313400;37324424400;38356649500
	SciVis	24-24 Oct. 2003	Effectively visualizing multi-valued flow data using color and texture	10.1109/VISUAL.2003.1250362	http://dx.doi.org/10.1109/VISUAL.2003.1250362	115	121	1250362	colour graphics;convolution;data visualisation;flow visualisation;image processing	Reynolds number;color weaving;data visualization;flow visualization;information representation;line integral convolution;multiple co-located color encoded distributions;multivalued flow data;scalar distributions;streamwise-spanwise planes;texture stitching;vector distributions	Aerospace industry;Aircraft;Chemical industry;Computer graphics;Computer science;Convolution;Data visualization;Fuels;Streaming media;Stress		In this paper we offer several new insights and techniques for effectively using color and texture to simultaneously convey information about multiple 2D scalar and vector distributions, in a way that facilitates allowing each distribution to be understood both individually and in the context of one or more of the other distributions. Specifically, we introduce the concepts of: color weaving for simultaneously representing information about multiple co-located color encoded distributions; and texture stitching for achieving more spatially accurate multi-frequency line integral convolution representations of combined scalar and vector distributions. The target application for our research is the definition, detection and visualization of regions of interest in a turbulent boundary layer flow at moderate Reynolds number. In this work, we examine and analyze streamwise-spanwise planes of three-component velocity vectors with the goal of identifying and characterizing spatially organized packets of hairpin vortices.	Urness, T.;Interrante, V.;Longmire, E.;Ganapathisubramani, B.	Dept. of Comput. Sci. & Eng., Minnesota Univ., USA|c|;;;	37282639600;37282637800;37282625600;37282627400
	SciVis	24-24 Oct. 2003	Image based flow visualization for curved surfaces	10.1109/VISUAL.2003.1250363	http://dx.doi.org/10.1109/VISUAL.2003.1250363	123	130	1250363	computational fluid dynamics;data visualisation;digital simulation;flow visualisation;image texture;rendering (computer graphics)	animated textures;computational fluid dynamics;curved surfaces;flow animation;graphics hardware;image space;image-based flow visualization;line integral convolution;surface rendering;texture mapping;triangular meshes;white noise images	Analytical models;Animation;Computational modeling;Computer simulation;Data visualization;Hardware;Image generation;Rendering (computer graphics);Surface texture;White noise		A new method for the synthesis of dense, vector-field aligned textures on curved surfaces is presented, called IBFVS. The method is based on image based flow visualization (IBFV). In IBFV two-dimensional animated textures are produced by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of filtered white noise images. We produce flow aligned texture on arbitrary three-dimensional triangular meshes in the same spirit as the original method: texture is generated directly in image space. We show that IBFVS is efficient and effective. High performance (typically fifty frames or more per second) is achieved by exploiting graphics hardware. Also, IBFVS can easily be implemented and a variety of effects can be achieved. Applications are flow visualization and surface rendering. Specifically, we show how to visualize the wind field on the earth and how to render a dirty bronze bunny.	van Wijk, J.J.	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|	37267249200
	SciVis	24-24 Oct. 2003	Image space based visualization of unsteady flow on surfaces	10.1109/VISUAL.2003.1250364	http://dx.doi.org/10.1109/VISUAL.2003.1250364	131	138	1250364	computational fluid dynamics;data visualisation;digital simulation;flow visualisation;image texture	Lagrangian-Eulerian advection;computational fluid dynamics;dynamic meshes;flow visualization;image space based visualization;spatio-temporal correlation;surface representation;surface unsteady flow;texture mapping;time-dependent geometry;time-dependent topology;time-dependent vector fields	Biomedical imaging;Computational fluid dynamics;Computational modeling;Computer graphics;Data visualization;Geometry;Hardware;Lagrangian functions;Surface texture;Topology		We present a technique for direct visualization of unsteady flow on surfaces from computational fluid dynamics. The method generates dense representations of time-dependent vector fields with high spatio-temporal correlation using both Lagrangian-Eulerian advection and image based flow visualization as its foundation. While the 3D vector fields are associated with arbitrary triangular surface meshes, the generation and advection of texture properties is confined to image space. Frame rates of up to 20 frames per second are realized by exploiting graphics card hardware. We apply this algorithm to unsteady flow on boundary surfaces of, large, complex meshes from computational fluid dynamics composed of more than 250,000 polygons, dynamic meshes with time-dependent geometry and topology, as well as medical data.	Laramee, R.S.;Jobard, B.;Hauser, H.	VRVis Res. Center, Graz, Austria|c|;;	37267247900;37267249300;37274158800
	SciVis	24-24 Oct. 2003	A multi-resolution data structure for two-dimensional Morse-Smale functions	10.1109/VISUAL.2003.1250365	http://dx.doi.org/10.1109/VISUAL.2003.1250365	139	146	1250365	computational geometry;computer graphics;geographic information systems;terrain mapping;topology	Morse-Smale complex;critical point theory;geometric hierarchy;geometric methods;mesh traversal operations;multiresolution data structure;terrain;topological methods;two-dimensional functions	Computer science;Data analysis;Data structures;Electrostatic measurements;Image processing;Laboratories;Multiresolution analysis;Scientific computing;Solid modeling;Spatial resolution		We combine topological and geometric methods to construct a multi-resolution data structure for functions over two-dimensional domains. Starting with the Morse-Smale complex, we construct a topological hierarchy by progressively canceling critical points in pairs. Concurrently, we create a geometric hierarchy by adapting the geometry to the changes in topology. The data structure supports mesh traversal operations similarly to traditional multi-resolution representations.	Bremer, P.-T.;Edelsbrunner, H.;Hamann, B.;Pascucci, V.	Center for Image Process. & Integrated Comput., California Univ., Davis, CA, USA|c|;;;	37564112000;37282291100;37282068700;37284312600
	SciVis	24-24 Oct. 2003	Planet-sized batched dynamic adaptive meshes (P-BDAM)	10.1109/VISUAL.2003.1250366	http://dx.doi.org/10.1109/VISUAL.2003.1250366	147	154	1250366	computational geometry;image resolution;rendering (computer graphics);terrain mapping	P-BDAM;core simplification algorithm;geometric continuity;graphics hardware;host-to-graphics communication;interactive rendering;multiresolution;out-of-core management;planet-sized batched dynamic adaptive meshes;points triangulation;single precision floating points;terrain surfaces	Computer graphics;Data visualization;Hardware;Mars;Planets;Prefetching;Rendering (computer graphics);Solid modeling;Tiles;World Wide Web		We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.	Cignoni, P.;Ganovelli, F.;Gobbetti, E.;Marton, F.;Ponchio, F.;Scopigno, R.	ISTI - CNR, Pisa, Italy|c|;;;;;	37265783400;37265786900;37346861300;37550808100;37265788700;37270887900
	SciVis	24-24 Oct. 2003	Real-time refinement and simplification of adaptive triangular meshes	10.1109/VISUAL.2003.1250367	http://dx.doi.org/10.1109/VISUAL.2003.1250367	155	162	1250367	computational geometry;data visualisation;image resolution;terrain mapping	adaptive meshes;adaptive triangular meshes;cloth simulation;data retrieval;geometrical proximity;multiresoluton;out-of-core storage layout;procedural modeling;real-time refinement;real-time simplification;real-time terrain visualization;refinement rule mapping;semiregular meshes	Application software;Cache storage;Chromium;Computational modeling;Computer graphics;Data visualization;Information retrieval;Large-scale systems;Physics;Spatial resolution		In this paper we present a generic method for incremental mesh adaptation based on hierarchy of semi-regular meshes. Our method supports any refinement rule mapping vertices onto vertices such as 1-to-4 split or v3-subdivision. Resulting adaptive mesh has subdivision connectivity and hence good aspect ratio of triangles. Hierarchic representation of the mesh allows incremental local refinement and simplification operations exploiting frame-to-frame coherence. We also present an out-of-core storage layout scheme designed for semi-regular meshes of arbitrary subdivision connectivity. It provides high cache coherency in the data retrieval and relies on the interleaved storage of resolution levels and maintaining good geometrical proximity within each level. The efficiency of the proposed method is demonstrated with applications in physically-based cloth simulation, real-time terrain visualization and procedural modeling.	Volkov, V.;Ling Li	Moscow Inst. of Phys. & Technol., Russia|c|;	38198208400;38200968100
	SciVis	24-24 Oct. 2003	Interactive view-dependent rendering with conservative occlusion culling in complex environments	10.1109/VISUAL.2003.1250368	http://dx.doi.org/10.1109/VISUAL.2003.1250368	163	170	1250368	computational geometry;data visualisation;rendering (computer graphics);solid modelling	cluster hierarchy;clustering;conservative occlusion culling;frame-to-frame coherence;hardware-accelerated occlusion queries;image quality;interactive display;interactive rendering;multiresolution hierarchies;partitioning algorithm;popping artifacts;view-dependent rendering	Acceleration;Clustering algorithms;Computer graphics;Displays;Hardware;Image quality;Layout;Partitioning algorithms;Rendering (computer graphics);Runtime		This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.	Yoon, S.-E.;Salomon, B.;Manocha, D.	North Carolina Univ., Chapel Hill, NC, USA|c|;;	37279394100;37271825900;37267825600
	SciVis	24-24 Oct. 2003	Fast volume segmentation with simultaneous visualization using programmable graphics hardware	10.1109/VISUAL.2003.1250369	http://dx.doi.org/10.1109/VISUAL.2003.1250369	171	176	1250369	computerised tomography;data visualisation;image segmentation;medical image processing;parallel processing;rendering (computer graphics)	computational masking;data visualization;fast volume segmentation;floating point precision;fragment programs;graphics processor;image segmentation;medical imaging;parallel processing;programmable graphics hardware;region growing;streaming computation;structure segmentation	Anatomy;Biomedical imaging;Data visualization;Graphics;Hardware;Image segmentation;Parallel processing;Rendering (computer graphics);System buses;Volume measurement		Segmentation of structures from measured volume data, such as anatomy in medical imaging, is a challenging data-dependent task. In this paper, we present a segmentation method that leverages the parallel processing capabilities of modern programmable graphics hardware in order to run significantly faster than previous methods. In addition, collocating the algorithm computation with the visualization on the graphics hardware circumvents the need to transfer data across the system bus, allowing for faster visualization and interaction. This algorithm is unique in that it utilizes sophisticated graphics hardware functionality (i.e., floating point precision, render to texture, computational masking, and fragment programs) to enable fast segmentation and interactive visualization.	Sherbondy, A.;Houston, M.;Napel, S.	Stanford Univ., CA, USA|c|;;	37282594600;37563167000;37328954600
	SciVis	24-24 Oct. 2003	Hybrid segmentation and exploration of the human lungs	10.1109/VISUAL.2003.1250370	http://dx.doi.org/10.1109/VISUAL.2003.1250370	177	184	1250370	computerised tomography;endoscopes;image segmentation;lung;medical image processing;virtual reality	airway system;anatomical structures;bronchi;human lungs;hybrid segmentation;image segmentation;intensity contrast;lower airways;lung tumors;multislice CT;partial volume effects;seed point;tracheo-bronchial tree;user interaction;vascular system;vascular tree;virtual endoscopy system	Anatomical structure;Biological materials;Blood;Endoscopes;Humans;Hybrid power systems;Lungs;Pipelines;Respiratory system;Visualization		Segmentation of the tracheo-bronchial tree of the lungs is notoriously difficult. This is due to the fact that the small size of some of the anatomical structures is subject to partial volume effects. Furthermore, the limited intensity contrast between the participating materials (air, blood, and tissue) increases the segmentation of difficulties. In this paper, we propose a hybrid segmentation method which is based on a pipeline of three segmentation stages to extract the lower airways down to the seventh generation of the bronchi. User interaction is limited to the specification of a seed point inside the easily detectable trachea at the upper end of the lower airways. Similarly, the complementary vascular tree of the lungs can be segmented. Furthermore, we modified our virtual endoscopy system to visualize the vascular and airway system of the lungs along with other features, such as lung tumors.	Bartz, D.;Mayer, D.;Fischer, J.;Ley, S.;del Rio, A.;Thust, S.;Heussel, C.P.;Kauczor, H.-U.	Visual Comput. for Medicine, Eberhard-Karls-Univ. Tubingen, Germany|c|;;;;;;;	37448237300;38197124100;37551595300;38068879800;38202852500;38198928900;37945387300;37945386700
	SciVis	24-24 Oct. 2003	Feature-space analysis of unstructured meshes	10.1109/VISUAL.2003.1250371	http://dx.doi.org/10.1109/VISUAL.2003.1250371	185	192	1250371	computational geometry;data visualisation;feature extraction;image processing;rendering (computer graphics)	data exploration;data structure;feature detection;feature extraction;feature space clustering;feature-space analysis;functional domain;image partitioning;image segmentation;imaging applications;iso-surfacing;mean shifting;simulations;spatial coordinates;spatial domain;unstructured meshes;volume rendering	Chromium;Computational geometry;Computer graphics;Computer vision;Data analysis;Data visualization;Image processing;Image segmentation;Solid modeling;Surface fitting		Unstructured meshes are often used in simulations and imaging applications. They provide advanced flexibility in modeling abilities but are more difficult to manipulate and analyze than regular data. This work provides a novel approach for the analysis of unstructured meshes using feature-space clustering and feature-detection. Analyzing and revealing underlying structures in data involve operators on both spatial and functional domains. Slicing concentrates more on the spatial domain, while iso-surfacing or volume rendering concentrate more on the functional domain. Nevertheless, many times it is the combination of the two domains which provides real insight on the structure of the data. In this work, a combined feature-space is defined on top of unstructured meshes in order to search for structure in the data. A point in feature-space includes the spatial coordinates of the point in the mesh domain and all chosen attributes defined on the mesh. A distance measures between points in feature-space is defined enabling the utilization of clustering using the mean shift procedure (previously used for images) on unstructured meshes. Feature space analysis is shown to be useful for feature-extraction, for data exploration and partitioning.	Shamir, A.	The Interdisciplinary Center, Herzliya, Israel|c|	37266753700
	SciVis	24-24 Oct. 2003	Clifford convolution and pattern matching on vector fields	10.1109/VISUAL.2003.1250372	http://dx.doi.org/10.1109/VISUAL.2003.1250372	193	200	1250372	data visualisation;feature extraction;flow visualisation;pattern matching	Clifford algebra;Clifford convolution;convolution operation;feature detection;flow visualization;glyphs;image processing;isosurfaces;multivector filter masks;pattern matching;scalar masks;streamlines;vector fields;vector multiplication	Algebra;Computer vision;Convolution;Feature extraction;Filters;Image edge detection;Image processing;Pattern matching;Streaming media;Visualization		The goal of this paper is to define a convolution operation which transfers image processing and pattern matching to vector fields from flow visualization. For this, a multiplication of vectors is necessary. Clifford algebra provides such a multiplication of vectors. We define a Clifford convolution on vector fields with uniform grids. The Clifford convolution works with multivector filter masks. Scalar and vector masks can be easily converted to multivector fields. So, filter masks from image processing on scalar fields can be applied as well as vector and scalar masks. Furthermore, a method for pattern matching with Clifford convolution on vector fields is described. The method is independent of the direction of the structures. This provides an automatic approach to feature detection. The features can be visualized using any known method like glyphs, isosurfaces or streamlines. The features are defined by filter masks instead of analytical properties and thus the approach is more intuitive.	Ebling, J.;Scheuermann, G.	Kaiserslautern, Germany|c|;	37425394400;37282574800
	SciVis	24-24 Oct. 2003	Space efficient fast isosurface extraction for large datasets	10.1109/VISUAL.2003.1250373	http://dx.doi.org/10.1109/VISUAL.2003.1250373	201	208	1250373	data compression;data structures;data visualisation;feature extraction;transform coding	data compression;data retrieval;data structure;dataset cells;interval information compression;isosurface cells;isosurface extraction;nonuniform quantization;optimal search performance;space efficiency;space efficient algorithm;storage overhead;transform coding	Compaction;Data mining;Data structures;Information retrieval;Information science;Isosurfaces;Quantization;Runtime;Transform coding;Visualization		In this paper, we present a space efficient algorithm for speeding up isosurface extraction. Even though there exist algorithms that can achieve optimal search performance to identify isosurface cells, they prove impractical for large datasets due to a high storage overhead. With the dual goals of achieving fast isosurface extraction and simultaneously reducing the space requirement, we introduce an algorithm based on transform coding to compress the interval information of the cells in a dataset. Compression is achieved by first transforming the cell intervals (minima, maxima) into a form which allows more efficient compaction. It is followed by a dataset optimized non-uniform quantization stage. The compressed data is stored in a data structure that allows fast searches in the compression domain, thus eliminating the need to retrieve the original representation of the intervals at run-time. The space requirement of our search data structure is the mandatory cost of storing every cell ID once, plus an overhead for quantization information. The overhead is typically in the order of a few hundredths of the dataset size.	Bordoloi, U.D.;Han-Wei Shen	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;	37561558700;37279493500
	SciVis	24-24 Oct. 2003	Volume tracking using higher dimensional isosurfacing	10.1109/VISUAL.2003.1250374	http://dx.doi.org/10.1109/VISUAL.2003.1250374	209	216	1250374	computational geometry;computer graphics;data visualisation;feature extraction;optical tracking	critical time steps;higher dimensional geometry;higher dimensional isosurfacing;interval volumes;local feature tracking;local feature visualization;time-varying data;time-varying isosurfaces;time-varying volumetric data;topological event detection;user selected local features;volume tracking	Animation;Bifurcation;Computational geometry;Data mining;Data visualization;Event detection;Feature extraction;High performance computing;Information science;Isosurfaces		Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.	Guangfeng Ji;Han-Wei Shen;Wenger, R.	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;	38202947500;37279493500;37284274100
	SciVis	24-24 Oct. 2003	Out-of-core isosurface extraction of time-varying fields over irregular grids	10.1109/VISUAL.2003.1250375	http://dx.doi.org/10.1109/VISUAL.2003.1250375	217	224	1250375	buffer storage;data structures;data visualisation;feature extraction	BBIO trees;I/O-optimal interval searches;buffer technique;cache oblivious searches;disk storage;irregular grids;isosurface queries;memory hierarchy;meta cell indexing;meta cell technique;meta interval collapsing scheme;out-of-core isosurface extraction;preprocessing phase;spatial coherence;temporal coherence;time tree algorithm;time-varying fields	Clustering algorithms;Computer graphics;Data mining;Data visualization;Grid computing;Information science;Isosurfaces;Partitioning algorithms;Runtime;Spatial coherence		In this paper, we propose a novel out-of-core isosurface extraction technique for large time-varying fields over irregular grids. We employ our meta-cell technique to explore the spatial coherence of the data, and our time tree algorithm to consider the temporal coherence as well. Our one-time preprocessing phase first partitions the dataset into meta-cells that cluster spatially neighboring cells together and are stored in disk. We then build a time tree to index the meta-cells for fast isosurface extraction. The time tree takes advantage of the temporal coherence among the scalar values at different time steps, and uses BBIO trees as secondary structures, which are stored in disk and support I/O-optimal interval searches. The time tree algorithm employs a novel meta-interval collapsing scheme and the buffer technique, to take care of the temporal coherence in an I/O-efficient way. We further make the time tree cache-oblivious, so that searching on it automatically performs optimal number of block transfers between any two consecutive levels of memory hierarchy (such as between cache and main memory and between main memory and disk) simultaneously. At run-time, we perform optimal cache-oblivious searches in the time tree, together with I/O-optimal searches in the BBIO trees, to read the active meta-cells from disk and generate the queried isosurface efficiently. The experiments demonstrate the effectiveness of our new technique. In particular, compared with the query-optimal main-memory algorithm by Cignoni et al. (1997) (extended for time-varying fields) when there is not enough main memory, our technique can speed up the isosurface queries from more than 18 hours to less than 4 minutes.	Yi-Jen Chiang	Dept. of Comput. & Inf. Sci., Polytech. Univ., Brooklyn, NY, USA|c|	37288235400
	SciVis	24-24 Oct. 2003	Saddle connectors - an approach to visualizing the topological skeleton of complex 3D vector fields	10.1109/VISUAL.2003.1250376	http://dx.doi.org/10.1109/VISUAL.2003.1250376	225	232	1250376	computational fluid dynamics;data visualisation;flow visualisation	3D flow fields;complex 3D vector fields;complex flow data;critical points;saddle connectors;separatrices;stream lines;stream surfaces;topological skeleton visualization;vector field topology;visualization tool	Chromium;Computer graphics;Connectors;Data flow computing;Data visualization;Eigenvalues and eigenfunctions;Jacobian matrices;Skeleton;Switches;Topology		One of the reasons that topological methods have a limited popularity for the visualization of complex 3D flow fields is the fact that such topological structures contain a number of separating stream surfaces. Since these stream surfaces tend to hide each other as well as other topological features, for complex 3D topologies the visualizations become cluttered and hardly interpretable. This paper proposes to use particular stream lines called saddle connectors instead of separating stream surfaces and to depict single surfaces only on user demand. We discuss properties and computational issues of saddle connectors and apply these methods to complex flow data. We show that the use of saddle connectors makes topological skeletons available as a valuable visualization tool even for topologically complex 3D flow data.	Theisel, H.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.	MPI Informatik Saarbrucken, Germany|c|;;;	37266875400;37282635100;37282272000;37271851300
	SciVis	24-24 Oct. 2003	3D IBFV: hardware-accelerated 3D flow visualization	10.1109/VISUAL.2003.1250377	http://dx.doi.org/10.1109/VISUAL.2003.1250377	233	240	1250377	computational fluid dynamics;flow visualisation;image texture	2D flow visualization;2D instances;2D textures;3D IBFV;3D flow visualization;OpenGL;advected gray value;color noise;dye advection;dye decay;dye insertion;hardware acceleration;hardware-accelerated method;occlusion problem;opacity noise;texture advection;texture-based IBFV	Acceleration;Animation;Colored noise;Computational fluid dynamics;Data visualization;Graphics;Hardware;Mathematics;Rendering (computer graphics);Streaming media		We present a hardware-accelerated method for visualizing 3D flow fields. The method is based on insertion, advection, and decay of dye. To this aim, we extend the texture-based IBFV technique presented by van Wijk (2001) for 2D flow visualization in two main directions. First, we decompose the 3D flow visualization problem in a series of 2D instances of the mentioned IBFV technique. This makes our method benefit from the hardware acceleration the original IBFV technique introduced. Secondly, we extend the concept of advected gray value (or color) noise by introducing opacity (or matter) noise. This allows us to produce sparse 3D noise pattern advections, thus address the occlusion problem inherent to 3D flow visualization. Overall, the presented method delivers interactively animated 3D flow, uses only standard OpenGL 1.1 calls and 2D textures, and is simple to understand and implement.	Telea, A.;van Wijk, J.J.	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|;	37268047100;37267249200
	SciVis	24-24 Oct. 2003	Chameleon: an interactive texture-based rendering framework for visualizing three-dimensional vector fields	10.1109/VISUAL.2003.1250378	http://dx.doi.org/10.1109/VISUAL.2003.1250378	241	248	1250378	computer animation;image enhancement;image texture;rendering (computer graphics)	3D flow textures;3D vector fields visualization;chameleon rendering;geometry-based visualization;hardware-assisted slice sweeping algorithm;interactive texture-based rendering;streamlines generation;structural perception;texture coordinates;texture mapping;texture-based visualization;visual cues;visualization pipeline decoupling;volume rendering framework	Chromium;Computer graphics;Data flow computing;Data mining;Data visualization;Information science;Pipelines;Rendering (computer graphics);Shape;Tornadoes		In this paper we present an interactive texture-based technique for visualizing three-dimensional vector fields. The goal of the algorithm is to provide a general volume rendering framework allowing the user to compute three-dimensional flow textures interactively, and to modify the appearance of the visualization on the fly. To achieve our goal, we decouple the visualization pipeline into two disjoint stages. First, streamlines are generated from the 3D vector data. Various geometric properties of the streamlines are extracted and converted into a volumetric form using a hardware-assisted slice sweeping algorithm. In the second phase of the algorithm, the attributes stored in the volume are used as texture coordinates to look up an appearance texture to generate both informative and aesthetic representations of the underlying vector field. Users can change the input textures and instantaneously visualize the rendering results. With our algorithm, visualizations with enhanced structural perception using various visual cues can be rendered in real time. A myriad of existing geometry-based and texture-based visualization techniques can also be emulated.	Guo-Shi Li;Bordoloi, U.D.;Han-Wei Shen	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;	38200539100;38481208600;37279493500
	SciVis	24-24 Oct. 2003	HyperLIC	10.1109/VISUAL.2003.1250379	http://dx.doi.org/10.1109/VISUAL.2003.1250379	249	256	1250379	computational fluid dynamics;computer animation;data visualisation;image processing;magnetic resonance imaging	HyperLIC;animation production;anisotropic properties;computational fluid dynamics;diffusion-tensor MRI;direct volume rendering;hyperstreamlines;image production;line integral convolution;multipass approach;symmetric tensor fields visualization	Animation;Anisotropic magnetoresistance;Chromium;Computational fluid dynamics;Computer science;Convolution;Data visualization;Eigenvalues and eigenfunctions;Magnetic resonance imaging;Tensile stress		We introduce a new method for visualizing symmetric tensor fields. The technique produces images and animations reminiscent of line integral convolution (LIC). The technique is also slightly related to hyperstreamlines in that it is used to visualize tensor fields. However, the similarity ends there. HyperLIC uses a multi-pass approach to show the anisotropic properties in a 2D or 3D tensor field. We demonstrate this technique using data sets from computational fluid dynamics as well as diffusion-tensor MRI.	Zheng, X.;Pang, A.	Comput. Sci. Dept., California Univ., Santa Cruz, CA, USA|c|;	37274785100;37267352000
	SciVis	24-24 Oct. 2003	Quasi-static approach approximation for 6 degrees-of-freedom haptic rendering	10.1109/VISUAL.2003.1250380	http://dx.doi.org/10.1109/VISUAL.2003.1250380	257	262	1250380	aerospace computing;engineering graphics;haptic interfaces;rendering (computer graphics);virtual reality	1000 Hz;6-degrees-of-freedom haptics;aircraft engine;haptic refresh rate;haptic rendering;movable object simulation;numerical integration;physically based modeling;quasistatic approximation;robust collision avoidance;second-order differential equations;simulated aircraft geometry;static equilibrium;stiff systems;torque feedback;virtual coupling;voxel sampling	Aircraft propulsion;Computational modeling;Differential equations;Force feedback;Geometry;Haptic interfaces;Large-scale systems;Maintenance;Robustness;Solid modeling		In this paper, we propose a quasi-static approximation (QSA) approach to simulate the movement of the movable object in 6-degrees-of-freedom (DOF) haptic rendering. In our QSA approach, we solve for static equilibrium during each haptic time step, ignoring any dynamical properties such as inertia. The major contribution of this approach is to overcome the computational instability problem in overly stiff systems arising from numerical integration of second-order differential equations in previous dynamic models. Our primary experimental results on both simulated aircraft geometry and a large-scale real-world aircraft engine showed that our QSA approach was capable of maintaining the 1000Hz haptic refresh rate with more robust collision avoidance and more reliable force and torque feedback.	Ming Wan;McNeely, W.A.	The Boeing Co., Seattle, WA, USA|c|;	38198168300;37619958500
	SciVis	24-24 Oct. 2003	A constraint-based technique for haptic volume exploration	10.1109/VISUAL.2003.1250381	http://dx.doi.org/10.1109/VISUAL.2003.1250381	263	269	1250381	data visualisation;haptic interfaces;medical computing;transfer functions;virtual reality	brain white matter tissue;constraint-based technique;data probe;diffusion tensor fiber tracts;directional constraints;directional information;exploration modes;fiber orientation;field forces;haptic effects;haptic rendering;haptic volume exploration;heart muscle layers;human-computer interaction;immersive visualization;reaction forces;spring coupler;volumetric datasets	Computer graphics;Data visualization;Feedback;Friction;Haptic interfaces;Optical fiber couplers;Probes;Rendering (computer graphics);Scientific computing;Springs		We present a haptic rendering technique that uses directional constraints to facilitate enhanced exploration modes for volumetric datasets. The algorithm restricts user motion in certain directions by incrementally moving a proxy point along the axes of a local reference frame. Reaction forces are generated by a spring coupler between the proxy and the data probe, which can be tuned to the capabilities of the haptic interface. Secondary haptic effects including field forces, friction, and texture can be easily incorporated to convey information about additional characteristics of the data. We illustrate the technique with two examples: displaying fiber orientation in heart muscle layers and exploring diffusion tensor fiber tracts in brain white matter tissue. Initial evaluation of the approach indicates that haptic constraints provide an intuitive means or displaying directional information in volume data.	Ikits, M.;Brederson, J.D.;Hansen, C.D.;Johnson, C.R.	Sci. Comput. & Imaging Inst., Utah Univ., USA|c|;;;	37426872100;38198607400;37266777200;37276931400
	SciVis	24-24 Oct. 2003	Voxels on fire [computer animation]	10.1109/VISUAL.2003.1250382	http://dx.doi.org/10.1109/VISUAL.2003.1250382	271	278	1250382	Boltzmann machines;computational geometry;computer animation;fires;flames;rendering (computer graphics)	GPU acceleration;burning consumption;enhanced distance field;fire propagation animation;hardware-accelerated Lattice Boltzmann Model;isosurfaces;multiple fire fronts;object voxels;physically-based simulation;shell volume;splats;volumetric data sets;volumetric fire propagation model	Animation;Computational modeling;Computer graphics;Computer science;Fires;Fuels;Isosurfaces;Lattice Boltzmann methods;Rendering (computer graphics);Visualization		We introduce a method for the animation of fire propagation and the burning consumption of objects represented as volumetric data sets. Our method uses a volumetric fire propagation model based on an enhanced distance field. It can simulate the spreading of multiple fire fronts over a specified isosurface without actually having to create that isosurface. The distance field is generated from a specific shell volume that rapidly creates narrow spatial bands around the virtual surface of any given isovalue. The complete distance field is then obtained by propagation from the initial bands. At each step multiple fire fronts can evolve simultaneously on the volumetric object. The flames of the fire are constructed from streams of particles whose movement is regulated by a velocity field generated with the hardware-accelerated Lattice Boltzmann Model (LBM). The LBM provides a physically-based simulation of the air flow around the burning object. The object voxels and the splats associated with the flame particles are rendered in the same pipeline so that the volume data with its external and internal structures can be displayed along with the fire.	Ye Zhao;Wei, X.;Zhe Fan;Kaufman, A.;Hong Qin	Center for Visual Comput., Stony Brook Univ., NY, USA|c|;;;;	38199778800;37279025800;38198269200;37268052800;38199417100
	SciVis	24-24 Oct. 2003	Visually accurate multi-field weather visualization	10.1109/VISUAL.2003.1250383	http://dx.doi.org/10.1109/VISUAL.2003.1250383	279	286	1250383	clouds;computer animation;data visualisation;image enhancement;rendering (computer graphics);weather forecasting	atmospheric dynamics models;cloud dynamics;cloud scale;lighting calculations;multifield weather visualization;physically-based opacity;storm forecasting;storm scale;surface-based approaches;transfer function approaches;visually accurate visualization;volumetric illumination;volumetric multifield data;weather forecasting;weather spotter training	Clouds;Computer graphics;Data visualization;Isosurfaces;Light scattering;Meteorology;Particle scattering;Predictive models;Storms;Weather forecasting		Weather visualization is a difficult problem because it comprises volumetric multi-field data and traditional surface-based approaches obscure details of the complex three-dimensional structure of cloud dynamics. Therefore, visually accurate volumetric multi-field visualization of storm scale and cloud scale data is needed to effectively and efficiently communicate vital information to weather forecasters, improving storm forecasting, atmospheric dynamics models, and weather spotter training. We have developed a new approach to multi-field visualization that uses field specific, physically-based opacity, transmission, and lighting calculations per-field for the accurate visualization of storm and cloud scale weather data. Our approach extends traditional transfer function approaches to multi-field data and to volumetric illumination and scattering.	Riley, K.;Ebert, D.;Hansen, C.;Levit, J.	Purdue Univ., West Lafayette, IN, USA|c|;;;	37552979700;37282598900;37266777200;37550576700
	SciVis	24-24 Oct. 2003	Acceleration techniques for GPU-based volume rendering	10.1109/VISUAL.2003.1250384	http://dx.doi.org/10.1109/VISUAL.2003.1250384	287	292	1250384	computer graphic equipment;image texture;ray tracing;rendering (computer graphics);solid modelling	3D textures;ATI 9700 graphics card;GPU;GPU-based volume rendering;acceleration technique;direct volume rendering;display analysis;early ray termination;empty-space skipping;fragment processing;graphical processing units;per-fragment operation;programmable graphics hardware;texture based volume rendering;visual analysis;volume ray-casting;volumetric scalar fields	Acceleration;Chromium;Computer displays;Computer graphics;Data visualization;Hardware;Performance gain;Rendering (computer graphics);Sampling methods;Three dimensional displays		Nowadays, direct volume rendering via 3D textures has positioned itself as an efficient tool for the display and visual analysis of volumetric scalar fields. It is commonly accepted, that for reasonably sized data sets appropriate quality at interactive rates can be achieved by means of this technique. However, despite these benefits one important issue has received little attention throughout the ongoing discussion of texture based volume rendering: the integration of acceleration techniques to reduce per-fragment operations. In this paper, we address the integration of early ray termination and empty-space skipping into texture based volume rendering on graphical processing units (GPU). Therefore, we describe volume ray-casting on programmable graphics hardware as an alternative to object-order approaches. We exploit the early z-test to terminate fragment processing once sufficient opacity has been accumulated, and to skip empty space along the rays of sight. We demonstrate performance gains up to a factor of 3 for typical renditions of volumetric data sets on the ATI 9700 graphics card.	Kruger, J.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. Munich, Germany|c|;	37548560500;37444424000
	SciVis	24-24 Oct. 2003	Compression domain volume rendering	10.1109/VISUAL.2003.1250385	http://dx.doi.org/10.1109/VISUAL.2003.1250385	293	300	1250385	computer graphic equipment;image texture;rendering (computer graphics);vector quantisation	CPU;GPU;commodity graphics hardware;compression domain volume rendering;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;multiresolution covariance analysis;programmable hardware;real-time rendering;temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantization	Central Processing Unit;Computer graphics;Data visualization;Decoding;Encoding;Hardware;Large-scale systems;Rendering (computer graphics);Shock waves;Vector quantization		A survey of graphics developers on the issue of texture mapping hardware for volume rendering would most likely find that the vast majority of them view limited texture memory as one of the most serious drawbacks of an otherwise fine technology. In this paper, we propose a compression scheme for static and time-varying volumetric data sets based on vector quantization that allows us to circumvent this limitation. We describe a hierarchical quantization scheme that is based on a multiresolution covariance analysis of the original field. This allows for the efficient encoding of large-scale data sets, yet providing a mechanism to exploit temporal coherence in non-stationary fields. We show, that decoding and rendering the compressed data stream can be done on the graphics chip using programmable hardware. In this way, data transfer between the CPU and the graphics processing unit (GPU) can be minimized thus enabling flexible and memory efficient real-time rendering options. We demonstrate the effectiveness of our approach by demonstrating interactive renditions of Gigabyte data sets at reasonable fidelity on commodity graphics hardware.	Schneider, J.;Westermann, R.	Comput. Graphics & Visualization Group, Tech. Univ. Munich, Germany|c|;	37560044500;37444424000
	SciVis	24-24 Oct. 2003	High-quality two-level volume rendering of segmented data sets on consumer graphics hardware	10.1109/VISUAL.2003.1250386	http://dx.doi.org/10.1109/VISUAL.2003.1250386	301	308	1250386	image segmentation;rendering (computer graphics);solid modelling	MIP;alpha blending;consumer graphics hardware;direct volume rendering;image quality;iso-surfacing;nonphotorealistic rendering;pixel-resolution filtering;rendering mode;segmentated data sets;single rendering pass;volumetric data set	Blood vessels;Bones;Computer graphics;Data visualization;Filtering;Hardware;Image segmentation;Rendering (computer graphics);Skin;Transfer functions		One of the most important goals in volume rendering is to be able to visually separate and selectively enable specific objects of interest contained in a single volumetric data set, which can be approached by using explicit segmentation information. We show how segmented data sets can be rendered interactively on current consumer graphics hardware with high image quality and pixel-resolution filtering of object boundaries. In order to enhance object perception, we employ different levels of object distinction. First, each object can be assigned an individual transfer function, multiple of which can be applied in a single rendering pass. Second, different rendering modes such as direct volume rendering, iso-surfacing, and non-photorealistic techniques can be selected for each object. A minimal number of rendering passes is achieved by processing sets of objects that share the same rendering mode in a single pass. Third, local compositing modes such as alpha blending and MIP can be selected for each object in addition to a single global mode, thus enabling high-quality two-level volume rendering on GPUs.	Hadwiger, M.;Berger, C.;Hauser, H.	VRVis Res. Center, Austria|c|;;	37394809600;38197400800;37274158800
	SciVis	24-24 Oct. 2003	Hardware-based nonlinear filtering and segmentation using high-level shading languages	10.1109/VISUAL.2003.1250387	http://dx.doi.org/10.1109/VISUAL.2003.1250387	309	316	1250387	computer graphic equipment;computer graphics;image segmentation;nonlinear filters;visual languages;visual programming	4D vector arithmetic;GPU;cache coherence;consumer graphics hardware;edge preservation;graphical processing unit;graphics memory;hardware-based nonlinear filtering;high-level shading languages;image segmentation;volume analysis;volume smoothing	Computer graphics;Filtering;Fixed-point arithmetic;Hardware;Image edge detection;Image reconstruction;Image segmentation;Nonlinear filters;Pipelines;Smoothing methods		Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.	Viola, I.;Kanitsar, A.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;	37282726800;37282727500;37282552200
	SciVis	24-24 Oct. 2003	Empty space skipping and occlusion clipping for texture-based volume rendering	10.1109/VISUAL.2003.1250388	http://dx.doi.org/10.1109/VISUAL.2003.1250388	317	324	1250388	computer graphic equipment;image texture;rendering (computer graphics);solid modelling	empty space skipping;invisible voxels;iso-surface-like rendering;occlusion clipping;orthogonal BSP tree;orthogonal opacity map;texture coordinate;texture-based volume rendering;transfer function	Acceleration;Computer graphics;Computer science;Engines;Hardware;Head;Knee;Rendering (computer graphics);Torso;Transfer functions		We propose methods to accelerate texture-based volume rendering by skipping invisible voxels. We partition the volume into sub-volumes, each containing voxels with similar properties. Sub-volumes composed of only voxels mapped to empty by the transfer function are skipped. To render the adaptively partitioned sub-volumes in visibility order, we reorganize them into an orthogonal BSP tree. We also present an algorithm that computes incrementally the intersection of the volume with the slicing planes, which avoids the overhead of the intersection and texture coordinates computation introduced by the partitioning. Rendering with empty space skipping is 2 to 5 times faster than without it. To skip occluded voxels, we introduce the concept of orthogonal opacity map, that simplifies the transformation between the volume coordinates and the opacity map coordinates, which is intensively used for occlusion detection. The map is updated efficiently by the GPU. The sub-volumes are then culled and clipped against the opacity map. We also present a method that adaptively adjusts the optimal number of the opacity map updates. With occlusion clipping, about 60% of non-empty voxels can be skipped and an additional 80% speedup on average is gained for iso-surface-like rendering.	Li, W.;Mueller, K.;Kaufman, A.	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;;	38200194400;37273119700;37268052800
	SciVis	24-24 Oct. 2003	Hierarchical clustering for unstructured volumetric scalar fields	10.1109/VISUAL.2003.1250389	http://dx.doi.org/10.1109/VISUAL.2003.1250389	325	332	1250389	algorithm theory;data visualisation;principal component analysis;rendering (computer graphics);solid modelling	PCA;cluster generation;cluster hierarchy;hierarchical clustring;multiresolution representation;parallelizable classification algorithm;point cloud;principal component analysis;radial basis function;scalar field representation;unstructure volumetric scalar fields;volumetric scalar data set	Binary trees;Computational geometry;Computer graphics;Computer science;Data mining;Data visualization;Image processing;Principal component analysis;Scattering;Solid modeling		"We present a method to represent unstructured scalar fields at multiple levels of detail. Using a parallelizable classification algorithm to build a cluster hierarchy, we generate a multiresolution representation of a given volumetric scalar data set. The method uses principal component analysis (PCA) for cluster generation and a fitting technique based on radial basis functions (RBFs). Once the cluster hierarchy has been generated, we utilize a variety of techniques for extracting different levels of detail. The main strength of this work is its generality. Regardless of grid type, this method can be applied to any discrete scalar field representation, even one given as a ""point cloud""."	Co, C.S.;Heckel, B.;Hagen, H.;Hamann, B.;Joy, K.I.	Dept. of Comput. Sci., Univ. of California, Davis, CA, USA|c|;;;;	37828723800;37350243300;37282578800;37282068700;37267811400
	SciVis	24-24 Oct. 2003	Hardware-based ray casting for tetrahedral meshes	10.1109/VISUAL.2003.1250390	http://dx.doi.org/10.1109/VISUAL.2003.1250390	333	340	1250390	computer graphic equipment;image processing;ray tracing;rendering (computer graphics)	cyclic mesh;early ray termination;graphics adapter;hardware-based ray casting;memory transfer bottleneck;mesh data;nonconvex mesh;off-the-shelf programmable graphics hardware;ray integration;ray traversal;rendering algorithm;tetrahedral meshes;three-dimensional pre-integration tables;unstructured mesh	Algorithm design and analysis;Casting;Computer graphics;Hardware;Interactive systems;Isosurfaces;Rendering (computer graphics);Sorting;Transfer functions;Visualization		We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.	Weiler, Manfred;Kraus, M.;Merz, M.;Ertl, T.	Visualization & Interactive Syst. Group, Univ. of Stutgart, Germany|c|;;;	37268043100;37284293000;38140167100;37268023800
	SciVis	24-24 Oct. 2003	Visibility culling using plenoptic opacity functions for large volume visualization	10.1109/VISUAL.2003.1250391	http://dx.doi.org/10.1109/VISUAL.2003.1250391	341	348	1250391	data visualisation;image classification;ray tracing;rendering (computer graphics);solid modelling	POF;data set;data visualization;large volume visualization;off-line processing;opacity transfer function;parallel implementation;parallel volume rendering;plenoptic opacity function;ray casting;visibility culling	Acceleration;Chromium;Computer graphics;Computer networks;Data visualization;Electronic mail;Large-scale systems;Medical services;Rendering (computer graphics);Transfer functions		Visibility culling has the potential to accelerate large data visualization in significant ways. Unfortunately, existing algorithms do not scale well when parallelized, and require full re-computation whenever the opacity transfer function is modified. To address these issues, we have designed a Plenoptic Opacity Function (POF) scheme to encode the view-dependent opacity of a volume block. POFs are computed off-line during a pre-processing stage, only once for each block. We show that using POFs is (i) an efficient, conservative and effective way to encode the opacity variations of a volume block for a range of views, (ii) flexible for re-use by a family of opacity transfer functions without the need for additional off-line processing, and (iii) highly scalable for use in massively parallel implementations. Our results confirm the efficacy of POFs for visibility culling in large-scale parallel volume rendering; we can interactively render the Visible Woman dataset using software ray-casting on 32 processors, with interactive modification of the opacity transfer function on-the-fly.	Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.	Ohio State Univ., USA|c|;;;	37279695300;37281262900;37279493500;37430506600
	SciVis	24-24 Oct. 2003	Conveying shape and features with image-based relighting	10.1109/VISUAL.2003.1250392	http://dx.doi.org/10.1109/VISUAL.2003.1250392	349	354	1250392	archaeology;image classification;image intensifiers;image processing;image texture;rendering (computer graphics)	compositing process;highlights;image compositing system;image texture;image-based relighting;photographs;shadows;tangential lighting;technical illustration;user interface	Application software;Chromium;Computer graphics;Design engineering;Humans;Painting;Paints;Shape;Skull;User interfaces		Hand-crafted illustrations are often more effective than photographs for conveying the shape and important features of an object, but they require expertise and time to produce. We describe an image compositing system and user interface that allow an artist to quickly and easily create technical illustrations from a set of photographs of an object taken from the same point of view under variable lighting conditions. Our system uses a novel compositing process in which images are combined using spatially-varying light mattes, enabling the final lighting in each area of the composite to be manipulated independently. We describe an interface that provides for the painting of local lighting effects (e.g. shadows, highlights, and tangential lighting to reveal texture) directly onto the composite. We survey some of the techniques used in illustration and lighting design to convey the shape and features of objects and describe how our system can be used to apply these techniques.	Akers, D.;Losasso, F.;Klingner, J.;Agrawala, M.;Rick, J.;Hanrahan, P.	Stanford Univ., USA|c|;;;;;	37268691800;38125927600;37945252000;37282718200;37692531400;37349803800
	SciVis	24-24 Oct. 2003	Vicinity shading for enhanced perception of volumetric data	10.1109/VISUAL.2003.1250394	http://dx.doi.org/10.1109/VISUAL.2003.1250394	355	362	1250394	image classification;rendering (computer graphics);solid modelling	perceptual cues;point source lighting;shading model;uniform diffuse illumination;vicinity shading;volume rendering;volumetric data	Chromium;Graphics;Hardware;Light sources;Lighting;Ray tracing;Rendering (computer graphics);Shadow mapping;Shape;Solids		This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.	Stewart, A.J.	Sch. of Comput., Queen''s Univ., Kingston, Ont., Canada|c|	38197084300
	SciVis	24-24 Oct. 2003	LightKit: a lighting system for effective visualization	10.1109/VISUAL.2003.1250395	http://dx.doi.org/10.1109/VISUAL.2003.1250395	363	370	1250395	image classification;lighting;rendering (computer graphics);solid modelling	LightKit;VTK visualization toolkit;hardware graphics;light intensity;off-line rendering;scene illumination;three-dimensional synthetic scene;visualization process	Brightness;Cameras;Graphics;Hardware;Head;Layout;Lighting;Shape;Temperature;Visualization		LightKit is a system for lighting three-dimensional synthetic scenes. LightKit simplifies the task of producing visually pleasing, easily interpretable images for visualization while making it harder to produce results where the scene illumination distracts from the visualization process. LightKit is based on lighting designs developed by artists and photographers and shown in previous studies to enhance shape perception. A key light provides natural overhead illumination of the scene, augmented by fill, head, and back lights. By default, lights are attached to a normalized, subject-centric, camera-relative coordinate frame to ensure consistent lighting independent of camera location or orientation. This system allows all lights to be positioned by specifying just six parameters. The intensity of each light is specified as a ratio to the key light intensity, allowing the scene's brightness to be adjusted using a single parameter. The color of each light is specified by a single normalized color parameter called warmth that is based on color temperature of natural sources. LightKit's default values for light position, intensity, and color are chosen to produce good results for a variety of scenes. LightKit is designed to work with both hardware graphics systems and, potentially, higher quality off-line rendering systems. We provide examples of images created using a LightKit implementation within the VTK visualization toolkit software framework.	Halle, M.;Meng, J.	Harvard Med. Sch., Harvard Univ., USA|c|;	37436452900;38203084400
	SciVis	24-24 Oct. 2003	Mental registration of 2D and 3D visualizations (an empirical study)	10.1109/VISUAL.2003.1250396	http://dx.doi.org/10.1109/VISUAL.2003.1250396	371	378	1250396	CAD;data visualisation;graphical user interfaces;image processing;magnetic resonance imaging;solid modelling	2D visualization;3D visualization;CAD;ExoVis;computer aided design;flow visualization;in-place method;medical imaging;mental registration;oceanographic visualization;orientation icon;visualization domain	Biomedical imaging;Computer displays;Computer graphics;Data visualization;Graphical user interfaces;Navigation;Three dimensional displays;Two dimensional displays;Usability;User interfaces		2D and 3D views are used together in many visualization domains, such as medical imaging, flow visualization, oceanographic visualization, and computer aided design (CAD). Combining these views into one display can be done by: (1) orientation icon (i.e., separate windows), (2) in-place methods (e.g., clip and cutting planes), and (3) a new method called ExoVis. How 2D and 3D views are displayed affects ease of mental registration (understanding the spatial relationship between views), an important factor influencing user performance. This paper compares the above methods in terms of their ability to support mental registration. Empirical results show that mental registration is significantly easier with in-place displays than with ExoVis, and significantly easier with ExoVis than with orientation icons. Different mental transformation strategies can explain this result. The results suggest that ExoVis may be a better alternative to orientation icons when in-place displays are not appropriate (e.g., when in-place methods hide data or cut the 3D view into several pieces).	Tory, M.	Sch. of Comput. Sci., Simon Fraser Univ., USA|c|	37275861300
	SciVis	24-24 Oct. 2003	Visualization of noisy and biased volume data using first and second order derivative techniques	10.1109/VISUAL.2003.1250397	http://dx.doi.org/10.1109/VISUAL.2003.1250397	379	385	1250397	data visualisation;medical image processing;rendering (computer graphics)	CT data;MRI;bias field;biased volume data;data visualization;direct volume rendering;edge detector;first order derivative technique;global signal fluctuation;localization bias;medical imaging;noisy volume data;polyps;second order derivative technique;signal filtering;signal-to-noise ratio;surface extraction;surface localization;virtual colonoscopy;volume visualization	Computed tomography;Data visualization;Detectors;Filters;Fluctuations;Image edge detection;Ionizing radiation;Magnetic resonance imaging;Signal to noise ratio;Virtual colonoscopy		The quality of volume visualization depends strongly on the quality of the underlying data. In virtual colonoscopy, CT data should be acquired at a low radiation dose that results in a low signal-to-noise ratio. Alternatively, MRI data is acquired without ionizing radiation, but suffers from noise and bias (global signal fluctuations). Current volume visualization techniques often do not produce good results with noisy or biased data. This paper describes methods for volume visualization that deal with these imperfections. The techniques are based on specially adapted edge detectors using first and second order derivative filters. The filtering is integrated into the visualization process. The first order derivative method results in good quality images but suffers from localization bias. The second order method has better surface localization, especially in highly curved areas. It guarantees minimal detail smoothing resulting in a better visualization of polyps.	Persoon, M.P.;Serlie, I.W.O.;Post, F.H.;Truyen, R.;Vos, F.M.	Comput. Graphics & CAD/CAM Group, Delft Univ. of Technol., Netherlands|c|;;;;	38198910100;37394315500;37295045800;37394318300;37271678400
	SciVis	24-24 Oct. 2003	Fairing scalar fields by variational modeling of contours	10.1109/VISUAL.2003.1250398	http://dx.doi.org/10.1109/VISUAL.2003.1250398	387	392	1250398	approximation theory;image enhancement;interpolation;optimisation;rendering (computer graphics);solid modelling;variational techniques	algorithm;artifacts;contour;data set;filtering;isosurface extraction;resolution;scalar fields fairing;three-dimensional scalar field;trilinear interpolation;trilinear representation;two-dimensional scalar field;variational modeling;visualization;volume rendering	Computer vision;Data mining;Data visualization;Filtering;Image processing;Image reconstruction;Interpolation;Isosurfaces;Numerical analysis;Topology		Volume rendering and isosurface extraction from three-dimensional scalar fields are mostly based on piecewise trilinear representations. In regions of high geometric complexity such visualization methods often exhibit artifacts, due to trilinear interpolation. In this work, we present an iterative fairing method for scalar fields interpolating function values associated with grid points while smoothing the contours inside the grid cells based on variational principles. We present a local fairing method providing a piecewise bicubic representation of two-dimensional scalar fields. Our algorithm generalizes to the trivariate case and can be used to increase the resolution of data sets either locally or globally, reducing interpolation artifacts. In contrast to filtering methods, our algorithm does not reduce geometric detail supported by the data.	Bertram, M.	Univ. of Kaiserslautern, Germany|c|	37282067000
	SciVis	24-24 Oct. 2003	Visualization of volume data with quadratic super splines	10.1109/VISUAL.2003.1250399	http://dx.doi.org/10.1109/VISUAL.2003.1250399	393	400	1250399	computational geometry;data visualisation;image reconstruction;ray tracing;rendering (computer graphics)	Bernstein-Bezier techniques;CAGD;isosurface ray casting;isosurface rendering;nondiscrete model reconstruction;quadratic super splines;quadratic trivariate super spline;quasiinterpolating spline;ray-casting;rendered isosurface;super spline reconstruction;tetrahedral partitioning;uniform tetrahedral partition;volume data visualization;volume rendering	Approximation error;Chromium;Computational geometry;Computer graphics;Data visualization;Image reconstruction;Isosurfaces;Numerical analysis;Polynomials;Rendering (computer graphics)		We develop a new approach to reconstruct non-discrete models from gridded volume samples. As a model, we use quadratic trivariate super splines on a uniform tetrahedral partition ?. The approximating splines are determined in a natural and completely symmetric way by averaging local data samples, such that appropriate smoothness conditions are automatically satisfied. On each tetra-hedron of ? , the quasi-interpolating spline is a polynomial of total degree two which provides several advantages including efficient computation, evaluation and visualization of the model. We apply Bernstein-Bezier techniques well-known in CAGD to compute and evaluate the trivariate spline and its gradient. With this approach the volume data can be visualized efficiently e.g., with isosurface ray-casting. Along an arbitrary ray the splines are univariate, piecewise quadratics and thus the exact intersection for a prescribed isovalue can be easily determined in an analytic and exact way. Our results confirm the efficiency of the quasi-interpolating method and demonstrate high visual quality for rendered isosurfaces.	Rossl, C.;Zeilfelder, F.;Nurnberger, G.;Seidel, H.-P.	Max-Planck-Inst. fur Informatik, Saarbrucken, Germany|c|;;;	38345841600;38280511600;37565779800;37271851300
	SciVis	24-24 Oct. 2003	Using deformations for browsing volumetric data	10.1109/VISUAL.2003.1250400	http://dx.doi.org/10.1109/VISUAL.2003.1250400	401	408	1250400	data visualisation;graphical user interfaces;rendering (computer graphics);solid modelling	3D widgets;image deformation;interaction techniques;pop-up menu;semantic layers;spatial data;volumetric data browsing	Bones;Chromium;Computer graphics;Computer science;Cutting tools;Data visualization;Feedback;Humans;Muscles;Skin		"Many traditional techniques for ""looking inside"" volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, ""in place"" manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data."	McGuffin, M.J.;Tancau, L.;Balakrishnan, R.	Dept. of Comput. Sci., Univ. of Toronto, Ont., Canada|c|;;	37403234300;38198912900;37394495600
	SciVis	24-24 Oct. 2003	Video visualization	10.1109/VISUAL.2003.1250401	http://dx.doi.org/10.1109/VISUAL.2003.1250401	409	416	1250401	data visualisation;image sequences;video signal processing	image comparison metrics;linear dependence detector;security camera;spatial transfer technique;stream-based technique;traffic camera;video capturing;video conferencing system;video data;video email;video processing;video rendering;video sequences;video visualization;volume rendering video;volume scene graph;volume visualization	Cameras;Data mining;Data security;Data visualization;Feature extraction;Humans;Pipelines;Rendering (computer graphics);Video sequences;Videoconference		"Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for ""summarizing"" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing ""relative"" and ""absolute"" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences."	Daniel, G.;Chen, M.	Univ. of Wales Swansea, UK|c|;	38201565200;37280982800
	SciVis	24-24 Oct. 2003	High dimensional direct rendering of time-varying volumetric data	10.1109/VISUAL.2003.1250402	http://dx.doi.org/10.1109/VISUAL.2003.1250402	417	424	1250402	data visualisation;image classification;ray tracing;rendering (computer graphics);solid modelling;time-varying systems	4D raycasting;four-dimensional data field;high dimensional direct rendering;high dimensional projection;high dimensional slicing;hyperplanes;hyperprojection volume;hyperslice;image hyperplane;integration operator;space-time feature;time-varying data;time-varying volumetric data;transfer function;user interface;volume rendering;volume specification	Animation;Art;Computer graphics;Data visualization;Hypercubes;Mathematical model;Photography;Rendering (computer graphics);Transfer functions;USA Councils		We present an alternative method for viewing time-varying volumetric data. We consider such data as a four-dimensional data field, rather than considering space and time as separate entities. If we treat the data in this manner, we can apply high dimensional slicing and projection techniques to generate an image hyperplane. The user is provided with an intuitive user interface to specify arbitrary hyperplanes in 4D, which can be displayed with standard volume rendering techniques. From the volume specification, we are able to extract arbitrary hyperslices, combine slices together into a hyperprojection volume, or apply a 4D raycasting method to generate the same results. In combination with appropriate integration operators and transfer functions, we are able to extract and present different space-time features to the user.	Woodring, J.;Chaoli Wang;Han-Wei Shen	Ohio State Univ., USA|c|;;	37542815100;38200676700;37279493500
	SciVis	24-24 Oct. 2003	A frequency-sensitive point hierarchy for images and volumes	10.1109/VISUAL.2003.1250403	http://dx.doi.org/10.1109/VISUAL.2003.1250403	425	432	1250403	image processing;rendering (computer graphics)	Gavor wavelet;X-ray rendering;ellipsoidal point primitives;error metric;frequency characteristics;frequency-sensitive point hierarchy;frequency-space analysis;image conversion;interactive splatting volume renderer;iso-surface rendering;quality criteria;sampling rate;space-efficient irregular point hierarchy;spherical point;transfer function;user-specified frame rate	Computer errors;Computer science;Discrete wavelet transforms;Engines;Frequency;Image sampling;Rendering (computer graphics);Root mean square;Transfer functions;USA Councils		This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.	Welsh, T.;Mueller, K.	Center for Visual Comput., Comput. Sci., Stony Brook Univ., USA|c|;	37738942000;37273119700
	SciVis	24-24 Oct. 2003	Herarchical splatting of scattered data	10.1109/VISUAL.2003.1250404	http://dx.doi.org/10.1109/VISUAL.2003.1250404	433	440	1250404	algorithm theory;data visualisation;image processing;pattern clustering;rendering (computer graphics);solid modelling	3D points;PCA clustering;astronomical observation;colored points;data visualization;direct volume rendering;hierarchical splatting;hierarchical visualization;image quality;interactive visualization;numerical particle simulation;point distribution;point-based rendering algorithm;scalar density;scattered data;surface geometry;vertex shader;visualization application;voxel resolution	Acceleration;Clustering algorithms;Data structures;Data visualization;Geometry;Hardware;Numerical simulation;Particle scattering;Rendering (computer graphics);Workstations		Numerical particle simulations and astronomical observations create huge data sets containing uncorrelated 3D points of varying size. These data sets cannot be visualized interactively by simply rendering millions of colored points for each frame. Therefore, in many visualization applications a scalar density corresponding to the point distribution is resampled on a regular grid for direct volume rendering. However, many fine details are usually lost for voxel resolutions which still allow interactive visualization on standard workstations. Since no surface geometry is associated with our data sets, the recently introduced point-based rendering algorithms cannot be applied as well. In this paper we propose to accelerate the visualization of scattered point data by a hierarchical data structure based on a PCA clustering procedure. By traversing this structure for each frame we can trade-off rendering speed vs. image quality. Our scheme also reduces memory consumption by using quantized relative coordinates and it allows for fast sorting of semi-transparent clusters. We analyze various software and hardware implementations of our renderer and demonstrate that we can now visualize data sets with tens of millions of points interactively with sub-pixel screen space error on current PC graphics hardware employing advanced vertex shader functionality.	Hopf, M.;Ertl, T.	Visualization & Interactive Syst. Group, Univ. of Stuttgart, Germany|c|;	37427327200;37268023800
	SciVis	24-24 Oct. 2003	A framework for sample-based rendering with O-buffers	10.1109/VISUAL.2003.1250405	http://dx.doi.org/10.1109/VISUAL.2003.1250405	441	448	1250405	antialiasing;image representation;rendering (computer graphics)	2D O-buffer;3D O-buffer;delaying reconstruction;frame buffer;hierarchical O-buffers;hybrid rendering;hybrid volume rendering;image quality;image-based rendering;irregular sampling;layered depth O-buffers;layered depth image;multiple resamplings;regular base grid;sample-based graphics;sample-based rendering;spatial information	Buffer storage;Clouds;Computer graphics;Computer science;Image resolution;Image sampling;Layout;Radio access networks;Rendering (computer graphics);Solid modeling		We present an innovative modeling and rendering primitive, called the O-buffer, for sample-based graphics, such as images, volumes and points. The 2D or 3D O-buffer is in essence a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The offset is typically quantized for compact representation and efficient rendering. The O-buffer emancipates pixels and voxels from the regular grids and can greatly improve the modeling power of images and volumes. It is a semi-regular structure which lends itself to efficient construction and rendering. Image quality can be improved by storing more spatial information with samples and by avoiding multiple resamplings and delaying reconstruction to the final rendering stage. Using O-buffers, more accurate multi-resolution representations can be developed for images and volumes. It can also be exploited to represent and render unstructured primitives, such as points, particles, curvilinear or irregular volumes. The O-buffer is therefore a uniform representation for a variety of graphics primitives and supports mixing them in the same scene. We demonstrate the effectiveness of the O-buffer with hierarchical O-buffers, layered depth O-buffers, and hybrid volume rendering with O-buffers.	Huamin Qu;Kaufman, A.;Ran Shao;Kumar, A.	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;;;	37272637300;37268052800;37284278600;38200498200
	SciVis	24-24 Oct. 2003	Monte Carlo volume rendering	10.1109/VISUAL.2003.1250406	http://dx.doi.org/10.1109/VISUAL.2003.1250406	449	456	1250406	Monte Carlo methods;image processing;probability;rendering (computer graphics)	MCVR;Monte Carlo Volume Rendering;Monte Carlo integration;Monte Carlo volume rendering;X-ray image;client/server connection;image interactivity;image quality;image resolution;pixel intensity;probability density function;progressive refinement;quantization error;volume reconstruction	Clouds;Data visualization;Image reconstruction;Image resolution;Monte Carlo methods;Pixel;Probability density function;Quantization;Rendering (computer graphics);X-ray imaging		In this paper a novel volume-rendering technique based on Monte Carlo integration is presented. As a result of a preprocessing, a point cloud of random samples is generated using a normalized continuous reconstruction of the volume as a probability density function. This point cloud is projected onto the image plane, and to each pixel an intensity value is assigned which is proportional to the number of samples projected onto the corresponding pixel area. In such a way a simulated X-ray image of the volume can be obtained. Theoretically, for a fixed image resolution, there exists an M number of samples such that the average standard deviation of the estimated pixel intensities us under the level of quantization error regardless of the number of voxels. Therefore Monte Carlo Volume Rendering (MCVR) is mainly proposed to efficiently visualize large volume data sets. Furthermore, network applications are also supported, since the trade-off between image quality and interactivity can be adapted to the bandwidth of the client/server connection by using progressive refinement.	Csebfalvi, B.;Szirmay-Kalos, L.	Dept. of Control Eng. & Inf. Technol., Budapest Tech. Univ., Hungary|c|;	37284317200;38198907700
	SciVis	24-24 Oct. 2003	Visibility based methods and assessment for detail-recovery	10.1109/VISUAL.2003.1250407	http://dx.doi.org/10.1109/VISUAL.2003.1250407	457	464	1250407	image restoration;image texture;mesh generation;rendering (computer graphics)	detail recovery;geometry texture;hires meshes;mapping method;normal mapping;per-texel visibility;recovering technique;self-occlusion information;simplified meshes;texture mapping;visibility based assessment;visibility based method	Acceleration;Chromium;Data visualization;Frequency;Geometry;Graphics;Hardware;Rendering (computer graphics);Shadow mapping;Surface texture		"In this paper we propose a new method for the creation of normal maps for recovering the detail on simplified meshes and a set of objective techniques to metrically evaluate the quality of different recovering techniques. The proposed techniques, that automatically produces a normal-map texture for a simple 3D model that ""imitates"" the high frequency detail originally present in a second, much higher resolution one, is based on the computation of per-texel visibility and self-occlusion information. This information is used to define a point-to-point correspondence between simplified and hires meshes. Moreover, we introduce a number of criteria for measuring the quality (visual or otherwise) of a given mapping method, and provide efficient algorithms to implement them. Lastly, we apply them to rate different mapping methods, including the widely used ones and the new one proposed here."	Tarini, M.;Cignoni, P.;Scopigno, R.	ISTI, CNR, Pisa, Italy|c|;;	37591264000;37265783400;37270887900
	SciVis	24-24 Oct. 2003	Large mesh simplification using processing sequences	10.1109/VISUAL.2003.1250408	http://dx.doi.org/10.1109/VISUAL.2003.1250408	465	472	1250408	application program interfaces;image sequences;solid modelling	API;abstractions;boundary-based processing;buffer-based processing;connectivity information;geometry information;mesh access;mesh data;mesh processing sequence;mesh simplification;out-of-core access;out-of-core algorithm;out-of-core mesh processing;traversal active elements;traversal order	Chromium;Computer graphics;Data structures;Gold;Information geometry;Laboratories;Lifting equipment;Prototypes;Smoothing methods;Solid modeling		In this paper we show how out-of-core mesh processing techniques can be adapted to perform their computations based on the new processing sequence paradigm (Isenburg, et al., 2003), using mesh simplification as an example. We believe that this processing concept will also prove useful for other tasks, such a parameterization, remeshing, or smoothing, for which currently only in-core solutions exist. A processing sequence represents a mesh as a particular interleaved ordering of indexed triangles and vertices. This representation allows streaming very large meshes through main memory while maintaining information about the visitation status of edges and vertices. At any time, only a small portion of the mesh is kept in-core, with the bulk of the mesh data residing on disk. Mesh access is restricted to a fixed traversal order, but full connectivity and geometry information is available for the active elements of the traversal. This provides seamless and highly efficient out-of-core access to very large meshes for algorithms that can adapt their computations to this fixed ordering. The two abstractions that are naturally supported by this representation are boundary-based and buffer-based processing. We illustrate both abstractions by adapting two different simplification methods to perform their computation using a prototype of our mesh processing sequence API. Both algorithms benefit from using processing sequences in terms of improved quality, more efficient execution, and smaller memory footprints.	Isenburg, M.;Lindstrom, P.;Gumhold, S.;Snoeyink, J.	North Carolina Univ., Chapel Hill, NC, USA|c|;;;	37281897600;37269320000;37565742800;37282623700
	SciVis	24-24 Oct. 2003	Appearance-preserving view-dependent visualization	10.1109/VISUAL.2003.1250409	http://dx.doi.org/10.1109/VISUAL.2003.1250409	473	480	1250409	computational geometry;data visualisation	appearance-preserving visualization;geometry-preserving aspect;level-of-detail hierarchy;mesh simplification;multiresolution models;quadric error metric;quadric-based simplification;screen-space metric;texture-preserving aspect;view-dependent simplification;view-dependent visualization	Buildings;Chromium;Computational geometry;Computer graphics;Data visualization;Error correction;Image reconstruction;Large-scale systems;Solid modeling;Urban planning		In this paper a new quadric-based view-dependent simplification scheme is presented. The scheme provides a method to connect mesh simplification controlled by a quadric error metric with a level-of-detail hierarchy that is accessed continuously and efficiently based on current view parameters. A variety of methods for determining the screen-space metric for the view calculation are implemented and evaluated, including an appearance-preserving method that has both geometry- and texture-preserving aspects. Results are presented and compared for a variety of models.	Jang, J.;Ribarsky, W.;Shaw, C.;Wonka, P.	GVU Center, Georgia Inst. of Technol., Atlanta, Georgia|c|;;;	38197765400;37300425000;37358198200;37304396700
	SciVis	24-24 Oct. 2003	Shape simplification based on the medial axis transform	10.1109/VISUAL.2003.1250410	http://dx.doi.org/10.1109/VISUAL.2003.1250410	481	488	1250410	computational geometry;image reconstruction;solid modelling;surface reconstruction	3D objects;MAT;medial axis transform;polygonal surface;shape simplification;surface reconstruction method;topology preservation	Computer graphics;Computer science;Image reconstruction;Laboratories;Reconstruction algorithms;Robustness;Shape;Solid modeling;Surface reconstruction;Topology		We present a new algorithm for simplifying the shape of 3D objects by manipulating their medial axis transform (MAT). From an unorganized set of boundary points, our algorithm computes the MAT, decomposes the axis into parts, then selectively removes a subset of these parts in order to reduce the complexity of the overall shape. The result is simplified MAT that can be used for a variety of shape operations. In addition, a polygonal surface of the resulting shape can be directly generated from the filtered MAT using a robust surface reconstruction method. The algorithm presented is shown to have a number of advantages over other existing approaches.	Tam, R.;Heidrich, W.	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;	38181846100;37269011000
	SciVis	24-24 Oct. 2003	Adaptive design of a global opacity transfer function for direct volume rendering of ultrasound data	10.1109/VISUAL.2003.1250411	http://dx.doi.org/10.1109/VISUAL.2003.1250411	489	496	1250411	biomedical MRI;realistic images;rendering (computer graphics);transfer functions	3D ultrasound;CT data;MRI data;data acquisition;direct volume rendering;echogenicity;global OTF;linear OTF;magnetic resonance imaging;opacity transfer function;signal-to-noise ratio;sonographic data;tube cores;voxels	Computed tomography;Couplings;Data acquisition;Data visualization;Magnetic resonance imaging;Piecewise linear techniques;Signal design;Signal to noise ratio;Transfer functions;Ultrasonic imaging		While there are a couple of transfer function design approaches for CT and MRI (magnetic resonance imaging) data, direct volume rendering of ultrasound data still relies on manual adjustment of an inflexible piecewise linear opacity transfer function (OTF) on a trial-and-error basis. The main challenge of automatically designing an OTF for visualization of sonographic data is the low signal-to-noise ratio in combination with real time data acquisition at frame rates up to 25 volumes per second. In this paper, we present an efficient solution of this task. Our approach is based on the evaluation of tube cores, i.e., collections of voxels gathered by traversing the volume in rendering directions. We use information about the probable position of an interface between tissues of different echogenicity to adaptively design an OTF in a multiplicative way. We show the appropriateness of our approach by examples, deliberately on data sets of moderate quality arising frequently in clinical settings.	Honigmann, D.;Ruisz, J.;Haider, C.	Adv. Comput. Vision GmbH, ACV, Vienna, Austria|c|;;	37326165100;38198925300;38197646400
	SciVis	24-24 Oct. 2003	Gaussian transfer functions for multi-field volume visualization	10.1109/VISUAL.2003.1250412	http://dx.doi.org/10.1109/VISUAL.2003.1250412	497	504	1250412	Gaussian distribution;data visualisation;realistic images;rendering (computer graphics);transfer functions	3D volumetric datasets;CT;Gaussian transfer functions;cryosection;graphics hardware;multidimensional transfer function;multifield visualization;multivariate data;volume rendering;volume visualization	Computed tomography;Computer graphics;Data visualization;Geometrical optics;Hardware;Multidimensional systems;Rendering (computer graphics);Scientific computing;Table lookup;Transfer functions		Volume rendering is a flexible technique for visualizing dense 3D volumetric datasets. A central element of volume rendering is the conversion between data values and observable quantities such as color and opacity. This process is usually realized through the use of transfer functions that are precomputed and stored in lookup tables. For multidimensional transfer functions applied to multivariate data, these lookup tables become prohibitively large. We propose the direct evaluation of a particular type of transfer functions based on a sum of Gaussians. Because of their simple form (in terms of number of parameters), these functions and their analytic integrals along line segments can be evaluated efficiently on current graphics hardware, obviating the need for precomputed lookup tables. We have adopted these transfer functions because they are well suited for classification based on a unique combination of multiple data values that localize features in the transfer function domain. We apply this technique to the visualization of several multivariate datasets (CT, cryosection) that are difficult to classify and render accurately at interactive rates using traditional approaches.	Kniss, J.;premoze, S.;Ikits, M.;Lefohn, A.;Hansen, C.;Praun, E.	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake, UT, USA|c|;;;;;	37324263400;38149547900;37426872100;38198885000;37266777200;37266873200
	SciVis	24-24 Oct. 2003	A novel interface for higher-dimensional classification of volume data	10.1109/VISUAL.2003.1250413	http://dx.doi.org/10.1109/VISUAL.2003.1250413	505	512	1250413	image segmentation;knowledge acquisition;neural nets;realistic images;rendering (computer graphics);transfer functions;user interfaces	artificial neural network;classification function;color map function;graphics hardware;interactive rendering;interactive visualization;multidimensional transfer function;opacity map function;user interface;volume data;volume visualization;voxel	Data visualization		In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.	Tzeng, F.-Y.;Lum, E.B.;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	37425953500;37282576300;37275869400
	SciVis	24-24 Oct. 2003	Curvature-based transfer functions for direct volume rendering: methods and applications	10.1109/VISUAL.2003.1250414	http://dx.doi.org/10.1109/VISUAL.2003.1250414	513	520	1250414	image processing;realistic images;rendering (computer graphics);transfer functions	anisotropic diffusion;convolution-based differentiation;convolution-based reconstruction;curvature information;curvature-based transfer function;direct volume rendering;flowline curvature;isosurface uncertainty visualization;multidimensional transfer function;nonphotorealistic volume rendering;scalar field;surface curvature;surface smoothing	Anisotropic magnetoresistance;Concrete;Convolution;Filters;Guidelines;Smoothing methods;Surface reconstruction;Transfer functions;Visualization;Volume measurement		Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.	Kindlmann, G.;Whitaker, R.;Tasdizen, T.;Moller, T.	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake, UT, USA|c|;;;	37282742400;37267322600;37265762400;37275858700
	SciVis	24-24 Oct. 2003	A visual exploration process for the analysis of Internet routing data	10.1109/VISUAL.2003.1250415	http://dx.doi.org/10.1109/VISUAL.2003.1250415	523	530	1250415	Internet;data visualisation;graphical user interfaces;security of data	Internet routing data analysis;Internet security;Internet stability;homeland security;information visualization;network visualization;text visualization;visual exploration	Business;Data security;Data visualization;Government;Information security;Internet;Production;Protection;Routing;Stability		The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.	Soon Tee Teoh;Kwan-Liu Ma;Wu, S.F.	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	37412023800;37275869400;37281058700
	SciVis	24-24 Oct. 2003	Visualization, optimization, business strategy: a case study	10.1109/VISUAL.2003.1250416	http://dx.doi.org/10.1109/VISUAL.2003.1250416	531	538	1250416	data visualisation;graphical user interfaces;optimisation;pattern recognition	VisAD;a priori mathematical formulation;business strategy;information visualization;optimization;pattern recognition	Chromium;Computer aided software engineering;Computer graphics;Cost function;Customer service;Hardware;Land transportation;Optimization methods;Pattern recognition;Visualization		We describe a visualization application intended for operational use in formulating business strategy in the customer service arena. The visualization capability provided in this application implicitly allows the user to better formulate the objective function for large optimization runs which act to minimize costs based on certain input parameters. Visualization is necessary because many of the inputs to the optimization runs are themselves strategic business decisions which are not pre-ordained. Both information visualization presentations and three-dimensional visualizations are included to help users better understand the cost/benefit tradeoffs of these strategic business decisions. Here, visualization explicitly provides value not possible algorithmically, as the perceived benefit of different combinations of service level does not have an a priori mathematical formulation. Thus, we take advantage of the fundamental power of visualization, bringing the user's intuition and pattern recognition skills into the solution, while simultaneously taking advantage of the strength of algorithmic approaches to quickly and accurately find an optimal solution to a well-defined problem.	Gresh, D.L.;Kelton, E.I.	IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	37378534100;38198667500
	SciVis	24-24 Oct. 2003	Interactive 3D visualization of rigid body systems	10.1109/VISUAL.2003.1250417	http://dx.doi.org/10.1109/VISUAL.2003.1250417	539	546	1250417	automobile industry;colour graphics;data visualisation;digital simulation;graphical user interfaces;interactive systems	automotive engine design;automotive engine simulation;automotive industry;engine belt driven timing drive visualization;engine chain visualization;glyph based visualization;iconic visualization;interactive 3D visualization;intuitive 3D visualization;rigid body dynamics;rigid body simulation;three-dimensional visualization	Analytical models;Animation;Automotive engineering;Belts;Biological system modeling;Computational modeling;Computer graphics;Computer simulation;Data visualization;Vehicle dynamics		Simulation of rigid body dynamics has been a field of active research for quite some time. However, the presentation of simulation results has received far less attention so far. We present an interactive and intuitive 3D visualization framework for rigid body simulation data. We introduce various glyphs representing vector attributes such as force and velocity as well as angular attributes including angular velocity and torque. We have integrated our visualization method into an application developed at one of the leading companies in automotive engine design and simulation. We apply our principles to visualization of chain and belt driven timing drives in engines.	Konyha, Z.;Matkovic, K.;Hauser, H.	VRVis Res. Center, Austria|c|;;	38190845700;38188281400;37274158800
	SciVis	24-24 Oct. 2003	Visualizing industrial CT volume data for nondestructive testing applications	10.1109/VISUAL.2003.1250418	http://dx.doi.org/10.1109/VISUAL.2003.1250418	547	554	1250418	computerised tomography;data visualisation;feature extraction;graphical user interfaces;nondestructive testing;rendering (computer graphics);solid modelling	computed tomography;data visualization;feature extraction;hardware-acceleration rendering;image processing;industrial CT volume data;interactive visualization;nondestructive testing;scientific visualization;surface modeling;user interface;volume rendering;volume visualization	Computed tomography;Computer industry;Cost function;Data visualization;Feature extraction;Histograms;Inspection;Nondestructive testing;Rendering (computer graphics);Volume measurement		This paper describes a set of techniques developed for the visualization of high-resolution volume data generated from industrial computed tomography for nondestructive testing (NDT) applications. Because the data are typically noisy and contain fine features, direct volume rendering methods do not always give us satisfactory results. We have coupled region growing techniques and a 2D histogram interface to facilitate volumetric feature extraction. The new interface allows the user to conveniently identify, separate or composite, and compare features in the data. To lower the cost of segmentation, we show how partial region growing results can suggest a reasonably good classification function for the rendering of the whole volume. The NDT applications that we work on demand visualization tasks including not only feature extraction and visual inspection, but also modeling and measurement of concealed structures in volumetric objects. An efficient filtering and modeling process for generating surface representation of extracted features is also introduced. Four CT data sets for preliminary NDT are used to demonstrate the effectiveness of the new visualization strategy that we have developed.	Huang, R.;Kwan-Liu Ma;McCormick, P.;Ward, W.	California Univ., Davis, CA, USA|c|;;;	37288597500;37275869400;37282708700;38203215500
	SciVis	24-24 Oct. 2003	Visualization of steep breaking waves and thin spray sheets around a ship	10.1109/VISUAL.2003.1250419	http://dx.doi.org/10.1109/VISUAL.2003.1250419	555	559	1250419	computational fluid dynamics;data visualisation;hydrodynamics;naval engineering computing;parallel programming;waves	breaking wave simulation;hydrodynamics;isosurfaces;large-scale simulations;marching cubes;multilevel parallelism;naval vessels;scalar data;spray sheets;steep breaking wave visualization;steep breaking waves;thin spray sheet simulation;thin spray sheet visualization	Application software;Computational modeling;Data visualization;Hydrodynamics;Isosurfaces;Marine vehicles;Poisson equations;Spraying;Surface reconstruction;Surface waves		The simulation of breaking of waves, the formation of thin spray sheets, and the entertainment of air around the next generation of naval surface combatants is an ongoing 3-year Department of Defense (DoD) Challenge Project. The goal of this project is a validated computation capability to model the full hydrodynamics around a surface combatant including all of the processes that affect mission and performance. Visualization of these large-scale simulations is paramount to understanding the complex physics involved. These simulations produce enormous data sets with both surface and volumetric qualities. Wave breaking, spray sheets, and air entertainment can be visualized using isosurfaces of scalar data. Visualization of quantities such as the vorticity field also provides insight into the dynamics of droplet and bubble formation. This paper documents the techniques used, results obtained, and lessons learned from the visualization of the hydrodynamics of naval vessels.	Adams, P.;Dommermuth, D.	ERDC, Major Shared Resource Center, Vicksburg, MS, USA|c|;	37297590400;37299300400
	SciVis	24-24 Oct. 2003	Accelerating large data analysis by exploiting regularities	10.1109/VISUAL.2003.1250420	http://dx.doi.org/10.1109/VISUAL.2003.1250420	561	568	1250420	data analysis;data models;data visualisation;object-oriented programming	C++ language;CFD simulation;computational fluid dynamics;curvilinear data sets;cylindrical meshes;data analysis;data models;data visualization;demand-driven evaluation;large data sets;mesh replacement;mesh replacements;mesh rigid-body motion discovery;mesh transformation;multizone data;object-oriented methods;out-of-core paging;regularity finding;rigid body motion;scientific visualization;time series;time-series data;visualization algorithms	Acceleration;Algorithm design and analysis;Computational fluid dynamics;Data analysis;Data models;Data visualization;Interpolation;NASA;Pattern analysis;Postal services		We present techniques for discovering and exploiting regularity in large curvilinear data sets. The data can be based on a single mesh or a mesh composed of multiple submeshes (also known as zones). Multi-zone data are typical in Computational Fluid Dynamics (CFD) simulations. Regularities include axis-aligned rectilinear and cylindrical meshes as well as cases where one zone is equivalent to a rigid body transformation of another. Our algorithms can also discover rigid-body motion of meshes in time-series data. Next, we describe a data model where we can utilize the results from the discovery process in order to accelerate large data visualizations. Where possible, we replace general curvilinear zones with rectilinear or cylindrical zones. In rigid-body motion cases, we replace a time-series of meshes with a transformed mesh object where a reference mesh is dynamically transformed based on a given time value in order to satisfy geometry requests, on demand. The data model enables us to make these substitutions and dynamic transformations transparently with respect to the visualization algorithms. We present results with large data sets where we combine our mesh replacement and transformation techniques with out-of-core paging in order to achieve analysis speedups ranging from 1.5 to 2.	Ellsworth, D.;Moran, P.J.	Adv. Manage. Technol. Inc., NASA Ames Res. Center, Moffett Field, CA, USA|c|;	37282594500;37264891100
	SciVis	24-24 Oct. 2003	Visualizing spatial and temporal variability in coastal observatories	10.1109/VISUAL.2003.1250421	http://dx.doi.org/10.1109/VISUAL.2003.1250421	569	574	1250421	data visualisation;digital simulation;graphical user interfaces;rivers;software tools;solid modelling	3D visualization tools;4D visualization tools;CORIE;Columbia River;coastal observatories;environmental observation;forecasting systems;interactive visualization;spatial variability visualization;temporal variability visualization	Computational modeling;Data visualization;Ecosystems;Heart;Observatories;Power engineering computing;Predictive models;Rivers;Sea measurements;Sustainable development		In this paper, we describe a set of 3D and 4D visualization tools and techniques for CORIE, a complex environmental observation and forecasting system (EOFS) for the Columbia River. The Columbia River, a complex and highly variable estuary, is the target of numerous cross-disciplinary ecosystem research projects and is at the heart of multiple sustainable development issues with long reaching implications for the Pacific Northwest. However, there has been until recently no comprehensive and objective system available for modeling this environment, and as a consequence, researchers and agencies have had inadequate tools for evaluating the effects of natural resource management decisions. CORIE was designed to address this gap and is a major step towards the vision of a scalable, multi-use, real-time EOFS. Although CORIE already had a rich set of visualization tools, most of them produced 2D visualizations and did not allow for interactive visualization. Our work adds advanced interactive 3D tools to CORIE, which can be used for further inspection of the simulated and measured data.	Jimenez, W.H.;Correa, W.T.;Silva, C.T.;Baptista, A.M.	OGI Sch. of Sci. & Eng., Oregon Health & Sci. Univ., Portland, OR, USA|c|;;;	38139545800;38152504300;37275249200;37371354900
	SciVis	24-24 Oct. 2003	Producing high-quality visualizations of large-scale simulation	10.1109/VISUAL.2003.1250422	http://dx.doi.org/10.1109/VISUAL.2003.1250422	575	580	1250422	computational geometry;computer animation;data visualisation;digital simulation;geometric programming;solid modelling	Pentagon;civil engineering;commercial animation;computer graphics;geometric computing;high-quality visualization;image-based technique;large-scale simulation;simulation data;state-of-the-art simultion	Animation;Art;Civil engineering;Computational modeling;Computer graphics;Data visualization;Large-scale systems;Layout;Resource management;Software systems		This paper describes the work of a team of researchers in computer graphics, geometric computing, and civil engineering to produce a visualization of the September 2001 attack on the Pentagon. The immediate motivation for the project was to understand the behavior of the building under the impact. The longer term motivation was to establish a path for producing high-quality visualizations of large scale simulations. The first challenge was managing the enormous complexity of the scene to fit within the limits of state-of-the art simulation software systems and supercomputing resources. The second challenge was to integrate the simulation results into a high-quality visualization. To meet this challenge, we implemented a custom importer that simplifies and loads the massive simulation data in a commercial animation system. The surrounding scene is modeled using image-based techniques and is also imported in the animation system where the visualization is produced. A specific issue for us was to federate the simulation and the animation systems, both commercial systems not under our control and following internally different conceptualizations of geometry and animation. This had to be done such that scalability was achieved. The reusable link created between the two systems allows communicating the results to non-specialists and the public at large, as well as facilitating communication in teams with members having diverse technical backgrounds.	Popescu, V.;Hoffmann, C.;Kilic, S.;Sozen, M.;Meador, S.	Purdue Univ., USA|c|;;;;	37272425500;37359029500;38196945000;38197908500;37442441900
	SciVis	24-24 Oct. 2003	Interactive protein manipulation	10.1109/VISUAL.2003.1250423	http://dx.doi.org/10.1109/VISUAL.2003.1250423	581	588	1250423	computer graphics;data visualisation;genetics;graphical user interfaces;medical computing;proteins;solid modelling	amino acid sequence;computational science;gene coding;interactive protein manipulation;interactive visualization;inverse kinematics;modeling program;molecular modeling;protein structure prediction	Amino acids;Chemicals;Computational biology;Computer graphics;Kinematics;Predictive models;Proteins;Sequences;Spine;Visualization		"We describe an interactive visualization and modeling program for the creation of protein structures ""from scratch."" The input to our program is an amino acid sequence - decoded from a gene - and a sequence of predicted secondary structure types for each amino acid - provided by external structure prediction programs. Our program can be used in the set-up phase of a protein structure prediction process; the structures created with it serve as input for a subsequent global internal energy minimization, or another method of protein structure prediction. Our program supports basic visualization methods for protein structures, interactive manipulation based on inverse kinematics, and visualization guides to aid a user in creating ""good"" initial structures."	Kreylos, O.;Max, N.L.;Hamann, B.;Crivelli, S.N.;Bethel, E.W.	Dept. of Comput. Sci., Univ. of California, Davis, CA, USA|c|;;;;	37726031300;37267387800;37282068700;37565737200;38198872100
	SciVis	24-24 Oct. 2003	Holographic video display of time-series volumetric medical data	10.1109/VISUAL.2003.1250424	http://dx.doi.org/10.1109/VISUAL.2003.1250424	589	596	1250424	computer graphic equipment;holography;medical image processing;rendering (computer graphics)	MRI dataset;animated electro-holographic visualization;brain lesion;computer graphic rendering;hologram encoding;holographic video display;magnetic resonance imaging;medical imaging;multiple sclerosis;spatial display;time-series volumetric medical data	Animation;Application software;Biomedical imaging;Computer displays;Data visualization;Holography;Lesions;Magnetic resonance imaging;Multiple sclerosis;Pipelines		We describe an animated electro-holographic visualization of brain lesions due to the progression of multiple sclerosis. A research case study is used which documents the expression of visible brain lesions in a series of magnetic resonance imaging (MRI) volumes collected over the interval of one year. Some of the salient information resident within this data is described, and the motivation for using a dynamic spatial display to explore its spatial and temporal characteristics is stated. We provide a brief overview of spatial displays in medical imaging applications, and then describe our experimental visualization pipeline, from the processing of MRI datasets, through model construction, computer graphic rendering, and hologram encoding. The utility, strengths and shortcomings of the electro-holographic visualization are described and future improvements are suggested.	Plesniak, W.;Halle, M.;Pieper, S.D.;Wells, W.;Jakab, M.;Meier, D.S.;Benton, S.A.;Guttmann, R.G.;Kikinis, R.	;;;;;;;;	37868928800;38320157400;37424578200;38349463500;38202666300;38196814800;37371177100;37963994600;38319729000
	SciVis	24-24 Oct. 2003	Heart-muscle fiber reconstruction from diffusion tensor MRI	10.1109/VISUAL.2003.1250425	http://dx.doi.org/10.1109/VISUAL.2003.1250425	597	602	1250425	adaptive filters;biomedical MRI;digital simulation;magnetic resonance imaging;medical image processing;solid modelling;tensors	3D diffusion tensor MRI data;fiber tracing;heart-muscle fiber reconstruction;magnetic resonance imaging;moving least squares;scalar and tensor glyph visualization;tensor visualization	Cells (biology);Data visualization;Diffusion tensor imaging;Eigenvalues and eigenfunctions;Ellipsoids;Heart;Least squares methods;Magnetic resonance imaging;Muscles;Tensile stress		In this paper we use advanced tensor visualization techniques to study 3D diffusion tensor MRI data of a heart. We use scalar and tensor glyph visualization methods to investigate the data and apply a moving least squares (MLS) fiber tracing method to recover and visualize the helical structure and the orientation of the heart muscle fibers.	Zhukov, L.;Barr, A.H.	Dept. of Comput. Sci., California Inst. of Technol., USA|c|;	37266085200;37360174300
	SciVis	24-24 Oct. 2003	Which comes first, usability or utility?	10.1109/VISUAL.2003.1250426	http://dx.doi.org/10.1109/VISUAL.2003.1250426	605	606	1250426			Computer interfaces;Computer science;Data visualization;Educational institutions;Human computer interaction;Laboratories;Motorcycles;Switches;Usability;Vehicles			Grinstein, G.	University of Massachusetts Lowell|c|	
	SciVis	24-24 Oct. 2003	Interoperability of visualization software and data models is not an achievable goal	10.1109/VISUAL.2003.1250427	http://dx.doi.org/10.1109/VISUAL.2003.1250427	607	610	1250427			Chromium;Computer interfaces;Data models;Data visualization;Graphics;Laboratories;Memory;Probes;Standardization;Standards organizations			Bethel, E.W.	Lawrence Berkeley National Laboratory|c|	38198872100
	SciVis	24-24 Oct. 2003	Information and scientific visualization: separate but equal or happy together at last	10.1109/VISUAL.2003.1250428	http://dx.doi.org/10.1109/VISUAL.2003.1250428	611	614	1250428			Bioinformatics;Bonding;Chemistry;Computer displays;Data mining;Data visualization;Genomics;Scientific computing;Spatial databases;Visual databases			Rhyne, T.;Tory, M.;Munzner, T.;Ward, M.;Johnson, C.;Laidlaw, D.H.	North Carolina State University|c|;;;;;	37282569700;37275861300;37349490300;38197247500;38199532300;37275712600
	SciVis	19-24 Oct. 2003	Do I really see a bone?	10.1109/VISUAL.2003.1250429	http://dx.doi.org/10.1109/VISUAL.2003.1250429	615	617	1250429			Biomedical imaging;Bones;Data mining;Data visualization;Displays;Feature extraction;Image reconstruction;Libraries;Medical simulation;Supercomputers			Machiraju, R.;Yoo, T.;Crawfis, R.;Ebert, D.;Stredney, D.	The Ohio State University|c|;;;;	37269516700;38199089200;37284273900;38202925600;37329502700
	SciVis	24-24 Oct. 2003	Visualization experiences and issues in deep space exploration	10.1109/VISUAL.2003.1250430	http://dx.doi.org/10.1109/VISUAL.2003.1250430	619	621	1250430			Data visualization;Earth;Instruments;Laboratories;Mars;Planets;Propulsion;Space exploration;Space missions;Terrestrial atmosphere			Wright, J.;Burleigh, S.;Maruya, M.;Maxwell, S.;Pischel, R.	Jet Propulsion Laboratory|c|;;;;	37270871700;37297068800;38203097900;37392500700;38198673300
