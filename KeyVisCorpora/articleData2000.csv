Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis	2000	New methods for the visualization of electric power system information	10.1109/INFVIS.2000.885101	http://dx.doi.org/10.1109/INFVIS.2000.885101	131	16c	885101	computer animation;data visualisation;electricity supply industry;power system analysis computing	data aggregation;electric industry restructuring;electric power system information visualization;electrical nodes;interactive 3D data visualization;large-scale electric power systems;multivariate data;network power flows;power system flow animation;transmission system capacity	Animation;Data visualization;Industrial relations;Information analysis;Job shop scheduling;Large-scale systems;Load flow;Power system analysis computing;Power systems;Power transmission lines		One area in need of new research in information visualization is the operation and analysis of large-scale electric power systems. In analyzing power systems, one is usually confronted with a large amount of multivariate data. With systems containing tens of thousands of electrical nodes (buses), a key challenge is to present this data in a form so the user can assess the state of the system in an intuitive and quick manner. This is particularly true when trying to analyze relationships between actual network power flows, the scheduled power flows, and the capacity of the transmission system. With electric industry restructuring and the move towards having a single entity, such as an independent system operator or pool, operate a much larger system, this need has become more acute. This paper presents several power system visualization techniques to help in this task. These techniques include animation of power system flow values, contouring of bus and transmission line flow values, data aggregation techniques and interactive 3D data visualization	Overbye, T.J.;Weber, J.D.	Illinois Univ., Urbana, IL, USA|c|;	37272088600;37333495700
	InfoVis	2000	Visualizing massive multi-digraphs	10.1109/INFVIS.2000.885089	http://dx.doi.org/10.1109/INFVIS.2000.885089	39	47	885089	data visualisation;directed graphs;graphical user interfaces;interactive systems;set theory;trees (mathematics)	C language;Java-3D;MGV;arbitrary visual representations;client-server paradigm;drill-down interface;geographic information;graph data;graph hierarchy slice;integrated visualization/exploration system;interactive pixel-oriented maps;interactive response;massive multi-digraph navigation;massive multi-digraph visualization;multi-linked views;navigation control;out-of-core graph hierarchy;predetermined tree;statistical displays;underlying digraph;vertex set;visualization techniques;zoomable label based interface	Data visualization;Java;Laboratories;Navigation;Plugs;Random access memory;Read-write memory;Three dimensional displays;Tree graphs;Two dimensional displays		We describe MGV, an integrated visualization and exploration system for massive multi-digraph navigation. MGV's only assumption is that the vertex set of the underlying digraph corresponds to the set of leaves of a predetermined tree T. MGV builds an out-of-core graph hierarchy and provides mechanisms to plug in arbitrary visual representations for each graph hierarchy slice. Navigation from one level to another of the hierarchy corresponds to the implementation of a drill-down interface. In order to provide the user with navigation control and interactive response, MGV incorporates a number of visualization techniques like interactive pixel-oriented 2D and 3D maps, statistical displays, multi-linked views, and a zoomable label based interface. This makes the association of geographic information and graph data very natural. MGV follows the client-server paradigm and it is implemented in C and Java-3D. We highlight the main algorithmic and visualization techniques behind the tools and point out along the way several possible application scenarios. Our techniques are being applied to multi-graphs defined on vertex sets with sizes ranging from 100 million to 250 million vertices	Abello, J.;Korn, J.	;	37662339600;38179814200
	InfoVis	2000	Creativity, complexity, and precision: information visualization for (landscape) architecture	10.1109/INFVIS.2000.885105	http://dx.doi.org/10.1109/INFVIS.2000.885105	167	171	885105	CAD;data visualisation;groupware;human factors;user interfaces	3D collaborative electronic workspace;CAD;data storage;ethnographic studies;heterogeneous work materials;human-centered approach;information visualization;landscape design	Collaborative work;Computer architecture;Computer science;Data visualization;Electrical capacitance tomography;Humans;Logistics;Memory;Sociology;Space technology		Drawing on ethnographic studies of (landscape) architects at work, this paper presents a human-centered approach to information visualization. A 3D collaborative electronic workspace allows people to configure, save and browse arrangements of heterogeneous work materials. Spatial arrangements and links are created and maintained as an integral part of ongoing work with `live' documents and objects. The result is an extension of the physical information space of the architects' studio that utilizes the potential of electronic data storage, visualization and network technologies to support work with information in context	Buscher, M.;Shapiro, D.;Christensen, M.;Mogensen, P.;Orbaek, P.	Dept. of Sociology, Lancaster Univ., UK|c|;;;;	38026813600;38031107700;37442180300;38017841600;38018324800
	InfoVis	2000	Metaphor-aware 3D navigation	10.1109/INFVIS.2000.885104	http://dx.doi.org/10.1109/INFVIS.2000.885104	155	165	885104	Internet;computer network management;data visualisation;user interfaces	3D browsers;3D interfaces;CyberNet project;adaptive navigation features;computer network management;information visualization;metaphor-aware 3D navigation;three-dimensional interfaces;user interface;virtual 3D space	Cameras;Data visualization;Decision making;Mice;Motion planning;Navigation;Project management;Research and development management;User interfaces		Anyone who has ever experienced three-dimensional (3D) interfaces will agree that navigating in a 3D world is not a trivial task. The user interface of traditional 3D browsers provides simple navigation tools that allow the user to modify the camera parameters such as orientation, position and focal. Using these tools, it is frequent that, after some movements, the user is lost in the virtual 3D space and usually tries to restart from the beginning. We present how the 3D navigation problem is addressed in the context of the CyberNet project (Abel et al., 2000). Our underlying principle is to help the user navigate by adapting the navigation tool to the virtual world. We feel that the navigation schemes provided by the 3D browsers are too generic for some specific 3D tools and we have developed adaptive navigation features that are dependent on the 3D metaphor used for visualizing the information and on the user's task	Russo dos Santos, C.;Gros, P.;Loisel, D.;Paris, J.P.	Eurecom Inst., Sophia Antipolis, France|c|;;;	38255198800;37267120600;37442603000;38255941300
	InfoVis	2000	From metaphor to method: cartographic perspectives on information visualization	10.1109/INFVIS.2000.885095	http://dx.doi.org/10.1109/INFVIS.2000.885095	91	97	885095	cartography;data visualisation	cartographic form;feature labeling;geographic information;information visualization;map design;map projections;mapping;spatial metaphors	Visualization		By virtue of their spatio-cognitive abilities, humans are able to navigate through geographic space as well as meaningfully communicate geographic information represented in cartographic form. The current dominance of spatial metaphors in information visualization research is the result of the realization that those cognitive skills also have value in the exploration and analysis of non-geographic information. While mapping or landscape metaphors are routinely used in this field, there is a noticeable lack of consideration for existing cartographic expertise. This is especially apparent whenever problematic issues are encountered, such as graphic complexity or feature labeling. There are a number of areas in which a cartographic outlook could provide a valuable perspective. This paper discusses how geographic and cartographic notions may influence the design of visualizations for textual information spaces. Map projections, generalization, feature labeling and map design issues are discussed	Skupin, A.	Dept. of Geogr., New Orleans Univ., LA, USA|c|	38015091900
	InfoVis	2000	Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations	10.1109/INFVIS.2000.885091	http://dx.doi.org/10.1109/INFVIS.2000.885091	57	65	885091	computer displays;data visualisation;interactive systems	complete information space;flexible browsing;focus/context display;information hierarchies;information hierarchy;navigation techniques;peripheral slices;radial space-filling hierarchy visualizations;visualization/interaction techniques	Computer displays;Educational institutions;File systems;Geometry;Navigation;Organization Charts;Space technology;Visualization		Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space	Stasko, J.;Zhang, E.	GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;	37267736900;38020590400
	InfoVis	2000	A scalable framework for information visualization	10.1109/INFVIS.2000.885088	http://dx.doi.org/10.1109/INFVIS.2000.885088	27	36	885088	data visualisation;graphical user interfaces;graphs	3-dimensional visualization space;Focus+Context technique;arbitrary levels of detail;complex hierarchy graphs;dynamic hierarchy computation;frame of reference;graphical interface;heterogeneous information spaces;high dimensional information space;information quantities;information sets;information structures;preprocessing;scalable information visualization framework;textual similarities;unstructured information spaces;user controlled refinement	Computer graphics;Computer interfaces;Computer science;Control systems;Data visualization;Extraterrestrial measurements;Filtering;Merging;Navigation;Tree graphs		The paper describes major concepts of a scalable information visualization framework. We assume that the exploration of heterogeneous information spaces at arbitrary levels of detail requires a suitable preprocessing of information quantities, the combination of different graphical interfaces and the illustration of the frame of reference of given information sets. The innovative features of our system include: dynamic hierarchy computation and user controlled refinement of those hierarchies for preprocessing unstructured information spaces; a new Focus+Context technique for visualizing complex hierarchy graphs; a new paradigm for visualizing information structures within their frame of reference; and a new graphical interface that utilizes textual similarities to arrange objects of high dimensional information space in 3-dimensional visualization space	Kreuseler, M.;Lopez, N.;Schumann, H.	Dept. of Comput. Sci., Rostock Univ., Germany|c|;;	37938665500;38025121600;37283240400
	InfoVis	2000	Redefining the focus and context of focus+context visualization	10.1109/INFVIS.2000.885094	http://dx.doi.org/10.1109/INFVIS.2000.885094	85	89	885094	data visualisation	Flip Zooming;desktop computer;focus+context technique;information visualization	Art;Books;Displays;Focusing;Painting;Tiles;Visualization;Web pages		The increasing diversity of computers, especially among small mobile devices such as mobile phones and PDAs, raise new questions about information visualization techniques developed for the desktop computer. Using a series of examples ranging from applications for ordinary desktop displays to web-browsers and other applications for PDAs, we describe how a focus+context technique, Flip Zooming, is changed due to the situation it is used in. Based on these examples, we discuss how the use of “focus” and “context” in focus+context techniques change in order to fit new areas of use for information visualization	Bjork, S.;Redstrom, J.	Interactive Inst., Gothenburg, Sweden|c|;	37444610400;37444612100
	InfoVis	2000	Collaborative geographic visualization: enabling shared understanding of environmental processes	10.1109/INFVIS.2000.885102	http://dx.doi.org/10.1109/INFVIS.2000.885102	137	141	885102	data visualisation;environmental science computing;geography;groupware;task analysis;user centred design	collaborative geographic visualization;dynamic geovisualization displays;environmental processes;environmental science research;expert guideline-based evaluation;group work;human-centered system design;summative comparative evaluation;usability;user task analysis;user-centered evaluation;virtual environments	Animation;Collaboration;Collaborative work;Data visualization;Decision making;Displays;Geography;Lifting equipment;Process planning;Prototypes		We describe a prototype same-time/different-place collaborative geovisualization environment. We outline an approach to understanding use and usability and present results of interviews with domain experts about the ways in which collaborative visualization might enable groups to work at a distance. One goal for our research is to design an effective and flexible system that can support group work on environmental science research mediated through dynamic geovisualization displays. We are addressing this goal using a four-step human-centered system design process, modeled on that proposed by (Gabbard et al., 1999) for development and evaluation of virtual environments. The steps they delineate are: user task analysis; expert guideline-based evaluation; formative user-centered evaluation; and summative comparative evaluation	Brewer, I.;MacEachren, A.M.;Abdo, H.;Gundrum, J.;Otto, G.	Dept. of Geogr., Penn State Univ., PA, USA|c|;;;;	38018021800;37374699000;38015217400;38015217200;38016367600
	InfoVis	2000	Information content measures of visual displays	10.1109/INFVIS.2000.885096	http://dx.doi.org/10.1109/INFVIS.2000.885096	99	103	885096	data visualisation;software metrics;user interfaces	information content;metrics;relative effectiveness;visualization	Displays		With an increase in the number of different visualization techniques, it becomes necessary to develop a measure for evaluating the effectiveness of visualizations. Metrics to evaluate visual displays were developed based on measures of information content developed by Shannon and used in communication theory. These measures of information content can be used to quantify the relative effectiveness of displays	Yang-Pelaez, J.	Dept. of Mech. Eng., MIT, Cambridge, MA, USA|c|	38015163000
	InfoVis	2000	Lighthouse: showing the way to relevant information	10.1109/INFVIS.2000.885099	http://dx.doi.org/10.1109/INFVIS.2000.885099	125	129	885099	Internet;data visualisation;information resources;information retrieval;information retrieval systems;online front-ends;user interfaces	Lighthouse;Web-based information retrieval system;clustering visualization;document retrieval;document visualization;online interface;ranked list;search engine	Computer science;Feedback;Information retrieval;Organizing;Search engines;User interfaces;Visualization;Web pages;Web search;Web sites		Lighthouse is an on-line interface for a Web-based information retrieval system. It accepts queries from a user, collects the retrieved documents from the search engine, organizes and presents them to the user. The system integrates two known presentations of the retrieved results, the ranked list and clustering visualization, in a novel and effective way. It accepts the user's input and adjusts the document visualization accordingly. We give a brief overview of the system	Leuski, A.;Allan, J.	Center for Intelligent Inf. Retrieval, Massachusetts Univ., Amherst, MA, USA|c|;	37846700600;37647480800
	InfoVis	2000	Density functions for visual attributes and effective partitioning in graph visualization	10.1109/INFVIS.2000.885090	http://dx.doi.org/10.1109/INFVIS.2000.885090	49	56	885090	data visualisation;graphs;interactive systems;probability	associated value;divisive clustering;empty clusters;graph elements;graph partitioning;graph visualization;metric values;probability density functions;statistics;subsets;uniform distribution;visual attributes	Application software;Chromium;Computer graphics;Data visualization;Mathematics;Navigation;Probability density function;Read only memory;Statistics;Tree graphs		Two tasks in graph visualization require partitioning: the assignment of visual attributes and divisive clustering. Often, we would like to assign a color or other visual attributes to a node or edge that indicates an associated value. In an application involving divisive clustering, we would like to partition the graph into subsets of graph elements based on metric values in such a way that all subsets are evenly populated. Assuming a uniform distribution of metric values during either partitioning or coloring can have undesired effects such as empty clusters or only one level of emphasis for the entire graph. Probability density functions derived from statistics about a metric can help systems succeed at these tasks	Herman, I.;Marshall, M.S.;Melancon, G.	Centre for Math. & Comput. Sci., Amsterdam, Netherlands|c|;;	38196438600;38253081000;37283186100
	InfoVis	2000	Interactive problem solving via algorithm visualization	10.1109/INFVIS.2000.885103	http://dx.doi.org/10.1109/INFVIS.2000.885103	145	153	885103	CAD;data visualisation;problem solving;program visualisation;search problems;user interfaces	COMIND tool;Kaleidoscope;Lattice;MAP;algorithm visualization;human-machine collaboration;industrial product conceptual design;interactive intelligence;interactive problem solving;multidimensional data visualization;search algorithms	Chemical technology;Computer industry;Computer science;Hip;Lattices;Problem-solving;Product design;Space exploration;Visual databases;Visualization		COMIND is a tool for conceptual design of industrial products. It helps designers define and evaluate the initial design space by using search algorithms to generate sets of feasible solutions. Two algorithm visualization techniques, Kaleidoscope and Lattice, and one visualization of n-dimensional data, MAP, are used to externalize the machine's problem solving strategies and the tradeoffs as a result of using these strategies. After a short training period, users are able to discover tactics to explore design space effectively, evaluate new design solutions, and learn important relationships among design criteria, search speed and solution quality. We thus propose that visualization can serve as a tool for interactive intelligence, ie., human-machine collaboration for solving complex problems	Pu, P.;Lalanne, D.	Dept. of Comput. Sci., Swiss Federal Inst. of Technol., Lausanne, Switzerland|c|;	37390082400;38335809700
	InfoVis	2000	A taxonomy of visualization techniques using the data state reference model	10.1109/INFVIS.2000.885092	http://dx.doi.org/10.1109/INFVIS.2000.885092	69	75	885092	data models;data visualisation;interactive systems	Data State Model;data domains;data state reference model;information visualization techniques;operating steps;taxonomic analysis	Data analysis;Data visualization;Geographic Information Systems;Information analysis;Pipelines;Read only memory;Taxonomy		In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly	Chi, Ed H.	Xerox Palo Alto Res. Center, CA, USA|c|	37448030800
	InfoVis	2000	Getting portals to behave	10.1109/INFVIS.2000.885087	http://dx.doi.org/10.1109/INFVIS.2000.885087	15	25	885087	data visualisation;graphical user interfaces;human factors;interactive systems	data analysis;data canvas;data visualization environments;graphical representations;interactive browsing;multiple graphical representations;portal behaviors;portals;visualization environment;visualization environments;visualization systems;visually programmable setting	Cities and towns;Concrete;Data analysis;Data visualization;Navigation;Portals;Shape;Taxonomy;Transportation;Two dimensional displays		Data visualization environments help users understand and analyze their data by permitting interactive browsing of graphical representations of the data. To further facilitate understanding and analysis, many visualization environments have special features known as portals, which are sub-windows of a data canvas. Portals provide a way to display multiple graphical representations simultaneously, in a nested fashion. This makes portals an extremely powerful and flexible paradigm for data visualization. Unfortunately, with this flexibility comes complexity. There are over a hundred possible ways each portal can be configured to exhibit different behaviors. Many of these behaviors are confusing and certain behaviors can be inappropriate for a particular setting. It is desirable to eliminate confusing and inappropriate behaviors. The authors construct a taxonomy of portal behaviors and give recommendations to help designers of visualization systems decide which behaviors are intuitive and appropriate for a particular setting. They apply these recommendations to an example setting that is fully visually programmable and analyze the resulting reduced set of behaviors. Finally, the authors consider a real visualization environment and demonstrate some problems associated with behaviors that do not follow their recommendations	Olston, C.;Woodruff, A.	Stanford Univ., CA, USA|c|;	37371920000;37354912800
	InfoVis	2000	GADGET/IV: a taxonomic approach to semi-automatic design of information visualization applications using modular visualization environment	10.1109/INFVIS.2000.885093	http://dx.doi.org/10.1109/INFVIS.2000.885093	77	83	885093	application generators;computer aided software engineering;data visualisation;software architecture	GADGET/IV;Wehrend matrix;World Wide Web site access frequency analysis;data visualization;embedded information;goal-oriented application design guidance;goal-oriented taxonomy;information visualization applications;modular visualization environment;scientific visualization applications;semi-automatic design;system architecture;user assistance flow;visualization goal specification	Computers;Data engineering;Data visualization;Guidelines;Notice of Violation;Power engineering and energy;Programming environments;Prototypes;Taxonomy;User interfaces		Since novice users of visualization systems lack knowledge and expertise in data visualization, it is a tough task for them to generate efficient and effective visualizations that allow them to comprehend information that is embedded in the data. Therefore, systems supporting the users to design appropriate visualizations are of great importance. The GADGET (Goal-oriented Application Design Guidance for modular visualization EnvironmenTs) system, which has been developed by the authors (1997), interactively helps users to design scientific visualization applications by presenting appropriate MVE (Modular Visualization Environment) prototypes according to the specification of the visualization goals expressed mainly with the Wehrend matrix (S. Wehrend & C. Lewis, 1990). This paper extends this approach in order to develop a system named GADGET/IV, which is intended to provide the users with an environment for semi-automatic design of information visualization (IV) applications. To this end, a novel goal-oriented taxonomy of IV techniques is presented. Also, an initial design of the system architecture and user assistance flow is described. The usefulness of the GADGET/IV system is illustrated with example problems of Web site access frequency analysis	Fujishiro, I.;Ichikawa, Y.;Furuhata, R.;Takeshima, Y.	Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;;	37282596600;37618383200;38015236500;37282600100
	InfoVis	2000	Visualizing sequential patterns for text mining	10.1109/INFVIS.2000.885097	http://dx.doi.org/10.1109/INFVIS.2000.885097	105	111	885097	data mining;data visualisation;pattern recognition;very large databases	data mining;knowledge discovery;large datasets;large text corpora;sequential pattern visualization;statistical measures;text mining	Association rules;Data mining;Data visualization;Event detection;Laboratories;Motion pictures;Ores;Read only memory;Statistics;Text mining		A sequential pattern in data mining is a finite series of elements such as A?B?C?D where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment	Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.	Pacific Northwest Lab., Richland, WA, USA|c|;;;;	37280665600;37672002300;37372586800;37725413900;37273308900
	InfoVis	2000	Polaris: a system for query, analysis and visualization of multi-dimensional relational databases	10.1109/INFVIS.2000.885086	http://dx.doi.org/10.1109/INFVIS.2000.885086	5	14	885086	data visualisation;formal specification;interactive systems;query processing;relational databases;user interfaces;very large databases	Pivot Table interface;Polaris;complex queries;data sets;dense graphical representations;exploration tasks;large multi-dimensional databases;multi-dimensional relational database visualization;relational queries;table based graphical displays;user interface;visual feedback;visual specifications	Polarization;Relational databases;Visualization		In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations	Stolte, C.;Hanrahan, P.	Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;	37442008700;37349803800
	InfoVis	2000	ThemeRiver: visualizing theme changes over time	10.1109/INFVIS.2000.885098	http://dx.doi.org/10.1109/INFVIS.2000.885098	115	123	885098	data visualisation;document handling	ThemeRiver;document collection;prototype system;temporally associated documents;textual presentation;thematic variations;theme change visualization;timeline	Bars;Data visualization;Histograms;Prototypes;Rivers;Testing;USA Councils;Usability			Havre, S.;Hetzler, B.;Nowell, L.	Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;	37282588900;37374614800;37725426400
	SciVis	13-13 Oct. 2000	Extracting regions of interest applying a local watershed transformation	10.1109/VISUAL.2000.885672	http://dx.doi.org/10.1109/VISUAL.2000.885672	21	28	885672	computer vision;data visualisation;feature extraction;image segmentation	basin-merging strategy;catchment basins;computer vision;controlled region growth;data visualization;feature extraction;image segmentation;local watershed transformation;memory requirement;rain-falling simulation;region of interest extraction;threshold values;volume data processing	Biomedical imaging;Computational modeling;Computer vision;Data visualization;Floods;Gray-scale;Image processing;Image segmentation;Merging;Pixel		We present a new technique for extracting regions of interest (ROI) applying a local watershed transformation. The proposed strategy for computing catchment basins in a given region of interest is based on a rain-falling simulation. Unlike the standard watershed algorithms, which flood the complete (gradient magnitude of an) image, the proposed approach allows us to perform this task locally. Thus, a controlled region growth is performed, saving time and reducing the memory requirement especially when applied on volume data. A second problem arising from the standard watershed transformation is the over-segmented result and the lack of sound criteria for merging the computed basins. For overcoming this drawback, we present a basin-merging strategy introducing four criteria for merging adjacent basins. The threshold values applied in this strategy are derived from the user input and match rather the attributes of the selected object than of all objects in the image. In doing so, the user is not required to adjust abstract numbers, but to simply select a coarse region of interest. Moreover, the proposed algorithm is not limited to the 2D case. As we show in this work, it is suitable for volume data processing as well. Finally, we present the results of applying the proposed approach on several example images and volume data sets.	Stoev, S.L.;Strasser, W.	WSI/GRIS, Tubingen Univ., Germany|c|;	37730629300;37356207300
	SciVis	13-13 Oct. 2000	A visibility determination algorithm for interactive virtual endoscopy	10.1109/VISUAL.2000.885673	http://dx.doi.org/10.1109/VISUAL.2000.885673	29	36	885673	data visualisation;medical image processing;quadtrees;ray tracing;rendering (computer graphics)	Marching Cubes;graphics accelerator;interactive frame rates;interactive virtual endoscopy;medical image processing;quadtree subdivision algorithm;ray termination;rendering;space leaping;template-based ray casting;triangulation;visibility determination algorithm;visible voxels;volume data	Acceleration;Biomedical optical imaging;Casting;Computer graphics;Data mining;Endoscopes;Radiology;Rendering (computer graphics);Visualization;Workstations		We present a new visibility determination algorithm for interactive virtual endoscopy. The algorithm uses a modified version of template-based ray casting to extract a view dependent set of potentially visible voxels from volume data. The voxels are triangulated by Marching Cubes and the triangles are rendered onto the display by a graphics accelerator. Early ray termination and space leaping are used to accelerate the ray casting step and a quadtree subdivision algorithm is used to reduce the number of cast rays. Compared to other recently proposed rendering algorithms for virtual endoscopy, our rendering algorithm does not require a long preprocessing step or a high-end graphics workstation, but achieves interactive frame rates on a standard PC equipped with a low-cost graphics accelerator.	Hietala, R.;Oikarinen, J.	Dept. of Diagnostic Radiol., Oulu Univ., Finland|c|;	38015320500;37992690100
	SciVis	13-13 Oct. 2000	3D digital cleansing using segmentation rays	10.1109/VISUAL.2000.885674	http://dx.doi.org/10.1109/VISUAL.2000.885674	37	44	885674	image classification;image reconstruction;image segmentation;medical image processing;ray tracing;rendering (computer graphics)	3D digital cleansing;distinct-intensity region intersection;endoscopic organs;image classification;image reconstruction;medical image processing;partial volume effect;ray casting;segmentation rays;three dimensional digital cleansing;volume rendering;volumetric contrast enhancement	Biomedical optical imaging;Cancer detection;Colon;Colonic polyps;Computer science;Endoscopes;Humans;Optical materials;Surface reconstruction;Virtual colonoscopy		We propose a novel approach for segmentation and digital cleansing of endoscopic organs. Our method can be used for a variety of segmentation needs with little or no modification. It aims at fulfilling the dual and often conflicting requirements of a fast and accurate segmentation and also eliminates the undesirable partial volume effect which contemporary approaches cannot. For segmentation and digital cleansing, we use the peculiar characteristics exhibited by the intersection of any two distinct-intensity regions. To detect these intersections we cast rays through the volume, which we call the segmentation rays as they assist in the segmentation. We then associate a certain task of reconstruction and classification with each intersection the ray detects. We further use volumetric contrast enhancement to reconstruct surface lost by segmentation (if any), which aids in improving the quality of the volume rendering.	Lakare, S.;Wan, M.;Sato, M.;Kaufman, A.	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;	37282740200;37362958300;37732410200;37268052800
	SciVis	13-13 Oct. 2000	CEASAR: a smooth, accurate and robust centerline extraction algorithm	10.1109/VISUAL.2000.885675	http://dx.doi.org/10.1109/VISUAL.2000.885675	45	52	885675	image segmentation;length measurement;medical image processing	CEASAR algorithm;aorta;automatic virtual navigation;colon;data preprocessing;human organs;length measurements;robust centerline extraction algorithm;virtual camera;winding tubular structures	Automatic control;Cameras;Colon;Data preprocessing;Geometry;Humans;Length measurement;Navigation;Robustness;Testing		We present CEASAR, a centerline extraction algorithm that delivers smooth, accurate and robust results. Centerlines are needed for accurate measurements of length along winding tubular structures. Centerlines are also required in automatic virtual navigation through human organs, such as the colon or the aorta, as they are used to control movement and orientation of the virtual camera. We introduce a concise but general definition of a centerline, and provide an algorithm that finds the centerline accurately and rapidly. Our algorithm is provably correct for general geometries. Our solution is fully automatic, which frees the user from having to engage in data preprocessing. For a number of test datasets, we show the smooth and accurate centerlines computed by our CEASAR algorithm on a single 194 MHz MIPS R10000 CPU within five minutes.	Bitter, I.;Sato, M.;Bender, M.;McDonnell, K.T.;Kaufman, A.;Wan, M.	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;	37300365400;37732410200;37265216900;37882660300;37268052800;37362958300
	SciVis	13-13 Oct. 2000	H-BLOB: a hierarchical visual clustering method using implicit surfaces	10.1109/VISUAL.2000.885677	http://dx.doi.org/10.1109/VISUAL.2000.885677	61	68	885677	data mining;data visualisation;very large databases	H-BLOB;cluster hierarchies;cluster tree;edge contraction;hierarchical visual clustering method;implicit surfaces;information visualization;level-of-detail strategy;very large datasets;visual data mining;visual decision making;visualization algorithm	Algorithm design and analysis;Clustering algorithms;Clustering methods;Computer science;Couplings;Data mining;Data visualization;Decision making;Electrical capacitance tomography;Partitioning algorithms		We present a new hierarchical clustering and visualization algorithm called H-BLOB, which groups and visualizes cluster hierarchies at multiple levels-of-detail. Our method is fundamentally different to conventional clustering algorithms, such as C-means, K-means, or linkage methods that are primarily designed to partition a collection of objects into subsets sharing similar attributes. These approaches usually lack an efficient level-of-detail strategy that breaks down the visual complexity of very large datasets for visualization. In contrast, our method combines grouping and visualization in a two stage process constructing a hierarchical setting. In the first stage a cluster tree is computed making use of an edge contraction operator. Exploiting the inherent hierarchical structure of this tree, a second stage visualizes the clusters by computing a hierarchy of implicit surfaces. We believe that H-BLOB is especially suited for the visualization of very large datasets and for visual decision making in information visualization. The versatility of the algorithm is demonstrated using examples from visual data mining.	Sprenger, T.C.;Gross, M.H.	Dept. of Comput. Sci., Swiss Fed. Inst. of Technol., Zurich, Switzerland|c|;	37374656700;37275694700
	SciVis	13-13 Oct. 2000	A spreadsheet interface for visualization exploration	10.1109/VISUAL.2000.885678	http://dx.doi.org/10.1109/VISUAL.2000.885678	69	76	885678	data visualisation;rendering (computer graphics);spreadsheet programs;user interfaces	2D window;data exploration;data sets;data visualization exploration;interaction techniques;rendering;spreadsheet interface;tabular organization;two-dimensional window;user interfaces	Chromium;Collaboration;Computer graphics;Computer science;Data visualization;Displays;Graphical user interfaces;Image processing;Rendering (computer graphics);User interfaces		As the size and complexity of data sets continues to increase, the development of user interfaces and interaction techniques that expedite the process of exploring that data must receive new attention. Regardless of the speed of rendering, it is important to coherently organize the visual process of exploration: this information both grants insights about the data to a user and can be used by collaborators to understand the results. To fulfil these needs, we present a spreadsheet-like interface to data exploration. The interface displays a 2-dimensional window into visualization parameter space which users manipulate as they search for desired results. Through tabular organization and a clear correspondence between parameters and results, the interface eases the discovery, comparison and analysis of the underlying data. Users can utilize operators and the integrated interpreter to further explore and automate the visualization process; using a method introduced in this paper, these operations can be applied to cells in different stacks of the interface. Via illustrations using a variety of data sets, we demonstrate the efficacy of this novel interface.	Jankun-Kelly, T.J.;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;	37399870300;37275869400
	SciVis	13-13 Oct. 2000	Procedural annotation of uncertain information	10.1109/VISUAL.2000.885679	http://dx.doi.org/10.1109/VISUAL.2000.885679	77	84	885679	data integrity;data visualisation;natural sciences computing;uncertainty handling	data values;distorting glyphs;procedural annotation;scientific visualization;uncertain information;uncertainty visualization	Computational modeling;Data visualization;Displays;Geographic Information Systems;Image restoration;Investments;Measurement errors;Shape;Uncertainty;Weather forecasting		In many applications of scientific visualization, a large quantity of data is being processed and displayed in order to enable a viewer to make informed and effective decisions. Since little data is perfect, there is almost always some degree of associated uncertainty. This uncertainty is an important part of the data and should be taken into consideration when interpreting the data. Uncertainty, however, should not overshadow the data values. Many methods that address the problem of visualizing data with uncertainty can distort the data and emphasize areas with uncertain values. We have developed a method for showing the uncertainty information together with data with minimal distraction. This method uses procedurally generated annotations which are deformed according to the uncertainty information. As another possible technique we propose distorting glyphs according to the uncertainty information.	Cedilnik, A.;Rheingans, P.	Maryland Univ., Baltimore, MD, USA|c|;	38018584500;37282292000
	SciVis	13-13 Oct. 2000	Simplification of tetrahedral meshes with accurate error evaluation	10.1109/VISUAL.2000.885680	http://dx.doi.org/10.1109/VISUAL.2000.885680	85	92	885680	computational geometry;data reduction;data visualisation;mesh generation	accurate error evaluation;approximation error;computational efficiency;edge collapse;geometrical shape;incremental 3D mesh simplification;scalar field;tetrahedral mesh simplification;topological shape;volume dataset reduction;volume visualization	Approximation error;Computational efficiency;Data visualization;Geometry;Interpolation;Iterative methods;Scattering;Shape;Topology		The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.	Cignoni, P.;Montani, C.;Rocchini, C.;Scopigno, R.	Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;	37265783400;37265786500;37333160000;37270887900
	SciVis	13-13 Oct. 2000	Tetrahedron based, least squares, progressive volume models with application to freehand ultrasound data	10.1109/VISUAL.2000.885681	http://dx.doi.org/10.1109/VISUAL.2000.885681	93	100	885681	computational geometry;data models;data visualisation;interpolation;least squares approximations;medical image processing;piecewise linear techniques;real-time systems	compressed volume model;freehand ultrasound data;iterative technique;least squares progressive volume models;medical image processing;piecewise linear interpolation;piecewise linear model;progressive tetrahedral domains;real time system;subdivision scheme;tetrahedron based volume models	Arm;Biomedical imaging;Cathode ray tubes;Gray-scale;History;Image registration;Least squares methods;Patient monitoring;Probes;Ultrasonic imaging		We present a new method for the modeling of freehand collected three-dimensional ultrasound data. The model is piecewise linear and based upon progressive tetrahedral domains created by a subdivision scheme which splits a tetrahedron on on its longest edge and guarantees a valid tetrahedrization. Least squares error is used to characterize the model and an effective iterative technique is used to compute the values of the model at the vertices of the tetrahedral grid. Since the subdivision strategy is adaptive, the complexity of the model conforms to the complexity of the data leading to an extremely efficient and highly compressed volume model. The model is evaluated in real time using piecewise linear interpolation, and gives a medical professional the chance to see images which would not be possible using conventional ultrasound techniques.	Roxborough, T.;Nielson, G.M.	Arizona State Univ., Tempe, AZ, USA|c|;	37373016900;37283754100
	SciVis	13-13 Oct. 2000	On-the-fly rendering of losslessly compressed irregular volume data	10.1109/VISUAL.2000.885682	http://dx.doi.org/10.1109/VISUAL.2000.885682	101	108	885682	data compression;rendering (computer graphics);storage allocation	Gatun;I/O bandwidth requirement;compression;integrated tetrahedral mesh compression/rendering algorithm;irregular grid rendering pipeline;local connectivity information;losslessly compressed irregular volume data;on-the-fly rendering;runtime memory footprint requirement;tetrahedral meshes;very large irregular-grid data sets	Algorithm design and analysis;Bandwidth;Chromium;Compression algorithms;Head;Image coding;Lead compounds;Pipelines;Rendering (computer graphics);Streaming media		Very large irregular-grid data sets are represented as tetrahedral meshes and may incur significant disk I/O access overhead in the rendering process. An effective way to alleviate the disk I/O overhead associated with rendering a large tetrahedral mesh is to reduce the I/O bandwidth requirement through compression. Existing tetrahedral mesh compression algorithms focus only on compression efficiency and cannot be readily integrated into the mesh rendering process, and thus demand that a compressed tetrahedral mesh be decompressed before it can be rendered into a 2D image. This paper presents an integrated tetrahedral mesh compression and rendering algorithm called Gatun, which allows compressed tetrahedral meshes to be rendered incrementally as they are being decompressed, thus leading to an efficient irregular grid rendering pipeline. Both compression and rendering algorithms in Gatun exploit the same local connectivity information among adjacent tetrahedra, and thus can be tightly integrated into a unified implementation framework. Our tetrahedral compression algorithm is specifically designed to facilitate the integration with an irregular grid renderer without any compromise in compression efficiency. A unique performance advantage of Gatun is its ability to reduce the runtime memory footprint requirement by releasing memory allocated to tetrahedra as early as possible.	Chuan-Kai Yang;Mitra, T.;Tzi-cker Chiueh	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	37558175900;37282510200;37273336700
	SciVis	13-13 Oct. 2000	Hardware-accelerated volume and isosurface rendering based on cell-projection	10.1109/VISUAL.2000.885683	http://dx.doi.org/10.1109/VISUAL.2000.885683	109	116	885683	computational complexity;image texture;rendering (computer graphics);sorting;transfer functions	2D texture mapping;3D texture mapping;BSP-XMPVO sorting algorithm;arbitrary transfer functions;cell sorting technique;cell-projection;hardware-accelerated isosurface rendering;hardware-accelerated volume rendering;multiple shaded isosurfaces;projected tetrahedra algorithm;tetrahedral volume cells;time complexity;unstructured meshes	Chromium;Computer graphics;Image generation;Image reconstruction;Interactive systems;Isosurfaces;Rendering (computer graphics);Sorting;Transfer functions;Visualization		We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.	Rottger, S.;Kraus, M.;Ertl, T.	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	37357145300;37284293000;37268023800
	SciVis	13-13 Oct. 2000	Achieving color uniformity across multi-projector displays	10.1109/VISUAL.2000.885684	http://dx.doi.org/10.1109/VISUAL.2000.885684	117	124	885684	calibration;colour graphics;data visualisation;virtual reality	collaborative immersive virtual environments;color uniformity;corrections;imagery;intensity;large area tiled displays;multi-projector displays;per channel color look-up-tables;photometric calibration;photometric nonuniformity;projectors;scientific visualization	Calibration;Collaborative work;Color;Displays;Humans;Photometry;Rendering (computer graphics);Table lookup;Virtual environment;Visualization		Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).	Majumder, A.;Zhu He;Towles, H.;Welch, G.	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;	38477162600;38024209800;37298881100;37300645000
	SciVis	13-13 Oct. 2000	Automatic alignment of high-resolution multi-projector displays using an uncalibrated camera	10.1109/VISUAL.2000.885685	http://dx.doi.org/10.1109/VISUAL.2000.885685	125	130	885685	computer graphic equipment;data visualisation;large screen displays	automatic alignment;high-resolution multi-projector displays;projected image tiling;relative neighboring projector mismatch measurement;scalable high-resolution display;single display surface;uncalibrated camera	Cameras;Cathode ray tubes;Computer displays;Computer science;Computer vision;Data visualization;Flat panel displays;Humans;Instruments;Simulated annealing		A scalable, high-resolution display may be constructed by tiling many projected images over a single display surface. One fundamental challenge for such a display is to avoid visible seams due to misalignment among the projectors. Traditional methods for avoiding seams involve sophisticated mechanical devices and expensive CRT projectors, coupled with extensive human effort for fine-tuning the projectors. The paper describes an automatic alignment method that relies on an inexpensive, uncalibrated camera to measure the relative mismatches between neighboring projectors, and then correct the projected imagery to avoid seams without significant human effort.	Chen, Y.;Clark, D.W.;Finkelstein, A.;Housel, T.C.;Li, K.	Dept. of Comput. Sci., Princeton Univ., NJ, USA|c|;;;;	37423646500;37333576800;37429653900;37443159300;37277619300
	SciVis	13-13 Oct. 2000	Shock and vortex visualization using a combined visual/haptic interface	10.1109/VISUAL.2000.885686	http://dx.doi.org/10.1109/VISUAL.2000.885686	131	137	885686	computational fluid dynamics;data visualisation;flow visualisation;graphical user interfaces;haptic interfaces;rendering (computer graphics);shock waves;vortices	combined visual/haptic interface;exploratory interaction;fluid dynamics data;graphical rendering modes;haptic rendering modes;rendering modes;shock surface visualization;vortex core visualization	Aerospace engineering;Computer interfaces;Data engineering;Data visualization;Displays;Electric shock;Fluid dynamics;Haptic interfaces;Rendering (computer graphics);Solids		Specific rendering modes are developed for a combined visual/haptic interface to allow exploration and understanding of fluid dynamics data. The focus is on visualization of shock surfaces and vortex cores. Advantages provided by augmenting traditional graphical rendering modes with haptic rendering modes are discussed. Particular emphasis is placed on synergistic combinations of visual and haptic modes which enable rapid, exploratory interaction with the data. Implementation issues are also discussed.	Lawrence, D.A.;Lee, C.D.;Pao, Lucy Y.;Novoselov, R.Y.	Dept. of Aerosp. Eng. Sci., Colorado Univ., Boulder, CO, USA|c|;;;	37270752800;37280408300;37270749300;37270750300
	SciVis	13-13 Oct. 2000	Six degree-of-freedom haptic display of polygonal models	10.1109/VISUAL.2000.885687	http://dx.doi.org/10.1109/VISUAL.2000.885687	139	146	885687	force feedback;haptic interfaces;virtual reality	PHANToM Premium 1.5;contact determination;convex primitives;geometric locality;incremental algorithms;mechanical interaction;moderately complex polygonal models;object-object contacts;predictive methods;restoring forces;restoring torques;six degree of freedom force feedback device;six degree-of-freedom haptic display;temporal coherence;virtual touch	Coherence;Computational modeling;Computer displays;Computer graphics;Computer science;Force feedback;Haptic interfaces;Imaging phantoms;Probes;Virtual prototyping		We present an algorithm for haptic display of moderately complex polygonal models with a six degree of freedom (DOF) force feedback device. We make use of incremental algorithms for contact determination between convex primitives. The resulting contact information is used for calculating the restoring forces and torques and thereby used to generate a sense of virtual touch. To speed up the computation, our approach exploits a combination of geometric locality, temporal coherence, and predictive methods to compute object-object contacts at kHz rates. The algorithm has been implemented and interfaced with a 6-DOF PHANToM Premium 1.5. We demonstrate its performance on force display of the mechanical interaction between moderately complex geometric structures that can be decomposed into convex primitives.	Gregory, A.;Mascarenhas, A.;Ehmann, S.;Ming Lin;Manocha, D.	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;	37362087700;38030858700;37449231600;37278387400;38470517600
	SciVis	13-13 Oct. 2000	A level-set method for flow visualization	10.1109/VISUAL.2000.885688	http://dx.doi.org/10.1109/VISUAL.2000.885688	147	154	885688	computational fluid dynamics;data visualisation;flow visualisation;rendering (computer graphics)	automatic graphical primitive placement;dense 3D fields;distortion;dynamic behavior;evolving structures;flow direction;flow dynamics;geometrical aspects;homogeneous streams;multiscale representation;scalar level-set representation;steady flow visualization;texture-based surface rendering;topological aspects;vector field data conversion	Data mining;Data visualization;Fluid dynamics;Image analysis;Interactive systems;Monitoring;Rendering (computer graphics);Scientific computing;Surface texture;Three dimensional displays		We propose a technique for visualizing steady flow. Using this technique, we first convert the vector field data into a scalar level-set representation. We then analyze the dynamic behavior and subsequent distortion of level-sets and interactively monitor the evolving structures by means of texture-based surface rendering. Next, we combine geometrical and topological considerations to derive a multiscale representation and to implement a method for the automatic placement of a sparse set of graphical primitives depicting homogeneous streams in the fields. Using the resulting algorithms, we have built a visualization system that enables us to effectively display the flow direction and its dynamics even for dense 3D fields.	Westermann, R.;Johnson, C.;Ertl, T.	Sci. Comput. & Visualization Group, Univ. of Technol., Aachen, Germany|c|;;	37444424000;37276931400;37268023800
	SciVis	13-13 Oct. 2000	Hardware-accelerated texture advection for unsteady flow visualization	10.1109/VISUAL.2000.885689	http://dx.doi.org/10.1109/VISUAL.2000.885689	155	162	885689	computational fluid dynamics;computer animation;flow instability;flow visualisation;image enhancement;image texture	2D unsteady flow visualization;EMXI graphics;OpenGL-1.2 specification;SGI Octane;animations;dye advection techniques;edge effects;feature extraction;hardware-accelerated texture advection algorithm;high image quality;image enhancement;noise frequency;particles;spatial coherence techniques;temporal coherence techniques	Acceleration;Animation;Computer displays;Computer graphics;Frequency;Hardware;Image quality;Information technology;Software algorithms;Visualization		We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.	Jobard, B.;Erlebacher, G.;Hussaini, M.Y.	Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;	37267249300;37324424400;37324426600
	SciVis	13-13 Oct. 2000	A flow-guided streamline seeding strategy	10.1109/VISUAL.2000.885690	http://dx.doi.org/10.1109/VISUAL.2000.885690	163	170	885690	computational fluid dynamics;data visualisation;flow visualisation	3D flow fields;Poisson disk distribution;critical points;flow features;flow field;flow pattern;flow-guided streamline seeding strategy;seed placement strategy	Computer science;NASA;Streaming media;Visualization		The paper presents a seed placement strategy for streamlines based on flow features in the dataset. The primary goal of our seeding strategy is to capture flow patterns in the vicinity of critical points in the flow field, even as the density of streamlines is reduced. Secondary goals are to place streamlines such that there is sufficient coverage in non-critical regions, and to vary the streamline placements and lengths so that the overall presentation is aesthetically pleasing (avoid clustering of streamlines, avoid sharp discontinuities across several streamlines, etc.). The procedure is straightforward and non-iterative. First, critical points are identified. Next, the flow field is segmented into regions, each containing a single critical point. The critical point in each region is then seeded with a template depending on the type of critical point. Finally, additional seed points are randomly distributed around the field using a Poisson disk distribution to minimize closely spaced seed points. The main advantage of this approach is that it does not miss the features around critical points. Since the strategy is not image-guided, and hence not view dependent, significant savings are possible when examining flow fields from different viewpoints, especially for 3D flow fields.	Verma, V.;Kao, D.;Pang, A.	Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA|c|;;	37273605600;37339406400;37267352000
	SciVis	13-13 Oct. 2000	Enabling level-of-detail matching for exterior scene synthesis	10.1109/VISUAL.2000.885691	http://dx.doi.org/10.1109/VISUAL.2000.885691	171	178	885691	data visualisation;image sampling;importance sampling;rendering (computer graphics)	contrast sensitivity function;error metric;error profiles;expected image error;exterior scene synthesis;image sampling rate;image-plane resolution;importance sampling method;level-of-detail matching;multirate filtering;multiresolution spheres;object projection;perspective projection;reference object image;terrain height field feature;viewing distances;vision system	Computer graphics;Data visualization;Energy resolution;Filtering;Frequency;Image resolution;Layout;Military computing;Rendering (computer graphics);Surface topography		The work presents a method to enable matching of level-of-detail (LOD) models to image-plane resolution over large variations in viewing distances often present in exterior images. A relationship is developed between image sampling rate, viewing distance, object projection, and expected image error due to LOD approximations. This is employed in an error metric to compute error profiles for LOD models. Multirate filtering in the frequency space of a reference object image is utilized to approximate multiple distant views over a range of orientations. An importance sampling method is described to better characterize perspective projection over view distance. A contrast sensitivity function (CSF) is employed to approximate the response of the vision system. Examples are presented for multiresolution spheres and a terrain height field feature. Future directions for extending this method are described.	Scoggins, R.K.;Machiraju, R.;Moorhead, R.J.	Eng. Res. & Dev. Center, US Army Corp. of Eng., Vicksburg, MS, USA|c|;;	37738265200;37269516700;37282559500
	SciVis	13-13 Oct. 2000	Basic research for coloring multichannel MRI data	10.1109/VISUAL.2000.885693	http://dx.doi.org/10.1109/VISUAL.2000.885693	187	194	885693	biological tissues;biomedical MRI;colour graphics;data visualisation;medical image processing;radial basis function networks;transfer functions	Visible Female data set;Visible Human data sets;color volume data sets;full-color cross-sections;independent component analysis;multichannel MRI volume data;neural net training;radial basis function network;sample data;scanning conditions;tissue physical characteristics enhancement;transfer functions;voxel color value assignment	Biomedical imaging;Computed tomography;Humans;Independent component analysis;Magnetic resonance imaging;Medical diagnostic imaging;Protons;Radial basis function networks;Surgery;Transfer functions		This is basic research for assigning color values to voxels of multichannel MRI volume data. The MRI volume data sets obtained under different scanning conditions are transformed into their components by independent component analysis (ICA), which enhances the physical characteristics of the tissue. The transfer functions for generating color values from independent components are obtained using a radial basis function network, a kind of neural net, by training the network with sample data chosen from the Visible Female data set. The resultant color volume data sets correspond well with the full-color cross-sections of the Visible Human data sets.	Muraki, S.;Nakai, T.;Kita, Y.	MITI, Electrotech. Lab., Ibaraki, Japan|c|;;	37378239800;37409357900;37278620500
	SciVis	13-13 Oct. 2000	Volume illustration: non-photorealistic rendering of volume models	10.1109/VISUAL.2000.885694	http://dx.doi.org/10.1109/VISUAL.2000.885694	195	202	885694	data visualisation;image enhancement;lighting;rendering (computer graphics);solid modelling	data visualization;feature amplification;flexible design;important feature enhancement;lighting models;local volume characteristics;manual tuning;nonphotorealistic rendering;physics-based illumination model;shading;structural details;structural perception;transfer function;translucent materials;volume appearance;volume illustration;volume models;volume rendering approaches	Application software;Chromium;Computer graphics;Computer science;Data visualization;Lighting;Manuals;Optical attenuators;Rendering (computer graphics);Transfer functions		Accurately and automatically conveying the structure of a volume model is a problem that has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing structural perception of volume models through the amplification of features and the addition of illumination effects.	Ebert, D.;Rheingans, P.	Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;	38472155500;37282292000
	SciVis	13-13 Oct. 2000	Pen-and-ink rendering in volume visualisation	10.1109/VISUAL.2000.885696	http://dx.doi.org/10.1109/VISUAL.2000.885696	203	210	885696	data visualisation;image texture;rendering (computer graphics);solid modelling;spatial data structures	3D texture mapping;image space;image-based data representations;nonphotorealistic rendering techniques;object space;pen-and-ink rendering methods;solid textures;volume rendering pipeline;volume visualisation;volume-based data representations	Biomedical imaging;Casting;Computer graphics;Computer science;Humans;Magnetic resonance imaging;Pipelines;Rendering (computer graphics);Solids;Visualization			Treavett, S.M.F.;Chen, M.	Dept. of Comput. Sci., Univ. of Wales, Swansea, UK|c|;	37725999600;38026251100
	SciVis	13-13 Oct. 2000	Two-level volume rendering - fusing MIP and DVR	10.1109/VISUAL.2000.885697	http://dx.doi.org/10.1109/VISUAL.2000.885697	211	218	885697	data visualisation;merging;rendering (computer graphics);solid modelling	compositing;direct volume rendering;dynamical systems;focus-and-context approach;information visualization;inner structure visualization;interactive frame rate;locally rendered structures;maximum-intensity projection;medical applications;merging;object-by-object rendering;semi-transparent outer parts;two-level volume rendering;volumetric data	Biomedical engineering;Biomedical imaging;Chromium;Computer graphics;Data visualization;Focusing;Image generation;Merging;Rendering (computer graphics);Transfer functions		Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.	Hauser, H.;Mroz, L.;Bischi, G.-I.;Groller, M.E.	VRVis Res. Centre, Wien Univ. of Technol., Austria|c|;;;	37274158800;37282641800;38015245800;38471589000
	SciVis	13-13 Oct. 2000	FastSplats: optimized splatting on rectilinear grids	10.1109/VISUAL.2000.885698	http://dx.doi.org/10.1109/VISUAL.2000.885698	219	226	885698	error analysis;hidden feature removal;image texture;opacity;optimisation;rendering (computer graphics)	3D solid texturing;FastSplats;bump mapping;color bleeding;footprint scan-conversion;frame-buffer access;hardware implementation;image quality;in-memory texture mapping pipeline;integrated rendering pipeline;numerical error analysis;occasion-based acceleration;occlusion culling;opacity;opaque data sets;optimized splatting;performance;popping;post-rendering classification;rectilinear grids;shading;software;speedup;storage;summed area table	Acceleration;Design optimization;Hardware;Hemorrhaging;Image quality;Packaging;Pipelines;Rendering (computer graphics);Software packages;Solids		Splatting is widely applied in many areas, including volume, point-based and image-based rendering. Improvements to splatting, such as eliminating popping and color bleeding, occasion-based acceleration, post-rendering classification and shading, have all been recently accomplished. These improvements share a common need for efficient frame-buffer accesses. We present an optimized software splatting package, using a newly designed primitive, called FastSplat, to scan-convert footprints. Our approach does not use texture mapping hardware, but supports the whole pipeline in memory. In such an integrated pipeline, we are then able to study the optimization strategies and address image quality issues. While this research is meant for a study of the inherent trade-off of splatting, our renderer, purely in software, achieves 3- to 5-fold speedups over a top-end texture hardware implementation (for opaque data sets). We further propose a method of efficient occlusion culling using a summed area table of opacity. 3D solid texturing and bump mapping capabilities are demonstrated to show the flexibility of such an integrated rendering pipeline. A detailed numerical error analysis, in addition to the performance and storage issues, is also presented. Our approach requires low storage and uses simple operations. Thus, it is easily implementable in hardware.	Huang, Jian;Mueller, K.;Shareef, N.;Crawfis, R.	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;	37367805100;37273119700;37355552900;37284273900
	SciVis	13-13 Oct. 2000	Texturing techniques for terrain visualization	10.1109/VISUAL.2000.885699	http://dx.doi.org/10.1109/VISUAL.2000.885699	227	234	885699	computational geometry;computer animation;data visualisation;image resolution;image texture;interactive systems;real-time systems;rendering (computer graphics);software performance evaluation;terrain mapping;topography (Earth)	approximation errors;blending;image pyramid;interactive animated terrain content design;interactive texture lenses;level-of-detail terrain models;masking;multi-pass rendering algorithm;multi-resolution textures;multi-texturing;real-time performance;spatio-temporal data;terrain geometry;terrain texture;terrain visualization;texture animation;texture tree;topographic textures	Animation;Application software;Computer graphics;Computer science;Data visualization;Geometry;Large-scale systems;Rendering (computer graphics);Solid modeling;Terrain mapping		Presents a new rendering technique for processing multiple multi-resolution textures of LOD (level-of-detail) terrain models and describes its application to interactive, animated terrain content design. The approach is based on a multi-resolution model for terrain texture which cooperates with a multi-resolution model for terrain geometry. For each texture layer, an image pyramid and a texture tree are constructed. Multiple texture layers can be associated with one terrain model and can be combined in different ways, e.g. by blending and masking. The rendering algorithm simultaneously traverses the multi-resolution geometry model and the multi-resolution texture model, and takes into account geometric and texture approximation errors. It uses multi-pass rendering and exploits multi-texturing to achieve real-time performance. Applications include interactive texture lenses, texture animation and topographic textures. These techniques offer an enormous potential for developing new visualization applications for presenting, exploring and manipulating spatio-temporal data.	Dollner, J.;Baumann, K.;Hinrichs, K.	Dept. of Comput. Sci., Munster Univ., Germany|c|;;	38471840600;37884503800;38472676700
	SciVis	13-13 Oct. 2000	Simplification of surface annotations	10.1109/VISUAL.2000.885700	http://dx.doi.org/10.1109/VISUAL.2000.885700	235	242	885700	CAD;antialiasing;cartography;computational geometry;data models;data visualisation;engineering graphics;image texture;rendering (computer graphics)	CAD data models;CAD/CAM;additional information;blurring;cartography;color;data visualization;directed asymmetric tolerance;finite element method;geometric models;low-resolution surface detail;magnification;mesh structure;object appearance;pixelization;polygonal path;rendering cost;rendering performance;surface annotation simplification;texture maps	Costs;Data models;Data visualization;Geometry;Performance gain;Rivers;Roads;Solid modeling;Surface texture;Surface topography		Geometric models are often annotated to provide additional information during visualization. Maps may be marked with rivers, roads or topographical information, and CAD data models may highlight the underlying mesh structure. While this additional information may be extremely useful, there is a rendering cost associated with it. Texture maps have often been used to convey this information at relatively low cost, but they suffer from blurring and pixelization at high magnification. We present a technique for simplifying surface annotations based on directed, asymmetric tolerance. By maintaining the annotations as geometry, as opposed to textures, we are able to simplify them while still maintaining the overall appearance of the model over a wide range of magnifications. Texture maps may still be used to provide low-resolution surface detail, such as color. We demonstrate a significant gain in rendering performance while retaining the original appearance of objects from many application domains.	Suits, F.;Klosowski, J.T.;Horn, W.P.;Lecina, G.	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;	37370454300;37442701500;37361807200;38015271000
	SciVis	13-13 Oct. 2000	Uniform frequency images: adding geometry to images to produce space-efficient textures	10.1109/VISUAL.2000.885701	http://dx.doi.org/10.1109/VISUAL.2000.885701	243	250	885701	Fourier analysis;Nyquist criterion;computational geometry;data compression;data visualisation;image coding;image morphing;image sampling;image texture;rendering (computer graphics)	Fourier analysis;Nyquist limit;data visualization;frequency balancing property;geometry;graceful space-quality tradeoff;graphics hardware;image compression techniques;image reconstruction;image sampling;image size reduction;image uncompression;inverse warp;local frequency content redistribution;parameterization;piecewise-linear warping function;polygons;rendering;space-efficient textures;storage requirements;texture coordinates;texture map;top-down algorithm;uniform frequency images;uniform local frequency properties;warped image downsampling	Acceleration;Frequency;Geometry;Graphics;Hardware;Image coding;Image reconstruction;Image storage;Piecewise linear techniques;Rendering (computer graphics)		"Discusses the concept of uniform frequency images, which exhibit uniform local frequency properties. Such images make optimal use of space when sampled close to their Nyquist limit. A warping function may be applied to an arbitrary image to redistribute its local frequency content, reducing its highest frequencies and increasing its lowest frequencies in order to approach this uniform frequency ideal. The warped image may then be downsampled according to its new, reduced Nyquist limit, thereby reducing its storage requirements. To reconstruct the original image, the inverse warp is applied. We present a general, top-down algorithm to automatically generate a piecewise-linear warping function with this frequency balancing property for a given input image. The image size is reduced by applying the warp and then downsampling. We store this warped, downsampled image plus a small number of polygons with texture coordinates to describe the inverse warp. The original image is later reconstructed by rendering the associated polygons with the warped image applied as a texture map, a process which is easily accelerated by current graphics hardware. As compared to previous image compression techniques, we generate a similar graceful space-quality tradeoff with the advantage of being able to ""uncompress"" images during rendering. We report results for several images with sizes ranging from 15,000 to 300,000 pixels, achieving reduction rates of 70-90% with improved quality over downsampling alone."	Hunter, A.;Cohen, J.D.	Johns Hopkins Univ., MD, USA|c|;	38023544500;37275763600
	SciVis	13-13 Oct. 2000	Topology preserving and controlled topology simplifying multiresolution isosurface extraction	10.1109/VISUAL.2000.885703	http://dx.doi.org/10.1109/VISUAL.2000.885703	259	266	885703	computational geometry;data visualisation;topology;very large databases	coarse isosurface;controlled topology simplification;interactive visualization;level-of-detail;multiresolution isosurface extraction;multiresolution isosurface visualization;topological structure;topology preservation;very large data sets;volume data	Chromium;Computer graphics;Computer science;Data mining;Data visualization;Image resolution;Isosurfaces;Mathematics;Numerical analysis;Topology		Multiresolution methods are becoming increasingly important tools for the interactive visualization of very large data sets. Multiresolution isosurface visualization allows the user to explore volume data using simplified and coarse representations of the isosurface for overview images, and finer resolution in areas of high interest or when zooming into the data. Ideally, a coarse isosurface should have the same topological structure as the original. The topological genus of the isosurface is one important property which is often neglected in multiresolution algorithms. This results in uncontrolled topological changes which can occur whenever the level-of-detail is changed. The scope of this paper is to propose an efficient technique which allows preservation of topology as well as controlled topology simplification in multiresolution isosurface extraction.	Gerstner, T.;Pajarola, Renato	Dept. of Appl. Math., Bonn Univ., Germany|c|;	38015261400;37282193800
	SciVis	13-13 Oct. 2000	Isosurfacing in higher dimensions	10.1109/VISUAL.2000.885704	http://dx.doi.org/10.1109/VISUAL.2000.885704	267	273	885704	computational geometry;computer animation;data visualisation;table lookup;very large databases	4D isosurfaces;Marching Cubes;animation;hypercubes;interval volumes;isosurface generation;isovalue threshold;large data sets;lookup tables;oblique cross-sections;oblique hyperplanes;sampling;time-varying data;triangulation tables;visualization algorithms	Animation;Information science;Interpolation;Isosurfaces;Piecewise linear techniques;Sampling methods;Silicon		Visualization algorithms have seen substantial improvements in the past several years. However, very few algorithms have been developed for directly studying data in dimensions higher than three. Most algorithms require a sampling in three-dimensions before applying any visualization algorithms. This sampling typically ignores vital features that may be present when examined in oblique cross-sections, and places an undo burden on system resources when animation through additional dimensions is desired. For time-varying data of large data sets, smooth animation is desired at interactive rates. We provide a fast Marching Cubes like algorithm for hypercubes of any dimension. To support this, we have developed a new algorithm to automatically generate the isosurface and triangulation tables for any dimension. This allows the efficient calculation of 4D isosurfaces, which can be interactively sliced to provide smooth animation or slicing through oblique hyperplanes. The former allows for smooth animation in a very compressed format. The latter provide better tools to study time-evolving features as they move downstream. We also provide examples in using this technique to show interval volumes or the sensitivity of a particular isovalue threshold.	Bhaniramka, P.;Wenger, R.;Crawfis, R.	Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|;;	37284272700;37284274100;37284273900
	SciVis	13-13 Oct. 2000	Semi-regular mesh extraction from volumes	10.1109/VISUAL.2000.885705	http://dx.doi.org/10.1109/VISUAL.2000.885705	275	282	885705	computational geometry;data visualisation;mesh generation	Marching Cubes;arbitrary topology;aspect ratio triangles;data visualization;distance volumes;geometrically adaptive sampling rate;iso-surface geometry;isosurface extraction;iterative multiscale force-based solver;multiresolution meshes;multiscale refinement;semiregular mesh extraction;surface wavefront propagation	Data mining;Data visualization;Finite element methods;Geometry;Level set;Noise reduction;Sampling methods;Surface fitting;Surface waves;Topology		We present a novel method to extract iso-surfaces from distance volumes. It generates high quality semi-regular multiresolution meshes of arbitrary topology. Our technique proceeds in two stages. First, a very coarse mesh with guaranteed topology is extracted. Subsequently an iterative multi-scale force-based solver refines the initial mesh into a semi-regular mesh with geometrically adaptive sampling rate and good aspect ratio triangles. The coarse mesh extraction is performed using a new approach we call surface wavefront propagation. A set of discrete iso-distance ribbons are rapidly built and connected while respecting the topology of the iso-surface implied by the data. Subsequent multi-scale refinement is driven by a simple force-based solver designed to combine good iso-surface fit and high quality sampling through reparameterization. In contrast to the Marching Cubes technique our output meshes adapt gracefully to the iso-surface geometry, have a natural multiresolution structure and good aspect ratio triangles, as demonstrated with a number of examples.	Wood, Z.J.;Desbrun, M.;Schroder, P.;Breen, D.	California Inst. of Technol., Pasadena, CA, USA|c|;;;	38014682800;37332366200;37282570000;37349884100
	SciVis	13-13 Oct. 2000	Scanline surfacing: building separating surfaces from planar contours	10.1109/VISUAL.2000.885706	http://dx.doi.org/10.1109/VISUAL.2000.885706	283	289	885706	computational geometry;data visualisation;image segmentation;medical image processing;rendering (computer graphics);surface fitting	abutting surfaces;bifurcation;colored polygons;complex surface topology;embedded features;medical image segmentation;medical imaging datasets;parallel planar slices;planar contours;regions of interest;scanline rendering;scanline surfacing;separating surface extraction;three dimensional surface reconstruction;tracing contours	Biological system modeling;Biology computing;Biomedical imaging;Electrical capacitance tomography;Image reconstruction;Image segmentation;Labeling;Magnetic resonance imaging;Solid modeling;Surface reconstruction		A standard way to segment medical imaging datasets is by tracing contours around regions of interest in parallel planar slices. Unfortunately, the standard methods for reconstructing three dimensional surfaces from those planar contours tend to be either complicated or not very robust. Furthermore, they fail to consistently mesh abutting structures which share portions of contours. We present a novel, straight-forward algorithm for accurately and automatically reconstructing surfaces from planar contours. Our algorithm is based on scanline rendering and separating surface extraction. By rendering the contours as distinctly colored polygons and reading back each rendered slice into a segmented volume, we reduce the complex problem of building a surface from planar contours to the much simpler problem of extracting separating surfaces from a classified volume. Our scanline surfacing algorithm robustly handles complex surface topologies such as bifurcations, embedded features and abutting surfaces.	Weinstein, D.	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|	37337510400
	SciVis	13-13 Oct. 2000	Navigating high-dimensional spaces to support design steering	10.1109/VISUAL.2000.885707	http://dx.doi.org/10.1109/VISUAL.2000.885707	291	296	885707	CAD;data visualisation;interactive systems	IRIS Explorer design steering;concept design;design cycle;design visualization;high-dimensional space navigation;interactive environment;local optimisation	Chromium;Computational modeling;Computer simulation;Data visualization;Design engineering;Design optimization;Humans;Iris;Monitoring;Navigation		Throughout the design cycle, visualization, whether a sketch scribbled on the back of a spare piece of paper or a fully detailed drawing, has been the mainstay of design: we need to see the product. One of the most important stages of the design cycle is the initial, or concept, stage and it is here that design variants occur in large numbers to be vetted quickly. At this initial stage the human element, the designer is crucial to the success of the product. We describe an interactive environment for concept design which recognises the needs of the designer, not only to see the product and make rapid modifications, but also to monitor the progress of their design towards some preferred solution. This leads to the notion of a design parameter space, typically high-dimensional, which must also be visualized in addition to the product itself. Using a module developed for IRIS Explorer design steering is presented as a navigation of this space in order to search for optimal designs, either manually or by local optimisation.	Wright, H.;Brodlie, K.;David, T.	Dept. of Comput. Sci., Hull Univ., UK|c|;;	37609618400;37271754900;37739474000
	SciVis	13-13 Oct. 2000	Visualization of multi-dimensional data with vector-fusion	10.1109/VISUAL.2000.885708	http://dx.doi.org/10.1109/VISUAL.2000.885708	297	302	885708	computational geometry;data mining;data visualisation;pattern recognition;sensor fusion	3D spherical helices;4D line;4D spherical helices;SBP algorithm;SBP vector data signatures;automatic target recognition;circle;data mining;frequency spectra;multidimensional data visualization;multidimensional models;parallel coordinates;pattern recognition;vector fusion;vector-fused data signature;vectorizing data	Data mining;Data visualization;Fingerprint recognition;Frequency;Geometry;Pattern recognition;Proteins;Shape;Solid modeling;Target recognition		Multi-dimensional entities are modeled, displayed and understood with a new algorithm vectorizing data of any dimensionality. This algorithm is called SBP; it is a vectorized generalization of parallel coordinates. Classic geometries of any dimensionality can be demonstrated to facilitate perception and understanding of the shapes generated by this algorithm. SBP images of a 4D line, a circle and 3D and 4D spherical helices are shown. A strategy for synthesizing multi-dimensional models matching multi-dimensional data is presented. Current applications include data mining; modeling data-defined structures of scientific interest such as protein structure and Calabi-Yau figures as multi-dimensional geometric entities; generating vector-fused data signature fingerprints of classic frequency spectra that identify substances; and treating complex targets as multi-dimensional entities for automatic target recognition. SBP vector data signatures apply to all pattern recognition problems.	Johnson, R.R.	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|	37435878200
	SciVis	13-13 Oct. 2000	Real-world relativity: image-based special relativistic visualization	10.1109/VISUAL.2000.885709	http://dx.doi.org/10.1109/VISUAL.2000.885709	303	310	885709	colour graphics;data visualisation;realistic images;rendering (computer graphics)	Doppler effect;brightness;camera;color;film sequences;geometry;image generation;image-based special relativistic visualization;interactive viewing;light;movies;plenoptic function;real-world relativity;real-world scenes;relativistic panoramas;rendering;searchlight effect;snapshots	Brightness;Cameras;Doppler effect;Geometry;Image generation;Layout;Production;Relativistic effects;Rendering (computer graphics);Visualization		This paper describes a novel rendering technique for special relativistic visualization. It is an image-based method which allows to render high speed flights through real-world scenes filmed by a standard camera. The relativistic effects on image generation are determined by the relativistic aberration of light, the Doppler effect, and the searchlight effect. These account for changes of apparent geometry, color and brightness of the objects. It is shown how the relativistic effects can be taken into account by a modification of the plenoptic function. Therefore, all known image-based nonrelativistic rendering methods can easily be extended to incorporate relativistic rendering. Our implementation allows interactive viewing of relativistic panoramas and the production of movies which show super-fast travel. Examples in the form of snapshots and film sequences are included.	Weiskopf, D.;Kobras, D.;Ruder, H.	Inst. of Astron. & Astrophys., Tubingen Univ., Germany|c|;;	38470313600;38015244300;37565759500
	SciVis	13-13 Oct. 2000	Visualizing geodesics	10.1109/VISUAL.2000.885710	http://dx.doi.org/10.1109/VISUAL.2000.885710	311	318	885710	computational geometry;data visualisation;differential geometry;nonlinear differential equations	approximation error;arbitrary surfaces;data set;differential equations;geodesics visualization;geometry;numerical algorithms;physics;scientific visualization;straight lines	Acceleration;Approximation error;Character generation;Computer science;Data visualization;Differential equations;Geometry;Physics;Testing		"One of the main research topics in scientific visualization is to ""visualize the appropriate features"" of a certain structure or data set. Geodesics are very important in geometry and physics, but there is one major problem which prevents scientists from using them as a visualization tool: the differential equations for geodesics are very complicated and in most cases numerical algorithms must be used. There is always a certain approximation error involved. How can you be sure to visualize the features and not only the approximation quality. The paper presents an algorithm to overcome this problem. It consists of two parts. In the first, a geometric method for the construction of geodesics of arbitrary surfaces is introduced. This method is based on the fundamental property that geodesics are a generalization of straight lines on plains. In the second part these geodesics are used to generate local nets on the surfaces."	Hotz, I.;Hagen, H.	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;	37282721800;37282578800
	SciVis	13-13 Oct. 2000	Geometric compression for interactive transmission	10.1109/VISUAL.2000.885711	http://dx.doi.org/10.1109/VISUAL.2000.885711	319	326	885711	computational geometry;data compression;data visualisation;mesh generation	compression ratios;data compression;data visualization;geometric compression;interactive mesh transmission;mesh coding;mesh topology	Compression algorithms;Data compression;Geometry;Image coding;Image generation;Image reconstruction;Layout;Solid modeling;Strips;Topology		The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.	Devillers, O.;Gandoin, P.-M.	Inst. Nat. de Recherche en Inf. et Autom., Sophia Antipolis, France|c|;	37390088800;37314223500
	SciVis	13-13 Oct. 2000	Toward a compelling sensation of telepresence: demonstrating a portal to a distant (static) office	10.1109/VISUAL.2000.885712	http://dx.doi.org/10.1109/VISUAL.2000.885712	327	333	885712	groupware;office automation;rendering (computer graphics);teleworking;user interfaces;virtual reality	3D collaborative telepresence;3D tele-collaboration;Office of the Future;distant office;dynamic scene modeling;high-fidelity scene reconstruction;modeling algorithms;real-time system;rendering;scene reconstruction;static scene acquisition;stereo projective display;tele-immersion;tracking	Assembly;Collaboration;Collaborative software;Collaborative work;Computer science;Displays;Hardware;Image reconstruction;Layout;Portals		In 1998 we introduced the idea for a project we call the Office of the Future. Our long-term vision is to provide a better every-day working environment, with high-fidelity scene reconstruction for life-sized 3D tele-collaboration. In particular, we want a true sense of presence with our remote collaborator and their real surroundings. The challenges related to this vision are enormous and involve many technical tradeoffs. This is true in particular for scene reconstruction. Researchers have been striving to achieve real-time approaches, and while they have made respectable progress, the limitations of conventional technologies relegate them to relatively low resolution in a restricted volume. We present a significant step toward our ultimate goal, via a slightly different path. In lieu of low-fidelity dynamic scene modeling we present an exceedingly high fidelity reconstruction of a real but static office. By assembling the best of available hardware and software technologies in static scene acquisition, modeling algorithms, rendering, tracking and stereo projective display, we are able to demonstrate a portal to a real office, occupied today by a mannequin, and in the future by a real remote collaborator. We now have both a compelling sense of just how good it could be, and a framework into which we will later incorporate dynamic scene modeling, as we continue to head toward our ultimate goal of 3D collaborative telepresence.	Wei-Chao Wen;Towles, H.;Nyland, L.;Welch, G.;Fuchs, H.	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;	;37298881100;37347602300;37300645000;37285537200
	SciVis	13-13 Oct. 2000	Topology preserving compression of 2D vector fields	10.1109/VISUAL.2000.885714	http://dx.doi.org/10.1109/VISUAL.2000.885714	343	350	885714	data compression;data visualisation;interactive systems;topology	2D vector fields;angular errors;compressed vector fields;constrained clustering;distance metric;local error metrics;precise error bounds;simulated data sets;topology information;topology preserving compression;weighted magnitude	Analytical models;Clustering algorithms;Compression algorithms;Computer errors;Data analysis;Degradation;Earth;Streaming media;Topology;Visualization		We present an algorithm for compressing 2D vector fields that preserves topology. Our approach is to simplify the given data set using constrained clustering. We employ different types of global and local error metrics including the earth mover's distance metric to measure the degradation in topology as well as weighted magnitude and angular errors. As a result, we obtain precise error bounds in the compressed vector fields. Experiments with both analytic and simulated data sets are presented. Results indicate that one can obtain significant compression with low errors without losing topology information.	Lodha, S.K.;Renteria, J.C.;Roskin, K.M.	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;	38479728800;37658638100;38015336900
	SciVis	13-13 Oct. 2000	A topology simplification method for 2D vector fields	10.1109/VISUAL.2000.885716	http://dx.doi.org/10.1109/VISUAL.2000.885716	359	366	885716	computational fluid dynamics;critical points;data visualisation;flow visualisation;pattern clustering;piecewise linear techniques;topology;turbulence	2D vector fields;critical points;maximal distances;piecewise linear representation;plane turbulent vector fields;prescribed radius;simplified vector fields;topology analysis;topology simplification method;visual clutter;visualization method;vortices	Computational fluid dynamics;Computer science;Data engineering;Data visualization;Fluid flow measurement;Mechanical variables measurement;Merging;Piecewise linear techniques;Topology;Vectors		Topology analysis of plane, turbulent vector fields results in visual clutter caused by critical points indicating vortices of finer and finer scales. A simplification can be achieved by merging critical points within a prescribed radius into higher order critical points. After building clusters containing the singularities to merge, the method generates a piecewise linear representation of the vector field in each cluster containing only one (higher order) singularity. Any visualization method can be applied to the result after this process. Using different maximal distances for the critical points to be merged results in a hierarchy of simplified vector fields that can be used for analysis on different scales.	Tricoche, X.;Scheuermann, G.;Hagen, H.	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;	37282575100;37282574800;37282578800
	SciVis	13-13 Oct. 2000	Constructing material interfaces from data sets with volume-fraction information	10.1109/VISUAL.2000.885717	http://dx.doi.org/10.1109/VISUAL.2000.885717	367	372	885717	computational fluid dynamics;computational geometry;data visualisation;surface fitting	Voronoi cells;barycentric coordinate tuple;boundary surface approximation;data sets;dual data set;dual mesh;dual tetrahedral mesh;grid structure;material boundaries;material boundary interface reconstruction;material interfaces;physical space;reconstruction problem;tetrahedron;vertex;volume fractions;volume-fraction information	Data analysis;Equations;Face;Grid computing;Hydrodynamics;Image reconstruction;Numerical simulation;Surface cracks;Surface reconstruction;Surface treatment		We present a new algorithm for material boundary interface reconstruction from data sets containing volume fractions. We transform the reconstruction problem to a problem that analyzes the dual data set, where each vertex in the dual mesh has an associated barycentric coordinate tuple that represents the fraction of each material present. After constructing the dual tetrahedral mesh from the original mesh, we construct material boundaries by mapping a tetrahedron into barycentric space and calculating the intersections with Voronoi cells in barycentric space. These intersections are mapped back to the original physical space and triangulated to form the boundary surface approximation. This algorithm can be applied to any grid structure and can treat any number of materials per element/vertex.	Bonnell, K.S.;Schikore, D.R.;Joy, K.I.;Duchaineau, M.;Hamann, B.	CIPIC, California Univ., Davis, CA, USA|c|;;;;	37550791600;37355637500;37267811400;37267813100;37282068700
	SciVis	13-13 Oct. 2000	New techniques for topologically correct surface reconstruction	10.1109/VISUAL.2000.885718	http://dx.doi.org/10.1109/VISUAL.2000.885718	373	380	885718	linear programming;mesh generation;surface fitting;topology	Delaunay complex;fast algorithm;lambda intervals;linear programming;postprocessing step;reconstruction schemes;smooth regions;topological clean up;topologically correct surface reconstruction	Computational geometry;Computer science;Image reconstruction;Image sampling;Linear programming;Piecewise linear techniques;Reconstruction algorithms;Surface cleaning;Surface reconstruction;Topology		We present a novel approach to surface reconstruction based on the Delaunay complex. First we give a simple and fast algorithm that picks locally a surface at each vertex. For that, we introduce the concept of ?-intervals. It turns out that for smooth regions of the surface this method works very well and at difficult parts of the surface yields an output well-suited for postprocessing. As a postprocessing step we propose a topological clean up and a new technique based on linear programming in order to establish a topologically correct surface. These techniques should be useful also for many other reconstruction schemes.	Adamy, U.;Giesen, J.;John, M.	Inst. for Theor. Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	38015316100;37325999500;38027270700
	SciVis	13-13 Oct. 2000	Polyhedral modeling	10.1109/VISUAL.2000.885719	http://dx.doi.org/10.1109/VISUAL.2000.885719	381	387	885719	computational geometry;data visualisation;interpolation;mesh generation;surface fitting;topology	CAD/CAM;arbitrary topolog;boundary curve network construction;computer graphics;explicit closed form parametrization;geometric modeling;interpolation;iso-surface extraction;mesh vertices;normal vector input;polyhedral meshes;polyhedral modeling;smooth surfaces;surface reconstruction;triangle 4-split method;triangulated polyhedral mesh;visual smooth surface;visualization	Application software;CADCAM;Computer aided manufacturing;Image reconstruction;Polynomials;Rough surfaces;Surface reconstruction;Surface roughness;Surface treatment;Visualization		Polyhedral meshes are used for visualization, computer graphics or geometric modeling purposes and result from many applications like iso-surface extraction, surface reconstruction or CAD/CAM. The paper introduces a method for constructing smooth surfaces from a triangulated polyhedral mesh of arbitrary topology. It presents a new algorithm which generalizes and improves the triangle 4-split method (S. Hahmann and G.-P. Bonneau) in the crucial point of boundary curve network construction. This network is then filled in by a visual smooth surface from which an explicit closed form parametrization is given. Furthermore, the method becomes now completely local and can interpolate normal vector input at the mesh vertices.	Bonneau, G.-P.;Hahmann, S.	CNRS, Univ. of Grenoble, France|c|;	37368609100;37378532500
	SciVis	13-13 Oct. 2000	Anisotropic geometric diffusion in surface processing	10.1109/VISUAL.2000.885721	http://dx.doi.org/10.1109/VISUAL.2000.885721	397	405	885721	computational geometry;finite difference methods;image processing;matrix algebra;mesh generation;tensors	anisotropic curvature evolution;anisotropic geometric diffusion;arbitrary unstructured triangular meshes;diffusion tensor;discretized surface smoothing;evolving surface;geometric evolution problems;geometric features;image processing methodology;multiscale method;multiscale parameter;nonlinear diffusion equations;preconditioned iterative solvers;semi-implicit finite difference discretization;shape operator;spatial finite element discretization;surface processing;systems of linear equations;timestep	Anisotropic magnetoresistance;Filters;Finite difference methods;Finite element methods;Image processing;Mathematics;Nonlinear equations;Shape;Smoothing methods;Tensile stress		A new multiscale method in surface processing is presented which combines the image processing methodology based on nonlinear diffusion equations and the theory of geometric evolution problems. Its aim is to smooth discretized surfaces while simultaneously enhancing geometric features such as edges and corners. This is obtained by an anisotropic curvature evolution, where time is the multiscale parameter. Here, the diffusion tensor depends on the shape operator of the evolving surface. A spatial finite element discretization on arbitrary unstructured triangular meshes and a semi-implicit finite difference discretization in time are the building blocks of the easy to code algorithm presented. The systems of linear equations in each timestep are solved by appropriate, preconditioned iterative solvers. Different applications underline the efficiency and flexibility of the presented type of surface processing tool.	Clarenz, U.;Diewald, U.;Rumpf, M.	Inst. for Appl. Math., Bonn Univ., Germany|c|;;	37268037900;37449648400;37268036500
	SciVis	8-13 Oct. 2000	Multi-resolution dynamic meshes with arbitrary deformations	10.1109/VISUAL.2000.885724	http://dx.doi.org/10.1109/VISUAL.2000.885724	423	430	885724	computational geometry;computer graphics;directed graphs	T-DAG;adaptive multi-resolution representation;arbitrary deformations;attribute changes;connectivity changes;incremental algorithm;input mesh;internally deforming models;large static geometric object display;large static geometric object transmission;multi-resolution dynamic meshes;partial playback;position changes;scientific simulations;time-dependent directed acyclic graph;topology changes	Computational modeling;Computer displays;Data mining;Data visualization;Deformable models;Isosurfaces;Laboratories;Layout;Scientific computing;Solid modeling		Multi-resolution techniques and models have been shown to be effective for the display and transmission of large static geometric object. Dynamic environments with internally deforming models and scientific simulations using dynamic meshes pose greater challenges in terms of time and space, and need the development of similar solutions. We introduce the T-DAG, an adaptive multi-resolution representation for dynamic meshes with arbitrary deformations including attribute, position, connectivity and topology changes. T-DAG stands for time-dependent directed acyclic graph which defines the structure supporting this representation. We also provide an incremental algorithm (in time) for constructing the T-DAG representation of a given input mesh. This enables the traversal and use of the multi-resolution dynamic model for partial playback while still constructing new time-steps.	Shamir, A.;Pascucci, V.;Bajaj, C.	Center for Comput. Visualization, Texas Univ., Austin, TX, USA|c|;;	37266753700;37284312600;37282899200
	SciVis	13-13 Oct. 2000	Fast visualization methods for comparing dynamics: a case study in combustion	10.1109/VISUAL.2000.885725	http://dx.doi.org/10.1109/VISUAL.2000.885725	433	436	885725	chemistry computing;combustion;data visualisation;real-time systems	combustion;dynamics;exploration;fast visualization methods;geometric symmetry mappings;parameter space surveys;real-time settings;spectral displays;summary visualization;tiling	Combustion;Computer aided software engineering;Data visualization;Displays;Fires;Fuels;Laboratories;Motion pictures;Pattern formation;Temperature dependence		Visualization can be an important tool for displaying, categorizing and digesting large quantities of inter-related information during laboratory and simulation experiments. Summary visualizations that compare and represent data sets in the context of a collection are particularly valuable. Applicable visualizations used in these settings must be fast (near real time) and should allow the addition of data sets as they are acquired without requiring rerendering of the visualization. This paper examines several visualization techniques for representing collections of data sets in a combustion experiment including spectral displays, tiling and geometric mappings of symmetry. The application provides insight into how such visualizations might be used in practical real-time settings to assist in exploration and in conducting parameter space surveys.	Robbins, K.A.;Gorman, M.	Div. of Comput. Sci., Texas Univ., San Antonio, TX, USA|c|;	37282602100;38182206800
	SciVis	13-13 Oct. 2000	Mastering interactive surface rendering for Java-based diagnostic applications	10.1109/VISUAL.2000.885726	http://dx.doi.org/10.1109/VISUAL.2000.885726	437	440	885726	Java;data visualisation;medical image processing;rendering (computer graphics)	J-Vision;Java-based diagnostic applications;cutting planes;explicit surface representation;interactive clipping;interactive surface rendering;interactivity;iso-surface display;medical data sets;medical image diagnosis;medical image viewing;multiple stacked transparent surfaces;radiology;shear-warp projection;splatting;visualization;volumetric density data set diagnosis	Application software;Biomedical imaging;Computer displays;Computer graphics;Data visualization;Hardware;Hospitals;Java;Medical diagnostic imaging;Rendering (computer graphics)		The display of iso-surfaces in medical data sets is an important visualization technique used by radiologists for the diagnosis of volumetric density data sets. The demands put by radiologists on such a display technique are interactivity, multiple stacked transparent surfaces and cutting planes that allow an interactive clipping of the surfaces. This paper presents a Java based, platform independent implementation of a very fast surface rendering algorithm which combines the advantages of explicit surface representation, splatting, and shear-warp projection to fulfill all these requirements. The algorithm is implemented within the context of J-Vision, an application for viewing and diagnosing medical images which is currently in use at various hospitals.	Mroz, L.;Wegenkittl, R.;Groller, E.	Inst. of Comput. Graphics, Wien Univ. of Technol., Austria|c|;;	37282641800;37267822600;37284271200
	SciVis	13-13 Oct. 2000	A computational steering system for studying microwave interactions with missile bodies	10.1109/VISUAL.2000.885727	http://dx.doi.org/10.1109/VISUAL.2000.885727	441	444	885727	digital simulation;engineering graphics;microwaves;military computing;missiles;radiation effects;virtual reality	CAVE;computational steering system;computer modeling system;computer simulation system;graphical output display;immersive virtual environment;interface;inverse steering;microwave interactions;missile bodies;missile electronics;network flow visualization package;simulation parameter space;simulation workflow	Computational modeling;Computer simulation;Displays;Electromagnetic radiation;Laboratories;Missiles;Packaging;Steering systems;Virtual reality;Visualization		The paper describes a computer modeling and simulation system that supports computational steering, which is an effort to make the typical simulation workflow more efficient. Our system provides an interface that allows scientists to perform all of the steps in the simulation process in parallel and online. It uses a standard network flow visualization package, which has been extended to display graphical output in an immersive virtual environment such as a CAVE. Our system allows scientists to interactively manipulate simulation parameters and observe the results. It also supports inverse steering, where the user specifies the desired simulation result, and the system searches for the simulation parameters that achieve this result. Taken together, these capabilities allow scientists to more efficiently and effectively understand model behavior, as well as to search through simulation parameter space. The paper is also a case study of applying our system to the problem of simulating microwave interactions with missile bodies. Because these interactions are difficult to study experimentally, and have important effects on missile electronics, there is a strong desire to develop and validate simulation models of this phenomena.	Swan, J.E.;Lanzagorta, M.;Maxwell, D.;Kuo, E.;Uhlmann, J.;Anderson, W.;Haw-Jye Shyu;Smith, W.	Virtual Reality Lab., Naval Res. Lab., Washington, DC, USA|c|;;;;;;;	37295140400;37295678700;38028495400;37372263000;37264967300;37290721200;37618138200;38020250500
	SciVis	13-13 Oct. 2000	Four-dimensional non-linear ray tracing as a visualization tool for gravitational physics	10.1109/VISUAL.2000.885728	http://dx.doi.org/10.1109/VISUAL.2000.885728	445	448	885728	data visualisation;differential geometry;general relativity;gravitation;physics computing;ray tracing;space-time configurations	3D ray tracing;4D nonlinear ray tracing;caustic surfaces;gravitational field;gravitational lens;gravitational physics;images;null geodesics;rigidly rotating dust disc;space-time;visualization tool;warp drive metric	Astronomy;Astrophysics;Computational geometry;Computer graphics;Drives;Electrical capacitance tomography;Lenses;Physics;Ray tracing;Visualization		General relativistic ray tracing is presented as a tool for gravitational physics. It is shown how standard three-dimensional ray tracing can be extended to allow for general relativistic visualization. This visualization technique provides images as seen by an observer under the influence of a gravitational field and allows to probe space-time by null geodesics. Moreover, a technique is proposed for visualizing the caustic surfaces generated by a gravitational lens. The suitability of general relativistic ray tracing is demonstrated by means of two examples, namely the visualization of the rigidly rotating disk of dust and the warp drive metric.	Weiskopf, D.	Inst. for Astron. & Astrophys., Tubingen Univ., Germany|c|	38470313500
	SciVis	13-13 Oct. 2000	Combining local and remote visualization techniques for interactive volume rendering in medical applications	10.1109/VISUAL.2000.885729	http://dx.doi.org/10.1109/VISUAL.2000.885729	449	452	885729	computerised tomography;data visualisation;image texture;medical image processing;rendering (computer graphics);stereo image processing	2D visualization;3D texture mapping;3D visualization;clinical environment;high-quality direct volume rendering;interactive volume rendering;local desktop computers;local visualization technique;medical diagnosis;neuroradiology;remote high-end graphics hardware;remote visualization technique;tomographic image data	Biomedical equipment;Biomedical imaging;Computer graphics;Data visualization;Hardware;Medical diagnosis;Medical diagnostic imaging;Medical services;Rendering (computer graphics);Tomography		For a comprehensive understanding of tomographic image data in medicine, interactive and high-quality direct volume rendering is an essential prerequisite. This is provided by visualization using 3D texture mapping which is still limited to high-end graphics hardware. In order to make it available in a clinical environment, we present a system which uniquely combines local desktop computers and remote high-end graphics hardware. In this context, we exploit the standard visualization capabilities to a maximum which are available in the clinical environment. For 3D representations of high resolution and quality we access the remote specialized hardware. Various tools for 2D and 3D visualization are provided which meet the requirements of a medical diagnosis. This is demonstrated with examples from the field of neuroradiology which show the value of our strategy in practice.	Engel, K.;Hastreiter, P.;Ertl, T.	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	37266847600;37373297800;37268023800
	SciVis	13-13 Oct. 2000	An integrated visualization and design toolkit for flexible prosthetic heart valves	10.1109/VISUAL.2000.885730	http://dx.doi.org/10.1109/VISUAL.2000.885730	453	456	885730	CAD;cardiology;computational fluid dynamics;data visualisation;haemodynamics;medical computing;prosthetics	blood flow;cardiac cycle;flexible prosthetic heart valves;initial geometry;initial material properties;integrated visualization/design toolkit;interlinked modules;leaflet flexing;valve leaflet;valve motion;visual programming interface	Arteries;Biomedical engineering;Blood;Computer graphics;Engineering in medicine and biology;Geometry;Heart valves;Mechanical engineering;Prosthetics;Visualization		We describe a toolkit for the design and visualization of flexible artificial heart valves. The toolkit consists of interlinked modules with a visual programming interface. The user of the toolkit can set the initial geometry and material properties of the valve leaflet, solve for the flexing of the leaflet and the flow of blood around it, and display the results using the visualization capabilities of the toolkit. The interactive nature of our environment is highlighted by the fact that changes in leaflet properties are immediately reflected in the flow field and response of the leaflet. Hence the user may, in a single session, investigate a broad range of designs, each one of which provides important information about the blood flow and motion of the valve during the cardiac cycle.	Fenlon, A.J.;David, T.;Walton, J.P.R.B.	Sch. of Mech. Eng., Leeds Univ., UK|c|;;	37725037700;37739474000;37282730800
	SciVis	13-13 Oct. 2000	Immersive virtual reality for visualizing flow through an artery	10.1109/VISUAL.2000.885731	http://dx.doi.org/10.1109/VISUAL.2000.885731	457	460	885731	blood vessels;cardiovascular system;flow simulation;flow visualisation;gesture recognition;haemodynamics;medical computing;numerical analysis;rendering (computer graphics);speech-based user interfaces;virtual reality	coronary artery graft model;flow visualization;future lesion sources;gestural interactions;graft failure rate;immersive virtual reality;numerically simulated flow data;rendering techniques;voice interactions	Arteries;Cardiology;Geometry;Heart;Lesions;Numerical simulation;Plasma simulation;Solid modeling;Virtual reality;Visualization		We present an immersive system for exploring numerically simulated flow data through a model of a coronary artery graft. This tightly-coupled interdisciplinary project is aimed at understanding how to reduce the failure rate of these grafts. The visualization system provides a mechanism for exploring the effect of changes to the geometry, to the flow, and for exploring potential sources of future lesions. The system uses gestural and voice interactions exclusively, moving away from more traditional windows/icons/menus/point-and-click (WIMP) interfaces. We present an example session using the system and discuss our experiences developing, testing, and using it. We describe some of the interaction and rendering techniques that we experimented with and describe their level of success. Our experience suggests that systems like this are exciting to clinical researchers, but conclusive evidence of their value is not yet available.	Forsberg, A.;Laidlaw, D.H.;van Dam, A.;Kirby, R.M.;Elion, J.L.	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;;;	37612088000;37275712600;37426649000;37275716100;37390773900
	SciVis	13-13 Oct. 2000	Mastering interactive virtual bronchioscopy on a low-end PC	10.1109/VISUAL.2000.885732	http://dx.doi.org/10.1109/VISUAL.2000.885732	461	464	885732	blood vessels;computerised tomography;data visualisation;medical image processing;microcomputer applications;rendering (computer graphics);stereo image processing;tumours	blood vessels;computer tomograph;cross-sectional 3D data;endoluminal view;external structures;image based rendering techniques;inner lumen shape;interactive virtual bronchioscopy;low-end PC;operation planning;real time frame rates;surface rendering;transbronchial biopsy;transfer functions;tumor;virtual endoscopy;visualization;volume rendering techniques	Biomedical imaging;Biopsy;Blood vessels;Computer displays;Endoscopes;Neoplasms;Rendering (computer graphics);Shape;Transfer functions;Visualization		Virtual endoscopy presents the cross-sectional acquired 3D-data of a computer tomograph as an endoluminal view. The common approach for the visualization of a virtual endoscopy is surface rendering, yielding images close to a real endoscopy. If external structures are of interest, volume rendering techniques have to be used. These methods do not display the exact shape of the inner lumen very well. For certain applications, e.g. operation planning of a transbronchial biopsy, both the shape of the inner lumen as well as outer structures like blood vessels and the tumor have to be delineated. A method is described, that allows a quick and easy hybrid visualization using overlays of different visualization methods like different surfaces or volume renderings with different transfer functions in real time on a low-end PC. To achieve real time frame rates, image based rendering techniques have been used.	Wegenkittl, R.;Vilanova, A.;Hegedust, B.;Freund, M.C.;Groller, E.M.	Tiani Medgraph GesmbH, Vienna, Austria|c|;;;;	37267822600;37282551500;38015263000;38028756700;38185405200
	SciVis	13-13 Oct. 2000	Interactive visualization of protein dynamics	10.1109/VISUAL.2000.885733	http://dx.doi.org/10.1109/VISUAL.2000.885733	465	468	885733	biology computing;computer animation;data visualisation;molecular biophysics;proteins	3D animations;atom motion filtering;interactive 3D visualization;photoactive yellow protein;protein dynamics;protein motions;subspace;time dependent characteristics	Animation;Biological processes;Biological system modeling;Bonding;Computer graphics;Computer science;Filters;Mathematics;Protein engineering;Visualization		The study of time dependent characteristics of proteins is important for gaining insight into many biological processes. However, visualizing protein dynamics by animating atom trajectories does not provide satisfactory results. When the trajectory is sampled with large times steps, the impression of smooth motion will be destroyed due to the effects of temporal aliasing. Sampling with small time steps will result in the camouflage of interesting motions. In this case study, we discuss techniques for the interactive 3D visualization of the dynamics of the photoactive yellow protein. We use essential dynamics methods to filter out uninteresting atom motions from the larger concerted motions. In this way, clear and concise 3D animations of protein motions can be produced. In addition, we discuss various interactive techniques that allow exploration of the essential subspace of the protein. We discuss the merits of these techniques when applied to the analysis of the yellow protein.	Huitema, H.;van Liere, R.	Center for Math. & Comput. Sci., Amsterdam, Netherlands|c|;	38015187400;37282925600
	SciVis	13-13 Oct. 2000	Interactive visualization of particle-in-cell simulations	10.1109/VISUAL.2000.885734	http://dx.doi.org/10.1109/VISUAL.2000.885734	469	472	885734	computer animation;data visualisation;digital simulation;high energy physics instrumentation computing;interactive systems;particle accelerators;real-time systems;rendering (computer graphics)	Onyx2 Infinite Reality hardware;astrophysical shocks;case study;electron acceleration;frame rates;graphics subsystems;hardware specifications;interactive real time animation;interactive visualization;parallel Particle-in-Cell code;particle acceleration;particle accelerators;particle-in-cell simulations;plasma surfatron;saturation mechanism;solar corona;visual objects;visualization system;volume rendered particle density functionals	Acceleration;Animation;Electric shock;Electrons;Graphics;Hardware;Plasma accelerators;Real time systems;Rendering (computer graphics);Visualization		The authors present a visualization system for interactive real time animation and visualization of simulation results from a parallel Particle-in-Cell code. The system was designed and implemented for the Onyx2 Infinite Reality hardware. A number of different visual objects, such as volume rendered particle density functionals were implemented. To provide sufficient frame rates for interactive visualization, the system was designed to provide performance close to the hardware specifications both in terms of the I/O and graphics subsystems. The presented case study applies the developed system to the evolution of an instability that gives rise to a plasma surfatron, a mechanism which rapidly can accelerate particles to very high velocities and thus be of great importance in the context of electron acceleration in astrophysical shocks, in the solar corona and in particle accelerators. The produced visualizations have allowed us to identify a previously unknown saturation mechanism for the surfatron and direct research efforts into new areas of interest.	Ljung, P.;Dieckmann, M.;Andersson, N.;Ynnerman, A.	Dept. of Sci. & Technol., Linkopings Univ., Sweden|c|;;;	37284208400;37325011700;37328079900;37284192000
	SciVis	13-13 Oct. 2000	Visualization of time dependent confocal microscopy data	10.1109/VISUAL.2000.885735	http://dx.doi.org/10.1109/VISUAL.2000.885735	473	476	885735	biology computing;cellular biophysics;data visualisation;living systems;microscopy;virtual reality	application-specific demands;case study;cell biology;cell division;chromosomes;interactive virtual reality enabled visualization system;living cells;microscopic analysis;presentation techniques;proteus;spatial complexity;time dependent 3D data sets;time dependent 3D live cells;time dependent confocal microscopy data visualization;visualization techniques	Biological cells;Cells (biology);Computer graphics;DNA;Data visualization;Fluorescence;Gene expression;Labeling;Microscopy;Proteins		The microscopic analysis of time dependent 3D live cells provides considerable challenges to visualization. Effective visualization can provide insight into the structure and functioning of living cells. The paper presents a case study in which a number of visualization techniques were applied to analyze a specific problem in cell biology: the condensation and de-condensation of chromosomes during cell division. The spatial complexity of the data required sophisticated presentation techniques. The interactive virtual reality enabled visualization system, proteus, specially equipped for time dependent 3D data sets is described. An important feature of proteus is that it is extendible to cope with application-specific demands.	De Leeuw, W.C.;van Liere, R.;van Driel, R.	Centre for Math. & Comput. Sci., Amsterdam, Netherlands|c|;;	37327212900;37282925600;37281621600
	SciVis	13-13 Oct. 2000	Visual data fusion for applications of high-resolution numerical weather prediction	10.1109/VISUAL.2000.885736	http://dx.doi.org/10.1109/VISUAL.2000.885736	477	480	885736	data visualisation;digital simulation;geophysics computing;sensor fusion;weather forecasting	data consumer;data fusion approach;high-resolution numerical weather prediction;predictive weather simulations;scientific data;scientific visualization strategies;visual data fusion;visualization design;weather-sensitive applications	Application software;Atmospheric modeling;Computational modeling;Computer graphics;Data visualization;Decision making;Fusion power generation;Humans;Predictive models;Weather forecasting		Non-traditional applications of scientific data challenge the typical approaches to visualization. In particular popular scientific visualization strategies fail when the expertise of the data consumer is in a different field than the one that generated the data and data from the user's domain must be utilized as well. This problem occurs when predictive weather simulations are used for a number of weather-sensitive applications. A data fusion approach is adopted for visualization design and utilized for specific example problems.	Treinish, L.A.	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	37372175500
	SciVis	13-13 Oct. 2000	Case study: a methodology for plume visualization with application to real-time acquisition and navigation	10.1109/VISUAL.2000.885737	http://dx.doi.org/10.1109/VISUAL.2000.885737	481	484	885737	data acquisition;data visualisation;digital simulation;geophysics computing;image thinning;oceanography;real-time systems;seafloor phenomena	case study;centerline representation;field data sets;field datasets;idealized cone;large scale observable features;navigation;plume behavior;plume isosurface;plume visualization;quantitative capturing;real time acquisition;real time adjustment;seafloor hydrothermal plumes;shipboard data collection systems;skeleton points;skeletonization;turbulent eddies;visualization techniques	Acoustic imaging;Atmospheric modeling;Computational modeling;Computer aided software engineering;Data visualization;Instruments;Oceans;Sea floor;Skeleton;Vents		Applications of visualization techniques that facilitate comparison of simulation and field datasets of seafloor hydrothermal plumes are demonstrated in order to explore and confirm theories of plume behavior. In comparing these datasets, there is no one-to-one correspondence. We show the comparison by performing quantitative capturing of large scale observable features. The comparisons are needed not only to improve the relevance of the simulations to the field observations, but also to enable real time adjustment of shipboard data collection systems. Our approach for comparing simulation and field datasets is to use skeletonization and centerline representation. Features representing plumes are skeletonized. Skeleton points are used to construct a centerline and to quantify plume properties on planes normal to the centerline. These skeleton points are further used to construct an idealized cone representing a plume isosurface. The difference between the plume feature and the cone is identified as protrusions of turbulent eddies. Comparison of the simulation and field data sets through these abstractions illustrates how these abstractions characterize a plume.	Bemis, K.G.;Silver, D.;Rona, P.;Chengwei Feng	Inst. of Marine & Coastal Sci., Rutgers Univ., New Brunswick, NJ, USA|c|;;;	37282733100;37274132700;37282733200;38021818900
	SciVis	13-13 Oct. 2000	Vector fields simplification-a case study of visualizing climate modeling and simulation data sets	10.1109/VISUAL.2000.885738	http://dx.doi.org/10.1109/VISUAL.2000.885738	485	488	885738	climatology;data visualisation;digital simulation;filtering theory;geophysics computing	East Asia;case study;circulation;climate modeling;critical points;feature filtering technique;filtering technique;multiresolution fashion;neighboring regions;regional climate modeling;regional climate modeling data set;simulation data sets;sporadic critical points;strong shear;topology;vector field simplification;vector fields;vorticity;weather instability	Asia;Atmospheric modeling;Chromium;Computational modeling;Computer aided software engineering;Data visualization;Filtering;Laboratories;Topology;Wind speed		In our study of regional climate modeling and simulation, we frequently encounter vector fields that are crowded with large numbers of critical points. A critical point in a flow is where the vector field vanishes. While these critical points accurately reflect the topology of the vector fields, in our study only a subset of them is worth further investigation. We present a filtering technique based on the vorticity of the vector fields to eliminate the less interesting and sometimes sporadic critical points in a multiresolution fashion. The neighboring regions of the preserved features, which are characterized by strong shear and circulation, are potential locations of weather instability. We apply our feature filtering technique to a regional climate modeling data set covering East Asia in the summer of 1991.	Pak Chung Wong;Foote, H.;Leung, R.;Jurrus, E.;Adams, D.;Thomas, J.	Pacific Northwest Lab., Richland, WA, USA|c|;;;;;	37280665600;37372586800;37443545300;37725413900;38022952100;37273308900
	SciVis	13-13 Oct. 2000	WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data	10.1109/VISUAL.2000.885739	http://dx.doi.org/10.1109/VISUAL.2000.885739	489	492	885739	cardiology;data visualisation;digital simulation;interactive systems;medical computing;statistical analysis	3D anatomical data;WEAVE;Workbench Environment for Analysis and Visual Exploration;biomedical application;cardiac simulation;custom 3D visualizations;heart excitation;interactive color brushing;interactive visualization applications;measurement data;multidimensional statistical representations;scientists;simulation data;statistical visualizations;three-dimensional visualizations;transparent linking;visual linking	Biomedical engineering;Biomedical measurements;Computational modeling;Couplings;Data visualization;Extraterrestrial measurements;Heart;Joining processes;Medical simulation;Multidimensional systems		WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.	Gresh, D.L.;Rogowitz, B.E.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;	37378534100;37332114400;37330343000;37443860200;38021754100
	SciVis	13-13 Oct. 2000	Visualizing high-dimensional predictive model quality	10.1109/VISUAL.2000.885740	http://dx.doi.org/10.1109/VISUAL.2000.885740	493	496	885740	data visualisation;learning by example;pattern classification	benchmark data set;census data;classification models;high-dimensional data space projection;high-dimensional predictive model quality visualization;inductive learning techniques;instance mapping;large high-dimensional data sets;learned models;model understanding;probabilistic prediction display;variable/class correlation	Artificial intelligence;Bayesian methods;Computer science;Data visualization;Diseases;Input variables;Learning systems;Machine learning;Machine learning algorithms;Predictive models		Using inductive learning techniques to construct classification models from large, high-dimensional data sets is a useful way to make predictions in complex domains. However, these models can be difficult for users to understand. We have developed a set of visualization methods that help users to understand and analyze the behavior of learned models, including techniques for high-dimensional data space projection, display of probabilistic predictions, variable/class correlation, and instance mapping. We show the results of applying these techniques to models constructed from a benchmark data set of census data, and draw conclusions about the utility of these methods for model understanding.	Rheingans, P.;desJardins, M.	Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;	37282292000;37552291200
	SciVis	13-13 Oct. 2000	Visualizing volume data using physical models	10.1109/VISUAL.2000.885741	http://dx.doi.org/10.1109/VISUAL.2000.885741	497	500	885741	data visualisation;image segmentation;stereo image processing	3D data sets;3D physical models;cutting operations;display-based visualization;interlocking pieces;segmentation operations;solid freeform fabrication equipment;volume data visualization	Biomedical imaging;Computer graphics;Data mining;Data visualization;Glass;Head;Humans;Image segmentation;Skull;Solid modeling		Visualization techniques enable scientists to interactively explore 3D data sets, segmenting and cutting them to reveal inner structure. While powerful, these techniques suffer from one serious flaw-the images they create are displayed on a flat piece of glass or paper. It is not really 3D-it can only be made to appear 3D. We describe the construction of 3D physical models from volumetric data. Using solid freeform fabrication equipment, these models are built as separate interlocking pieces that express in physical form the segmentation and cutting operations common in display-based visualization.	Nadeau, David R.;Bailey, M.J.	Supercomput. Center, California Univ., San Diego, La Jolla, CA, USA|c|;	37374054100;37280473500
	SciVis	13-13 Oct. 2000	Visualizing DIII-D Tokamak magnetic field lines	10.1109/VISUAL.2000.885742	http://dx.doi.org/10.1109/VISUAL.2000.885742	501	504	885742	data visualisation;physics computing;plasma toroidal confinement	DIII-D Tokamak magnetic field line visualization;Interactive speeds;OpenGL;hardware support	Data analysis;Data visualization;Hardware;Magnetic confinement;Magnetic fields;Physics;Plasma confinement;Plasma sources;Tokamaks;Toroidal magnetic fields		We demonstrate the use of a combination of perceptually effective techniques for visualizing magnetic field data from the DIII-D Tokamak. These techniques can be implemented to run very efficiently on machines with hardware support for OpenGL. Interactive speeds facilitate clear communication of magnetic field structure, enhancing fusion scientists' understanding of their data, and thereby accelerating their research.	Schussman, G.;Kwan-Liu Ma;Schissel, D.;Evans, T.	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;	37283639900;37275869400;37267819800;37428337500
	SciVis	13-13 Oct. 2000	Real-time visualization of the clear-up of a former US naval base	10.1109/VISUAL.2000.885743	http://dx.doi.org/10.1109/VISUAL.2000.885743	505	508	885743	data visualisation;military computing;naval engineering computing;real-time systems;underwater vehicles	Holy Loch;Scotland;Whole Field Modelling System;barges;clear-up operation;cranes;facilitated decision-making;former US nuclear submarine base;grabs;magnets;offshore working environment;real-time visualization;remotely operated vehicles;seabed topography;spatial awareness;temporal awareness;underwater environment	Boats;Computer graphics;Cranes;Real time systems;Remotely operated vehicles;Sonar;Transducers;Underwater vehicles;Visualization;Wires		The paper describes the effective real-time visualization of the clear-up operation of a former US nuclear submarine base, located in Holy Loch, Scotland. The Whole Field Modelling System has provided an extremely accurate real-time visualization of a large number of varying parameters such as remotely operated vehicles, cranes, barges, grabs, magnets, and detailed seabed topography. The system has improved the field staffs' spatial and temporal awareness of the underwater environment and facilitated decision-making within the complex offshore working environment.	Chapman, P.;Wills, D.;Stevens, P.;Brookes, G.	Sonar Res. & Dev. Ltd., Beverley, UK|c|;;;	37364789000;37368030400;37373315000;37372177500
	SciVis	13-13 Oct. 2000	Multi-resolution visualization techniques for nested weather models	10.1109/VISUAL.2000.885745	http://dx.doi.org/10.1109/VISUAL.2000.885745	513	516	885745	data visualisation;digital simulation;flow visualisation;geophysics computing;weather forecasting;wind	bandpass filtering;cloud-scale resolution;mesoscale weather models;multi-resolution meshes;multi-resolution visualization techniques;multi-resolution weather forecasting data;nested computational meshes;nested weather models;seed point identification;simulations;small-scale phenomena;streamline calculations;vector field visualization;wind fields	Animation;Application software;Atmospheric modeling;Computational modeling;Data visualization;Grid computing;Multiresolution analysis;Predictive models;Weather forecasting;Wind		Scaling of simulations challenges the effectiveness of conventional visualization methods. This problem becomes two-fold for mesoscale weather models that operate in near-real-time at cloud-scale resolution. For example, typical approaches to vector field visualization (e.g., wind) are based upon global methods, which may not illustrate detailed structure. In addition, such computations employ multi-resolution meshes to capture small-scale phenomena, which are not properly reflected in both vector and scalar realizations. To address the former critical point analysis and simple bandpass filtering of wind fields is employed for better seed point identification of streamline calculations. For the latter, an encapsulation of nested computational meshes is developed for general realization. It is then combined with the seed point calculation for an improved vector visualization of multi-resolution weather forecasting data.	Treinish, L.A.	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	37372175500
