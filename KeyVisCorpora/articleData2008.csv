Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis+SciVis	Nov.-Dec. 2008	Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation	10.1109/TVCG.2008.153	http://dx.doi.org/10.1109/TVCG.2008.153	1539	1148	4658123	computer animation;data visualisation	animated rotations;bounding volumes;multidimensional visual exploration;scatterplot matrix navigation;visual queries	Animation;Data visualization;Graphics;Light scattering;Multidimensional systems;Navigation;Optical polarization;Rendering (computer graphics);Visual analytics;Vocabulary	Index Terms&#8212;interaction;multivariate data;navigation;visual analytics;visual exploration;visual queries	Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.	Elmqvist, N.;Dragicevic, P.;Fekete, J.	INRIA, Paris|c|;;	37295438200;37590932700;37407972900
	InfoVis+SciVis	Nov.-Dec. 2008	A Framework of Interaction Costs in Information Visualization	10.1109/TVCG.2008.109	http://dx.doi.org/10.1109/TVCG.2008.109	1149	1156	4658124	data visualisation;user interfaces	information visualization;interaction cost;multiple input mode costs;physical-motion costs;state-change costs;system-power costs;view-change costs;visual-cluttering costs;visualization design	Costs;Crystallization;Encoding;Mice;Navigation;Particle measurements;Taxonomy;Usability;User interfaces;Visualization	Framework;Index Terms&#8212;Information Visualization;Interaction;Interface Evaluation	Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.	Lam, H.	Univ. of British Columbia, Vancouver, BC|c|	37873130000
	InfoVis+SciVis	Nov.-Dec. 2008	Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps	10.1109/TVCG.2008.114	http://dx.doi.org/10.1109/TVCG.2008.114	1157	1164	4658125	data visualisation;directed graphs	balloon focus;data query;data visualization;directed acyclic graph;multifocus+context method;treemaps	Computer interfaces;Computer science;Data visualization;Displays;File systems;Large-scale systems;Manuals;Navigation;Telecommunication traffic;Tree graphs	Index Terms&#8212;Treemap;fisheye;focus+context;magnification;multi-focus;multi-scale viewing.;visualizing query results	The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.	Ying Tu;Han-Wei Shen	Comput. Sci. & Eng. Dept., Ohio State Univ., Columbus, OH|c|;	37875062100;37279493500
	InfoVis+SciVis	Nov.-Dec. 2008	Multi-Focused Geospatial Analysis Using Probes	10.1109/TVCG.2008.149	http://dx.doi.org/10.1109/TVCG.2008.149	1165	1172	4658126	data visualisation;geographic information systems	3D GIS;agent-based social simulation;census data exploration tool;geospatial information visualizations;local inspection;multifocused geospatial analysis;probes;spatial awareness;user-defined regions-of-interest	Probes	Index Terms&#8212;Multiple-view techniques;focus + context;geospatial analysis;geospatial visualization;probes	Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.	Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.	Charlotte Visualization Center, UNC Charlotte, Charlotte, NC|c|;;;;	37591215700;37606064200;37297344900;37300425000;37592409400
	InfoVis+SciVis	Nov.-Dec. 2008	Distributed Cognition as a Theoretical Framework for Information Visualization	10.1109/TVCG.2008.121	http://dx.doi.org/10.1109/TVCG.2008.121	1173	1180	4658127	cognition;data visualisation	cognitive science;distributed cognition;information visualization;informing InfoVis design	Buildings;Cognition;Cognitive science;Data visualization;Distributed computing;Electronic mail;Guidelines;Humans;Performance evaluation;Testing	Index Terms&#8212;Information visualization;distributed cognition;interaction;representation;theory and methods	Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building.	Zhicheng Liu;Nersessian, N.J.;Stasko, J.T.	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA|c|;;	37592993600;37412991300;37267736900
	InfoVis+SciVis	Nov.-Dec. 2008	EMDialog: Bringing Information Visualization into the Museum	10.1109/TVCG.2008.127	http://dx.doi.org/10.1109/TVCG.2008.127	1181	1188	4658128	data visualisation;exhibitions;humanities;interactive systems	digital information display;information visualization;interaction technique;museum;visual representation	Art;Data visualization;Displays;Information analysis;Libraries;Space technology	Index Terms&#8212;artistic information visualization;interactive information visualization;public displays.;walk-up-and-use interaction	Digital information displays are becoming more common in public spaces such as museums, galleries, and libraries. However, the public nature of these locations requires special considerations concerning the design of information visualization in terms of visual representations and interaction techniques. We discuss the potential for, and challenges of, information visualization in the museum context based on our practical experience with EMDialog, an interactive information presentation that was part of the Emily Carr exhibition at the Glenbow Museum in Calgary. EMDialog visualizes the diverse and multi-faceted discourse about this Canadian artist with the goal to both inform and provoke discussion. It provides a visual exploration environment that offers interplay between two integrated visualizations, one for information access along temporal, and the other along contextual dimensions. We describe the results of an observational study we conducted at the museum that revealed the different ways visitors approached and interacted with EMDialog, as well as how they perceived this form of information presentation in the museum context. Our results include the need to present information in a manner sufficiently attractive to draw attention and the importance of rewarding passive observation as well as both short- and longer term information exploration.	Hinrichs, U.;Schmidt, H.;Carpendale, S.	Calgary Univ., Calgary, AB|c|;;	37869968000;37874733000;37285000100
	InfoVis+SciVis	Nov.-Dec. 2008	Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation	10.1109/TVCG.2008.137	http://dx.doi.org/10.1109/TVCG.2008.137	1189	1196	4658129	data visualisation;database management systems;user interfaces	Tableau;database visualization system;design space analysis;graphical history tools;information visualization;interactive history tools	Aggregates;Data analysis;Data visualization;History;Mice;Pattern analysis;Presses;Research and development;Usability;Visual databases	Index Terms&#8212;Visualization;analysis;evaluation;history;presentation;undo	Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.	Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.	Univ. of California at Berkeley, Berkeley, CA|c|;;;	37550791300;37372036700;37442008700;37282718200
	InfoVis+SciVis	Nov.-Dec. 2008	Who Votes For What? A Visual Query Language for Opinion Data	10.1109/TVCG.2008.187	http://dx.doi.org/10.1109/TVCG.2008.187	1197	1204	4658130	data visualisation;human computer interaction;query languages	bar graphs;data analysis;general election;interactive visualization;opinion data;pie charts;statistical graphics;tabular data sets;visual query language	Computer graphics;Data analysis;Data visualization;Database languages;Demography;Nominations and elections;Voting	Index Terms&#8212;Visual query languages;data analysis;human-computer interaction;radial visualization	Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.	Draper, G.;Riesenfeld, R.F.	Sch. of Comput., Univ. of Utah, Salt Lake City, UT|c|;	37869715500;37448812400
	InfoVis+SciVis	Nov.-Dec. 2008	VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery	10.1109/TVCG.2008.175	http://dx.doi.org/10.1109/TVCG.2008.175	1205	1212	4658131	Internet;data mining;data visualisation;information filters;online front-ends;query processing	VisGets;Web browser;Web resources;Web-based information discovery;Web-based information exploration;Web-based search interfaces;World Wide Web;data filters;dynamic search queries;interactive query visualizations	Computer science;Data visualization;Feeds;Information filtering;Information filters;Information retrieval;Prototypes;Semantic Web;Web search;Web sites	Index Terms&#8212;Information visualization;World Wide Web;exploratory search;information retrieval;visual information seeking.	In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.	Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.	Comput. Sci. Dept., Univ. of Calgary, Calgary, AB|c|;;;	;37285000100;37669874100;37276124700
	InfoVis+SciVis	Nov.-Dec. 2008	Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration	10.1109/TVCG.2008.178	http://dx.doi.org/10.1109/TVCG.2008.178	1213	1220	4658132	Internet;data integrity;data visualisation;search engines;semantic Web	Web;Web-based visualization system;Wikipedia data;data integration;fast path search algorithm;interactive visual exploration;search-based integration;semistructured data	Cleaning;Collaboration;Collaborative software;Costs;Data mining;Data visualization;Eyes;Iterative algorithms;Semantic Web;Wikipedia	Index Terms&#8212;Wikipedia;data integration;information visualization;search interface;semantic web	"Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the ""long tail"" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed."	Chan, B.;Wu, L.;Talbot, J.;Cammarano, M.;Hanrahan, P.	Stanford Univ., Stanford, CA|c|;;;;	37876908500;37877444800;37604514900;37870000300;37349803800
	InfoVis+SciVis	Nov.-Dec. 2008	The Word Tree, an Interactive Visual Concordance	10.1109/TVCG.2008.172	http://dx.doi.org/10.1109/TVCG.2008.172	1221	1228	4658133	data visualisation;document handling;information retrieval	Many Eyes;Word Tree;information-retrieval technique;interactive visual concordance;keyword-in-context method	Blogs;Computer displays;Data visualization;Drilling;Eyes;Feedback;Frequency;Information retrieval;Tree data structures;Tree graphs	Index Terms&#8212;Many Eyes;Text visualization;case study;concordance;document visualization;information retrieval;search.	"We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional ""keyword-in-context"" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization."	Wattenberg, M.	IBM Res., Cambridge, MA|c|	37550759700
	InfoVis+SciVis	Nov.-Dec. 2008	HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections	10.1109/TVCG.2008.138	http://dx.doi.org/10.1109/TVCG.2008.138	1229	1236	4658134	data mining;document handling	HiPP;analysis capability;document collections;hierarchical point placement strategy;visual knowledge discovery	Computational efficiency;Data mining;Data visualization;Displays;Multidimensional systems;Text analysis	Index Terms&#8212;Text and document visualization;hierarchical multidimensional visualization;high-dimensional data.;visual knowledge discovery	Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.	Paulovich, F.V.;Minghim, R.	Inst. de Cienc. Mat. e de Comput., Sao Paulo Univ., Sao Paulo|c|;	37590969400;37371567600
	InfoVis+SciVis	Nov.-Dec. 2008	Particle-based labeling: Fast point-feature labeling without obscuring other visual features	10.1109/TVCG.2008.152	http://dx.doi.org/10.1109/TVCG.2008.152	1237	1244	4658135	data visualisation	data visualization;fast point feature labeling;flexible 2D labeling;information visualization;non-occluding distant labels;particle-based labeling;point-feature label placement problem;visual features;visual representation	Clouds;Data visualization;Labeling;NP-hard problem;Pipelines;Shape;Solids;Space exploration	Index Terms&#8212;automatic label placement;dynamic labeling;information visualization;interactive labeling;occlusion-free	In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.	Luboschik, M.;Schumann, H.;Cords, H.	Univ. of Rostock, Rostock|c|;;	37869995900;37283240400;37869995100
	InfoVis+SciVis	Nov.-Dec. 2008	Stacked Graphs &#x02013; Geometry &amp; Aesthetics	10.1109/TVCG.2008.166	http://dx.doi.org/10.1109/TVCG.2008.166	1245	1252	4658136	data visualisation	aesthetics;communication-minded visualization;complex layered graph;geometry;layered graph;stacked graphs	Algorithm design and analysis;Blogs;Data visualization;Geometry;Graphics;History;Mathematical analysis;Motion pictures;Optimization methods;Process design	Index Terms&#8212;Streamgraph;ThemeRiver;aesthetics;communication-minded visualization;last.fm;listening history;time series	In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.	Byron, L.;Wattenberg, M.	New York Times, New York, NY|c|;	37868017200;37550759700
	InfoVis+SciVis	Nov.-Dec. 2008	Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context	10.1109/TVCG.2008.117	http://dx.doi.org/10.1109/TVCG.2008.117	1253	1260	4658137	biology computing;data visualisation;decision theory;graph theory;iterative methods;knowledge representation	biological system;cerebral tool;data information display;design decision;drawing package;dynamic knowledge representation;interaction graph layout;iterative process;living cells reaction observation;multiple experimental condition visualization	Biological system modeling;Biological systems;Cells (biology);Collaborative tools;Context modeling;Data analysis;Displays;Immune system;Performance analysis;Visualization	Graph layout;Index Terms&#8212;design study;small multiples;systems biology visualization	Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.	Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.	Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;	37869962900;37349490300;37869963200;37587984100
	InfoVis+SciVis	Nov.-Dec. 2008	The Shaping of Information by Visual Metaphors	10.1109/TVCG.2008.171	http://dx.doi.org/10.1109/TVCG.2008.171	1269	1276	4658138	data visualisation	information shaping;information visualization;internal knowledge representations;tree visualizations;visual metaphors	Cognition;Data visualization;Delay;Knowledge representation;Performance evaluation;Shape;Testing;Tree graphs;Usability	Cognition;Index Terms&#8212;evaluation;hierarchies;metaphors;visualization theory	The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.	Ziemkiewicz, C.;Kosara, R.	UNC, Charlotte, NC|c|;	37548028800;37282563400
	InfoVis+SciVis	Nov.-Dec. 2008	Viz-A-Vis: Toward Visualizing Video through Computer Vision	10.1109/TVCG.2008.185	http://dx.doi.org/10.1109/TVCG.2008.185	1261	1268	4658139	computer vision;data visualisation;video signal processing	Viz-A-Vis video visualization;automatic video analysis;computer vision;data aggregation;data segmentation;data table;information visualization procedural model;raw data transform	Computer vision;Visualization	Index Terms&#8212;Spatiotemporal visualization;image/video analytics;sensor analytics;time series data;video visualization	In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.	Romero, M.;Summet, J.;Stasko, J.;Abowd, G.	Georgia Tech, Atlanta, GA|c|;;;	37878399300;37300431800;37267736900;37297994200
	InfoVis+SciVis	Nov.-Dec. 2008	Geometry-Based Edge Clustering for Graph Visualization	10.1109/TVCG.2008.135	http://dx.doi.org/10.1109/TVCG.2008.135	1277	1284	4658140	computational geometry;data visualisation;graphs;pattern clustering	edge crossings;edge-clustering process;geometry-based edge clustering;graph visualization	Automatic control;Automatic generation control;Cities and towns;Data visualization;Displays;Mesh generation;Road transportation;Switches;Telecommunication traffic;Traffic control	Graph visualization;Index Terms&#8212;edge clustering;mesh;visual clutter	Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.	Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li	Hong Kong Univ. of Sci. & Technol., Kowloon|c|;;;;	37391623900;37405368200;37272637300;37280665600;37293190400
	InfoVis+SciVis	Nov.-Dec. 2008	On the Visualization of Social and other Scale-Free Networks	10.1109/TVCG.2008.151	http://dx.doi.org/10.1109/TVCG.2008.151	1285	1292	4658141	complex networks;data visualisation;graph theory;network theory (graphs);statistical distributions	computer graphics anisotropic shading;data visualization;dense crisscrossing array;edge semantics;graph filtering;node semantics;power-law distribution;scale-free network;social network;sociology	Anisotropic magnetoresistance;Computer graphics;Displays;Filtering;Filters;Layout;Social network services;Sociology;Stochastic processes;Visualization	Index Terms&#8212;Scale-free network;anisotropic shading;betweenness centrality;edge filtering	This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.	Yuntao Jia;Hoberock, J.;Garland, M.;Hart, J.C.	Illinois Univ., Urbana, IL|c|;;;	37532721900;37869982300;37272036400;37301161800
	InfoVis+SciVis	Nov.-Dec. 2008	Exploration of Networks using overview+detail with Constraint-based cooperative layout	10.1109/TVCG.2008.130	http://dx.doi.org/10.1109/TVCG.2008.130	1293	1300	4658142	data visualisation;graph theory	constrained graph layout algorithms;constraint-based cooperative layout;large network visualization;scalability fast force-based layout algorithms;sophisticated edge routing	Clustering algorithms;Heuristic algorithms;Network topology;Prototypes;Routing;Scalability;Stability;Technological innovation;Unified modeling language;Visualization	Graph drawing;Index Terms&#8212;constraints;force directed algorithms;multidimensional scaling.;stress majorization	A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.	Dwyer, T.;Marriott, K.;Schreiber, F.;Stuckey, P.;Woodward, M.;Wybrow, M.	Microsoft Res., Redmond, WA|c|;;;;;	37326161000;37354163600;37867195800;37372661500;37872168500;37867777700
	InfoVis+SciVis	Nov.-Dec. 2008	Rapid Graph Layout Using Space Filling Curves	10.1109/TVCG.2008.158	http://dx.doi.org/10.1109/TVCG.2008.158	1301	1308	4658143	computational complexity;data visualisation;graph theory	computational complexity;graph layout;graph visualization;node colocation;node-link diagrams;space filling curves	Clustering algorithms;Computational complexity;Data visualization;Filling;Lenses;Social network services;Tree graphs	Graph layout;Index Terms&#8212;Information visualization;Space filling curves	Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.	Muelder, C.;Kwan-Liu Ma	Univ. of California, Davis, CA|c|;	37299311900;37275869400
	InfoVis+SciVis	Nov.-Dec. 2008	Evaluating the Use of Data Transformation for Information Visualization	10.1109/TVCG.2008.129	http://dx.doi.org/10.1109/TVCG.2008.129	1309	1316	4658144	data visualisation;human computer interaction;human factors	data transformation techniques;data visualization;information visualization;user interaction;visualization quality	Cleaning;Data analysis;Data mining;Data visualization;Design methodology;Man machine systems;Sampling methods;Visual analytics	Index Terms&#8212;data cleaning;data transformation;empirical evaluation;user studies	Data transformation, the process of preparing raw data for effective visualization, is one of the key challenges in information visualization. Although researchers have developed many data transformation techniques, there is little empirical study of the general impact of data transformation on visualization. Without such study, it is difficult to systematically decide when and which data transformation techniques are needed. We thus have designed and conducted a two-part empirical study that examines how the use of common data transformation techniques impacts visualization quality, which in turn affects user task performance. Our first experiment studies the impact of data transformation on user performance in single-step, typical visual analytic tasks. The second experiment assesses the impact of data transformation in multi-step analytic tasks. Our results quantify the benefits of data transformation in both experiments. More importantly, our analyses reveal that (1) the benefits of data transformation vary significantly by task and by visualization, and (2) the use of data transformation depends on a user's interaction context. Based on our findings, we present a set of design recommendations that help guide the development and use of data transformation techniques.	Zhen Wen;Zhou, M.X.	IBM T. J. Watson Res. Center, Hawthorne, NY|c|;	37548307800;37399569300
	InfoVis+SciVis	Nov.-Dec. 2008	Improving the Readability of Clustered Social Networks using Node Duplication	10.1109/TVCG.2008.141	http://dx.doi.org/10.1109/TVCG.2008.141	1317	1324	4658145	data visualisation;graph theory;pattern clustering;social sciences computing	clustering method;graph readability;group actor;node duplication;social network visualization	Clustering;Communities;Layout;Social network services	Clustering;Graph Visualization;Index Terms&#8212;Node Duplications;Social Networks	Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.	Henr, N.;Bezerianos, A.;Fekete, J.	INRIA-LRI, Univ. of Sydney, Sydney, NSW|c|;;	;37413699200;37407972900
	InfoVis+SciVis	Nov.-Dec. 2008	Effectiveness of Animation in Trend Visualization	10.1109/TVCG.2008.125	http://dx.doi.org/10.1109/TVCG.2008.125	1325	1332	4658146	computer animation;data visualisation	Gapminder Trendalyzer;trend animation;trend visualization	Animation;Data analysis;Data visualization;Dictionaries;Displays	Index Terms&#8212;Information visualization;animation;design;experiment;trends	Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.	Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.	Microsoft Res., Redmond, WA|c|;;;;	37448060300;37603822300;37542391000;37293389400;37267736900
	InfoVis+SciVis	Nov.-Dec. 2008	Perceptual Organization in User-Generated Graph Layouts	10.1109/TVCG.2008.155	http://dx.doi.org/10.1109/TVCG.2008.155	1333	1339	4658147	data visualisation;graph theory	edge crossings;edge-lengths uniformity;network layout visualization;perceptual organization;user-generated graph layouts;visual representations	Algorithm design and analysis;Clustering algorithms;Communication networks;Concrete;Data visualization;Humans;Neural networks;Particle measurements;Performance analysis;Social network services	Index Terms&#8212;Network layout visualization;graph layout;perceptual organization;user studies	Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.	van Ham, F.;Rogowitz, B.	IBM Res., Cambridge|c|;	37882135400;37332114400
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Visual Analysis of Set-Typed Data	10.1109/TVCG.2008.144	http://dx.doi.org/10.1109/TVCG.2008.144	1340	1347	4658148	data analysis;data visualisation	CRM dataset;categorical data;data analysis;data visualization;heterogeneous datasets;interactive visual analysis;interactive visual exploration;multivariate datasets;numerical attributes;numerical strings;set-typed data	Cleaning;Computer Society;Data analysis;Data visualization;Focusing;Histograms;Information analysis;Multidimensional systems;Tensile stress;Videos	Categorical Data Visualization;Focus+Context Visualization;Index Terms&#8212;Interactive Visual Analysis;Interactive Visualization;Multidimensional Multivariate Data Visualization;Multiple Coordinated Views	While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.	Freiler, W.;Matkovic, K.;Hauser, H.	VRVis Res. Center, Vienna|c|;;	38017008700;38220979200;37274158800
	InfoVis+SciVis	Nov.-Dec. 2008	Spatially Ordered Treemaps	10.1109/TVCG.2008.165	http://dx.doi.org/10.1109/TVCG.2008.165	1348	1355	4658149	data visualisation;tree data structures	Flickr database;data order;geovisualization;locational consistency;spatially ordered treemaps;tessellated cartograms;visual ordering	Data visualization;Impedance;Informatics;Navigation;Spatial databases;Tree data structures;Tree graphs;Visual databases	CIELab;Cartograms;Geographic information;Geovisualization;Index Terms&#8212;Tree structures;Treemaps	Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.	Wood, J.;Dykes, J.	Sch. of Inf., City Univ. London, London|c|;	37399045100;37605079900
	InfoVis+SciVis	Nov.-Dec. 2008	Visualizing Incomplete and Partially Ranked Data	10.1109/TVCG.2008.181	http://dx.doi.org/10.1109/TVCG.2008.181	1356	1363	4658150	data visualisation;vectors	data ranking;discrete algebraic structure;incomplete data visualization;partially ranked data visualization;vector space	Computer science;Councils;Data visualization;Extraterrestrial measurements;Motion pictures;Multidimensional systems;Professional societies;Search engines;Statistics;Voting	Index Terms&#8212;Partial rankings;incomplete rankings;multidimensional scaling	Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.	Kidwell, P.;Lebanon, G.;Cleveland, W.S.	Dept. of Stat., Purdue Univ., West Lafayette, IN|c|;;	37865597100;37427770800;37282344300
	InfoVis+SciVis	Nov.-Dec. 2008	Texture-based Transfer Functions for Direct Volume Rendering	10.1109/TVCG.2008.169	http://dx.doi.org/10.1109/TVCG.2008.169	1364	1371	4658151	data visualisation;feature extraction;gradient methods;image classification;image colour analysis;image texture;rendering (computer graphics);transfer functions	direct volume rendering;feature classification;gradient value;texture-based transfer function;volumetric data face visualization	Biomedical imaging;Computer science;Data visualization;Image color analysis;Image segmentation;Lungs;Probes;Statistical analysis;Transfer functions;Visual system	Index Terms&#8212;data variability;medical imaging;statistical analysis;visualization;volume rendering	Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.	Caban, J.J.;Rheingans, P.	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	37541275000;37282292000
	InfoVis+SciVis	Nov.-Dec. 2008	Volume MLS Ray Casting	10.1109/TVCG.2008.186	http://dx.doi.org/10.1109/TVCG.2008.186	1372	1379	4658152	data visualisation;least squares approximations;ray tracing;rendering (computer graphics)	adaptive preintegration scheme;continuous functions;function evaluations;high-quality shading effects;high-quality volume integration;irregular grids;modern graphics hardware;moving least squares;shaded isosurface;volume MLS ray casting	Casting;Data visualization;Graphics;Image reconstruction;Interpolation;Isosurfaces;Least squares methods;Multilevel systems;Rendering (computer graphics);Scattering	Adaptive Integration;Index Terms&#8212;Moving Least Squares Reconstruction;Unstructured Grids;Volume Visualization	The method of Moving Least Squares (MLS) is a popular framework for reconstructing continuous functions from scattered data due to its rich mathematical properties and well-understood theoretical foundations. This paper applies MLS to volume rendering, providing a unified mathematical framework for ray casting of scalar data stored over regular as well as irregular grids. We use the MLS reconstruction to render smooth isosurfaces and to compute accurate derivatives for high-quality shading effects. We also present a novel, adaptive preintegration scheme to improve the efficiency of the ray casting algorithm by reducing the overall number of function evaluations, and an efficient implementation of our framework exploiting modern graphics hardware. The resulting system enables high-quality volume integration and shaded isosurface rendering for regular and irregular volume data.	Ledergerber, C.;Guennebaud, G.;Meyer, M.;Pfister, H.	Harvard Univ., Cambridge, MA|c|;;;	37869733800;37869737100;37564728700;37275698100
	InfoVis+SciVis	Nov.-Dec. 2008	Size-based Transfer Functions: A New Volume Exploration Technique	10.1109/TVCG.2008.162	http://dx.doi.org/10.1109/TVCG.2008.162	1380	1387	4658153	data visualisation;image classification;image representation;image segmentation;opacity;rendering (computer graphics);transfer functions	3D fields;complex 3D images;complex data exploration;detection filters;interactive rates;maximum intensity projection;size-based transfer functions;transfer functions;volume exploration technique	Aneurysm;Angiography;Arteries;Cancer detection;Data visualization;Frequency;Image segmentation;Neoplasms;Transfer functions;Veins	GPU Techniques;Index Terms&#8212;Interactive Visualization;Scale Space;Transfer Functions;Volume Rendering	The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.	Correa, C.;Kwan-Liu Ma	Univ. of California, Davis, CA|c|;	37282925900;37275869400
	InfoVis+SciVis	Nov.-Dec. 2008	Direct Volume Editing	10.1109/TVCG.2008.120	http://dx.doi.org/10.1109/TVCG.2008.120	1388	1395	4658154	colour graphics;image colour analysis;image resolution;image texture;rendering (computer graphics)	3D spherical brushes;Cartesian grids;GPU;artefact removal;direct volume editing;hole filling;interactive structure isolation;interactive volume editing;paint metaphor;surface painting;texture resolution;volume annotation;volume augmentation;volume resolution	Biomedical imaging;Brushes;Buildings;Data visualization;Engineering in medicine and biology;Filling;Graphics;Painting;Paints;Rendering (computer graphics)	GPU;Index Terms&#8212;Volume editing;annotations;carving;painting	In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.	Burger, K.;Westermann, R.	Tech. Univ. Munchen, Munich|c|;	;37444424000
	InfoVis+SciVis	Nov.-Dec. 2008	Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments	10.1109/TVCG.2008.163	http://dx.doi.org/10.1109/TVCG.2008.163	1396	1403	4658155	computational fluid dynamics;data visualisation;flow visualisation;interactive systems;rendering (computer graphics);smoke	interactive flow visualization;semitransparent streak surface;smoke rendering	Data visualization;Gases;Image motion analysis;Rendering (computer graphics);Shape;Surface structures;Testing;Topology;Wool	Index Terms&#8212;Unsteady flow visualization;smoke visualization.;streak surfaces	Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.	von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.	MPI Informatlk, Saarbrucken|c|;;;	37869714300;37282635100;37266875400;37271851300
	InfoVis+SciVis	Nov.-Dec. 2008	Generation of Accurate Integral Surfaces in Time-Dependent Vector Fields	10.1109/TVCG.2008.133	http://dx.doi.org/10.1109/TVCG.2008.133	1404	1411	4658156	data visualisation	graphical representation;integral surfaces;iterative refinement;surface approximation;time-dependent vector fields	Analytical models;Computational fluid dynamics;Computational modeling;Data analysis;Electronic mail;Fluid flow measurement;Iterative algorithms;Skeleton;Surface treatment;Visualization	3D vector field visualization;Index Terms&#8212;flow visualization;surface extraction;time-varying and time-series visualization	We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.	Garth, C.;Krishnan, H.;Tricoche, X.;Joy, K.I.	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA|c|;;;	37282573700;37866882400;37282575100;37267811400
	InfoVis+SciVis	Nov.-Dec. 2008	Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes	10.1109/TVCG.2008.183	http://dx.doi.org/10.1109/TVCG.2008.183	1412	1427	4658157	data visualisation;flow visualisation;medical computing;vortices	bronchial tubes;finite-time Lyapunov exponent maps;particle deposition;particle destination maps;particle/flow structure interaction visualization;vortex-dominated secondary flows	Aerospace simulation;Computational modeling;Computer simulation;Fluid dynamics;Fluid flow;Geometry;Lungs;Solid modeling;Trajectory;Visualization	FTLE;Index Terms&#8212;bronchial tube;particle trajectory;visualization	Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.	Soni, B.;Thompson, D.;Machiraju, R.	Mississippi State Univ., Oxford, MS|c|;;	37866648000;38181602100;37269516700
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Visualization and Analysis of Transitional Flow	10.1109/TVCG.2008.146	http://dx.doi.org/10.1109/TVCG.2008.146	1420	1427	4658158	boundary layers;cache storage;computational fluid dynamics;data visualisation;flow simulation;flow visualisation;interactive systems;laminar flow;turbulence	caching computation;data management;feature detection;flow simulation;interactive visualization;laminar flow;transitional flow analysis;turbulent flow	Collaboration;Computer vision;Data analysis;Data visualization;Fluctuations;Fluid flow;Fluid flow control;Large-scale systems;Navigation;Stochastic processes	Applications of Visualization;Flow Visualization;Index Terms&#8212;Transitional Flow;Turbulence	A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.	Johnson, G.P.;Calo, V.M.;Gaither, K.P.	Texas Adv. Comput. Center, Univ. of Texas, Austin, TX|c|;;	37269399700;37282574300;37282571800
	InfoVis+SciVis	Nov.-Dec. 2008	Continuous Scatterplots	10.1109/TVCG.2008.119	http://dx.doi.org/10.1109/TVCG.2008.119	1428	1435	4658159	computational geometry;data visualisation;interpolation;statistical analysis	3D tetrahedral grid;continuous histogram;continuous scatterplot;data attribute domain;data variable;dense plot;discrete data value visualization;discrete point;generic mathematical model;interpolation;isosurface statistical histogram;spatial grid domain	Computer Society;Data visualization;Displays;Frequency;Histograms;Interpolation;Isosurfaces;Mathematical model;Scattering;Statistics	Index Terms&#8212;Scatterplot;continuous frequency plot;histogram;interpolation	Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.	Bachthaler, S.;Weiskopf, D.	Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;	37869985900;37268045000
	InfoVis+SciVis	Nov.-Dec. 2008	Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets	10.1109/TVCG.2008.131	http://dx.doi.org/10.1109/TVCG.2008.131	1436	1451	4658160	data compression;data visualisation;rendering (computer graphics);statistical distributions	GPU-based rendering;Hurricane Isabel;cumulus clouds;data compression;data quantization;information visualization;ionization front instability data set;joint density distributions;large-eddy simulation;multitimepoint volumetric data sets;parallel coordinate plots	Clouds;Data analysis;Data preprocessing;Data visualization;Hurricanes;Ionization;Quantization;Scalability;Scattering;Usability	Index Terms&#8212;Parallel coordinate plots;linked related views.;multi-field;time-varying	Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.	Blaas, J.;Botha, C.P.;Post, F.H.	Data Visualization Group, Delft Univ. of Technol., Delft|c|;;	37550793100;37373834100;37295045800
	InfoVis+SciVis	Nov.-Dec. 2008	Vectorized Radviz and Its Application to Multiple Cluster Datasets	10.1109/TVCG.2008.173	http://dx.doi.org/10.1109/TVCG.2008.173	1444	1427	4658161	computational geometry;data visualisation;pattern clustering	circle circumference;data cluster ensemble;data flattening;dimensional anchor;multiple cluster dataset;vectorized radviz radial visualization	Clustering algorithms;Data visualization;Displays;Heuristic algorithms;Iris;Partitioning algorithms;Voting	Cluster Ensembles;Clustering;Flattening Datasets;Index Terms&#8212;Multiple Clustering;Radviz;Vectorized Radviz;Visualization	Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.	Sharko, J.;Grinstein, G.;Marx, K.A.	Dept. of Comput. Sci., Univ. of Massachusetts - Lowell, Lowell, MA|c|;;	37869996300;37360588500;37606703800
	InfoVis+SciVis	Nov.-Dec. 2008	Effective Visualization of Short Routes	10.1109/TVCG.2008.124	http://dx.doi.org/10.1109/TVCG.2008.124	1452	1458	4658162	cartography;data visualisation;realistic images;rendering (computer graphics);solid modelling	3D model;map depiction;realistic image;short route visualization;warped rendering	Computer graphics;Humans;Image generation;Layout;Navigation;Psychology;Rendering (computer graphics);Shape;Visualization	Index Terms&#8212;Maps;Route visualization;Space deformation	In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.	Degener, P.;Schnabel, R.;Schwartz, C.;Klein, R.	Comput. Graphics Group, Univ. of Bonn, Bonn|c|;;;	37870005900;37867979100;37719871100;37271619700
	InfoVis+SciVis	Nov.-Dec. 2008	Brushing of Attribute Clouds for the Visualization of Multivariate Data	10.1109/TVCG.2008.116	http://dx.doi.org/10.1109/TVCG.2008.116	1459	1466	4658163	data visualisation	high-dimensional data;manifold learning;multivariate data visualization;multivariate density estimation;visual clutter	Clouds;Data visualization;Fluid dynamics;Principal component analysis;Scattering;Temperature	Index Terms&#8212;Multivariate data;brushing;data transformation;linked views.;manifold learning	The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.	Janicke, H.;Scheuermann, G.	Univ. of Leipzig, Leipzig|c|;	;37282574800
	InfoVis+SciVis	Nov.-Dec. 2008	Visualizing Temporal Patterns in Large Multivariate Data using Modified Globbing	10.1109/TVCG.2008.184	http://dx.doi.org/10.1109/TVCG.2008.184	1467	1474	4658164	data visualisation;pattern matching	large multivariate data visualization;large scientific data;large time-dependent data set;temporal pattern extraction;temporal pattern visualization;textual pattern matching	Capacitive sensors;Computational modeling;Data mining;Data visualization;Displays;Large-scale systems;Pattern matching;Scalability;Testing;Uncertainty	Index Terms&#8212;Multivariate visualization;Time-varying;Uncertainty	Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.	Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu	Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;	37828700000;37281262900;37410066100;37672397100;37545504600
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Comparison of Scalar Fields Based on Largest Contours with Applications to Flow Visualization	10.1109/TVCG.2008.143	http://dx.doi.org/10.1109/TVCG.2008.143	1475	1482	4658165	computer graphics;edge detection;flow visualisation	complex fluid flow datasets;contour segmentation;contour trees;flow visualization;scalar fields;topological simplification;volumetric similarity measure	Computer vision;Data mining;Data visualization;Fluid flow;Isosurfaces;Navigation;Shape;Topology;Tree graphs;Volume measurement	Index Terms&#8212;Scalar topology;comparative visualization;contour tree;flow visualization;largest contours	Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.	Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.	Leipzig Univ., Leipzig|c|;;;;	37869538100;37565763400;37282624500;37403333700;37282574800
	InfoVis+SciVis	Nov.-Dec. 2008	Surface Extraction from Multi-field Particle Volume Data Using Multi-dimensional Cluster Visualization	10.1109/TVCG.2008.167	http://dx.doi.org/10.1109/TVCG.2008.167	1483	1490	4658166	astronomy computing;data visualisation;feature extraction;pattern clustering;rendering (computer graphics)	3D star coordinate layout;astrophysical simulation;automated multidimensional hierarchical clustering method;information visualization;multidimensional cluster visualization;multidimensional feature space exploration;multifield particle volume data visualization;multivariate function;object-space operation;point-based rendering;scientific visualization;smoothed particle hydrodynamic simulation;surface extraction;surface segmentation	Astrophysics;Clustering methods;Computational modeling;Data mining;Data visualization;Hydrodynamics;Interpolation;Level set;Sampling methods;Space exploration	Index Terms&#8212;Multi-field and multi-variate visualization;isosurfaces and surface extraction;particle simulations.;point-based visualization;star coordinates;visualization in astrophysics	Data sets resulting from physical simulations typically contain a multitude of physical variables. It is, therefore, desirable that visualization methods take into account the entire multi-field volume data rather than concentrating on one variable. We present a visualization approach based on surface extraction from multi-field particle volume data. The surfaces segment the data with respect to the underlying multi-variate function. Decisions on segmentation properties are based on the analysis of the multi-dimensional feature space. The feature space exploration is performed by an automated multi-dimensional hierarchical clustering method, whose resulting density clusters are shown in the form of density level sets in a 3D star coordinate layout. In the star coordinate layout, the user can select clusters of interest. A selected cluster in feature space corresponds to a segmenting surface in object space. Based on the segmentation property induced by the cluster membership, we extract a surface from the volume data. Our driving applications are smoothed particle hydrodynamics (SPH) simulations, where each particle carries multiple properties. The data sets are given in the form of unstructured point-based volume data. We directly extract our surfaces from such data without prior resampling or grid generation. The surface extraction computes individual points on the surface, which is supported by an efficient neighborhood computation. The extracted surface points are rendered using point-based rendering operations. Our approach combines methods in scientific visualization for object-space operations with methods in information visualization for feature-space operations.	Linsen, L.;Rosenthal, P.;Rosswog, S.	Sch. of Eng. & Sci., Jacobs Univ., Bremen|c|;;	37266826500;37643113600;37869996100
	InfoVis+SciVis	Nov.-Dec. 2008	Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy	10.1109/TVCG.2008.161	http://dx.doi.org/10.1109/TVCG.2008.161	1491	1498	4658167	data visualisation;endoscopes;medical image processing;rendering (computer graphics);surgery;virtual reality	ENT surgeons;advanced GPU volume rendering;endoscopic sinus surgery;graphical processing unit;image quality;individual patient datasets;risk structures;sinus endoscopy system;virtual endoscopic system	Biomedical optical imaging;Computer graphics;Endoscopes;Image quality;Image segmentation;Rendering (computer graphics);Skull;Surgery;System analysis and design;Visualization	Index Terms&#8212;medical visualization;operationplanning;sinus surgery;virtual endoscopy;volume rendering	For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.	Kruger, A.;Kubisch, C.;Preim, B.;Preim, B.	Dept. of Simulation & Graphics, Otto-von-Guericke-Univ. of Magdeburg, Magdeburg|c|;;;	;37869714800;37424645300;37866137400
	InfoVis+SciVis	Nov.-Dec. 2008	Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease	10.1109/TVCG.2008.136	http://dx.doi.org/10.1109/TVCG.2008.136	1499	1506	4658168	cardiology;data visualisation;diseases;medical image processing;single photon emission computed tomography	3D glyph visualization;coronary artery disease;coronary vessels stenoses;glyph-based SPECT visualization;left-ventricular myocardium;multivariate data set;myocardial perfusion imaging;single photon emission computed tomography	Acceleration;Arteries;Blood;Coronary arteriosclerosis;Data visualization;Heart;Myocardium;Positron emission tomography;Single photon emission computed tomography;Stress	Index Terms&#8212;Multivariate visualization;SPECT;glyph techniques;myocardial perfusion imaging	Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.	Meyer-Spradow, J.;Stegger, L.;Ropinski, T.;Hinrichs, K.	Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster|c|;;;	37869986400;37273031400;37295281400;37267218300
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Volume Exploration for Feature Detection and Quantification in Industrial CT Data	10.1109/TVCG.2008.147	http://dx.doi.org/10.1109/TVCG.2008.147	1507	1514	4658169	computerised tomography;data visualisation;engineering graphics;feature extraction;flaw detection;image classification;inspection;production engineering computing;rendering (computer graphics)	3D transfer function;cast metal part;defect detection;feature classification;feature detection;interactive industrial CT volume exploration;nondestructive testing;region growing;visualization-driven approach;volume rendering	Automotive engineering;Building materials;Computed tomography;Computer vision;Construction industry;Data visualization;Manufacturing industries;Metals industry;Nondestructive testing;Transfer functions	Index Terms&#8212;Multi-Dimensional Transfer Functions;Non-Destructive Testing;Region Growing;Volume Rendering	This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.	Hadwiger, M.;Rezk-Salama, C.;Geier, G.;Pabel, T.	VRVis Res. Center, Vienna|c|;;;	37394809600;37404228800;37869963700;37869964100
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Blood Damage Analysis for Ventricular Assist Devices	10.1109/TVCG.2008.142	http://dx.doi.org/10.1109/TVCG.2008.142	1515	1522	4658170	blood vessels;cardiovascular system;cellular biophysics;data visualisation;medical computing;orthotics;tensors;user interfaces;virtual reality	blood cell deformation;degenerative disease;fluid flow;function plotting;illness;interactive blood damage analysis;particle tracing;particle visualization;scalar data visualization method;tensor-based blood damage prediction model;ventricular assist device;virtual reality-based user interface	Biological system modeling;Blood;Computer simulation;Data visualization;Degenerative diseases;Fluid flow;Heart;Humans;Maintenance engineering;Tensile stress	Index Terms&#8212;Tensor visualization;blood damage;time-dependent data;ventricular assist device;virtual reality	Ventricular Assist Devices (VADs) support the heart in its vital task of maintaining circulation in the human body when the heart alone is not able to maintain a sufficient flow rate due to illness or degenerative diseases. However, the engineering of these devices is a highly demanding task. Advanced modeling methods and computer simulations allow the investigation of the fluid flow inside such a device and in particular of potential blood damage. In this paper we present a set of visualization methods which have been designed to specifically support the analysis of a tensor-based blood damage prediction model. This model is based on the tracing of particles through the VAD, for each of which the cumulative blood damage can be computed. The model's tensor output approximates a single blood cell's deformation in the flow field. The tensor and derived scalar data are subsequently visualized using techniques based on icons, particle visualization, and function plotting. All these techniques are accessible through a Virtual Reality-based user interface, which features not only stereoscopic rendering but also natural interaction with the complex three-dimensional data. To illustrate the effectiveness of these visualization methods, we present the results of an analysis session that was performed by domain experts for a specific data set for the MicroMed DeBakey VAD.	Hentschel, B.;Tedjo, I.;Probst, M.;Wolter, M.;Behr, M.;Bischof, C.;Kuhlen, T.	Virtual Reality Group, RWTH Aachen Univ., Aachen|c|;;;;;;	37680074400;37870001300;37867688300;37666649000;37865964700;37330529700;37391845800
	InfoVis+SciVis	Nov.-Dec. 2008	Box Spline Reconstruction On The Face-Centered Cubic Lattice	10.1109/TVCG.2008.115	http://dx.doi.org/10.1109/TVCG.2008.115	1523	1530	4658171	approximation theory;computational geometry;data visualisation;image reconstruction;image sampling;splines (mathematics)	6-direction box spline reconstruction algorithm;face-centered cubic lattice;face-centered cubic sampled data;triquadratic B-spline approximation order;volumetric data visualization	Algorithm design and analysis;Approximation algorithms;FCC;Filters;Lattices;Level set;Reconstruction algorithms;Sampling methods;Signal resolution;Spline	Face-Centered Cubic lattice;Index Terms&#8212;box spline;volumetric data reconstruction	We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.	Minho Kim;Entezari, A.;Peters, J.	CISE Dept., Univ. of Florida, Gainesville, FL|c|;;	37878688900;37268675600;37288759800
	InfoVis+SciVis	Nov.-Dec. 2008	Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs	10.1109/TVCG.2008.164	http://dx.doi.org/10.1109/TVCG.2008.164	1531	1546	4658172	convergence of numerical methods;data visualisation;feature extraction;gradient methods;least squares approximations;partial differential equations;rendering (computer graphics);surface fitting	PDE;auxiliary function;convergence;explicit Euler time integration;four-dimensional least-squares fitting;gradient estimation;mean curvature;partial differential equation;point-based rendering;regular structured grid;scalar field;signed distance function;smooth surface extraction;unstructured point-based volume data visualization	Convergence;Data mining;Data visualization;Information retrieval;Isosurfaces;Jacobian matrices;Mesh generation;Partial differential equations;Sensor systems;Surface fitting	Index Terms&#8212;PDEs;level sets;point-based visualization;surface extraction	Smooth surface extraction using partial differential equations (PDEs) is a well-known and widely used technique for visualizing volume data. Existing approaches operate on gridded data and mainly on regular structured grids. When considering unstructured point-based volume data where sample points do not form regular patterns nor are they connected in any form, one would typically resample the data over a grid prior to applying the known PDE-based methods. We propose an approach that directly extracts smooth surfaces from unstructured point-based volume data without prior resampling or mesh generation. When operating on unstructured data one needs to quickly derive neighborhood information. The respective information is retrieved by partitioning the 3D domain into cells using a fed-tree and operating on its cells. We exploit neighborhood information to estimate gradients and mean curvature at every sample point using a four-dimensional least-squares fitting approach. Gradients and mean curvature are required for applying the chosen PDE-based method that combines hyperbolic advection to an isovalue of a given scalar field and mean curvature flow. Since we are using an explicit time-integration scheme, time steps and neighbor locations are bounded to ensure convergence of the process. To avoid small global time steps, one can use asynchronous local integration. We extract a smooth surface by successively fitting a smooth auxiliary function to the data set. This auxiliary function is initialized as a signed distance function. For each sample and for every time step we compute the respective gradient, the mean curvature, and a stable time step. With these informations the auxiliary function is manipulated using an explicit Euler time integration. The process successively continues with the next sample point in time. If the norm of the auxiliary function gradient in a sample exceeds a given threshold at some time, the auxiliary function is reinitialized to a signed dista- - nce function. After convergence of the evolvution, the resulting smooth surface is obtained by extracting the zero isosurface from the auxiliary function using direct isosurface extraction from unstructured point-based volume data and rendering the extracted surface using point-based rendering methods.	Rosenthal, P.;Linsen, L.	Jacobs Univ. Bremen, Bremen|c|;	37643113600;37266826500
	InfoVis+SciVis	Nov.-Dec. 2008	Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes	10.1109/TVCG.2008.154	http://dx.doi.org/10.1109/TVCG.2008.154	1539	1546	4658173	computational geometry;data visualisation;mathematics computing;mesh generation;sampling methods	Delaunay-based meshing algorithms;labeled volume data;material intersections;multimaterial volumes;nonmanifold geometry;particle-based sampling	Biological materials;Biomedical materials;Data mining;Data visualization;Geometry;Geophysics computing;Magnetic resonance imaging;Sampling methods;Scientific computing;Solid modeling	Index Terms&#8212;Sampling;meshing;visualizations	Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.	Meyer, M.;Whitaker, R.;Kirby, R.M.;Ledergerber, C.;Pfister, H.	Initiative in Innovative Comput., Harvard Univ., Cambridge, MA|c|;;;;	37564728700;37267322600;37275716100;37869733800;37275698100
	InfoVis+SciVis	Nov.-Dec. 2008	Importance-Driven Time-Varying Data Visualization	10.1109/TVCG.2008.140	http://dx.doi.org/10.1109/TVCG.2008.140	1547	1554	4658174	data visualisation;entropy;pattern classification;pattern clustering	block-wise analysis;conditional entropy;feature-temporal space;importance-driven time-varying volume data visualization;information theory	Chaos;Data analysis;Data engineering;Data visualization;Earthquakes;Entropy;Information analysis;Information theory;Time measurement;Transfer functions	Index Terms&#8212;Time-varying data;clustering;conditional entropy;highlighting;joint feature-temporal space;transfer function.	The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.	Chaoli Wang;Hongfeng Yu;Kwan-Liu Ma	Dept. of Comput. Sci., Univ. of California, Davis, CA|c|;;	37405886900;37401024100;37275869400
	InfoVis+SciVis	Nov.-Dec. 2008	Visualizing Multiwavelength Astrophysical Data	10.1109/TVCG.2008.182	http://dx.doi.org/10.1109/TVCG.2008.182	1555	1562	4658175	astronomical image processing;data visualisation	2D celestial sphere;GPU-based interactive feature analysis;GPU-based volume visualization;allsky astrophysical imaging;broad electromagnetic spectrum;data processing;graphics processing unit;horseshoe representation;mini-map explorer;multiwavelength astrophysical data visualization;multiwavelength visualization techniques;textured image stacks	Data visualization;Detectors;Electromagnetic measurements;Electromagnetic spectrum;Extraterrestrial measurements;Frequency;Gamma rays;Image converters;Optical imaging;X-rays	Astrophysical visualization;Index Terms&#8212;astronomy;multiwavelength data	With recent advances in the measurement technology for allsky astrophysical imaging, our view of the sky is no longer limited to the tiny visible spectral range over the 2D Celestial sphere. We now can access a third dimension corresponding to a broad electromagnetic spectrum with a wide range of allsky surveys; these surveys span frequency bands including long long wavelength radio, microwaves, very short X-rays, and gamma rays. These advances motivate us to study and examine multiwavelength visualization techniques to maximize our capabilities to visualize and exploit these informative image data sets. In this work, we begin with the processing of the data themselves, uniformizing the representations and units of raw data obtained from varied detector sources. Then we apply tools to map, convert, color-code, and format the multiwavelength data in forms useful for applications. We explore different visual representations for displaying the data, including such methods as textured image stacks, the horseshoe representation, and GPU-based volume visualization. A family of visual tools and analysis methods are introduced to explore the data, including interactive data mapping on the graphics processing unit (GPU), the mini-map explorer, and GPU-based interactive feature analysis.	Hongwei Li;Chi-Wing Fu;Hanson, A.J.	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;	37881121400;37336329800;37333439100
	InfoVis+SciVis	Nov.-Dec. 2008	Visiting the G&#x0F6;del Universe	10.1109/TVCG.2008.177	http://dx.doi.org/10.1109/TVCG.2008.177	1563	1570	4658176	data visualisation;general relativity;physics computing;rendering (computer graphics);space-time configurations	Einstein field equations;Godel universe;general relativity;image quality;relativistic visualization;relativistic world model;rendering process	Dielectrics;Equations;History;Image generation;Image quality;Lighting;Optical propagation;Rendering (computer graphics);Table lookup;Visualization	Gdel universe;General relativity;Index Terms&#8212;nonlinear ray tracing;time travel.	Visualization of general relativity illustrates aspects of Einstein's insights into the curved nature of space and time to the expert as well as the layperson. One of the most interesting models which came up with Einstein's theory was developed by Kurt Godel in 1949. The Godel universe is a valid solution of Einstein's field equations, making it a possible physical description of our universe. It offers remarkable features like the existence of an optical horizon beyond which time travel is possible. Although we know that our universe is not a Godel universe, it is interesting to visualize physical aspects of a world model resulting from a theory which is highly confirmed in scientific history. Standard techniques to adopt an egocentric point of view in a relativistic world model have shortcomings with respect to the time needed to render an image as well as difficulties in applying a direct illumination model. In this paper we want to face both issues to reduce the gap between common visualization standards and relativistic visualization. We will introduce two techniques to speed up recalculation of images by means of preprocessing and lookup tables and to increase image quality through a special optimization applicable to the Godel universe. The first technique allows the physicist to understand the different effects of general relativity faster and better by generating images from existing datasets interactively. By using the intrinsic symmetries of Godel's spacetime which are expressed by the Killing vector field, we are able to reduce the necessary calculations to simple cases using the second technique. This even makes it feasible to account for a direct illumination model during the rendering process. Although the presented methods are applied to Godel's universe, they can also be extended to other manifolds, for example light propagation in moving dielectric media. Therefore, other areas of research can benefit from these generic improvements.	Grave, F.;Buser, M.	Inst. for Theor. Phys. & VISUS, Univ. of Stuttgart, Stuttgart|c|;	37565762400;37869988300
	InfoVis+SciVis	Nov.-Dec. 2008	The Seismic Analyzer: Interpreting and Illustrating 2D Seismic Data	10.1109/TVCG.2008.170	http://dx.doi.org/10.1109/TVCG.2008.170	1571	1578	4658177	data visualisation;oil technology;seismology	2D seismic data;hydrocarbon reservoirs;rendering algorithms;seismic analyzer;seismic illustrators;seismic interpreters;seismic structures;seismic volumetric reflection data;texture transfer functions	Boring;Data visualization;Drilling;Energy consumption;Geophysical measurements;Hydrocarbon reservoirs;Petroleum;Reflection;Seismic measurements;Transfer functions	Illustrative rendering;Index Terms&#8212;Seismic attributes;Seismic interpretation;Top-down interpretation	We present a toolbox for quickly interpreting and illustrating 2D slices of seismic volumetric reflection data. Searching for oil and gas involves creating a structural overview of seismic reflection data to identify hydrocarbon reservoirs. We improve the search of seismic structures by precalculating the horizon structures of the seismic data prior to interpretation. We improve the annotation of seismic structures by applying novel illustrative rendering algorithms tailored to seismic data, such as deformed texturing and line and texture transfer functions. The illustrative rendering results in multi-attribute and scale invariant visualizations where features are represented clearly in both highly zoomed in and zoomed out views. Thumbnail views in combination with interactive appearance control allows for a quick overview of the data before detailed interpretation takes place. These techniques help reduce the work of seismic illustrators and interpreters.	Patel, D.;Giertsen, C.;Thurmond, J.;Gjelberg, J.	Christian Michelsen Res., Bergen|c|;;;	37402844200;37884872900;37869961500;37869959900
	InfoVis+SciVis	Nov.-Dec. 2008	Hypothesis Generation in Climate Research with Interactive Visual Data Exploration	10.1109/TVCG.2008.139	http://dx.doi.org/10.1109/TVCG.2008.139	1579	1586	4658178	climatology;data analysis;geophysics computing	ECHAM5 climate model;ERA-40 reanalysis;climate change;climate research;computational data analysis;hypothesis generation;interactive visual data exploration;subsequent statistical evaluation	Atmosphere;Atmospheric measurements;Data analysis;Data visualization;Extraterrestrial measurements;Geophysical measurements;Robustness;Satellites;Signal to noise ratio;Weather forecasting	Index Terms&#8212;interactive visual exploration and analysis;interactive visual hypothesis generation;visualization for climate research.	One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.	Kehrer, J.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.	Dept. of Inf., Bergen Univ., Bergen|c|;;;;	37546620000;37546620600;37546620400;37884365600;37274158800
	InfoVis+SciVis	Nov.-Dec. 2008	Novel interaction techniques for neurosurgical planning and stereotactic navigation	10.1109/TVCG.2008.150	http://dx.doi.org/10.1109/TVCG.2008.150	1587	1594	4658179	data visualisation;medical computing;rendering (computer graphics);surgery	3D volume rendering;functional MRI;image guided neurosurgery;image-guided neurosurgery;magnetic resonance imaging;multimodal data visualization;neurosurgeons;neurosurgical planning;single photon emission computed tomography;stereotactic navigation;structural image modalities	Computed tomography;Data visualization;Electrodes;Epilepsy;Magnetic resonance imaging;Navigation;Neurosurgery;Shape control;Single photon emission computed tomography;Surgery	Index Terms&#8212;Irregular cropping;Multimodal visualization;User interaction	Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.	Joshi, A.;Scheinost, D.;Vives, K.P.;Spencer, D.D.;Staib, L.H.;Papademetris, X.	Dept. of Diagnostic Radiol., Yale Sch. of Med., New Haven, CT|c|;;;;;	37278517400;37869717400;37294407100;37290937600;37284143200;37294174000
	InfoVis+SciVis	Nov.-Dec. 2008	Visualization of Myocardial Perfusion Derived from Coronary Anatomy	10.1109/TVCG.2008.180	http://dx.doi.org/10.1109/TVCG.2008.180	1595	1602	4658180	blood;cardiology;data visualisation;diseases;medical diagnostic computing	3D anatomical tomographic scan;blood supply;coronary anatomy;coronary artery anatomy;coronary artery disease;heart muscle;myocardial perfusion visualization	Anatomy;Arteries;Blood;Computational modeling;Coronary arteriosclerosis;Data visualization;Heart;Medical simulation;Muscles;Myocardium	Cardiac visualization;Index Terms&#8212;coronary artery territories;myocardial perfusion	Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.	Termeer, M.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Nagel, E.	Vienna Univ. of Technol., Vienna|c|;;;;	37869997400;37374875300;37282551500;37374887400;37866652600
	InfoVis+SciVis	Nov.-Dec. 2008	Effective visualization of complex vascular structures using a non-parametric vessel detection method	10.1109/TVCG.2008.123	http://dx.doi.org/10.1109/TVCG.2008.123	1603	1610	4658181	computer vision;computerised tomography;data visualisation;medical image processing	Hessian based techniques;angiographic image;angiography images;clinical neurovascular x-ray computed tomography;complex vascular structures visualization;cylindrical structures;nonparametric vessel detection method;surgical planning;vessel detection	Biomedical imaging;Computed tomography;Data visualization;Medical diagnostic imaging;Radiology;Shape;Spatial resolution;Surgery;Transfer functions;X-ray imaging	Evaluation of visualization techniques;Index Terms&#8212;Vessel identification;Vessel visualization	"The effective visualization of vascular structures is critical for diagnosis, surgical planning as well as treatment evaluation. In recent work, we have developed an algorithm for vessel detection that examines the intensity profile around each voxel in an angiographic image and determines the likelihood that any given voxel belongs to a vessel; we term this the ""vesselness coefficient"" of the voxel. Our results show that our algorithm works particularly well for visualizing branch points in vessels. Compared to standard Hessian based techniques, which are fine-tuned to identify long cylindrical structures, our technique identifies branches and connections with other vessels. Using our computed vesselness coefficient, we explore a set of techniques for visualizing vasculature. Visualizing vessels is particularly challenging because not only is their position in space important for clinicians but it is also important to be able to resolve their spatial relationship. We applied visualization techniques that provide shape cues as well as depth cues to allow the viewer to differentiate between vessels that are closer from those that are farther. We use our computed vesselness coefficient to effectively visualize vasculature in both clinical neurovascular x-ray computed tomography based angiography images, as well as images from three different animal studies. We conducted a formal user evaluation of our visualization techniques with the help of radiologists, surgeons, and other expert users. Results indicate that experts preferred distance color blending and tone shading for conveying depth over standard visualization techniques."	Joshi, A.;Xiaoning Qian;Dione, D.P.;Bulsara, K.;Breuer, C.;Sinusas, A.J.;Papademetris, X.	Yale Univ., New Haven, CT|c|;;;;;;	37278517400;37398059300;37326190800;37869716400;38181319900;37267968800;37294174000
	InfoVis+SciVis	Nov.-Dec. 2008	Visualization of Cellular and Microvascular Relationships	10.1109/TVCG.2008.179	http://dx.doi.org/10.1109/TVCG.2008.179	1611	1618	4658182	biology computing;cellular biophysics;data visualisation	biological tissue;cellular structures;chronic diseases;microvascular anatomy;microvasculature structures	Arteries;Biomedical imaging;Blood vessels;Cells (biology);Computed tomography;Data visualization;Image resolution;Magnetic resonance imaging;Microscopy;Veins	Index Terms&#8212;cells;complex data;fibers;microscopy;vascular	Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.	Mayerich, D.M.;Abbott, L.;Keyser, J.	Dept. of Comput. Sci., Texas A&M Univ., College Station, TX|c|;;	37282589200;37884259000;37282588300
	InfoVis+SciVis	Nov.-Dec. 2008	A Practical Approach to Morse-Smale Complex Computation: Scalability and Generality	10.1109/TVCG.2008.110	http://dx.doi.org/10.1109/TVCG.2008.110	1619	1626	4658183	data visualisation;divide and conquer methods	Morse-Smale complex computation;critical point cancellations;divide-and-conquer strategy;scalar-valued data;weak topology complex	Adaptive mesh refinement;Data analysis;Data mining;Data visualization;Feature extraction;Grid computing;Large-scale systems;Scalability;Size control;Topology	Index Terms&#8212;Morse-Smale complex;Topology-based analysis;large scale data.		Gyulassy, A.;Bremer, P.-T.;Hamann, B.;Pascucci, V.	Livermore Nat. Lab., UC Davis & Lawrence, Livermore, CA|c|;;;	37870001700;37564112000;37282068700;37284312600
	InfoVis+SciVis	Nov.-Dec. 2008	Invariant Crease Lines for Topological and Structural Analysis of Tensor Fields	10.1109/TVCG.2008.148	http://dx.doi.org/10.1109/TVCG.2008.148	1627	1634	4658184	data visualisation	adaptive refinement strategy;fractional anisotropy;ridge line extraction algorithms;smooth reconstruction kernels;structural analysis;three-dimensional symmetric second-order tensor fields;topological analysis	Anisotropic magnetoresistance;Biomedical imaging;Computer vision;Data engineering;Data mining;Data visualization;Hospitals;Magnetic resonance imaging;Tensile stress;Topology	Index Terms&#8212;Tensor &#64257;crease extraction;elds;ridge lines;structural analysis;tensor invariants;topology	We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.	Tricoche, X.;Kindlmann, G.;Westin, C.-F.	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;	37282575100;37282742400;37294318400
	InfoVis+SciVis	Nov.-Dec. 2008	Estimating Crossing Fibers: A Tensor Decomposition Approach	10.1109/TVCG.2008.128	http://dx.doi.org/10.1109/TVCG.2008.128	1635	1642	4658185	biomedical MRI;data analysis;data visualisation;deconvolution;image representation;image resolution;medical image processing;neurophysiology;tensors	DT-MRI;Q-Ball imaging;crossing fiber estimation;data analysis;data visualization;diffusion weighted magnetic resonance imaging;diverse fiber distribution;high angular image resolution technique;nerve fiber tract;orientation distribution function;sphere;spherical deconvolution;tensor decomposition approach;tensor representation;voxel	Data mining;Deconvolution;Diffusion tensor imaging;Distribution functions;High-resolution imaging;Image reconstruction;Magnetic resonance imaging;Nerve fibers;Tensile stress;Visualization	DW-MRI;Index Terms&#8212;Q-Ball;fiber tracking;higher-order tensor;spherical deconvolution;tensor decomposition.	Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.	Schultz, T.;Seidel, H.-P.	MPI Inf., Saarbrucken|c|;	37606352800;37271851300
	InfoVis+SciVis	Nov.-Dec. 2008	Geodesic Distance-weighted Shape Vector Image Diffusion	10.1109/TVCG.2008.134	http://dx.doi.org/10.1109/TVCG.2008.134	1643	1650	4658186	data visualisation;differential geometry;feature extraction;image matching;image registration;image sampling;solid modelling;statistical analysis;surface fitting	3D surface matching;canonical rectangular domain;conformal geometry;encoding;feature detection;feature extraction;geodesic distance-weighted shape vector image diffusion;image sampling;multiscale diffusion space;statistical analysis;surface registration;surface visualization	Feature extraction;Geometry;Humans;Image sampling;Multi-stage noise shaping;Noise robustness;Pixel;Shape;Statistical analysis;Visualization	Index Terms&#8212;Multiscale Diffusion;Shape Vector Image;Surface Matching;Visualization	This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.	Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin	Wayne State Univ., Detroit, MI|c|;;;;	37285799200;37868989800;37290589700;37276603700;37276553900
	InfoVis+SciVis	Nov.-Dec. 2008	Edge Groups: An Approach to Understanding the Mesh Quality of Marching Methods	10.1109/TVCG.2008.122	http://dx.doi.org/10.1109/TVCG.2008.122	1651	1666	4658187	computational geometry;mesh generation	isosurface extraction algorithm;marching cubes;marching methods mesh quality;polygonization algorithms;polyhedral cell shapes;triangle mesh	Algorithm design and analysis;Computational modeling;Isosurfaces;Mathematics;Mesh generation;Pressing;Proposals;Robustness;Scientific computing;Shape	Index Terms&#8212;Isosurface extraction;Marching Cubes	Marching cubes is the most popular isosurface extraction algorithm due to its simplicity, efficiency and robustness. It has been widely studied, improved, and extended. While much early work was concerned with efficiency and correctness issues, lately there has been a push to improve the quality of marching cubes meshes so that they can be used in computational codes. In this work we present a new classification of MC cases that we call edge groups, which helps elucidate the issues that impact the triangle quality of the meshes that the method generates. This formulation allows a more systematic way to bound the triangle quality, and is general enough to extend to other polyhedral cell shapes used in other polygonization algorithms. Using this analysis, we also discuss ways to improve the quality of the resulting triangle mesh, including some that require only minor modifications of the original algorithm.	Dietrich, C.A.;Scheidegger, C.E.;Comba, J.L.D.;Nedel, L.P.;Silva, C.T.	Inst. de Inf., Univ. Fed. do Rio Grande do Sul, Rio Grande do Sul|c|;;;;	37867422200;37550809300;37267034700;37329407400;37275249200
	InfoVis+SciVis	Nov.-Dec. 2008	Revisiting Histograms and Isosurface Statistics	10.1109/TVCG.2008.160	http://dx.doi.org/10.1109/TVCG.2008.160	1659	1666	4658188	data visualisation;statistical analysis	Federer Coarea Formula;histogram equalization;isosurface statistics;isosurface-preserving transformations;statistical model	Brightness;Convergence;Data visualization;Frequency;Higher order statistics;Histograms;Humans;Isosurfaces;Kernel;Noise figure	Coarea Formula;Histograms;Index Terms&#8212;Isosurfaces	Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.	Scheidegger, C.E.	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake City, UT|c|	
	InfoVis+SciVis	Nov.-Dec. 2008	Visibility-driven Mesh Analysis and Visualization through Graph Cuts	10.1109/TVCG.2008.176	http://dx.doi.org/10.1109/TVCG.2008.176	1667	1674	4658189	computational geometry;data visualisation;graph theory;mesh generation;sampling methods	computational geometry;data visualization;graph cut;sampling method;visibility-driven triangular mesh analysis	Algorithm design and analysis;Electronic mail;Face detection;Geometry;Iterative algorithms;Robustness;Sampling methods;Solid modeling;Surface cracks;Visualization	Graph Cut;Index Terms&#8212;Inside Removal;Interior/Exterior Classification;Layer Classification;Normal Orientation	In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.	Zhou, K.;Zhang, E.;Bittner, J.;Wonka, P.	Arizona State Univ., Tempe, AZ|c|;;;	37873595500;37398562200;37739087200;37304396700
	InfoVis+SciVis	Nov.-Dec. 2008	Text Scaffolds for Effective Surface Labeling	10.1109/TVCG.2008.168	http://dx.doi.org/10.1109/TVCG.2008.168	1675	1682	4658190	rendering (computer graphics);solid modelling	3D surfaces;constructive solid geometry;proximal regions;surface labeling;surface text rendering;text scaffolds;textual labels	Art;Geometry;Labeling;Rough surfaces;Shape;Solids;Surface roughness;Surface texture;Three dimensional displays;Visualization	Index Terms&#8212;annotation;computational cartography;surface labeling;text authoring	In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.	Cipriano, G.;Gleicher, M.	Dept. of Comput. Sci., Wisconsin Univ., Madison, WI|c|;	37882969500;37282585700
	InfoVis+SciVis	Nov.-Dec. 2008	Relation-Aware Volume Exploration Pipeline	10.1109/TVCG.2008.159	http://dx.doi.org/10.1109/TVCG.2008.159	1683	1690	4658191	data visualisation;graph theory;rendering (computer graphics)	graph interface;region connection calculus;relation graph;relation-aware volume exploration pipeline;rendered images;scientific visualization;volumetric data	Analytical models;Calculus;Color;Data acquisition;Data mining;Data visualization;Pipelines;Quality assessment;Rendering (computer graphics);Volume measurement	Exploratory Visualization;Index Terms&#8212;Relation-Based Visualization;Visualization Pipeline.	Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.	Ming-Yuen Chan;Huamin Qu;Ka-Kei Chung;Wai-Ho Mak;Yingcai Wu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;;	37401176900;37272637300;37406959900;37306814700;37407308300
	InfoVis+SciVis	Nov.-Dec. 2008	VisComplete: Automating Suggestions for Visualization Pipelines	10.1109/TVCG.2008.174	http://dx.doi.org/10.1109/TVCG.2008.174	1691	1698	4658192	data visualisation;graph theory	analysis pipelines;open-source scientific workflow system;pipeline subgraphs;visualization pipelines	Computer interfaces;Data flow computing;Data visualization;Feedback;Open source software;Pipelines;Programming profession;Reproducibility of results;Software systems;Visual databases	Auto Completion;Index Terms&#8212;Scientific Visualization;Scientific Workflows	Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.	Koop, D.	Sch. of Comput., Univ. of Utah, Salt Lake City, UT|c|	
	InfoVis+SciVis	Nov.-Dec. 2008	Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System	10.1109/TVCG.2008.145	http://dx.doi.org/10.1109/TVCG.2008.145	1699	1706	4658193	automotive engineering;data visualisation;design engineering;engineering graphics;interactive systems;mechanical engineering computing;rapid prototyping (industrial)	automotive industry system design;common rail injection system;coupled steering loop;interactive visual analysis;interactive visual steering;rapid visual prototyping	Analytical models;Automotive engineering;Computational modeling;Manufacturing industries;Multidimensional systems;Prototypes;Rails;System analysis and design;Virtual prototyping;Visualization	Index Terms&#8212;common rail injection system;interactive computational steering;interactive visual analysis;simulation	Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.	Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.	VRVis Res. Center, Vienna|c|;;;	38188281400;37272650400;38188282900;37274158800
	InfoVis+SciVis	Nov.-Dec. 2008	AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation	10.1109/TVCG.2008.111	http://dx.doi.org/10.1109/TVCG.2008.111	1707	1722	4658194	data visualisation;interactive systems;ray tracing;rendering (computer graphics)	adaptive frustum tracing;edge diffraction;interactive sound propagation;scene primitives;specular reflection	Acoustic diffraction;Acoustic propagation;Auditory displays;Computational modeling;Interactive systems;Layout;Real time systems;Solid modeling;Virtual environment;Visualization	Index Terms&#8212;Sound propagation;auralization;interactive system	We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.	Chandak, A.;Lauterbach, C.;Taylor, M.;Zhimin Ren;Manocha, D.	UNC-Chapel Hill, Chapel Hill, NC|c|;;;;	37883391100;37606258500;37874722500;37401362100;37267825600
	InfoVis+SciVis	Nov.-Dec. 2008	Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data	10.1109/TVCG.2008.157	http://dx.doi.org/10.1109/TVCG.2008.157	1715	1722	4658195	data visualisation;query processing	GPU-based indexing structure;multitemporal visualization;query-driven visualization;time-varying adaptive mesh refinement data;visualization techniques	Adaptive mesh refinement;Analytical models;Biological system modeling;Computational modeling;Data analysis;Data visualization;Grid computing;Medical simulation;Mesh generation;Rendering (computer graphics)	AMR;Index Terms&#8212;Multitemporal Visualization;Query-Driven Visualization	The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.	Gosink, L.J.	Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA|c|	
	InfoVis+SciVis	Nov.-Dec. 2008	A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes	10.1109/TVCG.2008.108	http://dx.doi.org/10.1109/TVCG.2008.108	1723	1730	4658196	computer vision;data visualisation;flow visualisation	complex 3D geometry;dense 3D streamtubes;large data sets visualization;linear perspective;physically-based illumination	Aggregates;Data visualization;Geometry;Humans;Layout;Lighting;Psychology;Shape;Three dimensional displays;Visual system	3D shape perception;DT-MRI;Index Terms&#8212;flow visualization;global illumination;local illumination;multi-scale visualization;physically-based illumination;streamtubes;user study;volume completion;white matter tractography	Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.	Weigle, C.;Banks, D.C.	Dept. of Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN|c|;	37282585600;37356983700
	InfoVis+SciVis	Nov.-Dec. 2008	Focus+Context Visualization with Distortion Minimization	10.1109/TVCG.2008.132	http://dx.doi.org/10.1109/TVCG.2008.132	1731	1738	4658197	data visualisation;distortion;minimisation;solid modelling;surface fitting	distortion minimization;energy optimization model;interactive focus-context visualization;large surface model visualization	Biomedical engineering;Computer science;Deformable models;Displays;Lenses;Medical services;Optical distortion;Power engineering and energy;Space technology;Visualization	Focus+Context visualization;Index Terms&#8212;bounding space;magnification	The need to examine and manipulate large surface models is commonly found in many science, engineering, and medical applications. On a desktop monitor, however, seeing the whole model in detail is not possible. In this paper, we present a new, interactive Focus+Context method for visualizing large surface models. Our method, based on an energy optimization model, allows the user to magnify an area of interest to see it in detail while deforming the rest of the area without perceivable distortion. The rest of the surface area is essentially shrunk to use as little of the screen space as possible in order to keep the entire model displayed on screen. We demonstrate the efficacy and robustness of our method with a variety of models.	Yu-Shuen Wang;Tong-Yee Lee;Chiew-Lan Tai	Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng-Kung Univ., Tainan|c|;;	37407536000;37277268400;37324166000
	InfoVis+SciVis	Nov.-Dec. 2008	Color Design for Illustrative Visualization	10.1109/TVCG.2008.118	http://dx.doi.org/10.1109/TVCG.2008.118	1739	1754	4658198	colour graphics;data visualisation;knowledge based systems;rendering (computer graphics)	color design;effective color palettes;illustrative visualization;knowledge-based system;occluded objects;perceptual color maps;scene composition;semi-transparent layer rendering;visual aesthetics	Color;Data visualization;Engines;Graphics;Humans;Knowledge based systems;Layout;Rendering (computer graphics);Testing;Visual perception	Color design;Index Terms&#8212;conjoint analysis;illustrative visualization;transparency;user study evaluation;volume rendering	Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.	Lujin Wang;Giesen, J.;McDonnell, K.T.;Zolliker, P.;Mueller, K.	Center for Visual Comput., Stony Brook Univ., Stony Brook, NY|c|;;;;	37280763200;37325999500;37882660300;37680882500;37273119700
	InfoVis+SciVis	Nov.-Dec. 2008	An Efficient Naturalness-Preserving Image-Recoloring Method for Dichromats	10.1109/TVCG.2008.112	http://dx.doi.org/10.1109/TVCG.2008.112	1747	1754	4658199	colour graphics;colour vision;data visualisation;image colour analysis;image enhancement	CVD;automatic image-recoloring technique;color-contrast enhancement;color-vision deficients;dichromats;information visualization;naturalness-preserving image-recoloring method;scientific visualization	Chemistry;Computational efficiency;Data visualization;Face detection;Geology;Pediatrics;Photoreceptors;Proteins;Retina;Statistics	Color-contrast enhancement;Color-vision deficiency;Index Terms&#8212;Information and Scientific Visualization;Recoloring algorithms	We present an efficient and automatic image-recoloring technique for dichromats that highlights important visual details that would otherwise be unnoticed by these individuals. While previous techniques approach this problem by potentially changing all colors of the original image, causing their results to look unnatural to color vision deficients, our approach preserves, as much as possible, the image's original colors. Our approach is about three orders of magnitude faster than previous ones. The results of a paired-comparison evaluation carried out with fourteen color-vision deficients (CVDs) indicated the preference of our technique over the state-of-the-art automatic recoloring technique for dichromats. When considering information visualization examples, the subjects tend to prefer our results over the original images. An extension of our technique that exaggerates color contrast tends to be preferred when CVDs compared pairs of scientific visualization images. These results provide valuable information for guiding the design of visualizations for color-vision deficients.	Kuhn, G.R.;Oliveira, M.M.;Fernandes, Leandro A.F.	Inst. de Inf., UFRGS, Porto Alegre|c|;;	37882399100;37554064200;37349793000
	InfoVis+SciVis	Nov.-Dec. 2008	Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos	10.1109/TVCG.2008.126	http://dx.doi.org/10.1109/TVCG.2008.126	1755	1762	4658200	data visualisation;video signal processing;video surveillance	contextualized videos;path reconstruction tasks;real-time video data visualization;security surveillance system interface;simulated surveillance videos;spatial context presentation;video placement	Data visualization;Decision making;Guidelines;Humans;Information analysis;Information security;Particle measurements;Prototypes;Traffic control;Video surveillance	Index Terms&#8212;contextualized videos;design factors;path reconstruction;spatial context;tracking;user study;video placement	Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.	Yi Wang;Bowman, Doug;Krum, D.;Smith-Jackson, T.;Bailey, D.;Peck, S.;Anand, S.;Kennedy, T.;Abdrazakov, Y.	Virginia Tech., Blacksburg, VA|c|;;;;;;;;	37601156200;37282977600;37391946800;37869683100;37871634800;37876923500;37884773500;37877319800;37869681100
	VAST	19-24 Oct. 2008	Keynote address Practical applications of visual analytics: On the cusp of widespread adoption	10.1109/VAST.2008.4677347	http://dx.doi.org/10.1109/VAST.2008.4677347	xi	xi	4677347	business data processing;data visualisation	Tableau Software;data analysis;homeland security;visual analytics			Summary form only given. As practitioners and educators in the field of Visual Analytics Science and Technology, youpsilave seen the power of visual analytics for scientific and technical applications including Homeland Security. But visual analytics is spreading to the general business population solving unexpected problems and challenges. In this talk, Tableau Software CEO Christian Chabot will highlight the areas of opportunity for visual analytics and demonstrate real examples of practical problems being solved by visual analytics. Hepsilall share his vision for the future of this industry - how everyday people can and are using visual analytics to solve some of businesspsilas and societypsilas most challenging issues. Hepsilall also identify whatpsilas needed to bring visual analytics to the forefront of main-stream data analysis and how the industry is helping to deliver on those needs.	Chabot, C.		37872418500
	VAST	19-24 Oct. 2008	Visual cluster analysis of trajectory data with interactive Kohonen Maps	10.1109/VAST.2008.4677350	http://dx.doi.org/10.1109/VAST.2008.4677350	3	10	4677350	data analysis;data visualisation;interactive systems;pattern clustering;self-organising feature maps	automatic data analysis;human expert supervision;interactive Kohonen feature map;self-organizing feature map;trajectory data;user preference;visual-interactive cluster analysis	Algorithm design and analysis;Automatic control;Clustering algorithms;Data analysis;Data visualization;Humans;Monitoring;Self organizing feature maps;Trajectory;Visual analytics	H.4 [Information Systems]: Information Systems Applications;I.3.6 [Computing Methodologies]: Computer GraphicsMethodology and Techniques	Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results.	Schreck, T.;Bernard, J.;Tekusova, T.;Kohlhammer, J.	Interactive Graphics Syst. Group, TU Darmstadt, Darmstadt|c|;;;	37282557600;37606179600;37872455800;37449689200
	VAST	19-24 Oct. 2008	Crystal structures classifier for an evolutionary algorithm structure predictor	10.1109/VAST.2008.4677351	http://dx.doi.org/10.1109/VAST.2008.4677351	11	18	4677351	chemistry computing;crystal structure;crystallography;evolutionary computation	USPEX;clustering methods;combinatorial chemistry;crystal structure classifier;crystallography;evolutionary algorithm structure predictor	Acceleration;Chemistry;Clustering methods;Crystalline materials;Crystallography;Design methodology;Electronic mail;Evolutionary computation;Libraries;Multidimensional systems	I.5.2 [Pattern Recognition]: Design MethodologyClassifier design and evaluation;J.2 [Physical Sciences and Engineering]: Chemistry	USPEX is a crystal structure predictor based on an evolutionary algorithm. Every USPEX run produces hundreds or thousands of crystal structures, some of which may be identical. To ease the extraction of unique and potentially interesting structures we applied usual high-dimensional classification concepts to the unusual field of crystallography. We experimented with various crystal structure descriptors, distinct distance measures and tried different clustering methods to identify groups of similar structures. These methods are already applied in combinatorial chemistry to organic molecules for a different goal and in somewhat different forms, but are not widely used for crystal structures classification. We adopted a visual design and validation method in the development of a library (CrystalFp) and an end-user application to select and validate method choices, to gain userspsila acceptance and to tap into their domain expertise. The use of the classifier has already accelerated the analysis of USPEX output by at least one order of magnitude, promoting some new crystallographic insight and discovery. Furthermore the visual display of key algorithm indicators has led to diverse, unexpected discoveries that will improve the USPEX algorithms.	Valle, M.	Data Anal. & Visualization Services, Swiss Nat. Supercomput. Centre (CSCS)|c|	37866298300
	VAST	19-24 Oct. 2008	Model-driven Visual Analytics	10.1109/VAST.2008.4677352	http://dx.doi.org/10.1109/VAST.2008.4677352	19	26	4677352	data visualisation;inductive logic programming;inference mechanisms;learning (artificial intelligence);user interfaces	encoding;high-dimensional data visualization interface;inductive logic programming;logic-based deductive reasoning;machine learning;model-driven visual analytics	Data analysis;Data security;Data visualization;Humans;Information security;Logic programming;Machine learning;Machinery;Scattering;Visual analytics	Grand Tour;H.5.2 [Information Interfaces and Presentation]: User InterfacesGraphical user interfaces;High-dimensional Data;I.2.6 [Artificial Intelligence]: LearningConcept Learning;I.5.3 [Pattern Recognition]: ClusteringSimilarity Measures;Knowledge Discovery;Machine Learning;Network Security;Visual Analytics;Visual Clustering	We describe a visual analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning that will assist analysts to make sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. We use logic programming (LP) as the underlying computing machinery to encode the relations as rules and facts and compute with them. A unique aspect of our approach is that the LP rules are automatically learned, using Inductive Logic Programming, from examples of data that the analyst deems interesting when viewing the data in the high-dimensional visualization interface. Using this system, analysts will be able to construct models of arbitrary relationships in the data, explore the data for scenarios that fit the model, refine the model if necessary, and query the model to automatically analyze incoming (future) data exhibiting the encoded relationships. In other words it will support both model-driven data exploration, as well as data-driven model evolution. More importantly, by basing the construction of models on techniques from machine learning and logic-based deduction, the VA process will be both flexible in terms of modeling arbitrary, user-driven relationships in the data as well as readily scale across different data domains.	Garg, S.;Ramakrishnan, I.V.;Mueller, K.	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY|c|;;	37592970300;37874636200;37273119700
	VAST	19-24 Oct. 2008	Using visual analytics to maintain situation awareness in astrophysics	10.1109/VAST.2008.4677353	http://dx.doi.org/10.1109/VAST.2008.4677353	27	34	4677353	astronomy computing;data analysis;data visualisation;groupware	Sunfall Data Taking system;astrophysics domain;cognitively overloaded user;collaborative visual analytics application;complex heterogeneous data analysis;custom-built instrument maneuvering;informal usability evaluation;situation awareness;system architecture;system design process;visualization technique	Astrophysics;Context awareness;Data analysis;Data visualization;Instruments;International collaboration;Production systems;Time factors;Usability;Visual analytics	Data and knowledge visualization;astrophysics;scientific visualization;situation awareness;visual analytics	We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness.	Aragon, C.R.;Poon, S.S.;Aldering, G.S.;Thomas, R.C.;Quimby, R.	Lawrence Berkeley Nat. Lab., Berkeley, CA|c|;;;;	37564069800;37868031100;37871736600;37874439800;37867573100
	VAST	19-24 Oct. 2008	Understanding syndromic hotspots - a visual analytics approach	10.1109/VAST.2008.4677354	http://dx.doi.org/10.1109/VAST.2008.4677354	35	42	4677354	data visualisation;health care;medical administrative data processing;medical disorders	data patterns;data sources;demographic filtering;event detection;health care officials;kernel density estimation;statistical noise;syndromic hotspots;syndromic surveillance data	Data analysis;Demography;Detection algorithms;Event detection;Kernel;Medical services;Pattern recognition;Signal detection;Surveillance;Visual analytics		When analyzing syndromic surveillance data, health care officials look for areas with unusually high cases of syndromes. Unfortunately, many outbreaks are difficult to detect because their signal is obscured by the statistical noise. Consequently, many detection algorithms have a high false positive rate. While many false alerts can be easily filtered by trained epidemiologists, others require health officials to drill down into the data, analyzing specific segments of the population and historical trends over time and space. Furthermore, the ability to accurately recognize meaningful patterns in the data becomes more challenging as these data sources increase in volume and complexity. To facilitate more accurate and efficient event detection, we have created a visual analytics tool that provides analysts with linked geo-spatiotemporal and statistical analytic views. We model syndromic hotspots by applying a kernel density estimation on the population sample. When an analyst selects a syndromic hotspot, temporal statistical graphs of the hotspot are created. Similarly, regions in the statistical plots may be selected to generate geospatial features specific to the current time period. Demographic filtering can then be combined to determine if certain populations are more affected than others. These tools allow analysts to perform real-time hypothesis testing and evaluation.	Maciejewski, R.;Rudolph, S.;Hafen, R.;Abusalah, A.;Yakout, M.;Ouzzani, M.;Cleveland, W.S.;Grannis, S.J.;Wade, M.;Ebert, D.S.	;;;;;;;;;	37396008400;37396006000;37396008600;37872486500;38337088800;38365116100;37282344300;37646590100;37867664300;38472157000
	VAST	19-24 Oct. 2008	Configurable Spaces: Temporal analysis in diagrammatic contexts	10.1109/VAST.2008.4677355	http://dx.doi.org/10.1109/VAST.2008.4677355	43	50	4677355	data analysis;data visualisation;graph theory;knowledge based systems;knowledge representation	2D knowledge representation;Configurable Spaces;complex diagrammatically-represented system;geographic map;graph visualization;intelligence analysis;knowledge base;linked diagram;process chart;social network graph;temporal analysis;temporal concept map visualization	Data visualization;Graphical user interfaces;Humans;Information analysis;NIST;Pattern analysis;Prototypes;Social network services;Space technology;Visual analytics	concept maps;geo-temporal analysis;graph visualization;human information interaction;visual analytics	Social network graphs, concept maps, and process charts are examples of diagrammatic representations employed by intelligence analysts to understand complex systems. Unfortunately, these 2D representations currently do not easily convey the flow, sequence, tempo and other important dynamic behaviors within these systems. In this paper we present Configurable Spaces, a novel analytical method for visualizing patterns of activity over time in complex diagrammatically- represented systems. Configurable Spaces extends GeoTime's X, Y, T coordinate workspace space for temporal analysis to any arbitrary diagrammatic work space by replacing a geographic map with a diagram. This paper traces progress from concept to prototype, and discusses how diagrams can be created, transformed and leveraged for analysis, including generating diagrams from knowledge bases, visualizing temporal concept maps, and the use of linked diagrams for exploring complex, multi-dimensional, sequences of events. An evaluation of the prototype by the National Institute of Standards and Technology showed intelligence analysts believed they were able to attain an increased level of insight, were able to explore data more efficiently, and that Configurable Spaces would help them work faster.	Kapler, T.;Eccles, R.;Harper, R.;Wright, W.	;;;	37704437500;37425695700;37594531000;37654961400
	VAST	19-24 Oct. 2008	Spatio-temporal aggregation for visual analysis of movements	10.1109/VAST.2008.4677356	http://dx.doi.org/10.1109/VAST.2008.4677356	51	58	4677356	data visualisation;spatiotemporal phenomena	data movement visual analysis;interaction technique;spatio-temporal aggregation;traffic-oriented view;trajectory-oriented view	Chromium;Cities and towns;Data analysis;Data visualization;Filtering;Humans;Information analysis;Information processing;Information systems;Tracking	Movement data;aggregation;geovisualization;scalable visualization;spatio-temporal data	Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.	Andrienko, G.;Andrienko, N.	Fraunhofer Inst. IAIS, Sankt Augustin|c|;	37283047100;37283047700
	VAST	19-24 Oct. 2008	Maintaining interactivity while exploring massive time series	10.1109/VAST.2008.4677357	http://dx.doi.org/10.1109/VAST.2008.4677357	59	66	4677357	cache storage;data visualisation;query processing;temporal databases;time series;very large databases	ATLAS;ad hoc query;data analysis;data retrieval;distributed query load;hidden system latency;high performance database technology;massive time series dataset;predictive caching;temporal data visualization tool	Costs;Data analysis;Data visualization;Delay;Hardware;Information retrieval;Telecommunication traffic;Time series analysis;Visual analytics;Visual databases	D.2.11 [Software Engineering]: Software ArchitecturesDomain-specific architectures;H.5.2 [Information Interfaces And Presentation]: User InterfaceGraphical user interfaces (GUI);K.4.0 [Information Systems Applications]: General		Sye-Min Chan;Ling Xiao;Gerth, J.;Hanrahan, P.	Stanford Univ., Stanford, CA|c|;;;	37881321800;37836526900;37840462500;37349803800
	VAST	19-24 Oct. 2008	Collaborative synthesis of visual analytic results	10.1109/VAST.2008.4677358	http://dx.doi.org/10.1109/VAST.2008.4677358	67	74	4677358	groupware;user centred design	collaborative synthesis;organizational metaphors;role assignment;visual analytic tools	Biological system modeling;Collaboration;Collaborative tools;Collaborative work;Diseases;Geography;Laboratories;Recruitment;Visual analytics;Visualization	H.5.3 [Information Interfaces and Presentation]: Group and Organization Interfaces;Synthesis;collaboration;user-centered design;visual analytics	Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.	Robinson, A.C.	Dept. of Geogr., Pennsylvania State Univ., State College, PA|c|	37829187900
	VAST	19-24 Oct. 2008	Visual evaluation of text features for document summarization and analysis	10.1109/VAST.2008.4677359	http://dx.doi.org/10.1109/VAST.2008.4677359	75	82	4677359	data visualisation;text analysis	Web-related textual information;document analysis;document summarization;quantitative text feature;text feature visual evaluation;text visualization techniques	Algorithm design and analysis;Feature extraction;Feedback loop;Information analysis;Iterative algorithms;Iterative methods;Performance analysis;Text analysis;Text mining;Visualization	I.5.2 [Pattern Recognition]: Design MethodologyFeature evaluation and selection;I.7.5 [Document and Text Processing]: Document CaptureDocument Analysis	Thanks to the Web-related and other advanced technologies, textual information is increasingly being stored in digital form and posted online. Automatic methods to analyze such textual information are becoming inevitable. Many of those methods are based on quantitative text features. Analysts face the challenge to choose the most appropriate features for their tasks. This requires effective approaches for evaluation and feature-engineering.	Oelke, D.;Bak, P.;Keim, D.A.;Last, M.;Danon, G.	Univ. of Konstanz, Konstanz|c|;;;;	37591207400;37392085400;37283138700;37270862400;37872415700
	VAST	19-24 Oct. 2008	Evaluating the relationship between user interaction and financial visual analysis	10.1109/VAST.2008.4677360	http://dx.doi.org/10.1109/VAST.2008.4677360	83	90	4677360	data visualisation;financial data processing;interactive systems	empirical user studies testing;financial visual analysis;interactive visualization technique;user interaction;user's reasoning process;visual analytical tool	Data analysis;Data mining;Data visualization;Graphical user interfaces;Human computer interaction;Joining processes;Testing;User interfaces;Visual analytics;Wire	H.5.2 [Information Interfaces And Presentation (e.g., HCI)]: User InterfacesEvaluation/methodology;H.5.2 [Information Interfaces And Presentation (e.g., HCI)]: User InterfacesGraphical user interfaces (GUI)	It has been widely accepted that interactive visualization techniques enable users to more effectively form hypotheses and identify areas for more detailed investigation. There have been numerous empirical user studies testing the effectiveness of specific visual analytical tools. However, there has been limited effort in connecting a userpsilas interaction with his reasoning for the purpose of extracting the relationship between the two. In this paper, we present an approach for capturing and analyzing user interactions in a financial visual analytical tool and describe an exploratory user study that examines these interaction strategies. To achieve this goal, we created two visual tools to analyze raw interaction data captured during the user session. The results of this study demonstrate one possible strategy for understanding the relationship between interaction and reasoning both operationally and strategically.	Dong Hyun Jeong;Wenwen Dou;Lipford, H.R.;Stukes, F.;Chang, R.;Ribarsky, W.	;;;;;	37400451800;37606064200;37601288800;37601289000;37592409400;37300425000
	VAST	19-24 Oct. 2008	Visual analytics for complex concepts using a human cognition model	10.1109/VAST.2008.4677361	http://dx.doi.org/10.1109/VAST.2008.4677361	91	98	4677361	cognition;data visualisation	complex concepts;human cognition model;human reasoning;visual analytics designs	Art;Cognition;Collaboration;Computer interfaces;Guidelines;Humans;Problem-solving;Taxonomy;Visual analytics;Visualization	cognition and perception theory;embodied cognition;visual analytics;visualization taxonomies and models	As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.	Green, T.M.;Ribarsky, W.;Fisher, Brian	Charlotte Visualization Center, Univ. of North Carolina, Charlotte, NC|c|;;	37403562900;37300425000;37267458000
	VAST	19-24 Oct. 2008	Entity-based collaboration tools for intelligence analysis	10.1109/VAST.2008.4677362	http://dx.doi.org/10.1109/VAST.2008.4677362	99	106	4677362	entity-relationship modelling;groupware;software tools	entity workspace system;entity-based collaboration tools;information structures;intelligence analysis;software tools	Collaborative software;Collaborative tools;Collaborative work;Design optimization;Information analysis;Laboratories;Organizing;Software tools;System testing;Text analysis	H.3.3 [Information Search and Retrieval]: Information filtering;H.4 [Information Systems Applications]: H.4.m Miscellaneous;H.5.2 [User Interfaces]: Graphical user interfaces (GUI);H.5.3 [Group and Organization Interfaces]: Collaborative computing, Computer-supported cooperative work, Web-based interaction;argumentation marshalling;collaboration;collective intelligence;entity-based;exploratory search;information foraging;information workspace;intelligence analysis;semantic notebook;sensemaking;visual analytics;visualization	Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts.	Bier, E.A.;Card, S.K.;Bodnar, J.W.	Palo Alto Res. Center, Palo Alto, CA|c|;;	37282252000;37444594200;37830251400
	VAST	19-24 Oct. 2008	Applied visual analytics for economic decision-making	10.1109/VAST.2008.4677363	http://dx.doi.org/10.1109/VAST.2008.4677363	107	114	4677363	data visualisation;decision making;econometrics;profitability	acquiring-a-company framework;data visualization method;economic decision-making;empirical evidence;interactive visual analytics technique;profit-maximization decision strategy;visual analytics tool	Application software;Decision making;Helium;Statistics;Uncertainty;Visual analytics;Visualization		This paper introduces the application of visual analytics techniques as a novel approach for improving economic decision making. Particularly, we focus on two known problems where subjectspsila behavior consistently deviates from the optimal, the Winnerpsilas and Loserpsilas Curse. According to economists, subjects fail to recognize the profit-maximizing decision strategy in both the Winnerpsilas and Loserpsilas curse because they are unable to properly consider all the available information. As such, we have created a visual analytics tool to aid subjects in decision making under the Acquiring a Company framework common in many economic experiments. We demonstrate the added value of visual analytics in the decision making process through a series of user studies comparing standard visualization methods with interactive visual analytics techniques. Our work presents not only a basis for development and evaluation of economic visual analytic research, but also empirical evidence demonstrating the added value of applying visual analytics to general decision making tasks.	Savikhin, A.;Maciejewski, R.;Ebert, D.S.	Dept. of Econ., Purdue Univ., West Lafayette, IN|c|;;	37681662800;37396008400;38472157100
	VAST	19-24 Oct. 2008	Narratives: A visualization to track narrative events as they develop	10.1109/VAST.2008.4677364	http://dx.doi.org/10.1109/VAST.2008.4677364	115	122	4677364	Web sites;data visualisation;information retrieval;pattern clustering;text analysis;user interfaces	In-Spire system;Narratives interface;ThemeRiver system;Web log;clustering technique;narrative news event tracking;social media;temporal axis;text visualization;topical keyword retrieval;unstructured text stream analysis	Application software;Blogs;Computer graphics;Data mining;Data visualization;Displays;Event detection;Reflection;Text processing;Visual analytics	I.3.8 [Computer Graphics]: Applications;I.7.m [Document and Text Processing]: Miscellaneous;blogs;events;time series;topic detection and tracking;trends	Analyzing unstructured text streams can be challenging. One popular approach is to isolate specific themes in the text, and to visualize the connections between them. Some existing systems, like ThemeRiver, provide a temporal view of changes in themes; other systems, like In-Spire, use clustering techniques to help an analyst identify the themes at a single point in time. Narratives combines both of these techniques; it uses a temporal axis to visualize ways that concepts have changed over time, and introduces several methods to explore how those concepts relate to each other. Narratives is designed to help the user place news stories in their historical and social context by understanding how the major topics associated with them have changed over time. Users can relate articles through time by examining the topical keywords that summarize a specific news event. By tracking the attention to a news article in the form of references in social media (such as weblogs), a user discovers both important events and measures the social relevance of these stories.	Fisher, D.;Hoff, A.;Robertson, G.;Hurst, M.	;;;	37542391000;37867220900;37448060300;37884821400
	VAST	19-24 Oct. 2008	Characterizing users&#x2019; visual analytic activity for insight provenance	10.1109/VAST.2008.4677365	http://dx.doi.org/10.1109/VAST.2008.4677365	123	130	4677365	cognition;data visualisation;human factors	HARVEST visual analytic system;action type categorization;automatically-recorded event-based insight provenance;information visualization;manually recorded insight provenance;semantic building block;user visual analytic activity characterization	Data visualization;Humans;Information analysis;Information systems;Investments;Mice;Prototypes;Taxonomy;Visual analytics;Visual perception	Analytic Activity;H.5.0 [Information Systems]: Information Interfaces and PresentationGeneral;Information Visualization;Insight Provenance;Taxonomy;Visual Analytics	Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.	Gotz, D.;Zhou, M.X.	;	37601397400;37399569300
	VAST	19-24 Oct. 2008	The Scalable Reasoning System: Lightweight visualization for distributed analytics	10.1109/VAST.2008.4677366	http://dx.doi.org/10.1109/VAST.2008.4677366	131	138	4677366	Web services;data visualisation;law administration;mobile computing	Web service-oriented analytic framework;distributed visual analytic;knowledge creation process;lightweight visualization;mobile interface;regional law enforcement organization;scalable reasoning system	Algorithm design and analysis;Computer displays;Computer interfaces;Computer networks;Handheld computers;Information analysis;Law enforcement;Pervasive computing;Visual analytics;Visualization	C.2.4 [Computer Systems Organization]: Computer-Communication Networks Distributed Systems;H.5.3 [Information Systems]: Information Interfaces and PresentationGroup and Organization Interfaces;Web visualization;analytic reasoning;law enforcement;mobile visualization;multiple views	A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization.	Pike, W.A.;Bruce, J.;Baddeley, B.;Best, D.;Franklin, L.;May, R.;Rice, D.M.;Riensche, R.;Younkin, K.	;;;;;;;;	38330085300;37686679000;37295089300;37872380700;37867848700;37352747200;37866654000;37295087900;37697482300
	VAST	19-24 Oct. 2008	Generating hypotheses of trends in high-dimensional data skeletons	10.1109/VAST.2008.4677367	http://dx.doi.org/10.1109/VAST.2008.4677367	139	146	4677367	curve fitting;data analysis;graph theory;surface fitting	data analysis;data visualization;high-dimensional data skeleton;information-revealing representation;locally fit principal curve;optimal path;principal graph	Computer science;Data analysis;Data visualization;Mathematics;Navigation;Pixel;Shape;Skeleton;Surface fitting;Tin	G.4.1 [Mathematics of Computing]: Mathematical SoftwareAlgorithm design and analysis;I.5.3 [Computing Methodologies]: Pattern RecognitionClustering	We seek an information-revealing representation for high-dimensional data distributions that may contain local trends in certain subspaces. Examples are data that have continuous support in simple shapes with identifiable branches. Such data can be represented by a graph that consists of segments of locally fit principal curves or surfaces summarizing each identifiable branch. We describe a new algorithm to find the optimal paths through such a principal graph. The paths are optimal in the sense that they represent the longest smooth trends through the data set, and jointly they cover the data set entirely with minimum overlap. The algorithm is suitable for hypothesizing trends in high-dimensional data, and can assist exploratory data analysis and visualization.	Pokharkar, S.;Tin Kam Ho	;	37871721600;37331517300
	VAST	19-24 Oct. 2008	Multivariate visual explanation for high dimensional datasets	10.1109/VAST.2008.4677368	http://dx.doi.org/10.1109/VAST.2008.4677368	147	154	4677368	data analysis;data mining;data visualisation;differentiation;interactive systems	high dimensional dataset;interactive dimension reduction;multivariate analysis model construction;multivariate data analysis;multivariate data visual explanation;multivariate knowledge discovery;multivariate visualization system;numerical differentiation technique	Computer science;Data analysis;Data visualization;Displays;Jacobian matrices;Optical scattering;Physics;Proteins;Solvents;Statistical analysis	G.3 [Mathematics of Computing]: Probability and StatisticsMultivariate Statistics;H.5.2 [Information Interfaces and Presentation]: User InterfacesUser Centered Design;dimension reduction;multivariate analysis;multivariate model construction;multivariate visualization;visual analysis	Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.	Barlowe, S.;Tianyi Zhang;Yujie Liu;Jing Yang;Jacobs, D.	Dept of Comput. Sci., Univ. of North Carolina, Charlotte, NC|c|;;;;	37591128900;37875136000;37537604400;37292632600;37883522400
	VAST	19-24 Oct. 2008	Visual mining of multimedia data for social and behavioral studies	10.1109/VAST.2008.4677369	http://dx.doi.org/10.1109/VAST.2008.4677369	155	162	4677369	behavioural sciences computing;data mining;multimedia computing;social sciences computing;visual programming	behavioral studies;data mining;high-quality multimedia data;social studies;visual mining;visualization program	Data mining;Data visualization;Humans;Laboratories;Management information systems;Multimedia computing;Multimedia databases;Multimedia systems;Statistics;Switches	H.1.2 [Information Systems]: Models and principles - user/machine systems;H.2.8 [Database Management]: Database Applications Data mining;H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval;H.5.1 [Information Interface and Presentation]: Multimedia Information Systems;H.5.2 [Information Interface and Presentation]: User Interfaces  Graphical user interfaces (GUI);multimedia data;visual data mining	With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We de- - monstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.	Chen Yu;Yiwen Zhong;Smith, T.;Park, I.;Weixia Huang	;;;;	37404663400;37876145600;37872609000;37872999700;37874639400
	VAST	19-24 Oct. 2008	Multidimensional visual analysis using cross-filtered views	10.1109/VAST.2008.4677370	http://dx.doi.org/10.1109/VAST.2008.4677370	163	170	4677370	data analysis;data structures;data visualisation;query processing;visual databases	complex multidimensional set query expression;cross-filtered coordinated multiple view interface;data semantics;data visualization;design strategy;domain-specific data structure mapping;idiosyncratic combination;multidimensional visual data analysis tool;visual abstraction	Data analysis;Data structures;Data visualization;Geography;Management information systems;Multidimensional systems;Pattern analysis;Prototypes;Software engineering;Usability	D.2.2 [Software Engineering]: Design Tools and Techniques[User Interfaces];H.2.3 [Information Systems]: Database Management[Languages];H.5.2 [Information Systems]: Information Interfaces and Presentation[User Interfaces]	Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.	Weaver, C.	GeoVISTA Center & Dept. of Geogr., Pennsylvania State Univ., University Park, PA|c|	37564883300
	VAST	19-24 Oct. 2008	Interactive poster: Visual analytic techniques for CO2 emissions and concentrations in the United States	10.1109/VAST.2008.4677372	http://dx.doi.org/10.1109/VAST.2008.4677372	173	174	4677372	carbon compounds;data visualisation;environmental science computing;fossil fuels;global warming	CO2 concentrations;CO2 emissions;Earth atmosphere;United States;anthropogenic greenhouse gas;climate change;fossil fuel;visual analytics	Atmosphere;Biosphere;Carbon dioxide;Combustion;Data analysis;Fossil fuels;Global warming;Oceans;Production;Visual analytics	CO2;GIS;I.3.8 [Computer Graphics]: Applications;Interactive Visualization;Multivariate and Spatio-Temporal Data;Visual Analytics;Volume Visualization		Andrysco, N.;Benes, B.;Gurney, K.	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;	37660812000;37282737400;37297987800
	VAST	19-24 Oct. 2008	Envisioning user models for adaptive visualization	10.1109/VAST.2008.4677373	http://dx.doi.org/10.1109/VAST.2008.4677373	175	176	4677373	data visualisation;information retrieval;search engines;user modelling	Web search context;adaptive search system visualization;information access systems;log data extraction;user model envisioning;user modelling;visual information analysis;visual information browsing environment;visual intelligence analysis scenario;visual intelligence search	Analytical models;Context modeling;Data mining;Data visualization;Graphical user interfaces;Humans;Indexing;Information analysis;Information retrieval;Web search	H.3.1 [Content Analysis and Indexing]: Indexing method;H.3.3 [Information Search and Retrieval]: Information filtering;H.3.5 [Online Information Services]: Web-based services;H.5.2 [User Interfaces]: Graphical user interfaces (GUI);Personalized Search;Query;Relevance feedback;User model;VIBE;Visualization	Adaptive search systems apply user models to provide better separation of relevant and non-relevant documents in a list of results. This paper presents our attempt to leverage this ability of user models in the context of visual information analysis. We developed an adaptive visualization approach for presentation and exploration of search results. We simulated a visual intelligence search/analysis scenario with log data extracted from an adaptive information foraging study and were able to verify that our method can improve the ability of traditional relevance visualization to separate relevant and irrelevant information.	Jae-wook Ahn;Brusilovsky, P.	Sch. of Inf. Sci., Univ. of Pittsburgh, Pittsburgh, PA|c|;	37290862300;37265243700
	VAST	19-24 Oct. 2008	A compound approach for interactive visualization of time-oriented data	10.1109/VAST.2008.4677374	http://dx.doi.org/10.1109/VAST.2008.4677374	177	178	4677374	data mining;data visualisation;temporal databases;user centred design	interactive visualization;real-world visual analytics;temporal data mining;time-oriented data;user centered design	Business;Calendars;Computer interfaces;Data mining;Data visualization;Information systems;Knowledge engineering;User centered design;Visual analytics	H.5.m [Information Systems]: Information Interfaces And Presentation (e.g., HCI)Miscellaneous;I.3.6 [Computing Methodologies]: Computer GraphicsMethodology and Techniques	Many real-world visual analytics applications involve time-oriented data. I am working in a research project related to this challenge where I am responsible for the interactive visualization part. My goal are interactive visualizations to explore such time-oriented data according to the user tasks while considering the structure of time. Time is composed of many granularities that are likely to have crucial influence on the formation of the data. The challenge is to integrate the granularities into a detailed compound view on the data, like the compound eye of insects integrates many images into one view. Other members of our team are experts in temporal data mining and user centered design. The goal is to combine our research topics to an integrated system that helps domain experts to get more insight from their time-oriented data.	Lammarsch, T.	Dept. of Inf. & Knowledge Eng. (ike), Danube Univ. Krems, Krems|c|	37646290500
	VAST	19-24 Oct. 2008	Interactive poster - SocialRank: An ego- and time-centric workflow for relationship identification	10.1109/VAST.2008.4677375	http://dx.doi.org/10.1109/VAST.2008.4677375	179	180	4677375	electronic mail;social networking (online)	SocialRank;communication artifacts;email corpus;instant messaging;interactive poster;multidimensional scaling visualization techniques;relationship identification;relationship ranking algorithms;social attributes;social network diagram;time-centric workflow	Algorithm design and analysis;Blogs;Data visualization;Electronic mail;History;Information systems;Laboratories;Multidimensional systems;Physics;Social network services	H.4.3 [Information Systems]: Communications ApplicationsInformation browsers;H.5.2 [Information Systems]: Information Interfaces and PresentationUser interfaces;I.3.6 [Computing Methodologies]: Methodology and TechniquesInteraction techniques	From instant messaging and email to wikis and blogs, millions of individuals are generating content that reflects their relationships with others in the world, both online and offline. Since communication artifacts are recordings of life events, we can gain insights into the social attributes and structures of the people within this communication history. In this paper, we describe SocialRank, an ego- and time-centric workflow for identifying social relationships in an email corpus. This workflow includes four high-level tasks: discovery, validation, annotation and dissemination. SocialRank combines relationship ranking algorithms with timeline, social network diagram, and multidimensional scaling visualization techniques to support these tasks.	Montemayor, J.;Diehl, C.;Pekala, M.;Patrone, D.	Milton Eisenhower Res. Center, Johns Hopkins Univ. Appl. Phys. Lab., Laurel, MD|c|;;;	37295585500;37331563200;37270659700;37871719400
	VAST	19-24 Oct. 2008	Visual analysis for mutual fund performance	10.1109/VAST.2008.4677376	http://dx.doi.org/10.1109/VAST.2008.4677376	181	182	4677376	data visualisation;financial data processing;investment;stock markets	US stock fund;density-based distribution map;investment instrument;mutual fund performance;visual analysis	Data visualization;Decision making;Humans;Information systems;Instruments;Investments;Mutual funds;Performance analysis;Regression analysis;Visual databases	Decision Making;Distribution Map;Financial Data Visualization;H.1.2 [User/Machine Systems]: Human Information ProcessingVisualization;H.4.2 [Information Systems Applications]: Types of SystemsDecision Support;Mutual Funds;Regression Analysis	Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns.	Ye Zhao;Alsakran, J.;Xinlei Zhao	Kent State Univ., Kent, OH|c|;;	37277701200;37846905500;37880820400
	VAST	19-24 Oct. 2008	An information visualisation system for the understanding of web data	10.1109/VAST.2008.4677377	http://dx.doi.org/10.1109/VAST.2008.4677377	183	184	4677377	Web sites;data mining;data visualisation	Internet;Web data visualisation;Web metrics;Web site;data mining techniques;information visualisation system;visual Web mining tool	Data analysis;Data mining;Data visualization;Information analysis;Information retrieval;Internet;Logic;Service oriented architecture;Web mining;Web page design	H.4.3 [Information Systems Applications]: Communications ApplicationsInformation browsers;H.5.2 [Information Interfaces and Presentation(I.7)]: User InterfacesGraphical user interfaces (GUI), Interaction styles;H.5.4 [Information Interfaces and Presentation]: Hypertext/HypermediaNavigation, User issues	Internet has become one of the best communication and marketing tools. Hence, designing well-structured Web sites with the information or products that users look for is a crucial mission. For this reason, understanding Web data is a decisive task to assure the success of a Website. In that sense, data mining techniques provide many metrics and statistics useful to automatically discover the structure, contents and usage of a site. This research aims at proving the usefulness of a set of information visualisation techniques in order to analyse Web data, using a visual Web mining tool that allows the combination, coordination and exploration of visualisations to get insight on Web data. The tool, named WET, provides a set of visual metaphors that represent the structure of the Websites where Web metrics are overlaid.	Pascual-Cid, V.	Web Res. Group, Univ. Pompeu Fabra & Fundacio Barcelona Media, Barcelona|c|	37546950000
	VAST	19-24 Oct. 2008	Supporting exploration awareness for visual analytics	10.1109/VAST.2008.4677378	http://dx.doi.org/10.1109/VAST.2008.4677378	185	186	4677378	data visualisation;user interfaces	Information foraging;exploration awareness;information visualization;visual analytics	Data analysis;Data visualization;Decision making;Graphical user interfaces;History;Image analysis;Information analysis;Problem-solving;User interfaces;Visual analytics	H.5.2 [Information Interfaces and Presentation]: User InterfacesGraphical User Interfaces (GUI)	While exploring data using information visualization, analysts try to make sense of the data, build cases, and present them to others. However, if the exploration is long or done in multiple sessions, it can be hard for analysts to remember all interesting visualizations and the relationships among them they have seen. Often, they will see the same or similar visualizations, and are unable to recall when, why and how they have seen something similar. Recalling and retrieving interesting visualizations are important tasks for the analysis processes such as problem solving, reasoning, and conceptualization. In this paper, we argue that offering support for thinking based on past analysis processes is important, and present a solution for this.	Shrinivasan, Y.B.;van Wijk, J.J.	Eindhoven Univ. of Technol., Eindhoven|c|;	37681468200;37267249200
	VAST	19-24 Oct. 2008	Interactive poster: Visual data mining of unevenly-spaced event sequences	10.1109/VAST.2008.4677379	http://dx.doi.org/10.1109/VAST.2008.4677379	187	188	4677379	data analysis;data mining;data visualisation;very large databases;visual databases	data analysis;data visualization;human intuition;interactive poster;large database exploration;unevenly-spaced event sequence;visual data mining;visual processing	Data analysis;Data mining;Data visualization;Displays;Electronic mail;Feedback;Humans;Motion pictures;Sorting;Visual databases		We present a process for the exploration and analysis of large databases of events. A typical database is characterized by the sequential actions of a number of individual entities. These entities can be compared by their similarities in sequence and changes in sequence over time. The correlation of two sequences can provide important clues as to the possibility of a connection between the responsible entities, but an analyst might not be able to specify the type of connection sought prior to examination. Our process incorporates extensive automated calculation and data mining but permits diversity of analysis by providing visualization of results at multiple levels, taking advantage of human intuition and visual processing to generate avenues of inquiry.	Godwin, A.;Chang, R.;Kosara, R.;Ribarsky, W.	Visualization Center, Univ. of North Carolina at Charlotte, Charlotte, NC|c|;;;	37593027200;37592409400;37282563400;37300425000
	VAST	19-24 Oct. 2008	A 3D treemap approach for analyzing the classificatory distribution in patent portfolios	10.1109/VAST.2008.4677380	http://dx.doi.org/10.1109/VAST.2008.4677380	189	190	4677380	classification;data visualisation;patents	3D treemap;adjacency edge bundles;classificatory distribution;interactive visual techniques;international patent classification;patent classification system;patent portfolios	Appropriate technology;Classification tree analysis;Couplings;Data visualization;Gas insulated transmission lines;Interactive systems;Investments;Portfolios;Taxonomy;Visual analytics	3D Edge-Bundling;3D-Treemaps;Patent Co-Classification Analysis	Due to the complexity of the patent domain and the huge amount of data, advanced interactive visual techniques are needed to support the analysis of large patent collections and portfolios. In this paper we present a new approach for visualizing the classificatory distribution of patent collections among the International Patent Classification (IPC) - todaypsilas most important internationally agreed patent classification system with about 70.000 categories. Our approach is based on an interactive three-dimensional treemap overlaid with adjacency edge bundles.	Giereth, M.;Bosch, H.;Ertl, T.	Visualization & Interactive Syst. Inst., Univ. of Stuttgart, Stuttgart|c|;;	37681276000;37683989300;37268023800
	VAST	19-24 Oct. 2008	Visual analysis of seismic simulation data	10.1109/VAST.2008.4677381	http://dx.doi.org/10.1109/VAST.2008.4677381	191	192	4677381	data visualisation;earthquakes;finite element analysis;geophysics computing;rendering (computer graphics);seismology	earthquakes;finite element methods;photorealistic metaphors;seismic simulation data;terrain rendering engine;visual analysis	Analytical models;Buildings;Context modeling;Data visualization;Disaster management;Earthquakes;Engines;Finite element methods;Numerical simulation;Urban areas	I.3.3 [Computing Methodologies]: Computer GraphicsPicture/Image Generation;I.3.7 [Computing Methodologies]: Computer GraphicsThree-Dimensional Graphics and Realism	Seismic simulations use finite element methods to describe ground motion. The results of such numerical simulations are often difficult to interpret for decision makers. We describe a terrain rendering engine that uses photorealistic metaphors to represent typical terrain properties without representing an actual terrain. In the context of ground motion, a simulation of the effects of various types of earthquakes on buildings has been conducted. Usually, such structural response simulations are carried out independently and are being visualized separate from the ground motion simulation. We combine the results from both simulations in an interactive, hybrid visualization so that decision makers (first responders and emergency management agencies) are provided with a photo-realistic, simulated view of various earthquake scenarios, enabling them to study the effect of various earthquakes on buildings typical for a rural or urban area. We present a method for visually analyzing large-scale simulation data from different sources (ground motion simulation and structural response simulation) using photorealistic metaphors. We have implemented an intuitive, interactive system for visual analysis and inspection of possible effects of various types of earthquakes on an inventory of buildings typical for a particular area. The underlying rendering system can be easily adapted for other simulations, such as smoke plumes or biohazards.	Gerhardt, F.J.;Meyer, J.	Tech. Univ. of Kaiserslautern, Kaiserslautern|c|;	37645639800;37279771900
	VAST	19-24 Oct. 2008	VAST 2008 Challenge: Introducing mini-challenges	10.1109/VAST.2008.4677383	http://dx.doi.org/10.1109/VAST.2008.4677383			4677383	data visualisation	VAST 2008 Challenge;heterogeneous data collections;visual analytics	Cellular phones;Data analysis;Feedback;NIST;Performance analysis;Visual analytics;Visualization	H.5.2 [Information Interfaces & Presentations]: User Interfaces  Evaluation/methodology;contest;evaluation;human information interaction;metrics;sense making;visual analytics	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The VAST 2008 Challenge is the third year that such a competition was held in conjunction with the IEEE Visual Analytics Science and Technology (VAST) symposium. The authors restructured the contest format used in 2006 and 2007 to reduce the barriers to participation and offered four mini-challenges and a Grand Challenge. Mini Challenge participants were to use visual analytic tools to explore one of four heterogeneous data collections to analyze specific activities of a fictitious, controversial movement. Questions asked in the Grand Challenge required the participants to synthesize data from all four data sets. In this paper we give a brief overview of the data sets, the tasks, the participation, the judging, and the results.			
	VAST	19-24 Oct. 2008	Grand challenge award: Data integration visualization and collaboration in the VAST 2008 Challenge	10.1109/VAST.2008.4677384	http://dx.doi.org/10.1109/VAST.2008.4677384			4677384	data visualisation;groupware	CSCW environment;Grand Challenge award;VAST 2008 Challenge;data integration collaboration;data integration visualization;heterogeneous synthetic data set;semantic network;team working	Visual analytics	E.1 [Data]: Data StructuresGraphs and networks;H.5.3 [Information Systems]: Information Interfaces and PresentationGroup and Organization Interfaces;Visual analytics;data integration;geovisualization;information visualization;intelligence analysis;investigative analysis	The VAST 2008 Challenge consisted of four heterogeneous synthetic data sets each organized into separate mini-challenges. The Grand Challenge required integrating the raw data from these four data sets as well as integrating results and findings from team members working on specific mini-challenges. Modeling the problem with a semantic network provided a means for integrating both the raw data and the subjective findings.			
	VAST	19-24 Oct. 2008	Grand challenge award 2008: Support for diverse analytic techniques - nSpace2 and GeoTime visual analytics	10.1109/VAST.2008.4677385	http://dx.doi.org/10.1109/VAST.2008.4677385			4677385	Internet;graphical user interfaces;interactive systems	GeoTime;Web-based analytical tool;diverse analytic techniques;interactive visual analytics tools;nSpace2	Visual analytics	geo-spatial information systems;human information interaction;temporal analysis;visual analytics	GeoTime and nSpace2 are interactive visual analytics tools that were used to examine and interpret all four of the 2008 VAST Challenge datasets. GeoTime excels in visualizing event patterns in time and space, or in time and any abstract landscape, while nSpace2 is a web-based analytical tool designed to support every step of the analytical process. nSpace2 is an integrating analytic environment. This paper highlights the VAST analytical experience with these tools that contributed to the success of these tools and this team for the third consecutive year.			
	VAST	19-24 Oct. 2008	Grand challenge award: Interactive visual analytics palantir: The future of analysis	10.1109/VAST.2008.4677386	http://dx.doi.org/10.1109/VAST.2008.4677386			4677386	application program interfaces;data visualisation;user interfaces	Catalano Paraiso Manifesto Movement;Palantir;fabricated religious movement;financial analysts;governmental analysts;interactive visual analytics;world-class analytic platform	Finance;Information analysis;Visual analytics	H.5.2 [Information Systems]: Information Interfaces and PresentationUser Interfaces;Palantir;VAST 2008;collaboration;data visualization;visual analytics	Palantir is a world-class analytic platform used worldwide by governmental and financial analysts. This paper provides an introduction to the platform contextualized by its application to the 2008 IEEE VAST contest. In this challenge, we explored a notional dataset about a fabricated religious movement, Catalanopsilas Paraiso Manifesto Movement.			
	VAST	19-24 Oct. 2008	Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats	10.1109/VAST.2008.4677387	http://dx.doi.org/10.1109/VAST.2008.4677387			4677387	computer graphics;data visualisation	ComVis tool;Google Earth;integrated display geo-temporal analysis;landing sites;mass movement;migrant boat;migration patterns	Application software;Collaboration;Computer graphics;Histograms;Telecommunications;Visual analytics	I.3.0 [Computer Graphics]: General;I.3.6 [Computer Graphics]: Methodology and Techniques(Interaction techniques);J.4.1 [Social and Behavioral Sciences]: Sociology;Visual analytics;geo-temporal data	We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.	Miklin, R.	Dept. of Telecommun., Univ. of Zagreb, Zagreb|c|	
	VAST	19-24 Oct. 2008	Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit	10.1109/VAST.2008.4677388	http://dx.doi.org/10.1109/VAST.2008.4677388			4677388	data analysis;data visualisation;geographic information systems	Evacuation Trace Mini Challenge award;Geospatial Visual Analytics Toolkit;data visualization;moving people track analysis;spatio-temporal data analysis;tool integration analysis	Visual analytics	Movement data;aggregation;geovisualization;scalable visualization;spatio-temporal data	The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.	Andrienko, N.	Fraunhofer Inst. IAIS, Sankt Augustin|c|	
	VAST	19-24 Oct. 2008	Cell phone mini challenge award: Social network accuracy&#x2014; exploring temporal communication in mobile call graphs	10.1109/VAST.2008.4677389	http://dx.doi.org/10.1109/VAST.2008.4677389			4677389	cellular radio;graph theory	Catalano-Vidro social network;cell phone mini challenge award;mobile call graphs;social network accuracy;temporal communication patterns;visual analytic approaches	Visual analytics	D.2.2 [Software Engineering]: Design Tools and TechniquesUser interfaces;H.2.8 [Database Management]: Database ApplicationsData mining	In the mobile call mini challenge of VAST 2008 contest, we explored the temporal communication patterns of Catalano/Vidro social network which is reflected in the mobile call data. We focus on detecting the hierarchy of the social network and try to get the important actors in it. We present our tools and methods in this summary. By using the visual analytic approaches, we can find out not only the temporal communication patterns in the social network but also the hierarchy of it.	Qi Ye	Beijing Key Lab. of Intell. Telecommun. Software & Multimedia, Beijing Univ. of Posts & Telecommun., Beijing|c|	
	VAST	19-24 Oct. 2008	Evacuation traces mini challenge: User testing to obtain consensus discovering the terrorist	10.1109/VAST.2008.4677390	http://dx.doi.org/10.1109/VAST.2008.4677390			4677390	data visualisation;emergency services;security;terrorism;user interfaces	evacuation traces mini challenge;graphical representation;security applications;terrorist;user testing;visual analytics	Animation;Data security;Data visualization;Discrete event simulation;Information processing;Psychology;System testing;Visual analytics	H.1.2 [Models and principles]: User/Machine SystemsHuman information processing;H.1.2 [Models and principles]: User/Machine SystemsSoftware psychology;casualties detection;evacuation;user testing;visual analytics	The adoption of visual analytics methodologies in security applications is an approach that could lead to interesting results. Usually, the data that has to be analyzed finds in a graphical representation its preferred nature, such as spatial or temporal relationships. Due to the nature of these applications, it is very important that key-details are made easy to identify. In the context of the VAST 2008 Challenge, we developed a visualization tool that graphically displays the movement of 82 employees of the Miami Department of Health (USA). We also asked 13 users to identify potential suspects and observe what happened during an evacuation of the building caused by an explosion. In this paper we explain the results of the user testing we conducted and how the users interpreted the event taken into account.	Simeone, A.L.	Univ. of Bari, Bari|c|	
	VAST	19-24 Oct. 2008	Cell phone mini challenge award: Intuitive social network graphs visual analytics of cell phone data using mobivis and ontovis	10.1109/VAST.2008.4677391	http://dx.doi.org/10.1109/VAST.2008.4677391			4677391	cellular radio;graph theory;mobile computing;ontologies (artificial intelligence);social networking (online)	2008 VAST challenge;MobiVis;OntoVis;cell phone data;cell phone mini challenge award;intuitive social network graphs;ontology graph;semantic filtering;visual analytics	Visual analytics	Heterogeneous Graph Visualization;I.3.6 [Methodology and Techniques]Interaction Techniques;Visual Analytics	MobiVis is a visual analytics tools to aid in the process of processing and understanding complex relational data, such as social networks. At the core of these tools is the ability to filter complex networks structurally and semantically, which helps us discover clusters and patterns in the organization of social networks. Semantic filtering is obtained via an ontology graph, based on another visual analytics tool, called OntoVis. In this summary, we describe how these tools where used to analyze one of the mini-challenges of the 2008 VAST challenge.	Correa, C.D.	Visualization & Interface Design Innovation Group, Univ. of California, Davis, CA|c|	
	VAST	19-24 Oct. 2008	Using SocialAction to uncover structure in social networks over time	10.1109/VAST.2008.4677392	http://dx.doi.org/10.1109/VAST.2008.4677392			4677392	data visualisation;information networks	SocialAction;cell phone activity;social networks;social structure;time visualizations	Cellular phones;Computer science;Data analysis;Data mining;Data visualization;Histograms;Performance analysis;Social network services;Statistical analysis	SocialAction;VAST Challenge	I describe how SocialAction was used to find insights in an evolving social structure VAST Challenge 2008psilas Mini-Challenge 3. This analysis and SocialAction were given the award, ldquoCell Phone Mini Challenge Award: Time Visualizations of Cell Phone Activityrdquo.	Perer, A.	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD|c|	
	VAST	19-24 Oct. 2008	Cell phone Mini Challenge: Node-link animation award animating multivariate dynamic social networks	10.1109/VAST.2008.4677393	http://dx.doi.org/10.1109/VAST.2008.4677393			4677393	computer animation;data visualisation;mobile radio;social networking (online);telecommunication computing	cell phone mini challenge;multivariate dynamic social networks;node-link animation;visualization tool	Visual analytics	Dynamic social networks;Graph visualization;H.5.2 [Information Interfaces and Presentation]: User InterfacesGraphical User Interfaces (GUI);I.3.6 [Methodology and Techniques]: Interaction Techniques;Information visualization;Visual analytics	This article describes the visualization tool developed for analysing a dynamic social network of phone calls, for the VAST 2008 mini challenge. The tool was designed to highlight temporal changes in the network, by animating different network visual representations. We also explain how animating these network representations, helped to identify key events in the mini challenge problem scenario. Finally, we make some suggestions for future research and development in the area.	Farrugia, M.	Univ. Coll. Dublin, Dublin|c|	
	VAST	19-24 Oct. 2008	Migrant boat mini challenge award: Analysis summary a geo-temporal analysis of the migrant boat dataset	10.1109/VAST.2008.4677394	http://dx.doi.org/10.1109/VAST.2008.4677394			4677394	cartography;data visualisation;software packages	Caribbean island;dendrograms;geo-temporal analysis;geo-temporal patterns;migrant boat dataset;migrant boat mini challenge award;proportionally weighted migration maps;statistical software package;temporal variograms	Artificial intelligence;Information retrieval;Numerical analysis;Pattern analysis;Predictive models;Software packages;Visual analytics	G.1.1 [Numerical Analysis]: InterpolationInterpolation-Formulas;G.1.2 [Numerical Analysis]: ApproximationNonlinear Approximation;H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering;I.2.1 [Artificial Intelligence]: Applications and Expert SystemsCartography;geo-temporal analysis;visual analytics	The SPADAC team used various visual analytics tools and methods to find geo-temporal patterns of migration from a Caribbean island from 2005-2007. In this paper, we describe the tools and methods used in the analysis. These methods included generating temporal variograms, dendrograms, and proportionally weighted migration maps, using tools such as the R statistical software package and Signature Analysttrade. We found that there is a significant positive space-time correlation with the boat encounters (especially the landings), with a migratory shift further away from the point of departure over time.			
	VAST	19-24 Oct. 2008	Evacuation Traces Mini Challenge award: Innovative trace visualization staining for information discovery	10.1109/VAST.2008.4677395	http://dx.doi.org/10.1109/VAST.2008.4677395			4677395	data visualisation;pattern classification	evacuation traces mini challenge award;information discovery;innovative trace visualization staining;time-varying spatial data categorization	Visual analytics	H.5.2. [User Interfaces]: Graphical User Interfaces;Movement data;exploratory data analysis;interactive displays;visual analytics;visualization	Staining is a technique for categorizing time-varying spatial data; that is, data of things moving through space over time. In Staining, a stain is applied in either time or space, and the objects which move through the stain become marked. This technique and a research prototype demonstrating the technique were developed in response to the VAST 2008 Contest Mini-challenge: Evacuation Traces.	Bouvier, D.J.	Southern Illinois Univ. Edwardsville, Edwardsville, IL|c|	
	VAST	19-24 Oct. 2008	Award: Efficient toolkit integration solving the cell phone calls challenge with the Prajna Project	10.1109/VAST.2008.4677396	http://dx.doi.org/10.1109/VAST.2008.4677396			4677396	Java;cellular radio;data visualisation;inference mechanisms;knowledge representation;sensor fusion;social sciences computing;telecommunication computing	Java toolkit integration;Prajna project;cell phone call;data fusion;data visualization;geographic display;knowledge representation;semantic reasoning;social network display;software bridge;visual analytics application	Visual analytics	D.2.11 [Software Engineering]: Software Architectures - Domain-specific architectures;Information Visualization;Knowledge Representation;Software Toolkit;Toolkit Integration;[Computer Graphics]: Methodology and Techniques - Interaction Techniques	The Prajna Project is a Java toolkit designed to provide various capabilities for visualization, knowledge representation, geographic displays, semantic reasoning, and data fusion. Rather than attempt to recreate the significant capabilities provided in other tools, Prajna instead provides software bridges to incorporate other toolkits where appropriate. This challenge required the development of a custom application for visual analysis. By applying the utilities within the Prajna project, I developed a robust and diverse set of capabilities to solve the analytical challenge.			
