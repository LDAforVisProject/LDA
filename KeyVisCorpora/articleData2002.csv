Paper ID	Conference	Year	Title	DOI	Link	First Page	Last Page	IEEE Xplore Article Number	INSPEC Controlled	INSPEC Non-Controlled	IEEE Terms	Author Keywords	Abstract	Author Names	Author Affiliations	Author IDs
	InfoVis	2002	Angular brushing of extended parallel coordinates	10.1109/INFVIS.2002.1173157	http://dx.doi.org/10.1109/INFVIS.2002.1173157	127	130	1173157	data visualisation	CFD data visualization;angular brushing;data dimensions;extended parallel coordinates;rational data-properties	Brushes;Computational fluid dynamics;Computational modeling;Data analysis;Data visualization;Histograms;Multidimensional systems;Navigation;Prototypes;Writing		In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.	Hauser, H.;Ledermann, F.;Doleisch, H.	VRVis Res. Center, Vienna, Austria|c|;;	37274158800;37689207700;37546620400
	InfoVis	2002	Efficient cartogram generation: a comparison	10.1109/INFVIS.2002.1173144	http://dx.doi.org/10.1109/INFVIS.2002.1173144	33	36	1173144	cartography;data visualisation;geography;quadtrees	Gridfit technique;cartogram generation;epidemiological data;geography-related statistical information;map deformation problem;pixel-based distortion;population demographics;quadtree-like data structure;scanlines;statistical parameter;topology	Data structures;Data visualization;Demography;Displays;Humans;Iterative algorithms;Laboratories;Nominations and elections;Shape;Topology		Cartograms are a well-known technique for showing geography-related statistical information, such as population demographics and epidemiological data. The basic idea is to distort a map by resizing its regions according to a statistical parameter, but in a way that keeps the map recognizable. We deal with the problem of making continuous cartograms that strictly retain the topology of the input mesh. We compare two algorithms to solve the continuous cartogram problem. The first one uses an iterative relocation of the vertices based on scanlines. The second one is based on the Gridfit technique, which uses pixel-based distortion based on a quadtree-like data structure.	Keim, D.A.;North, S.C.;Panse, C.;Schneidewind, J.	AT&T Shannon Lab., Florham Park, NJ, USA|c|;;;	37283138700;37372818600;37282557300;37669961800
	InfoVis	2002	The illusion of perceived metric 3D structure	10.1109/INFVIS.2002.1173147	http://dx.doi.org/10.1109/INFVIS.2002.1173147	51	56	1173147	data visualisation;human factors;solid modelling;user interfaces;visual perception	3D visualizations;Euclidean distances;affine geometry;depth information;experiments;human spatial vision;illusion;near optimal viewing conditions;perceived metric 3D structure;shapes;space perception;three dimensional visualizations	Data visualization;Geometry;Humans;Information science;Psychology;Shape;Testing		A large body of results on the characteristics of human spatial vision suggests that space perception is distorted. Recent studies indicate that the geometry of visual space is best understood as Affine. If this is the case, it has far reaching implications on how 3D visualizations can be successfully employed. For instance, all attempts to build visualization systems where users are expected to discover relations based on Euclidean distances or shapes will be ineffective. Because visualization can, and sometimes do, employ all possible types of depth information and because the results from vision research usually concentrates on one or two such types, three experiments were performed under near optimal viewing conditions. The aim of the experiments was twofold: To test whether the earlier findings generalize to optimal viewing conditions and to get a sense of the size of the error under such conditions. The results show that the findings do generalize and that the errors are large. The implications of these results for successful visualizations are discussed.	Lind, M.;Bingham, G.P.	Dept. of Inf. Sci., Uppsala Univ., Sweden|c|;	37561614400;38136880400
	InfoVis	2002	Multiple foci drill-down through tuple and attribute aggregation polyarchies in tabular data	10.1109/INFVIS.2002.1173158	http://dx.doi.org/10.1109/INFVIS.2002.1173158	131	134	1173158	data visualisation	attribute aggregation polyarchies;data visualization;multiple foci drill-down;multiple hierarchical structures;polyarchical metadata;sport statistics;spreadsheet format;table attributes;tabular data;tuple aggregation polyarchies	Computer science;Data analysis;Data visualization;Electric breakdown;Geography;Information analysis;Organizing;Pattern analysis;Performance analysis;Statistics		Information analysis often involves decomposing data into sub-groups to allow for comparison and identification of relationships. Breakdown Visualization provides a mechanism to support this analysis through user guided drill-down of polyarchical metadata. This metadata describes multiple hierarchical structures for organizing tuple aggregations and table attributes. This structure is seen in financial data, organizational structures, sport statistics, and other domains. A spreadsheet format enables comparison of visualizations at any level of the hierarchy. Breakdown Visualization allows users to drill-down a single hierarchy then pivot into another hierarchy within the same view. It utilizes a fix and move technique that allows users to select multiple foci for drill-down.	Conklin, N.;Prabhakar, S.;North, C.	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	38137891600;38150082500;37419565900
	InfoVis	2002	SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation	10.1109/INFVIS.2002.1173148	http://dx.doi.org/10.1109/INFVIS.2002.1173148	57	64	1173148	data visualisation;diagrams;graphical user interfaces;tree data structures	SpaceTree;data visualization;design evolution;dynamic rescaling;experiment;filter functions;icons;integrated search;large node link tree exploration;node link tree diagrams;novel tree browser;optimized camera movement;topology	Cameras;Displays;Evolution (biology);Filling;Filters;Laboratories;Monitoring;Navigation;Network topology;Visualization		We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.	Plaisant, C.;Grosjean, J.;Bederson, B.B.	Human-Comput. Interaction Lab., Maryland Univ., MD, USA|c|;;	37283026800;37279773300;37279760100
	InfoVis	2002	Visualizing biosequence data using texture mapping	10.1109/INFVIS.2002.1173154	http://dx.doi.org/10.1109/INFVIS.2002.1173154	103	109	1173154	biology computing;data analysis;data mining;data visualisation;image texture;rendering (computer graphics)	biosequence data visualization;blending;data analysis;data mining;pattern discovery;protein sequences;rendering;text data visualization;texture mapping	Amino acids;Bioinformatics;Biotechnology;DNA;Data analysis;Data visualization;Pattern analysis;Proteins;Sequences;Technological innovation		Data-mining of information by the process of pattern discovery in protein sequences has been predominantly algorithm based. We discuss a visualization approach, which uses texture mapping and blending techniques to perform visual data-mining on text data obtained from discovering patterns in protein sequences. This visual approach, investigates the possibilities of representing text data in three dimensions and provides new possibilities of representing more dimensions of information in text data visualization and analysis. We also present a generic framework derived from this visualization approach to visualize text in biosequence data.	Thiagarajan, P.R.;Gao, G.R.	Biotechnol. Inst., Delaware Univ., Newark, DE, USA|c|;	38153582400;37334741200
	InfoVis	2002	A space-optimized tree visualization	10.1109/INFVIS.2002.1173152	http://dx.doi.org/10.1109/INFVIS.2002.1173152	85	92	1173152	data visualisation;diagrams;tree data structures;trees (mathematics);user interfaces	layout animation;mental map;screen resolution;semantic zooming technique;space-optimized tree visualization;tree drawing;tree structured relational data visualization;two dimensional space;very large hierarchies;zoomed views	Animation;Australia;Data visualization;Humans;Information technology;Large screen displays;Navigation;Space technology;Tree data structures;Tree graphs		We describe a new method for the visualization of tree structured relational data. It can be used especially for the display of very large hierarchies in a 2-dimensional space. We discuss the advantages and limitations of current techniques of tree visualization. Our strategy is to optimize the drawing of trees in a geometrical plane and maximize the utilization of display space by allowing more nodes and links to be displayed at a limit screen resolution. We use the concept of enclosure to partition the entire display space into a collection of local regions that are assigned to all nodes in tree T for the display of their sub-trees and themselves. To enable the exploration of large hierarchies, we use a modified semantic zooming technique to view the detail of a particular part of the hierarchy at a time based on user's interest. Layout animation is also provided to preserve the mental map while the user is exploring the hierarchy by changing zoomed views.	Quang Vinh Nguyen;Mao Lin Huang	Fac. of Inf. Technol., Univ. of Technol., Sydney, NSW, Australia|c|;	37267169300;37273547300
	InfoVis	2002	Multiscale visualization using data cubes	10.1109/INFVIS.2002.1173141	http://dx.doi.org/10.1109/INFVIS.2002.1173141	7	14	1173141	data structures;data visualisation;relational databases	data cubes;large data sets;multiscale pan-and-zoom systems;multiscale visualizations;relational databases;visual abstraction;zoom graph	Data analysis;Data visualization;Filtering;Filters;Pattern analysis;Polarization;Relational databases;Switches;Visual databases		Most analysts start with an overview of the data before gradually refining their view to be more focused and detailed. Multiscale pan-and-zoom systems are effective because they directly support this approach. However generating abstract overviews of large data sets is difficult, and most systems take advantage of only one type of abstraction: visual abstraction. Furthermore, these existing systems limit the analyst to a single zooming path on their data and thus a single set of abstract views. This paper presents: (1) a formalism for describing multiscale visualizations of data cubes with both data and visual abstraction, and (2) a method for independently zooming along one or more dimensions by traversing a zoom graph with nodes at different levels of detail. As an example of how to design multiscale visualizations using our system, we describe four design patterns using our formalism. These design patterns show the effectiveness of multiscale visualization of general relational databases.	Stolte, C.;Tang, D.;Hanrahan, P.	Stanford Univ., CA, USA|c|;;	37442008700;38003180800;37349803800
	InfoVis	2002	Internet traffic: visualization, discovery, and very large displays	10.1109/INFVIS.2002.1173140	http://dx.doi.org/10.1109/INFVIS.2002.1173140	3	4	1173140	Internet;data mining;data visualisation;telecommunication traffic recording	Internet traffic;individual visual displays;traffic measurements;very large displays;visualization tools	Cities and towns;Displays;Modems;Optical fiber cables;Smoothing methods;Switches;Telecommunication traffic;Visual databases;Visualization;Web and internet services		For a decade, the ruling common wisdom for Internet traffic held that it was everywhere bursty: over periods lasting tens of milliseconds to hundreds, the traffic was either much below its average rate or much above. In other words, the traffic was not smooth, not staying at all times close to its average. It was bursty on the cable running down a street, carrying the merged traffic of a small number of cable modem users in one section of a town. It was bursty on the core fiber of an Internet service provider, carrying the merged traffic of thousands of users from all over the country. The Internet was designed to accommodate the bursty traffic. The routers and switches that forward traffic from one place to the next were designed for burstiness, and Internet service providers allocated traffic loads on the devices based on an assumption of burstiness. Recently, it was discovered that the old common wisdom is not true. Visualization played a fundamental role in the discovery. The old wisdom held up for links with a small numbers of users. But as the number of users increases, the burstiness dissipates, and the traffic becomes smooth. Design of the high-load part of the Internet needs to be rethought. The old wisdom had persisted for high-load links because the databases of traffic measurements from them are immense, and the traffic measurements had not been studied in their fullest detail, which is necessary to see the smoothing. Visualization tools allowed the detail to be seen, and allowed the verification of a mathematical theory that predicts the smoothing. To see the detail, individual visual displays were created that take up an amount of virtual screen real estate measured in hundreds of pages. It is a simple idea: if you have a lot of data, and you want to see it in detail, you need a lot of space. What is needed now is a rich set of ideas and methods for navigating such very large displays.	Cleveland, W.S.	Dept. Stat. Res., Bell Labs., Holmdel, NJ, USA|c|	37282344300
	InfoVis	2002	A hybrid layout algorithm for sub-quadratic multidimensional scaling	10.1109/INFVIS.2002.1173161	http://dx.doi.org/10.1109/INFVIS.2002.1173161	152	158	1173161	computational complexity;data visualisation;interpolation	clustering techniques;complex data visualisation;complexity;hybrid layout algorithm;interpolation;layout quality;stochastic sampling;sub-quadratic multidimensional scaling	Multidimensional systems			Morrison, A.;Ross, G.;Chalmers, M.	Dept. of Comput. Sci., Glasgow Univ., UK|c|;;	37264873500;37282731400;37283487400
	InfoVis	2002	Case study: visualizing sets of evolutionary trees	10.1109/INFVIS.2002.1173150	http://dx.doi.org/10.1109/INFVIS.2002.1173150	71	74	1173150	biology computing;data visualisation;tree data structures;user interfaces	biology;case study;consensus tree;dataset;evolutionary tree visualization;evolutionary trees;organisms;point-set visualization;species;visual interface	Biology computing;Computer aided software engineering;DNA;Data visualization;Evolution (biology);Organisms;Phylogeny;Sequences;Systematics;Topology		We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization.	Amenta, N.;Klingner, J.	Texas Univ., Austin, TX, USA|c|;	37565128700;37945252000
	InfoVis	2002	Visualizing data with bounded uncertainty	10.1109/INFVIS.2002.1173145	http://dx.doi.org/10.1109/INFVIS.2002.1173145	37	40	1173145	data analysis;data integrity;data visualisation;graphs	abstract charts;bounded uncertainty;data analysis;data visualization;displays;error bars;graphs;statistical uncertainty	Bars;Data analysis;Data visualization;Displays;Error correction;Monitoring;NIST;Real time systems;Sampling methods;Uncertainty		Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately.	Olston, C.;Mackinlay, J.	Stanford Univ., CA, USA|c|;	37371920000;37372036700
	InfoVis	2002	Interactive information visualization of a million items	10.1109/INFVIS.2002.1173156	http://dx.doi.org/10.1109/INFVIS.2002.1173156	117	124	1173156	computer animation;data visualisation;interactive systems;interpolation	animation techniques;graphics cards;hardware-based techniques;interactive information visualization;overlap count;scatter plot diagrams;stereovision;treemaps	Animation;Data analysis;Data visualization;Displays;Human computer interaction;Information analysis;Sampling methods;Scalability;Scattering;Tree graphs		Existing information visualization techniques are usually limited to the display of a few thousand items. This article describes new interactive techniques capable of handling a million items (effectively visible and manageable on screen). We evaluate the use of hardware-based techniques available with newer graphics cards, as well as new animation techniques and non-standard graphical features such as stereovision and overlap count. These techniques have been applied to two popular information visualizations: treemaps and scatter plot diagrams; but are generic enough to be applied to other 2D representations as well.	Fekete, J.;Plaisant, C.	Human Comput. Interaction Lab., Maryland Univ., Baltimore, MD, USA|c|;	37407972900;37283026800
	InfoVis	2002	Building a visual database for example-based graphics generation	10.1109/INFVIS.2002.1173143	http://dx.doi.org/10.1109/INFVIS.2002.1173143	23	30	1173143	data visualisation;learning by example;visual databases	example-based graphics generation;feature-based scheme;information visualizations;learning from examples;visual database	Buildings;Computer graphics;Computer science;Data visualization;Displays;Engines;Performance analysis;Performance evaluation;Spatial databases;Visual databases		Example-based graphics generation systems automatically create new information visualizations by learning from existing graphic examples. As part of the effort on developing a general-purpose example-based generation system, we are building a visual database of graphic examples. In this paper, we address two main issues involved in constructing such a database: example selection and example modeling. As a result, our work offers three unique contributions: First, we build a visual database that contains a diverse collection of well-designed examples. Second, we develop a feature-based scheme to model all examples uniformly and accurately. Third, our visual database brings several important implications to the area of information visualization.	Zhou, M.X.;Min Chen;Ying Feng	IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;;	37399569300;38151550800;38102799300
	InfoVis	2002	ACE: a fast multiscale eigenvectors computation for drawing huge graphs	10.1109/INFVIS.2002.1173159	http://dx.doi.org/10.1109/INFVIS.2002.1173159	137	144	1173159	data visualisation;eigenvalues and eigenfunctions;interpolation;minimisation	ACE;algebraic multigrid computation of eigenvectors;algebraic multigrid technique;eigenvalue problem;fast multiscale eigenvectors computation;graph drawing algorithm;quadratic energy function	Clustering algorithms;Computer science;Data visualization;Eigenvalues and eigenfunctions;Image segmentation;Joining processes;Laplace equations;Mathematics;Minimization methods;Partitioning algorithms		We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too.	Koren, Y.;Carmel, L.;Harel, D.	Dept. of Comput. Sci. & Appl. Math., Weizmann Inst. of Sci., Rehovot, Israel|c|;;	37414256700;38144155300;37266021800
	InfoVis	2002	Beamtrees: compact visualization of large hierarchies	10.1109/INFVIS.2002.1173153	http://dx.doi.org/10.1109/INFVIS.2002.1173153	93	100	1173153	data visualisation;diagrams;tree data structures;trees (mathematics);user interfaces	Beamtrees;cushion treemaps;data visualization;diagrams;large hierarchical data sets;large hierarchy compact visualization;nested treemaps;nodes;stacked circular beams;treemap algorithm;user study	Computer science;Data mining;Data visualization;Mathematics;Testing;Three dimensional displays		Beamtrees are a new method for the visualization of large hierarchical data sets. Nodes are shown as stacked circular beams, such that both the hierarchical structure as well as the size of nodes are depicted. The dimensions of beams are calculated using a variation of the treemap algorithm. A small user study indicated that beamtrees are significantly more effective than nested treemaps and cushion treemaps for the extraction of global hierarchical information.	van Ham, F.;van Wijk, J.J.	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|;	37326291000;37267249200
	InfoVis	2002	Display design for the eye and mind	10.1109/INFVIS.2002.1173164	http://dx.doi.org/10.1109/INFVIS.2002.1173164	171	171	1173164			Books;Displays;Finance;Graphics;Hospitals;Humans;Information processing;Nervous system;Psychology;Reflection			Kosslyn, S.M.	Harvard University|c|	37378570400
	InfoVis	2002	Visual unrolling of network evolution and the analysis of dynamic discourse	10.1109/INFVIS.2002.1173160	http://dx.doi.org/10.1109/INFVIS.2002.1173160	145	151	1173160	data visualisation	discourse networks;dynamic discourse;network evolution;visual unrolling	Animation;Application software;Computer networks;Data visualization;Engineering drawings;Humans;Information science;Social network services;Software engineering;Text analysis		A new method for visualizing the class of incrementally evolving networks is presented. In addition to the intermediate states of the network it conveys the nature of the change between them by unrolling the dynamics of the network. Each modification is shown in a separate layer of a three-dimensional representation, where the stack of layers corresponds to a time line of the evolution. We focus on discourse networks as the driving application, but our method extends to any type of network evolving in similar ways.	Brandes, U.;Corman, S.R.	Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany|c|;	37550836200;38014884900
	InfoVis	2002	Process visualization with levels of detail	10.1109/INFVIS.2002.1173149	http://dx.doi.org/10.1109/INFVIS.2002.1173149	67	70	1173149	data visualisation;rendering (computer graphics);solid modelling;user interfaces	3D anchoring;3D model;collision avoidance;data source display;history encoding;information visualization techniques;levels of detail;process monitoring;process visualization;rendering;spring model;virtual instruments	Collision avoidance;Computerized monitoring;Context modeling;Displays;Encoding;History;Instruments;Light emitting diodes;Needles;Visualization		We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information.	Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, M.E.	VRVis Res. Center, Vienna, Austria|c|;;;	38220979200;37274158800;38221553100;37282552200
	InfoVis	2002	Visual path analysis	10.1109/INFVIS.2002.1173163	http://dx.doi.org/10.1109/INFVIS.2002.1173163	165	168	1173163	Web sites;data analysis;data visualisation;portals	Web services;Web site traffic flow analysis;clickstream;data visualisation;path analysis portal;path extraction algorithms;visual metaphor;visual path analysis	Aggregates;Algorithm design and analysis;Data mining;Navigation;Pattern analysis;Search engines;Switches;Uniform resource locators;Web page design;Web services		"We describe a system for analyzing the flow of traffic through Web sites. We decomposed the general path analysis problem into a set of distinct subproblems, and created a visual metaphor for analyzing each of them. Our system works off of multiple representations of the clickstream, and exposes the path extraction algorithms and data to the visual metaphors as Web services. We have combined the visual metaphors into a Web-based ""path analysis portal"" that lets the user easily switch between the different modes of analysis."	Keahey, T.A.;Eick, S.G.	;	38180025700;37282570100
	InfoVis	2002	Graphical encoding for information visualization: an empirical study	10.1109/INFVIS.2002.1173146	http://dx.doi.org/10.1109/INFVIS.2002.1173146	43	50	1173146	data visualisation;graphical user interfaces;psychology;user interfaces	data representation;graphical encoding;graphical user interfaces;icon color;icon shape;icon size;information visualization;psychology;psychophysics;user perceptual task;visual display elements	Computer displays;Computer science;Context;Data visualization;Encoding;Psychology;Shape;Signal detection;Software libraries;Statistics		Research in several areas provides scientific guidance for use of graphical encoding to convey information in an information visualization display. By graphical encoding we mean the use of visual display elements such as icon color, shape, size, or position to convey information about objects represented by the icons. Literature offers inconclusive and often conflicting viewpoints, including the suggestion that the effectiveness of a graphical encoding depends on the type of data represented. Our empirical study suggests that the nature of the users' perceptual task is more indicative of the effectiveness of a graphical encoding than the type of data represented.	Nowell, L.;Schulman, R.;Hix, D.	Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;	37725426400;37974832100;37295140000
	InfoVis	2002	Arc diagrams: visualizing structure in strings	10.1109/INFVIS.2002.1173155	http://dx.doi.org/10.1109/INFVIS.2002.1173155	110	116	1173155	data visualisation	arc diagrams;compiled code;string data;structure visualization	Autocorrelation;Chaos;DNA;Data visualization;Displays;Frequency;Histograms;Image sequence analysis;Performance analysis;Pixel		This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code.	Wattenberg, M.	IBM Res., Cambridge, MA, USA|c|	37550759700
	InfoVis	2002	Visualization schemas for flexible information visualization	10.1109/INFVIS.2002.1173142	http://dx.doi.org/10.1109/INFVIS.2002.1173142	15	22	1173142	data visualisation;relational databases;user interfaces	Snap-Together Visualization model;complex data collections;customized multiple-view visualizations;flexible information visualization;relational data schemas;relational databases;user interfaces;visualization schemas	Appropriate technology;Bioinformatics;Computer science;Data visualization;Database systems;Design methodology;Human computer interaction;Relational databases;User interfaces;Visual databases		Relational databases provide significant flexibility to organize, store, and manipulate an infinite variety of complex data collections. This flexibility is enabled by the concept of relational data schemas, which allow data owners to easily design custom databases according to their unique needs. However, user interfaces and information visualizations for accessing and utilizing databases have not kept pace with this level of flexibility. This paper introduces the concept of visualization schemas, based on the Snap-Together Visualization model, which are analogous to relational data schemas. Visualization schemas enable users to rapidly construct customized multiple-view visualizations for databases in a similarly flexible fashion without programming. Since the design of appropriate visualizations for a given database depends on the data schema, visualization schemas are a natural analogy to the data schema concept.	North, C.;Conklin, N.;Saini, V.	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	37419565900;38137891600;38152592400
	InfoVis	2002	Demystifying venture capital investing	10.1109/INFVIS.2002.1173162	http://dx.doi.org/10.1109/INFVIS.2002.1173162	161	164	1173162	data visualisation;financial data processing;investment	Double Histogram;Spiral Map;TimeTicker;venture capital investing demystifying;venture capitalists;visualization metaphors	Computer crashes;Condition monitoring;Histograms;Investments;Medical services;Milling machines;Spirals;Venture capital;Virtual colonoscopy;Visualization		Since the crash of the dot.coms, investors have gotten a lot more careful with where they place their money. Now more than ever it becomes really important for venture capitalists (VCs) to monitor the state of the startups market and continually update their investment strategy to suit the rapidly changing market conditions. This paper presents three new visualization metaphors (Spiral Map, TimeTicker, and Double Histogram) for monitoring the startups market. While we are focusing on the VC domain, the visual metaphors developed are general and can be easily applied to other domains.	Mei Chuah	Accenture Technol. Labs., Palo Alto, CA, USA|c|	37343565300
	InfoVis	2002	InterRing: an interactive tool for visually navigating and manipulating hierarchical structures	10.1109/INFVIS.2002.1173151	http://dx.doi.org/10.1109/INFVIS.2002.1173151	77	84	1173151	data visualisation;diagrams;tree data structures;user interfaces	InterRing;hierarchical data structures;hierarchical structure navigation;hierarchy visualization;interactive hierarchy reconfiguration;interactive tool;multi-focus distortions;node-link diagrams;radial space-filling techniques;usability	Computer displays;Computer science;Data structures;Data visualization;Feedback;File systems;Joining processes;Manuals;Navigation;Usability		Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.	Jing Yang;Ward, M.O.;Rundensteiner, E.A.	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;	37292632600;37268441700;37279217900
	SciVis	1-1 Nov. 2002	Integration of measurement tools in medical 3d visualizations	10.1109/VISUAL.2002.1183752	http://dx.doi.org/10.1109/VISUAL.2002.1183752	21	28	1183752	data visualisation;interactive systems;medical image processing;surgery	3D interaction techniques;computer-assisted surgery;integration tools;measurement tools;medical 3D visualizations;medical visualizations;quantitative analysis;spatial relations	Brain;Computed tomography;Current measurement;Data visualization;Goniometers;Medical diagnosis;Medical diagnostic imaging;Oncological surgery;Position measurement;Volume measurement		We discuss 3d interaction techniques for the quantitative analysis of spatial relations in medical visualizations. We describe the design and implementation of measurement tools to measure distances, angles and volumes in 3d visualizations. The visualization of measurement tools as recognizable 3d objects and a 3d interaction, which is both intuitive and precise, determines the usability of such facilities. Measurements may be carried out in 2d visualizations of the original radiological data and in 3d visualizations. The result of a measurement carried out in one view is also displayed in the other view appropriately. We discuss the validation of the obtained measures. Finally, we describe how some important measurement tasks may be solved automatically.	Preim, B.;Tietjen, C.;Spindler, W.;Peitgen, H.-O.	Center for Med. Diagnostic Syst. & Visualization, MeVis, Bremen, Germany|c|;;;	37424645300;37645846600;38149996100;37442956900
	SciVis	1-1 Nov. 2002	Fast visualization of plane-like structures in voxel data	10.1109/VISUAL.2002.1183753	http://dx.doi.org/10.1109/VISUAL.2002.1183753	29	36	1183753	bone;data visualisation;differential geometry;image reconstruction;image thinning;interactive systems;medical image processing;mesh generation;rendering (computer graphics)	binary voxel objects;bone biopsy microstructure;complex 3D structures;distance map;distance ordered thinning;expressive images;geodesic distance;geometric representation;homotopy;interactive rendering;noise sensitivity;object reconstruction;plane-like skeletons;rod-like structures;triangle count;triangulated surface;visualization;voxel data	Biopsy;Bones;Computer graphics;Data visualization;Geometry;Image reconstruction;Microstructure;Noise robustness;Skeleton;Surface reconstruction		We present a robust, noise-resistant criterion characterizing plane-like skeletons in binary voxel objects. It is based on a distance map and the geodesic distance along the object's boundary. A parameter allows us to control the noise sensitivity. If needed, homotopy with the original object might be reconstructed in a second step, using an improved distance ordered thinning algorithm. The skeleton is analyzed to create a geometric representation for rendering. Plane-like parts are transformed into an triangulated surface not enclosing a volume by a suitable triangulation scheme. The resulting surfaces have lower triangle count than those created with standard methods and tend to maintain the original geometry, even after simplification with a high decimation rate. Our algorithm allows us to interactively render expressive images of complex 3D structures, emphasizing independently plane-like and rod-like structures. The methods are applied for visualization of the microstructure of bone biopsies.	Prohaska, S.;Hege, H.-C.	Dept. for Sci. Visualization, Zuse Inst. Berlin, Germany|c|;	37282634700;37282272000
	SciVis	1-1 Nov. 2002	CPR - curved planar reformation	10.1109/VISUAL.2002.1183754	http://dx.doi.org/10.1109/VISUAL.2002.1183754	37	44	1183754	blood vessels;computerised tomography;data visualisation;medical image processing;rendering (computer graphics)	blood vessels;computed tomography;curved planar reformation;diagnostic purposes;image generation;longitudinal cross-sections;medical imaging;multi-path-CPR;rotating-CPR;surrounding tissue;thick-CPR;tubular structures;visualization	Biomedical imaging;Blood vessels;Chromium;Computed tomography;Computer displays;Computer graphics;Data visualization;Image generation;Magnetic resonance imaging;Radiology		Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.	Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;	37282727500;37282581000;37267822600;37267788200;37282552200
	SciVis	1-1 Nov. 2002	Direct surface extraction from 3D freehand ultrasound images	10.1109/VISUAL.2002.1183755	http://dx.doi.org/10.1109/VISUAL.2002.1183755	45	52	1183755	computational geometry;data visualisation;feature extraction;image sampling;medical image processing;radial basis function networks;ultrasonic imaging	3D freehand ultrasound images;approximating radial basis function;computational geometry;data samples;direct surface extraction;iso-surfacing;semi-structured ultrasound pixel data;single function	Active contours;Computed tomography;Computer science;Data mining;Image reconstruction;Image sampling;Probes;Surface fitting;Surface reconstruction;Ultrasonic imaging		This paper presents a new technique for the extraction of surfaces from 3D ultrasound data. Surface extraction from ultrasound data is challenging for a number of reasons including noise and artifacts in the images and nonuniform data sampling. A method is proposed to fit an approximating radial basis function to the group of data samples. An explicit surface is then obtained by iso-surfacing the function. In most previous 3D ultrasound research, a pre-processing step is taken to interpolate the data into a regular voxel array and a corresponding loss of resolution. We are the first to represent the set of semi-structured ultrasound pixel data as a single function. From this we are able to extract surfaces without first reconstructing the irregularly spaced pixels into a regular 3D voxel array.	Youwei Zhang;Rohling, Robert;Pai, D.K.	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;	38150692300;37296739100;38472260700
	SciVis	1-1 Nov. 2002	Interactive rendering of large volume data sets	10.1109/VISUAL.2002.1183757	http://dx.doi.org/10.1109/VISUAL.2002.1183757	53	60	1183757	data compression;data visualisation;image representation;image sampling;image texture;interactive systems;medical image processing;rendering (computer graphics);wavelet transforms	compressed hierarchical wavelet representation;hardware texture mapping;interactive frame rates;interactive rendering;interactive walkthrough;large volume data sets;local frequency spectrum;on-the-fly decompression;regular grid;scalar data sampling;standard PC hardware;visible human	Computer graphics;Data preprocessing;Data visualization;Frequency;Hardware;Humans;Image coding;Image generation;Prototypes;Rendering (computer graphics)		We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.	Guthe, S.;Wand, M.;Gonser, J.	WSI/GRIS, Tubingen Univ., Germany|c|;;	37728224400;37397544400;38149622600
	SciVis	1-1 Nov. 2002	Semotus Visum: a flexible remote visualization framework	10.1109/VISUAL.2002.1183758	http://dx.doi.org/10.1109/VISUAL.2002.1183758	61	68	1183758	client-server systems;data visualisation;rendering (computer graphics)	Semotus Visum;client server resources;flexible remote visualization framework;frame rates;high-performance system;large data sets;latency;multiple rendering methods	Computer networks;Data visualization;Distributed computing;Hardware;Java;Memory;Network servers;Protocols;Rendering (computer graphics);Streaming media		By offering more detail and precision, large data sets can provide greater insights to researchers than small data sets. However, these data sets require greater computing resources to view and manage. Remote visualization techniques allow the use of computers that cannot be operated locally. The Semotus Visum framework applies a high-performance client-server paradigm to the problem. The framework utilizes both client and server resources via multiple rendering methods. Experimental results show the framework delivers high frame rates and low latency across a wide range of data sets.	Luke, E.J.;Hansen, C.D.	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;	38156610200;37266777200
	SciVis	1-1 Nov. 2002	Out-of-core rendering of massive geometric environments	10.1109/VISUAL.2002.1183759	http://dx.doi.org/10.1109/VISUAL.2002.1183759	69	76	1183759	computational geometry;data visualisation;parallel algorithms;rendering (computer graphics);storage management	LOD-switching;culling techniques;external memory algorithm;level-of-detail switching;massive geometric environments;out-of-core rendering;parallel algorithm;performance;polygons;prioritized prefetching;rendering acceleration;scene graph;successive frames;visibility-based events	Acceleration;Chromium;Computer displays;Computer science;Layout;Partitioning algorithms;Prefetching;Rendering (computer graphics);Runtime;Solid modeling		We present an external memory algorithm for fast display of very large and complex geometric environments. We represent the model using a scene graph and employ different culling techniques for rendering acceleration. Our algorithm uses a parallel approach to render the scene as well as fetch objects from the disk in a synchronous manner. We present a novel prioritized prefetching technique that takes into account LOD-switching and visibility-based events between successive frames. We have applied our algorithm to large gigabyte-sized environments that are composed of thousands of objects and tens of millions of polygons. The memory overhead of our algorithm is output sensitive and is typically tens of megabytes. In practice, our approach scales with the model sizes, and its rendering performance is comparable to that of an in-core algorithm.	Varadhan, G.	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|	37267825100
	SciVis	1-1 Nov. 2002	Optimized view-dependent rendering for large polygonal datasets	10.1109/VISUAL.2002.1183760	http://dx.doi.org/10.1109/VISUAL.2002.1183760	77	84	1183760	rendering (computer graphics);tree data structures	computational geometry;graphics hardware;large datasets rendering;object modeling;spatial subdivision;spatial tree;view-dependence trees data-structure;view-dependent rendering	Acceleration;Chromium;Computational geometry;Computer graphics;Hardware;Mathematical model;Rendering (computer graphics);Solid modeling;Spatial resolution;Tree graphs		In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.	El-Sana, J.;Bachmat, E.	Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;	37393584400;37698248900
	SciVis	1-1 Nov. 2002	Volumetric shadows using splatting	10.1109/VISUAL.2002.1183761	http://dx.doi.org/10.1109/VISUAL.2002.1183761	85	92	1183761	data visualisation;rendering (computer graphics)	2D shadow buffer;light attenuation;multiple light sources;parallel lights;point lights;projective textured lights;rendering;splatting volume renderer;visualization;volumetric shadows	Chromium;Computer displays;Computer graphics;Information science;Layout;Light sources;Optical attenuators;Rendering (computer graphics);Tellurium;Three dimensional displays		This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. The light attenuation is modeled using splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer attenuates the light for each pixel. When the contribution of a footprint is added to the image buffer, as seen from the eye, we add the contribution to the shadow buffer, as seen from the light source. We have generated shadows for point lights and parallel lights using this algorithm. The shadow algorithm has been extended to deal with multiple light sources and projective textured lights.	Zhang, C.;Crawfis, R.	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;	37274216600;37284273900
	SciVis	1-1 Nov. 2002	Volume clipping via per-fragment operations in texture-based volume visualization	10.1109/VISUAL.2002.1183762	http://dx.doi.org/10.1109/VISUAL.2002.1183762	93	100	1183762	computational geometry;data visualisation;interpolation	complex geometries;data set;depth structure;hardware acceleration;perfragment operations;texture-based volume rendering;texture-based volume visualization;volume clipping;voxelized clip object	Chromium;Computer graphics;Data visualization;Geometry;Hardware;Image generation;Interactive systems;Rendering (computer graphics);Testing;Transfer functions		We propose new clipping methods that are capable of using complex geometries for volume clipping. The clipping tests exploit per-fragment operations on the graphics hardware to achieve high frame rates. In combination with texture-based volume rendering, these techniques enable the user to interactively select and explore regions of the data set. We present depth-based clipping techniques that analyze the depth structure of the boundary representation of the clip geometry to decide which parts of the volume have to be clipped. In another approach, a voxelized clip object is used to identify the clipped regions.	Weiskopf, D.;Engel, K.;Ertl, T.	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	38470313800;37266847600;38356653000
	SciVis	1-1 Nov. 2002	Interactive spectral volume rendering	10.1109/VISUAL.2002.1183763	http://dx.doi.org/10.1109/VISUAL.2002.1183763	101	108	1183763	colour graphics;data visualisation;real-time systems;realistic images;rendering (computer graphics);solid modelling	colour constancy;colour representation;datasets;interactive spectral volume rendering;palette;post-illumination;real-time scene relighting;realism;selective metamerism;spectral transfer functions;three-dimensional graphics;transfer function design;volumetric data;volumetric visualization	Color;Computer graphics;Image generation;Information systems;Layout;Light sources;Rendering (computer graphics);Transfer functions;Usability;Visualization		We describe a method for volume rendering using a spectral representation of colour instead of the traditional RGB model. It is shown how to use this framework for a novel exploration of datasets through enhanced transfer function design. Furthermore, our framework is extended to allow real-time re-lighting of the scene created with any rendering method. The technique of post-illumination is introduced to generate new spectral images for arbitrary light colours in real-time. Also a tool is described to design a palette of lights and materials having certain properties such as selective metamerism or colour constancy. Applied to spectral transfer functions, different light colours can accentuate or hide specific qualities of the data. In connection with post-illumination this provides a new degree of freedom for guided exploration of volumetric data, which cannot be achieved using the RGB model.	Bergner, S.;Moller, T.;Drew, M.S.;Finlayson, G.D.	Dept. of Simulation & Graphics, Magdeburg Univ., Germany|c|;;;	37418878100;37275858700;37282897100;37270741000
	SciVis	1-1 Nov. 2002	Interactive translucent volume rendering and procedural modeling	10.1109/VISUAL.2002.1183764	http://dx.doi.org/10.1109/VISUAL.2002.1183764	109	116	1183764	data visualisation;lighting;realistic images;rendering (computer graphics);solid modelling	3D graphics;interactive shading model;interactive translucent volume rendering;lighting;procedural modeling;realistic interactive modeling;shading models;visual quality;visualization;volumetric light attenuation effects;volumetric shadows	Application software;Clouds;Computed tomography;Computer graphics;Data visualization;Light scattering;Marine animals;Optical attenuators;Rendering (computer graphics);Transfer functions		Direct volume rendering is a commonly used technique in visualization applications. Many of these applications require sophisticated shading models to capture subtle lighting effects and characteristics of volumetric data and materials. Many common objects and natural phenomena exhibit visual quality that cannot be captured using simple lighting models or cannot be solved at interactive rates using more sophisticated methods. We present a simple yet effective interactive shading model which captures volumetric light attenuation effects to produce volumetric shadows and the subtle appearance of translucency. We also present a technique for volume displacement or perturbation that allows realistic interactive modeling of high frequency detail for real and synthetic volumetric data.	Kniss, J.;Premoze, S.;Hansen, C.;Ebert, D.	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;	37324263400;38149547900;37266777200;38472157400
	SciVis	1-1 Nov. 2002	A multiphase approach to efficient surface simplification	10.1109/VISUAL.2002.1183765	http://dx.doi.org/10.1109/VISUAL.2002.1183765	117	124	1183765	computational geometry;data visualisation;solid modelling	computational geometry;in-core iterative edge contraction;memory consumption;multiphase approach;object modeling;out-of-core uniform clustering phase;polygonal surface models;quadric error metrics;quadric-based iterative edge contraction;surface simplification;visualization	Chromium;Clustering algorithms;Clustering methods;Computational geometry;Computer graphics;Costs;Iterative algorithms;Iterative methods;Partitioning algorithms;Solid modeling		We present a new multiphase method for efficiently simplifying polygonal surface models of arbitrary size. It operates by combining an initial out-of-core uniform clustering phase with a subsequent in-core iterative edge contraction phase. These two phases are both driven by quadric error metrics, and quadrics are used to pass information about the original surface between phases. The result is a method that produces approximations of a quality comparable to quadric-based iterative edge contraction, but at a fraction of the cost in terms of running time and memory consumption.	Garland, M.;Shaffer, E.	Illinois Univ., Urbana, IL, USA|c|;	37272036400;37446940600
	SciVis	1-1 Nov. 2002	Geometric surface smoothing via anisotropic diffusion of normals	10.1109/VISUAL.2002.1183766	http://dx.doi.org/10.1109/VISUAL.2002.1183766	125	132	1183766	computational geometry;data visualisation;solid modelling	anisotropic diffusion of normals;changing topology;computational geometry;feature preserving surface smoothing;geometric surface smoothing;image filtering;image processing;level set surface models;object modeling;sharp geometric features;visualization	Anisotropic magnetoresistance;Isosurfaces;Laplace equations;Level set;Magnetic resonance imaging;Mathematics;Noise reduction;Shape;Smoothing methods;Topology		This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.	Tasdizen, T.;Whitaker, R.;Burchard, P.;Osher, S.	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;;	38263106800;37267322600;38149545900;37282704100
	SciVis	1-1 Nov. 2002	TetFusion: an algorithm for rapid tetrahedral mesh simplification	10.1109/VISUAL.2002.1183767	http://dx.doi.org/10.1109/VISUAL.2002.1183767	133	140	1183767	computational complexity;computational geometry;computer graphics;data visualisation	TetFusion;element boundary intersection;geometry decimation operation;interactive visualization;mesh-inconsistency problems;rapid LoD prototyping;rapid tetrahedral mesh simplification;time-varying datasets;volume tetrahedra	Chromium;Computational modeling;Computer graphics;Electrical capacitance tomography;Geometry;Laboratories;Medical simulation;Prototypes;Solid modeling;Visualization		This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.	Chopra, P.;Meyer, J.	Eng. Res. Center, Mississippi State Univ., MS, USA|c|;	38155160900;37279771900
	SciVis	1-1 Nov. 2002	Compressing polygon mesh geometry with parallelogram prediction	10.1109/VISUAL.2002.1183768	http://dx.doi.org/10.1109/VISUAL.2002.1183768	141	146	1183768	computational geometry;data compression;data visualisation;solid modelling	computational geometry;geometry coder;linear prediction;object modeling;parallelogram prediction;polygon mesh geometry compression;vertex position prediction;visualization	Bandwidth;Computational geometry;Computer graphics;Data visualization;Hardware;Predictive models;Rendering (computer graphics);Robustness;Semiconductor device modeling;Solid modeling		We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.	Isenburg, M.;Alliez, P.	North Carolina Univ., Chapel Hill, NC, USA|c|;	37281897600;37449235700
	SciVis	1-1 Nov. 2002	Probabilistic surfaces: point based primitives to show surface uncertainty	10.1109/VISUAL.2002.1183769	http://dx.doi.org/10.1109/VISUAL.2002.1183769	147	153	1183769	computational geometry;data visualisation;medical computing;rendering (computer graphics);solid modelling;tumours	computational geometry;display primitives;medicine;object modeling;point based primitives;polygon rendering;probabilistic surfaces;pseudo-coloring;shading;surface uncertainty;surface visualization;tumor formations	Data visualization;Displays;Moon;Neoplasms;Oil pollution;Petroleum;Pollution measurement;Solid modeling;Surface contamination;Uncertainty		Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.	Grigoryan, G.;Rheingans, P.	Maryland Univ., Baltimore, MD, USA|c|;	37282290900;37282292000
	SciVis	1-1 Nov. 2002	PMR: point to mesh rendering, a feature-based approach	10.1109/VISUAL.2002.1183770	http://dx.doi.org/10.1109/VISUAL.2002.1183770	155	162	1183770	computational geometry;data visualisation;rendering (computer graphics);solid modelling	PMR system;Voronoi diagram;computational geometry;computer graphics;display quality;feature geometry;feature-based approach;object modeling;point to mesh rendering;polygonal models;visualization	Chromium;Computational geometry;Computer displays;Computer graphics;Hardware;Image generation;Interpolation;Rendering (computer graphics);Solid modeling;Visualization		Within the field of computer graphics and visualization, it is often necessary to visualize polygonal models with large number of polygons. Display quality is mandatory, but it is also desirable to have the ability to rapidly update the display in order to facilitate interactive use. Point based rendering methods have been shown effective for this task. Building on this paradigm we introduce the PMR system which uses a hierarchy both in points and triangles for rendering. This hierarchy is fundamentally different from the ones used in existing methods. It is based on the feature geometry in the object space rather than its projection in the screen space. This provides certain advantages over the existing methods.	Dey, T.K.;Hudson, J.	Ohio State Univ., Columbus, OH, USA|c|;	37564265400;37737793900
	SciVis	1-1 Nov. 2002	Efficient simplification of point-sampled surfaces	10.1109/VISUAL.2002.1183771	http://dx.doi.org/10.1109/VISUAL.2002.1183771	163	170	1183771	computational geometry;data visualisation;rendering (computer graphics);solid modelling	3D objects;approximation error;geometry;hierarchical clustering;incremental clustering;intermediate tesselation;iterative simplification;local variation estimation;particle simulation algorithms;point-sampled geometry;point-sampled surface simplification;quadric error metrics;rendering;sampling density;visualization	Clouds;Clustering algorithms;Data visualization;Design methodology;Distortion measurement;Geometry;Geoscience;Iterative algorithms;Noise measurement;Sampling methods		We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.	Pauly, M.;Gross, Markus;Kobbelt, L.P.	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	37283033000;37275694700;37266790600
	SciVis	1-1 Nov. 2002	Exploring scalar fields using critical isovalues	10.1109/VISUAL.2002.1183772	http://dx.doi.org/10.1109/VISUAL.2002.1183772	171	178	1183772	data visualisation;interpolation;piecewise linear techniques	critical isovalues;hole formation;isosurface topology changes;large trivariate data set exploration;marching cubes algorithm;piecewise trilinear interpolation;rectilinear grid;scalar field visualization;surface component merging;topology preservation;trilinear interpolant;volume data	Computer graphics;Computer science;Data mining;Data visualization;Image processing;Interpolation;Isosurfaces;Merging;Table lookup;Topology		Isosurfaces are commonly used to visualize scalar fields. Critical isovalues indicate isosurface topology changes: the creation of new surface components, merging of surface components or the formation of holes in a surface component. Therefore, they highlight interesting isosurface behavior and are helpful in exploration of large trivariate data sets. We present a method that detects critical isovalues in a scalar field defined by piecewise trilinear interpolation over a rectilinear grid and describe how to use them when examining volume data. We further review varieties of the marching cubes (MC) algorithm, with the intention of preserving topology of the trilinear interpolant when extracting an isosurface. We combine and extend two approaches in such a way that it is possible to extract meaningful isosurfaces even when a critical value is chosen as the isovalue.	Weber, G.H.;Scheuermann, G.;Hagen, H.;Hamann, B.	AG Graphische Datenverarbeitung und Computergeometrie, Kaiserslautern Univ., Germany|c|;;;	37411444100;37282574800;38304705100;38295577900
	SciVis	1-1 Nov. 2002	Level set segmentation from multiple non-uniform volume datasets	10.1109/VISUAL.2002.1183773	http://dx.doi.org/10.1109/VISUAL.2002.1183773	179	186	1183773	computerised tomography;data visualisation;image reconstruction;image segmentation;medical image processing	3D reconstruction;CT scan;distance-weighted polynomial;imperfect registrations;laser scan reconstruction;level set;level set models;level set segmentation;moving least-squares;multiple volume datasets;segmentation;visualization	Computational efficiency;Computed tomography;Deformable models;Embryo;Laser noise;Level set;Mice;Polynomials;Sampling methods;Surface fitting		Typically 3-D MR and CT scans have a relatively high resolution in the scanning X-Y plane, but much lower resolution in the axial Z direction. This non-uniform sampling of an object can miss small or thin structures. One way to address this problem is to scan the same object from multiple directions. In this paper we describe a method for deforming a level set model using velocity information derived from multiple volume datasets with non-uniform resolution in order to produce a single high-resolution 3D model. The method locally approximates the values of the multiple datasets by fitting a distance-weighted polynomial using moving least-squares. The proposed method has several advantageous properties: its computational cost is proportional to the object surface area, it is stable with respect to noise, imperfect registrations and abrupt changes in the data, it provides gain-correction, and it employs a distance-based weighting to ensures that the contributions from each scan are properly merged into the final result. We have demonstrated the effectiveness of our approach on four multi-scan datasets, a Griffin laser scan reconstruction, a CT scan of a teapot and MR scans of a mouse embryo and a zucchini.	Museth, K.;Breen, D.E.;Zhukov, L.;Whitaker, R.T.	Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA|c|;;;	37284192900;38269872200;37266085200;37267322600
	SciVis	1-1 Nov. 2002	Efficient computation of the topology of level sets	10.1109/VISUAL.2002.1183774	http://dx.doi.org/10.1109/VISUAL.2002.1183774	187	194	1183774	computational complexity;computational geometry;data visualisation;divide and conquer methods;topology;tree data structures	Betti numbers;Contour Tree;divide-and-conquer algorithm;domain mesh;efficient algorithms;fundamental data structure;isosurfaces;level set topology;scalability;scientific visualization;time complexity	Contracts;Data visualization;Electrons;Isosurfaces;Laboratories;Level set;Scientific computing;Topology;Tree data structures;User interfaces			Pascucci, V.	Center of Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|	38262214600
	SciVis	1-1 Nov. 2002	Fast and reliable space leaping for interactive volume rendering	10.1109/VISUAL.2002.1183775	http://dx.doi.org/10.1109/VISUAL.2002.1183775	195	202	1183775	computational geometry;data visualisation;interactive systems;rendering (computer graphics)	Euclidean distance;SGI Power Challenge;cell-based reprojection scheme;complex volumetric scene;interactive navigation;interactive rendering;interactive volume rendering;object space coherence;ray casting;reliable space leaping;temporal coherence	Acceleration;Casting;Computer graphics;Euclidean distance;Imaging phantoms;Layout;Navigation;Object detection			Wan, M.;Sadiq, A.;Kaufman, A.	Boeing Co., Seattle, WA, USA|c|;;	37362958300;38139540100;37268052800
	SciVis	1-1 Nov. 2002	A new object-order ray-casting algorithm	10.1109/VISUAL.2002.1183776	http://dx.doi.org/10.1109/VISUAL.2002.1183776	203	210	1183776	biomedical imaging;data visualisation;ray tracing;rendering (computer graphics)	hidden volume removal;medical imaging;object-order ray-casting;ray tracing;ray-casting;scientific visualization;volume rendering	Biomedical optical imaging;Chromium;Computer graphics;Data visualization;Image generation;Image reconstruction;Optical filters;Recursive estimation;Rendering (computer graphics);Workstations			Mora, B.;Jessel, J.-P.;Caubet, Rene	Inst. de Recherche en Informatique de Toulouse (IRIT), Univ. Paul Sabatier, Toulouse, France|c|;;	37332752000;37391562600;37621345600
	SciVis	1-1 Nov. 2002	Non-photorealistic volume rendering using stippling techniques	10.1109/VISUAL.2002.1183777	http://dx.doi.org/10.1109/VISUAL.2002.1183777	211	218	1183777	data visualisation;rendering (computer graphics)	automatic preprocess;feature enhancement;interactive direct volume illustration;interactive visualizations;rendering;stipple drawing;stippling;volume rendering	Application software;Biomedical imaging;Chromium;Computer graphics;Data visualization;Engines;History;Medical simulation;Rendering (computer graphics);Surgery		Simulating hand-drawn illustration techniques can succinctly express information in a manner that is communicative and informative. We present a framework for an interactive direct volume illustration system that simulates traditional stipple drawing. By combining the principles of artistic and scientific illustration, we explore several feature enhancement techniques to create effective, interactive visualizations of scientific and medical datasets. We also introduce a rendering mechanism that generates appropriate point lists at all resolutions during an automatic preprocess, and modifies rendering styles through different combinations of these feature enhancements. The new system is an effective way to interactively preview large, complex volume datasets in a concise, meaningful, and illustrative manner. Volume stippling is effective for many applications and provides a quick and efficient method to investigate volume models.	Aidong Lu;Morris, C.J.;Ebert, D.S.;Rheingans, P.;Hansen, C.	Purdue Univ., West Lafayette, IN, USA|c|;;;;	38155731600;38000798200;38472157700;37282292000;37266777200
	SciVis	1-1 Nov. 2002	Interactive visualization of complex plant ecosystems	10.1109/VISUAL.2002.1183778	http://dx.doi.org/10.1109/VISUAL.2002.1183778	219	226	1183778	data visualisation;natural scenes;rendering (computer graphics)	complex landscapes;data reduction;ecosystems;geometrical representation;hierarchical data structure;interactive rendering;outdoor scenes;point-based rendering;polygonal plant models;whole plant populations	Computer displays;Computer graphics;Computer science;Ecosystems;Geometry;Layout;Shape;Vegetation mapping;Virtual reality;Visualization		We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.	Deussen, O.;Colditz, C.;Stamminger, M.;Drettakis, G.	Fac. of Comput. Sci., Dresden Univ. of Technol., Germany|c|;;;	37266781000;38149994300;37373910900;37282911900
	SciVis	1-1 Nov. 2002	Simulating fire with texture splats	10.1109/VISUAL.2002.1183779	http://dx.doi.org/10.1109/VISUAL.2002.1183779	227	234	1183779	Boltzmann equation;computer graphics;data visualisation;fires;realistic images;turbulence	Lattice Boltzmann Model;display primitives;high-detail textures;interactive rendering;open surface fire model;real-time simulation;textured splats	Acceleration;Combustion;Computational modeling;Displays;Equations;Fires;Fuels;Lattice Boltzmann methods;Surface texture;Temperature		We propose the use of textured splats as the basic display primitives for an open surface fire model. The high-detail textures help to achieve a smooth boundary of the fire and gain the small-scale turbulence appearance. We utilize the Lattice Boltzmann Model (LBM) to simulate physically-based equations describing the fire evolution and its interaction with the environment (e.g., obstacles, wind and temperature). The property of fuel and non-burning objects are defined on the lattice of the computation domain. A temperature field is also incorporated to model the generation of smoke from the fire due to incomplete combustion. The linear and local characteristics of the LBM enable us to accelerate the computation with graphics hardware to reach real-time simulation speed, while the texture splat primitives enable interactive rendering frame rates.	Wei, X.;Wei Li;Mueller, K.;Kaufman, A.	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;	37279025800;37278915900;37273119700;37268052800
	SciVis	1-1 Nov. 2002	Visualizing dynamic molecular conformations	10.1109/VISUAL.2002.1183780	http://dx.doi.org/10.1109/VISUAL.2002.1183780	235	242	1183780	biochemistry;data visualisation;molecular biophysics;molecular configurations	bioactivity;biochemical processes;biomolecules;conformation analysis;metastable conformational shapes;metastable molecular conformations;visual analysis;visualization	Biochemistry;Biological system modeling;Biology computing;Drugs;Information geometry;Metastasis;Molecular biophysics;Pathology;Shape;Visualization		The bioactivity of a molecule strongly depends on its metastable conformational shapes and the transitions between these. Therefore, conformation analysis and visualization is a basic prerequisite for the understanding of biochemical processes. We present techniques for visual analysis of metastable molecular conformations. Core of these are flexibly applicable methods for alignment of molecular geometries, as well as methods for depicting shape and 'fuzziness' of metastable conformations. All analysis tools are provided in an integrated working environment. The described techniques are demonstrated with pharmaceutically active biomolecules.	Schmidt-Ehrenberg, J.;Baum, D.;Hege, H.-C.	Zuse Inst. Berlin (ZIB), Germany|c|;;	38149516900;38182750200;37282272000
	SciVis	1-1 Nov. 2002	GeneVis: visualization tools for genetic regulatory network dynamics	10.1109/VISUAL.2002.1183781	http://dx.doi.org/10.1109/VISUAL.2002.1183781	243	250	1183781	data visualisation;genetics	GeneVis;biological visualization;dynamic visualizations;genetic networks;genetic regulation;genetic regulatory networks;particle-based simulation;visual environment	Biological information theory;Biological system modeling;Biology computing;Computational modeling;Computer interfaces;Genetics;Lenses;Medical simulation;Proteins;Visualization		GeneVis provides a visual environment for exploring the dynamics of genetic regulatory networks. At present time, genetic regulation is the focus of intensive research worldwide, and computational aids are being called for to help in the research of factors that are difficult to observe directly. GeneVis provides a particle-based simulation of genetic networks and visualizes the process of this simulation as it occurs. Two dynamic visualization techniques are provided, a visualization of the movement of the regulatory proteins and a visualization of the relative concentrations of these proteins. Several interactive tools relate the dynamic visualizations to the underlying genetic network structure.	Baker, C.A.H.;Carpendale, M.S.T.;Prusinkiewicz, P.;Surette, M.G.	Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;;	38145765600;37326090900;37266754700;37566595500
	SciVis	1-1 Nov. 2002	Isometric embedding by surface reconstruction from distances	10.1109/VISUAL.2002.1183782	http://dx.doi.org/10.1109/VISUAL.2002.1183782	251	257	1183782	computational geometry;data visualisation;image reconstruction;partial differential equations	Euclidean distances;abstract metric;computational physics;inner geometry;isometric embedding;partial differential equations;reconstruction;tensor fields	Differential equations;Embedded computing;Geometry;Interpolation;Physics computing;Surface fitting;Surface reconstruction;Surface treatment;Tensile stress;Topology		To display the intuitive meaning of an abstract metric it is helpful to look on an embedded surface with the same inner geometry as the given metric. The resulting partial differential equations have no standard solution. Only for some special cases satisfactory methods are known. I present a new algorithmic approach which is not based on differential equations. In contrast to other methods this technique also works if the embedding exists only locally. The fundamental idea is to estimate Euclidean distances, from which the surface is built up. In this paper I focus on the reconstruction of a surface from these estimated distances. Particular the influence of a perturbation of the distances on the shape of the resulting surface is investigated.	Hotz, I.	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|	37282721800
	SciVis	1-1 Nov. 2002	Fast view-dependent level-of-detail rendering using cached geometry	10.1109/VISUAL.2002.1183783	http://dx.doi.org/10.1109/VISUAL.2002.1183783	259	265	1183783	computational geometry;rendering (computer graphics);video signal processing	CABTT algorithm;CPU overhead;aggregate triangles;binary triangle tree based level of detail algorithms;cached geometry;fast view-dependent level of detail rendering;frame rate;geometry clusters;hardware accelerated rendering pipeline;video card	Acceleration;Aggregates;Clustering algorithms;Coherence;Computational geometry;Computer errors;Computer graphics;Hardware;Pipelines;Rendering (computer graphics)		Level-of-detail rendering is essential for rendering very large, detailed worlds in real-time. Unfortunately, level-of-detail computations can be expensive, creating a bottleneck at the CPU. This paper presents the CABTT algorithm, an extension to existing binary-triangle-tree-based level-of-detail algorithms. Instead of manipulating triangles, the CABTT algorithm instead operates on clusters of geometry called aggregate triangles. This reduces CPU overhead, eliminating a bottleneck common to level-of-detail algorithms. Since aggregate triangles stay fixed over several frames, they may be cached on the video card. This further reduces CPU load and fully utilizes the hardware accelerated rendering pipeline on modern video cards. These improvements result in a fourfold increase in frame rate over ROAM at high detail levels. Our implementation renders an approximation of an 8 million triangle height field at 42 frames per second with an maximum error of 1 pixel on consumer hardware.	Levenberg, J.	California Univ., Berkeley, CA, USA|c|	38149622100
	SciVis	1-1 Nov. 2002	Visibility-guided simplification	10.1109/VISUAL.2002.1183784	http://dx.doi.org/10.1109/VISUAL.2002.1183784	267	274	1183784	computer graphics;visibility	3D models;attribute error minimization;edge collapse sequences;geometric error minimization;graphics;low visibility regions;mesh simplification;mesh surfaces;polygon counts;rendering;surrounding camera sphere;view-independent visibility measure;visibility function;visibility-guided simplification algorithm	Cameras;Computer errors;Computer graphics;Costs;Educational institutions;Extraterrestrial measurements;Rendering (computer graphics);Shape;Solid modeling;Visualization		For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the number of low visibility regions in the original models.	Zhang, E.;Turk, G.	GVU Center & Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;	38145176200;37334922800
	SciVis	1-1 Nov. 2002	Maximum entropy light source placement	10.1109/VISUAL.2002.1183785	http://dx.doi.org/10.1109/VISUAL.2002.1183785	275	282	1183785	data visualisation;light sources;lighting;maximum entropy methods;optimisation	camera parameters;fast global optimization procedures;illumination;information measure;light position;maximum entropy light source placement;viewing parameters	Cameras;Computer graphics;Data visualization;Design optimization;Entropy;Histograms;Humans;Layout;Light sources;Lighting		"Finding the ""best"" viewing parameters for a scene is a difficult but very important problem. Fully automatic procedures seem to be impossible as the notion of ""best"" strongly depends on human judgment as well as on the application. In this paper a solution to the sub-problem of placing light sources for given camera parameters is proposed. A light position is defined to be optimal, when the resulting illumination reveals more about the scene than illuminations from all other light positions, i.e. the light position maximizes information that is added to the image through the illumination. With the help of an experiment with several subjects we could adapt the information measure to the actually perceived information content. We present fast global optimization procedures and solutions for two and more light sources."	Gumhold, S.	WSI/GRIS, Tubingen Univ., Germany|c|	37565742800
	SciVis	1-1 Nov. 2002	Computing singularities of 3D vector fields with geometric algebra	10.1109/VISUAL.2002.1183786	http://dx.doi.org/10.1109/VISUAL.2002.1183786	283	289	1183786	computational geometry;data visualisation;vectors	3D vector field singularities;Clifford algebra;critical points;geometric algebra;indexes;octree based solution;positions	Algebra;Algorithm design and analysis;Chromium;Computer science;Gaussian processes;Software algorithms;Software design;Terminology;Tin;Topology		Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.	Mann, S.;Rockwood, A.	Waterloo Univ., Ont., Canada|c|;	37998748200;37372689000
	SciVis	1-1 Nov. 2002	Seamster: inconspicuous low-distortion texture seam layout	10.1109/VISUAL.2002.1183787	http://dx.doi.org/10.1109/VISUAL.2002.1183787	291	298	1183787	data visualisation;image texture;visibility	Seamster;feature annotations;high surface curvature;inconspicuous low-distortion texture seam layout;low visibility regions;polygonal meshes;surface genus;surface orientation cues;surface texturing;texture mapping;visualization	Animals;Chromium;Computer graphics;Computer science;Frequency;Geometry;Notice of Violation;Shadow mapping;Surface texture;Visualization		Surface texturing aids the visualization of polygonal meshes by providing additional surface orientation cues and feature annotations. Such texturing is usually implemented via texture mapping, which is easier and more effective when the distortion of the mapping from the surface to the texture map is kept small. We have previously shown that distortion occurs when areas of high surface curvature are flattened into the texture map. By cutting the surface in these areas one can reduce texture map distortion at the expense of additional seam artifacts. This paper describes a faster technique for guiding a texture map seam through high distortion regions, while restricting the seam to regions of low visibility. This results in distortion reducing seams that are less visually distracting and take less time to compute. We have also observed that visibility considerations improve the speed of a recent method that adds cuts to reduce a surface genus.	Sheffer, A.;Hart, J.C.	Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa, Israel|c|;	37281781700;37301161800
	SciVis	1-1 Nov. 2002	Face-based luminance matching for perceptual colormap generation	10.1109/VISUAL.2002.1183788	http://dx.doi.org/10.1109/VISUAL.2002.1183788	299	306	1183788	computer vision;data visualisation;image matching;image representation	RGB input levels;colormap-based visualizations;computer graphics;face-based luminance matching;hardware configuration;image processing;image representation;luminance matching;perceptual colormap generation;viewing environment;visual processing	Brightness;Color;Computer displays;Computer science;Computer vision;Data visualization;Face;Humans;Monitoring;Shape		Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.	Kindlmann, G.;Reinhard, E.;Creem, S.	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;	37282742400;37275258400;38149521000
	SciVis	1-1 Nov. 2002	Geometric verification of swirling features in flow fields	10.1109/VISUAL.2002.1183789	http://dx.doi.org/10.1109/VISUAL.2002.1183789	307	314	1183789	automatic optical inspection;computational fluid dynamics;computational geometry;data visualisation;flow simulation;vortices	automated visual inspection;flow fields;geometric verification;numerically simulated datasets;procedurally generated datasets;streamline geometry;swirling features;swirling streamlines;vortex cores;vortices	Computational modeling;Data visualization;Detection algorithms;Geometry;Humans;Inspection;Large-scale systems;Numerical simulation;Testing;Tornadoes		In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.	Jiang, M.;Machiraju, R.;Thompson, D.	Ohio State Univ., Columbus, OH, USA|c|;;	37826582200;38268669300;38181602100
	SciVis	1-1 Nov. 2002	Comparative evaluation of visualization and experimental results using image comparison metrics	10.1109/VISUAL.2002.1183790	http://dx.doi.org/10.1109/VISUAL.2002.1183790	315	322	1183790	computational fluid dynamics;data visualisation;digital simulation;image processing;rheology	2nd-order Fourier comparison;base cases;comparative evaluation;computational fluid dynamics;computational steering;computer simulation;controlled comparison space;field trials;human vision system metrics;image comparison metrics;imagery;photographic image;rheological experiment;spatial domain metrics;spatial-frequency domain metrics;visualization	Application software;Computer graphics;Computer simulation;Computer vision;Design optimization;Humans;Image processing;Lighting;Rheology;Visualization		"Comparative evaluation of visualization and experimental results is a critical step in computational steering. In this paper, we present a study of image comparison metrics for quantifying the magnitude of difference between visualization of a computer simulation and a photographic image captured from an experiment. We examined eleven metrics, including three spatial domain, four spatial-frequency domain and four HVS (human-vision system) metrics. Among these metrics, a spatial-frequency domain metric called 2nd-order Fourier comparison was proposed specifically for this work. Our study consisted of two stages: base cases and field trials. The former is a general study on a controlled comparison space using purposely selected data, and the latter involves imagery results from computational fluid dynamics and a rheological experiment. This study has introduced a methodological framework for analyzing image-level methods used in comparative visualization. For the eleven metrics considered, it has offered a set of informative indicators as to the strengths and weaknesses of each metric. In particular, we have identified three image comparison metrics that are effective in separating ""similar"" and ""different"" image groups. Our 2nd-order Fourier comparison metric has compared favorably with others in two of the three tests, and has shown its potential to be used for steering computer simulation quantitatively."	Hualin Zhou;Min Chen;Webster, M.F.	Univ. of Wales, Swansea, UK|c|;;	38150365000;38026251100;37346467200
	SciVis	1-1 Nov. 2002	A model for the visualization exploration process	10.1109/VISUAL.2002.1183791	http://dx.doi.org/10.1109/VISUAL.2002.1183791	323	330	1183791	data visualisation;hypermedia markup languages	XML-based language;automated analysis;automated reporting;data exploration;information content;model;parameter derivation calculus;visualization exploration process	Calculus;Chromium;Collaboration;Computer graphics;Computer science;Data visualization;Documentation;History;Pressing;XML		The current state of the art in visualization research places strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process - the results, history, and relationships between those results - is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize information within the visualization process to further data exploration.	Jankun-Kelly, T.J.;Kwan-Liu Ma;Gertz, M.	Comput. Sci. Dept., California Univ., Davis, CA, USA|c|;;	38275083200;38298685400;38300018900
	SciVis	1-1 Nov. 2002	Sea of images	10.1109/VISUAL.2002.1183792	http://dx.doi.org/10.1109/VISUAL.2002.1183792	331	338	1183792	image coding;image reconstruction;real-time systems;rendering (computer graphics);storage management	complex lighting effects;complex visibility effects;computer graphics;dense reconstruction;dense sampling;dense storage;eye-height plane;image resampling;image storage;images compression;interactive walkthrough;large complex indoor environments;large photorealistic environment;motorized cart;multiresolution hierarchy;occlusion effects;omnidirectional image capture;plenoptic function;real-time prefetching;rendering;sea of images;simulated observer;specular reflections;visual experience	Computational modeling;Computer graphics;Image coding;Image reconstruction;Image sampling;Image storage;Indoor environments;Legged locomotion;Rendering (computer graphics);Solid modeling		"A long-standing research problem in computer graphics is to reproduce the visual experience of walking through a large photorealistic environment interactively. On one hand, traditional geometry-based rendering systems fall short of simulating the visual realism of a complex environment. On the other hand, image-based rendering systems have to date been unable to capture and store a sampled representation of a large environment with complex lighting and visibility effects. In this paper, we present a ""sea of images,"" a practical approach to dense sampling, storage, and reconstruction of the plenoptic function in large, complex indoor environments. We use a motorized cart to capture omnidirectional images every few inches on a eye-height plane throughout an environment. The captured images are compressed and stored in a multiresolution hierarchy suitable for real-time prefetching during an interactive walkthrough. Later, novel images are reconstructed for a simulated observer by resampling nearby captured images. Our system acquires 15,254 images over 1,050 square feet at an average image spacing of 1.5 inches. The average capture and processing time is 7 hours. We demonstrate realistic walkthroughs of real-world environments reproducing specular reflections and occlusion effects while rendering 15-25 frames per second."	Aliaga, Daniel G.;Funkhouser, T.;Yanovsky, D.;Carlbom, I.	Lucent Technol. Bell Labs, NJ, USA|c|;;;	37270561900;37283059800;38149818000;37270560600
	SciVis	1-1 Nov. 2002	Scalable alignment of large-format multi-projector displays using camera homography trees	10.1109/VISUAL.2002.1183793	http://dx.doi.org/10.1109/VISUAL.2002.1183793	339	346	1183793	calibration;computer vision;feature extraction	camera homography tree;camera homography trees;large-format multi-projector displays;multiple zoomed camera;scalable alignment;uncalibrated camera images;vision-based geometric alignment system	Calibration;Cameras;Chromium;Computational modeling;Computer displays;Computer graphics;Computer science;Degradation;Pixel;Robot vision systems		This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.	Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.	Comput. Sci., Princeton Univ., NJ, USA|c|;;;	37337226600;37282878500;37425426700;37277619300
	SciVis	1-1 Nov. 2002	Efficient compression and rendering of multi-resolution meshes	10.1109/VISUAL.2002.1183794	http://dx.doi.org/10.1109/VISUAL.2002.1183794	347	354	1183794	decoding;encoding;rendering (computer graphics);wavelet transforms	decoding;geometry coding;multiresolution meshes compression;multiresolution meshes rendering;vertex buffer mechanism;wavelets	Computer graphics;Computer science;Decoding;Geometry;Internet;Multiresolution analysis;Rendering (computer graphics);Rough surfaces;Solid modeling;Web server		We present a method to code the multiresolution structure of a 3D triangle mesh in a manner that allows progressive decoding and efficient rendering at a client machine. The code is based on a special ordering of the mesh vertices which has good locality and continuity properties, inducing a natural multiresolution structure. This ordering also incorporates information allowing efficient rendering of the mesh at all resolutions using the contemporary vertex buffer mechanism. The performance of our code is shown to be competitive with existing progressive mesh compression methods, while achieving superior rendering speed.	Karni, Z.;Bogomjakov, A.;Gotsman, C.	Fac. of Comput. Sci., Technion - Israel Inst. of Technol., Haifa, Israel|c|;;	37546486500;37281880000;37281769000
	SciVis	1-1 Nov. 2002	Bounded-distortion piecewise mesh parameterization	10.1109/VISUAL.2002.1183795	http://dx.doi.org/10.1109/VISUAL.2002.1183795	355	362	1183795	computational geometry;data compression;image coding;rendering (computer graphics)	3D painting;arbitrary genus 2-manifolds;bounded-distortion piecewise mesh parameterization;complex irregular meshes;computer graphics;digital geometry processing;distortion bound;mesh compression;mesh partitioning;remeshing;strictly bounded distortion;texture mapping	Application software;Chromium;Computational geometry;Computer graphics;Computer science;Image coding;Mesh generation;Painting;Surface texture;Visualization		Many computer graphics operations, such as texture mapping, 3D painting, remeshing, mesh compression, and digital geometry processing, require finding a low-distortion parameterization for irregular connectivity triangulations of arbitrary genus 2-manifolds. This paper presents a simple and fast method for computing parameterizations with strictly bounded distortion. The new method operates by flattening the mesh onto a region of the 2D plane. To comply with the distortion bound, the mesh is automatically cut and partitioned on-the-fly. The method guarantees avoiding global and local self-intersections, while attempting to minimize the total length of the introduced seams. To our knowledge, this is the first method to compute the mesh partitioning and the parameterization simultaneously and entirely automatically, while providing guaranteed distortion bounds. Our results on a variety of objects demonstrate that the method is fast enough to work with large complex irregular meshes in interactive applications.	Sorkine, O.;Cohen-Or, D.;Goldenthal, R.;Lischinski, D.	Sch. of Comput. Sci., Tel Aviv Univ., Israel|c|;;;	37283081500;37266751800;38149592600;37418740700
	SciVis	1-1 Nov. 2002	XFastMesh: fast view-dependent meshing from external memory	10.1109/VISUAL.2002.1183796	http://dx.doi.org/10.1109/VISUAL.2002.1183796	363	370	1183796	data structures;mesh generation;paged storage;rendering (computer graphics)	XFastMesh;binary subtrees;external memory data structure;file format;merge-tree forest;multiresolution triangle mesh data structure;multiresolution triangulation;paging;space cost;view-dependent meshing;view-dependent rendering	Chromium;Computer graphics;Computer science;Costs;Data structures;Displays;Image generation;Image storage;Rendering (computer graphics);Solid modeling		We present a novel disk-based multiresolution triangle mesh data structure that supports paging and view-dependent rendering of very large meshes at interactive frame rates from external memory. Our approach, called XFastMesh, is based on a view-dependent mesh simplification framework that represents half-edge collapse operations in a binary hierarchy known as a merge-tree forest. The proposed technique partitions the merge-tree forest into so-called detail blocks, which consist of binary subtrees, that are stored on disk. We present an efficient external memory data structure and file format that stores all detail information of the multiresolution triangulation method using significantly less storage then previously reported approaches. Furthermore, we present a paging algorithm that provides efficient loading and interactive rendering of large meshes from external memory at varying and view-dependent level-of-detail. The presented approach is highly efficient both in terms of space cost and paging performance.	DeCoro, C.;Pajarola, Renato	Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA|c|;	37330248600;37282193800
	SciVis	1-1 Nov. 2002	Tensor field visualisation using adaptive filtering of noise fields combined with glyph rendering	10.1109/VISUAL.2002.1183797	http://dx.doi.org/10.1109/VISUAL.2002.1183797	371	378	1183797	biomedical MRI;data visualisation;rendering (computer graphics)	adaptive filtering;data visualisation;direct volume rendering;glyph rendering;human heart muscle;noise fields;phase contrast magnetic resonance image data;strain-rate tensors;tensor field visualisation;three-dimensional adaptive filtering	Adaptive filters;Data visualization;Filtering;Heart;Humans;Muscles;Process control;Rendering (computer graphics);Tensile stress;Testing		While many methods exist for visualising scalar and vector data, visualisation of tensor data is still troublesome. We present a method for visualising second order tensors in three dimensions using a hybrid between direct volume rendering and glyph rendering. An overview scalar field is created by using three-dimensional adaptive filtering of a scalar field containing noise. The filtering process is controlled by the tensor field to be visualised, creating patterns that characterise the tensor field. By combining direct volume rendering of the scalar field with standard glyph rendering methods for detailed tensor visualisation, a hybrid solution is created. A combined volume and glyph renderer was implemented and tested with both synthetic tensors and strain-rate tensors from the human heart muscle, calculated from phase contrast magnetic resonance image data. A comprehensible result could be obtained, giving both an overview of the tensor field as well as detailed information on individual tensors.	Sigfridsson, A.;Ebbers, T.;Heiberg, E.;Wigstrom, L.	Dept. of Medicine & Care, Linkoping Univ., Sweden|c|;;;	37938415900;37830552200;37662873700;37295968100
	SciVis	1-1 Nov. 2002	Volume deformation for tensor visualization	10.1109/VISUAL.2002.1183798	http://dx.doi.org/10.1109/VISUAL.2002.1183798	379	386	1183798	data visualisation;eigenvalues and eigenfunctions	continuous representation;second-order 3D tensor fields visualization;volume deformation	Algorithm design and analysis;Biomedical imaging;Capacitive sensors;Chromium;Computer graphics;Computer science;Data visualization;Eigenvalues and eigenfunctions;Ellipsoids;Tensile stress		Visualizing second-order 3D tensor fields continue to be a challenging task. Although there are several algorithms that have been presented, no single algorithm by itself is sufficient for the analysis because of the complex nature of tensor fields. In this paper, we present two new methods, based on volume deformation, to show the effects of the tensor field upon its underlying media. We focus on providing a continuous representation of the nature of the tensor fields. Each of these visualization algorithms is good at displaying some particular properties of the tensor field.	Zheng, X.;Pang, A.	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	37274785100;37267352000
	SciVis	1-1 Nov. 2002	Oriented tensor reconstruction: tracing neural pathways from diffusion tensor MRI	10.1109/VISUAL.2002.1183799	http://dx.doi.org/10.1109/VISUAL.2002.1183799	387	394	1183799	biomedical MRI;data visualisation;eigenvalues and eigenfunctions;interpolation;least squares approximations	3D tensor fields;a priori assumptions;anatomical fibers tracing;brain-fiber pathways;computer graphics;diffusion tensor MRI;human brain DT-MRI data;identifiable anatomical structures;least squares filter;neural pathways tracing;oriented tensor reconstruction;voxel size resolution	Anatomical structure;Bridges;Data mining;Diffusion tensor imaging;Feature extraction;Humans;Image reconstruction;Magnetic resonance imaging;Neural pathways;Tensile stress		In this paper we develop a new technique for tracing anatomical fibers from 3D tensor fields. The technique extracts salient tensor features using a local regularization technique that allows the algorithm to cross noisy regions and bridge gaps in the data. We applied the method to human brain DT-MRI data and recovered identifiable anatomical structures that correspond to the white matter brain-fiber pathways. The images in this paper are derived from a dataset having 1218860 resolution. We were able to recover fibers with less than the voxel size resolution by applying the regularization technique, i.e., using a priori assumptions about fiber smoothness. The regularization procedure is done through a moving least squares filter directly incorporated in the tracing algorithm.	Zhukov, L.	Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA|c|	37266085200
	SciVis	1-1 Nov. 2002	QuadTIN: quadtree based triangulated irregular networks	10.1109/VISUAL.2002.1183800	http://dx.doi.org/10.1109/VISUAL.2002.1183800	395	402	1183800	computational geometry;data visualisation;quadtrees;rendering (computer graphics);virtual reality	QuadTIN;adaptive level-of-detail rendering algorithms;computational geometry;digital elevation models;interactive terrain visualization;interactive visualization;irregular triangulated network;multiresolution triangulation;quadtree based triangulated irregular networks;scientific visualization;terrain sampling;virtual reality	Application software;Computer graphics;Computer science;Data visualization;Digital elevation models;Geographic Information Systems;Rendering (computer graphics);Strips;Tin;Virtual reality		Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.	Pajarola, Renato;Antonijuan, M.;Lario, R.	Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA|c|;;	37282193800;38149718800;37331033400
	SciVis	1-1 Nov. 2002	Horizon occlusion culling for real-time rendering of hierarchical terrains	10.1109/VISUAL.2002.1183801	http://dx.doi.org/10.1109/VISUAL.2002.1183801	403	409	1183801	data visualisation;rendering (computer graphics)	hierarchical terrains;horizon occlusion culling;minimal preprocessing;real-time rendering;rendering	Computer graphics;Degradation;Fuses;Geographic Information Systems;Geometry;Hardware;Image quality;Layout;Rendering (computer graphics);Visualization		We present a technique to perform occlusion culling for hierarchical terrains at run-time. The algorithm is simple to implement and requires minimal pre-processing and additional storage, yet leads to 2-4 times improvement in framerate for views with high degrees of occlusion. Our method is based on the well-known occlusion horizon algorithm. We show how to adapt the algorithm for use with hierarchical terrains. The occlusion horizon is constructed as the terrain is traversed in an approximate front to back ordering. Regions of the terrain are compared to the horizon to determine when they are completely occluded from the viewpoint. Culling these regions leads to significant savings in rendering.	Lloyd, B.;Egbert, P.	Brigham Young Univ., Provo, UT, USA|c|;	37699443600;37298442300
	SciVis	1-1 Nov. 2002	Evaluation of a multimodal interface for 3D terrain visualization	10.1109/VISUAL.2002.1183802	http://dx.doi.org/10.1109/VISUAL.2002.1183802	411	418	1183802	data visualisation;geographic information systems;gesture recognition;speech recognition;virtual reality	3D terrain visualization;Earth 3D terrain model;GIS;gesture interface;gesture recognition;mouse driven interface;multimodal interface;multimodal speech interface;speech interface;speech recognition;virtual reality;visual navigation	Computer displays;Computer interfaces;Earth;Keyboards;Mice;Mobile computing;Navigation;Speech recognition;Visualization;Wearable computers		Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.	Krum, D.M.;Omoteso, O.;Ribarsky, W.;Starner, T.;Hodges, L.F.	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;	37391946800;38149705700;37300425000;37269366200;37282880200
	SciVis	1-1 Nov. 2002	Assisted navigation for large information spaces	10.1109/VISUAL.2002.1183803	http://dx.doi.org/10.1109/VISUAL.2002.1183803	419	426	1183803	data visualisation;database management systems	animated tours;camera planning;camera planning techniques;constraint-based viewpoint construction;data. visualization;graph traversal;navigation assistant;scientific visualization	Algorithm design and analysis;Animation;Clustering algorithms;Data visualization;Displays;Multidimensional systems;Navigation;Smart cameras;Software design;Software systems		This paper presents a new technique for visualizing large, complex collections of data. The size and dimensionality of these datasets make them challenging to display in an effective manner. The images must show the global structure of spatial relationships within the dataset, yet at the same time accurately represent the local detail of each data element being visualized. We propose combining ideas from information and scientific visualization together with a navigation assistant, a software system designed to help users identify and explore areas of interest within their data. The assistant locates data elements of potential importance to the user, clusters them into spatial regions, and builds underlying graph structures to connect the regions and the elements they contain. Graph traversal algorithms, constraint-based viewpoint construction, and intelligent camera planning techniques can then be used to design animated tours of these regions. In this way, the navigation assistant can help users to explore any of the areas of interest within their data. We conclude by demonstrating how our assistant is being used to visualize a multidimensional weather dataset.	Dennis, Brent M.	Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA|c|	37554695200
	SciVis	1-1 Nov. 2002	BM3D: motion estimation in time dependent volume data	10.1109/VISUAL.2002.1183804	http://dx.doi.org/10.1109/VISUAL.2002.1183804	427	433	1183804	data visualisation;motion estimation	BM3D;block matching technique;data movement reconstruction;motion estimation;time dependent volume data;vector data set sequence;volume data set sequence	Computer graphics;Computer science;Data visualization;Image motion analysis;Mathematics;Motion analysis;Motion estimation;Optical computing;Optical mixing;Video compression		This paper describes BM3D: a method for the analysis of motion in time dependent volume data. From a sequence of volume data sets a sequence of vector data sets representing the movement of the data is computed. A block matching technique is used for the reconstruction of data movement. The derived vector field can be used for the visualization of time dependent volume data. The method is illustrated in two applications.	Wim de Leeuw;van Liere, R.	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;	37327212900;37282925600
	SciVis	1-1 Nov. 2002	Kinetic visualization: a technique for illustrating 3D shape and structure	10.1109/VISUAL.2002.1183805	http://dx.doi.org/10.1109/VISUAL.2002.1183805	435	442	1183805	computer animation;data visualisation;image sequences;rendering (computer graphics);video signal processing	3D shape perception;3D structure perception;animations;depth;flowing particles;kinetic visualization;motion;motion cues;particle systems;spatial relationships;static objects;surface models;videos;visual cues;volumetric models	Animation;Computer graphics;Computer science;Data visualization;Fires;Kinetic theory;Rendering (computer graphics);Shape;Videos;Watches		Motion provides strong visual cues for the perception of shape and depth, as demonstrated by cognitive scientists and visual artists. This paper presents a novel visualization technique-kinetic visualization -that uses particle systems to add supplemental motion cues which can aid in the perception of shape and spatial relationships of static objects. Based on a set of rules following perceptual and physical principles, particles flowing over the surface of an object not only bring out, but also attract attention to, essential information on the shape of the object that might not be readily visible with conventional rendering that uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that in many cases the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. The results of a preliminary user study that we have conducted also show evidence that the supplemental motion cues help.	Lum, E.B.;Stompel, A.;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	37282576300;37947852700;37275869400
	SciVis	1-1 Nov. 2002	A radial focus+context visualization for multi-dimensional functions	10.1109/VISUAL.2002.1183806	http://dx.doi.org/10.1109/VISUAL.2002.1183806	443	450	1183806	data visualisation;graphical user interfaces	data visualization;graphical user interfaces;multi-dimensional functions;multidimensional function space;radial focus+context visualization;user-controlled polar focal point	Chromium;Computer graphics;Computer science;Data visualization;Graphical user interfaces;Human computer interaction;Multidimensional systems;Performance analysis;System performance;User interfaces		The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.	Jayaraman, S.;North, C.	Center for Human Comput. Interaction, Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;	38153606700;37419565900
	SciVis	1-1 Nov. 2002	BLIC: Bi-Level Isosurface Compression	10.1109/VISUAL.2002.1183807	http://dx.doi.org/10.1109/VISUAL.2002.1183807	451	458	1183807	computational geometry;data compression;data visualisation;image coding;solid modelling	BLIC;JBIG binary image compression;bi-level isosurface compression;context based arithmetic;entropy encoding;isosurface algorithms;isosurface data compression;marching cubes vertex;mesh connectivity;polygon meshes;scalar functions;volume grids	Arithmetic;Code standards;Data mining;Decoding;Entropy;Image coding;Isosurfaces;Mesh generation;Quantization;Smoothing methods		In this paper we introduce a new and simple algorithm to compress isosurface data. This is the data extracted by isosurface algorithms from scalar functions defined on volume grids, and used to generate polygon meshes or alternative representations. In this algorithm the mesh connectivity and a substantial proportion of the geometric information are encoded to a fraction of a bit per marching cubes vertex with a context based arithmetic coder closely related to the JBIG binary image compression standard. The remaining optional geometric information that specifies the location of each marching cubes vertex more precisely along its supporting intersecting grid edge, is efficiently encoded in scan-order with the same mechanism. Vertex normals can optionally be computed as normalized gradient vectors by the encoder and included in the bitstream after quantization and entropy encoding, or computed by the decoder in a postprocessing smoothing step. These choices are determined by trade-offs associated with an in-core vs. out-of-core decoder structure. The main features of our algorithm are its extreme simplicity and high compression rates.	Taubin, Gabriel	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	37282608000
	SciVis	1-1 Nov. 2002	Approximating normals for marching cubes applied to locally supported isosurfaces	10.1109/VISUAL.2002.1183808	http://dx.doi.org/10.1109/VISUAL.2002.1183808	459	466	1183808	data visualisation;interpolation;rendering (computer graphics)	Gouraud shading;cubes marching;locally supported isosurfaces;normals approximation;triangular mesh surface approximation	Approximation algorithms;Computer science;Data analysis;Data visualization;Interpolation;Isosurfaces;Lattices;State estimation;Topology		We present some new methods for computing estimates of normal vectors at the vertices of a triangular mesh surface approximation to an isosurface which has been computed by the marching cube algorithm. These estimates are required for the smooth rendering of triangular mesh surfaces. The conventional method of computing estimates based upon divided difference approximations of the gradient can lead to poor estimates in some applications. This is particularly true for isosurfaces obtained from a field function, which is defined only for values near to the isosurface. We describe some efficient methods for computing the topology of the triangular mesh surface, which is used for obtaining local estimates of the normals. In addition, a new, one pass, approach for these types of applications is described and compared to existing methods.	Nielson, G.M.;Huang, A.;Sylvester, S.	Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;;	37283754100;38147203400;38149703800
	SciVis	1-1 Nov. 2002	Volume warping for adaptive isosurface extraction	10.1109/VISUAL.2002.1183809	http://dx.doi.org/10.1109/VISUAL.2002.1183809	467	474	1183809	computational geometry;data visualisation;interpolation;solid modelling	adaptive isosurface extraction;computational geometry;data structures;imaging techniques;interactive exploration;isosurfaces;object modeling;polygonal approximations;solid modelling;uniformly sampled volumes;volume warping	Computational geometry;Computer graphics;Data mining;Data structures;Data visualization;High-resolution imaging;Image resolution;Isosurfaces;Solid modeling;Teeth		Polygonal approximations of isosurfaces extracted from uniformly sampled volumes are increasing in size due to the availability of higher resolution imaging techniques. The large number of I primitives represented hinders the interactive exploration of the dataset. Though many solutions have been proposed to this problem, many require the creation of isosurfaces at multiple resolutions or the use of additional data structures, often hierarchical, to represent the volume. We propose a technique for adaptive isosurface extraction that is easy to implement and allows the user to decide the degree of adaptivity as well as the choice of isosurface extraction algorithm. Our method optimizes the extraction of the isosurface by warping the volume. In a warped volume, areas of importance (e.g. containing significant details) are inflated while unimportant ones are contracted. Once the volume is warped, any extraction algorithm can be applied. The extracted mesh is subsequently unwarped such that the warped areas are rescaled to their initial proportions. The resulting isosurface is represented by a mesh that is more densely sampled in regions decided as important.	Balmelli, L.;Morris, C.J.;Taubin, Gabriel;Bernardini, F.	IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;;;	37369654900;38000798200;37282608000;38140117000
	SciVis	Oct. 27 2002-Nov. 1 2002	Interactive view-dependent rendering of large isosurfaces	10.1109/VISUAL.2002.1183810	http://dx.doi.org/10.1109/VISUAL.2002.1183810	475	482	1183810	computational geometry;data structures;rendering (computer graphics);solid modelling	computational geometry;data structure;edge bisection;graphics data structures;interactive view-dependent rendering;large isosurfaces rendering;mesh refinement;multiresolution structure;object modeling;recursive tetrahedral mesh refinement;view-dependent fashion	Data engineering;Data mining;Data structures;Data visualization;Image processing;Isosurfaces;Laboratories;Rendering (computer graphics);Scientific computing;Switches		We present an algorithm for interactively extracting and rendering isosurfaces of large volume datasets in a view-dependent fashion. A recursive tetrahedral mesh refinement scheme, based on longest edge bisection, is used to hierarchically decompose the data into a multiresolution structure. This data structure allows fast extraction of arbitrary isosurfaces to within user specified view-dependent error bounds. A data layout scheme based on hierarchical space filling curves provides access to the data in a cache coherent manner that follows the data access pattern indicated by the mesh refinement.	Gregorski, B.;Duchaineau, M.;Lindstrom, P.;Pascucci, V.;Joy, K.I.	Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|;;;;	37267290500;37267813100;37269320000;37284312600;37267811400
	SciVis	1-1 Nov. 2002	Case study: hardware-accelerated selective LIC volume rendering	10.1109/VISUAL.2002.1183811	http://dx.doi.org/10.1109/VISUAL.2002.1183811	485	488	1183811	flow visualisation;rendering (computer graphics)	2D dense flow fields visualization;3D local streamlines;3D significance map;VolumePro;flow structures;flow visualization;hardware-accelerated selective LIC volume rendering;line integral convolution;solid texture;viewing directions	Analytical models;Computational modeling;Computer aided software engineering;Convolution;Image generation;Integrated optics;Lighting;Rendering (computer graphics);Streaming media;Visualization		Line Integral Convolution (LIC) is a promising method for visualizing 2D dense flow fields. Direct extensions of the LIC method to 3D have not been considered very effective, because optical integration in viewing directions tends to spoil the coherent structures along 3D local streamlines. In our previous reports, we have proposed a selective approach to volume rendering of LIC solid texture using 3D significance map (S-map), derived from the characteristics of flow structures, and a specific illumination model for 3D streamlines. In this paper, we take full advantage of scalar volume rendering hardware, such as VolumePro, to realize a realtime 3D flow field visualization environment with the LIC volume rendering method.	Suzuki, Y.;Fujishiro, I.;Chen, L.;Nakamura, H.	Mitsubishi Electr. Corp., Japan|c|;;;	38147016200;37282596600;38151039900;38149940200
	SciVis	1-1 Nov. 2002	Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics	10.1109/VISUAL.2002.1183812	http://dx.doi.org/10.1109/VISUAL.2002.1183812	489	492	1183812	computational complexity;computerised tomography;data visualisation;solid modelling	Christmas tree scanning;complex real world objects;computed tomography;computer graphics;data enhancement;data presentation;model acquisition too;volume rendering	Application software;Chromium;Computed tomography;Computer aided software engineering;Computer graphics;Image segmentation;Laser modes;Radiology;Rendering (computer graphics);Tree graphs		We report on using computed tomography (CT) as a model acquisition tool for complex objects in computer graphics. Unlike other modeling and scanning techniques the complexity of the object is irrelevant in CT, which naturally enables to model objects with, for example, concavities, holes, twists or fine surface details. Once the data is scanned, one can apply post-processing techniques for data enhancement, modification or presentation. For demonstration purposes we chose to scan a Christmas tree which exhibits high complexity which is difficult or even impossible to handle with other techniques. However, care has to be taken to achieve good scanning results with CT. Further, we illustrate post-processing by means of data segmentation and photorealistic as well as non-photorealistic surface and volume rendering techniques.	Kanitsar, A.;Theussl, T.;Mroz, L.;Sramek, M.;Csebfalvi, B.;Hladuvka, J.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Rottger, S.;Guthe, S.;Purgathofer, W.;Groller, M.E.	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;;;;;;;;	37282727500;38149729100;37282641800;37268028700;37284317200;38149719800;37282581000;37267822600;37267788200;37357145300;37728224400;37448821300;37282552200
	SciVis	1-1 Nov. 2002	Case study: Visualization and analysis of high Rayleigh number - 3D convection in the Earth&#39;s mantle	10.1109/VISUAL.2002.1183813	http://dx.doi.org/10.1109/VISUAL.2002.1183813	493	496	1183813	data visualisation;feature extraction;geophysics computing;rendering (computer graphics)	3D convection;Earth Mantle;critical point analysis;heat conductivity;high Rayleigh number visualization;large-scale simulations;plume-like structures;velocity field;volume rendering	Computer aided software engineering;Computer graphics;Earth;Equations;Geoscience;Information analysis;Temperature;Thermal conductivity;Thermal pollution;Visualization			Erlebacher, G.;Yuen, D.A.;Dubuffet, F.	Sch. of Computational Sci. & Inf. Technol., Florida State Univ., Tallahassee, FL, USA|c|;;	37324424400;38476567400;38149813100
	SciVis	1-1 Nov. 2002	Immersive volume visualization of seismic simulations: A case study of techniques invented and lessons learned	10.1109/VISUAL.2002.1183814	http://dx.doi.org/10.1109/VISUAL.2002.1183814	497	500	1183814	data visualisation;geophysics computing;rendering (computer graphics);seismology	collaborative simulation;computer graphics;immersive volume visualization;rendering algorithms;seismic simulations;volumetric datasets	Collaboration;Computational modeling;Computer graphics;Computer simulation;Data visualization;Documentation;Geophysics computing;Large-scale systems;Rendering (computer graphics);Seismology		This paper is a documentation of techniques invented, results obtained and lessons learned while creating visualization algorithms to render outputs of large-scale seismic simulations. The objective is the development of techniques for a collaborative simulation and visualization shared between structural engineers, seismologists, and computer scientists. The computer graphics research community has been witnessing a large number of exemplary publications addressing the challenges faced while trying to visualize both large-scale surface and volumetric datasets lately. From a visualization perspective, issues like data preprocessing (simplification, sampling, filtering, etc.); rendering algorithms (surface and volume), and interaction paradigms (large-scale, highly interactive, highly immersive, etc.) have been areas of study. In this light, we outline and describe the milestones achieved in a large-scale simulation and visualization project, which opened the scope for combining existing techniques with new methods, especially in those cases where no existing methods were suitable. We elucidate the data simplification and reorganization schemes that we used, and discuss the problems we encountered and the solutions we found. We describe both desktop (high-end local as well as remote) interfaces and immersive visualization systems that we developed to employ interactive surface and volume rendering algorithms. Finally, we describe the results obtained, challenges that still need to be addressed, and ongoing efforts to meet the challenges of large-scale visualization.	Chopra, P.;Meyer, J.;Fernandez, A.	Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;	38155160900;37279771900;38146099300
	SciVis	1-1 Nov. 2002	Case study: A look of performance expression	10.1109/VISUAL.2002.1183815	http://dx.doi.org/10.1109/VISUAL.2002.1183815	501	504	1183815	art;data visualisation;music;rendering (computer graphics)	musical performance;performance expression;performance parameters visualization	Application software;Art;Books;Chromium;Computer aided software engineering;Data visualization;Instruments;Music;Painting;Time sharing computer systems		For most of the time, we enjoy and appreciate music performances as they are. Once we try to understand the performance not in subjective terms but in an objective way and share it with other people, visualizing the performance parameters is indispensable. In this paper, a figure for visualizing performance expressions is described. This figure helps people understand the cause and position of the performance expression as it has expressive cues, which coincide with the cognitive meaning of musical performance, and not by using only MIDI parameter values. The differences we hear between performances are clarified by visualized figures.	Hiraga, R.	Bunkyo Univ., Japan|c|	37597820500
	SciVis	1-1 Nov. 2002	Case study: Interactive visualization for Internet security	10.1109/VISUAL.2002.1183816	http://dx.doi.org/10.1109/VISUAL.2002.1183816	505	508	1183816	Internet;data visualisation;graphical user interfaces;interactive systems;routing protocols;security of data	Internet security;anomaly detection;border gateway protocol;graph drawing;graphical user interfaces;information visualization;interactive visualization;routing protocols	Computer aided software engineering;Computer science;Data analysis;Data security;Data visualization;Face detection;IP networks;Internet;Routing protocols;Spine		Internet connectivity is defined by a set of routing protocols which let the routers that comprise the Internet backbone choose the best route for a packet to reach its destination. One way to improve the security and performance of Internet is to routinely examine the routing data. In this case study, we show how interactive visualization of Border Gateway Protocol (BGP) data helps characterize routing behavior, identify weaknesses in connectivity which could potentially cripple the Internet, as well as detect and explain actual anomalous events.	Soon Tee Teoh;Kwan-Liu Ma;Wu, S.F.;Xiaoliang Zhao	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;	37412023800;37275869400;37272893500;37336974400
	SciVis	1-1 Nov. 2002	PRIMA: A case study of using information visualization techniques for patient record analysis	10.1109/VISUAL.2002.1183817	http://dx.doi.org/10.1109/VISUAL.2002.1183817	509	512	1183817	data visualisation;medical information systems	Opal;PRIMA;bioinformatics domain;bone marrow transplants;information visualization;patient record intelligent monitoring and analysis	Bioinformatics;Bones;Computer aided software engineering;Data visualization;Gene expression;Hospitals;Information analysis;Java;Laboratories;Medical diagnostic imaging		We have created an application, called PRIMA (Patient Record intelligent Monitoring and Analysis), which can be used to visualize and understand patient record data. It was developed to better understand a large collection of patient records of bone marrow transplants at Hadassah Hospital in Jerusalem, Israel. It is based on an information visualization toolkit, Opal, which has been developed at the IBM T.J. Watson Research Center. Opal allows intelligent, interactive visualization of a wide variety of different types of data. The PRIMA application is generally applicable to a wide range of patient record data, as the underlying toolkit is flexible with regard to the form of the input data. This application is a good example of the usefulness of information visualization techniques in the bioinformatics domain, as these techniques have been developed specifically to deal with diverse sets of often unfamiliar data. We illustrate several unanticipated findings which resulted from the use of a flexible and interactive information visualization environment.	Gresh, D.L.;Rabenhorst, D.A.;Shabo, A.	IBM Thomas J. Watson Res. Center, NY, USA|c|;;	37378534100;37739505800;37352131200
	SciVis	1-1 Nov. 2002	Case study: A virtual environment for genomic data visualization	10.1109/VISUAL.2002.1183818	http://dx.doi.org/10.1109/VISUAL.2002.1183818	513	516	1183818	medical computing;virtual reality	genomic data visualization;human genome sequence;virtual environment	Bioinformatics;Biological cells;Computer aided software engineering;Data visualization;Drugs;Genetics;Genomics;Humans;Sequences;Virtual environment		With the completion of the human genome sequence, and with the proliferation of genome-related annotation data, the need for scalable and more intuitive means for analysis becomes critical, At Variagenics and Small Design Firm, we have addressed this problem with a coherent three-dimensional space in which all data can be seen in a single context. This tool aids in integrating information at vastly divergent scales while maintaining accurate spatial and size relationships. Our visualization was successful in communicating to project teams with diverse backgrounds the magnitude and biological implication of genetic variation.	Adams, R.M.;Stancampiano, B.;McKenna, M.;Small, D.	Variagenics Inc., Cambridge, MA, USA|c|;;;	38148724800;38149911800;38182530100;38143014200
	SciVis	1-1 Nov. 2002	Case study: Visual debugging of finite element codes	10.1109/VISUAL.2002.1183819	http://dx.doi.org/10.1109/VISUAL.2002.1183819	517	520	1183819	data visualisation;finite element analysis;mathematics computing;program debugging	cell inversion;color coding;finite element codes;mesh subsets;visual debugging	Computational modeling;Computer aided software engineering;Data structures;Data visualization;Debugging;Finite element methods;Laboratories;Physics;Shape;Wire		We present an innovative application developed at Sandia National Laboratories for visual debugging of unstructured finite element physics codes. Our tool automatically locates anomalous regions, such as inverted elements or nodes whose variable values lie outside a prescribed range, then extracts mesh subsets around these features for detailed examination. The subsets are viewed using color coding of variable values superimposed on the mesh structure. This allows the values and their relative spatial locations within the mesh to be correlated at a glance. Both topological irregularities and hot spots within the data stand out visually, allowing the user to explore the exact numeric values of the grid at surrounding points over time. We demonstrate the utility of this approach by debugging a cell inversion in a simulation of an exploding wire.	Crossno, P.;Rogers, D.H.;Garasi, C.J.	Sandia Nat. Labs., USA|c|;;	37282576500;37265693000;37273805800
	SciVis	1-1 Nov. 2002	Case study: Interactive rendering of adaptive mesh refinement data	10.1109/VISUAL.2002.1183820	http://dx.doi.org/10.1109/VISUAL.2002.1183820	521	524	1183820	graphical user interfaces;interactive systems;mesh generation;octrees;rendering (computer graphics)	AMR data;PC graphics hardware;adaptive mesh refinement data;computational simulation technique;graphical user interface;hierarchical multiresolution data structure;interactive rendering;k-d trees;octrees;splatting;transfer function NVIDIA GeForce card;volume visualization algorithms	Adaptive mesh refinement;Computational modeling;Computer graphics;Data structures;Data visualization;Graphical user interfaces;Hardware;Rendering (computer graphics);Transfer functions;Tree graphs		Adaptive mesh refinement (AMR) is a popular computational simulation technique used in various scientific and engineering fields. Although AMR data is organized in a hierarchical multi-resolution data structure, the traditional volume visualization algorithms such as ray-casting and splatting cannot handle the form without converting it to a sophisticated data structure. In this paper, we present a hierarchical multi-resolution splatting technique using k-d trees and octrees for AMR data that is suitable for implementation on the latest consumer PC graphics hardware. We describe a graphical user interface to set transfer function and viewing/rendering parameters interactively. Experimental results obtained on a general purpose PC equipped with NVIDIA GeForce card are presented to demonstrate that the technique can interactively render AMR data (over 20 frames per second). Our scheme can easily be applied to parallel rendering of time-varying AMR data.	Sanghun Park;Bajaj, C.L.;Siddavanahalli, V.	Texas Univ., Austin, TX, USA|c|;;	37441461200;37282899200;37282577700
	SciVis	1-1 Nov. 2002	A case study in selective visualization of unsteady 3D flow	10.1109/VISUAL.2002.1183821	http://dx.doi.org/10.1109/VISUAL.2002.1183821	525	528	1183821	computational fluid dynamics;feature extraction;flow visualisation;interpolation	Kaplan turbine;isolated flow structures;low pressure values;particle seeding scheme;selective visualization;time-dependent data;unsteady 3D flow;vortex rope visualization;water pump	Application software;Blades;Chromium;Computational fluid dynamics;Computer aided software engineering;Computer graphics;Data visualization;Image processing;Textile industry;Turbines		In this case study, we explore techniques for the purpose of visualizing isolated flow structures in time-dependent data. Our primary industrial application is the visualization of the vortex rope, a rotating helical structure which builds up in the draft tube of a water turbine. The vortex rope can be characterized by high values of normalized helicity, which is a scalar field derived from the given CFD velocity data. In two related applications, the goal is to visualize the cavitation regions near the runner blades of a Kaplan turbine and a water pump, respectively. Again, the flow structure of interest can be defined by a scalar field, namely by low pressure values. We propose a particle seeding scheme based on quasi-random numbers, which minimizes visual artifacts such as clusters or patterns. By constraining the visualization to a region of interest, occlusion problems are reduced and storage efficiency is gained.	Bauer, D.;Peikert, R.;Sato, M.;Sick, M.	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;	38149335100;37282541100;37732410200;37828727500
	SciVis	1-1 Nov. 2002	Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces	10.1109/VISUAL.2002.1183822	http://dx.doi.org/10.1109/VISUAL.2002.1183822	529	532	1183822	flow simulation;flow visualisation;oceanographic techniques	Lagrangian-Eulerian time surfaces;internal waves;near zero vertical motion;ocean flow vertical motions visualization;ocean model simulations;thermocline depth	Computational modeling;Information technology;Lagrangian functions;Ocean temperature;Predictive models;Sea surface;Surface texture;Surface topography;Timing;Visualization		Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.	Grant, J.;Erlebacher, G.;O'Brien, J.	Center for Ocean-Atmos. Prediction Studies, Florida State Univ., Tallahassee, FL, USA|c|;;	38142293100;37324424400;38182438200
	SciVis	1-1 Nov. 2002	A case study on multiresolution visualization of local rainfall from weather radar measurements	10.1109/VISUAL.2002.1183823	http://dx.doi.org/10.1109/VISUAL.2002.1183823	533	536	1183823	atmospheric precipitation;computational geometry;data visualisation;meteorological radar;rain;rendering (computer graphics);solid modelling	backscatter;computational geometry;interactive visualization;level-of-detail;local rainfall;multiresolution visualization;object modeling;rain drops;real-time simultaneous visualization;solid modelling;three-dimensional precipitation information;weather radar measurements	Atmospheric measurements;Atmospheric modeling;Backscatter;Computer aided software engineering;Data visualization;Displays;Isosurfaces;Meteorological radar;Radar antennas;Rain		Weather radars can measure the backscatter from rain drops in the atmosphere. A complete radar scan provides three-dimensional precipitation information. For the understanding of the underlying atmospheric processes interactive visualization of these data sets is necessary. This is a challenging task due to the size, structure and required context of the data. In this case study, a multiresolution approach for real-time simultaneous visualization of radar measurements together with the corresponding terrain data is illustrated.	Gerstner, T.;Meetschen, D.;Griebel, M.;Simmer, C.	Dept. for Appl. Math., Bonn Univ., Germany|c|;;;	38015261400;38149815100;37282573500;37351750500
	SciVis	1-1 Nov. 2002	Rendering the first star in the Universe - A case study	10.1109/VISUAL.2002.1183824	http://dx.doi.org/10.1109/VISUAL.2002.1183824	537	540	1183824	astronomy computing;data structures;data visualisation;mesh generation;rendering (computer graphics)	adaptive hierarchical schemes;adaptive mesh refinement;data visualization;hierarchical data structure;numerical multilevel technique;quantitative examination;rendering;spatial scales;temporal scales	Adaptive mesh refinement;Bridges;Data structures;Data visualization;Production;Rendering (computer graphics);Software packages;Spatial resolution;TV;Virtual reality		"For quantitative examination of phenomena that simultaneously occur on very different spatial and temporal scales, adaptive hierarchical schemes are required. A special numerical multilevel technique, associated with a particular hierarchical data structure, is so-called adaptive mesh refinement (AMR). It allows one to bridge a wide range of spatial and temporal resolutions and therefore gains increasing popularity. We describe the interplay of several visualization and VR software packages for rendering time dependent AMR simulations of the evolution of the first star in the universe. The work was done in the framework of a television production for Discovery Channel television, ""The Unfolding Universe."". Parts of the data were taken from one of the most complex AMR simulation ever carried out: It contained up to 27 levels of resolution, requiring modifications to the texture based AMR volume rendering algorithm that was used to depict the density distribution of the gaseous interstellar matter. A voice and gesture controlled CAVE application was utilized to define camera paths following the interesting features deep inside the computational domains. Background images created from cosmological computational data were combined with the final renderings."	Kahler, R.;Cox, D.;Patterson, R.;Levy, S.;Hege, H.-C.;Abel, T.	Zuse Inst., Berlin, Germany|c|;;;;;	37282637000;38148604900;38140573600;37928834000;37282272000;37955451000
	SciVis	1-1 Nov. 2002	NASA&#39;s great zooms: a case study	10.1109/VISUAL.2002.1183825	http://dx.doi.org/10.1109/VISUAL.2002.1183825	541	544	1183825	data visualisation;geophysics computing;rendering (computer graphics);terrain mapping	Earth;NASA great zooms;NASA outreach visualizations;animations;cloud free journey;color matching;georegistration;remote sensing satellite data	Animation;Computer aided software engineering;Data visualization;Earth;Geoscience;Image resolution;NASA;Pixel;Remote sensing;Satellites		This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.	Shirah, G.W.;Mitchell, H.G.	;	37283251400;38137776900
	SciVis	1-1 Nov. 2002	A case study on automatic camera placement and motion for visualizing historical data	10.1109/VISUAL.2002.1183826	http://dx.doi.org/10.1109/VISUAL.2002.1183826	545	548	1183826	computer animation;data visualisation;graphical user interfaces	animation generation;automatic camera path generation;automatic camera placement;automatic camera positioning;graphical user interfaces;historical data visualization;optimal camera position	Animation;Automatic generation control;Cameras;Chromium;Computer aided software engineering;Data engineering;Data visualization;Design engineering;Layout;Navigation		In this paper, we address the problem of automatic camera positioning and automatic camera path generation in the context of historical data visualization. After short description of the given data, we elaborate on the constraints for the positioning of a virtual camera in such a way that not only the projected area is maximized, but also the depth of the displayed scene. This is especially important when displaying terrain models, which do not provide good 3D impression when only the projected area is maximized. Based on this concept, we present a method for computing an optimal camera position for each instant of time. Since the explored data are not static, but change depending on the explored scene time, we also discuss a method for animation generation. In order to avoid sudden changes of the camera position, when the previous method is applied for each frame (point in time), we introduce pseudo-events in time, which expand the bounding box defined by the currently active events of interest. In particular, this technique allows events happening in a future point in time to be taken into account such that when this time becomes current, all events of interest are already within the current viewing frustum of the camera.	Stoev, S.L.	Tubingen Univ., Germany|c|	37730629300
	SciVis	1-1 Nov. 2002	Case study on the adaptation of interactive visualization applications to Web-based production for operational mesoscale weather models	10.1109/VISUAL.2002.1183827	http://dx.doi.org/10.1109/VISUAL.2002.1183827	549	552	1183827	Web design;data visualisation;geophysics computing;interactive systems;meta data;weather forecasting	Web page;Web site;Web-based production;interactive visualization applications;meta-representation;operational mesoscale weather models;remote access;weather forecasting system;weather simulation	Application software;Bandwidth;Chromium;Computer aided software engineering;Computer graphics;Costs;Data visualization;Production;Weather forecasting;Web pages		Visualization is required for the effective utilization of data from a weather simulation. Appropriate mapping of user goals to the design of pictorial content has been useful in the development of interactive applications with sufficient bandwidth for timely access to the model data. When remote access to the model visualizations is required the limited bandwidth becomes the primary bottleneck. To help address these problems, visualizations are presented on a Web page as a meta-representation of the model output and serve as an index to simplify finding other visualizations of relevance. To provide consistency with extant interactive products and to leverage their cost of development, the aforementioned applications are adapted to automatically populate a Web site with images and interactions for an operational weather forecasting system.	Treinish, L.A.	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	37372175500
	SciVis	1-1 Nov. 2002	Exploring surface characteristics with interactive Gaussian images (a case study)	10.1109/VISUAL.2002.1183828	http://dx.doi.org/10.1109/VISUAL.2002.1183828	553	556	1183828	Gaussian distribution;computational geometry;data visualisation;interactive systems	Gauss map;Gaussian normal image;brushing;computational geometry;dense mapping;graphical object geometry;hidden details;illumination;interactive Gaussian images;interactive visualization tools;linking;polygonal meshes;polygonal models;shading;spherical projection;surface characteristics;surface curvature	Biomedical imaging;Cameras;Computational geometry;Data visualization;Gaussian processes;Joining processes;Libraries;Lighting control;Shape;Solid modeling		The Gauss map projects surface normals to a unit sphere, providing a powerful visualization of the geometry of a graphical object. it can be used to predict visual events caused by changes in lighting, shading, and camera control. We present an interactive technique for portraying the Gauss map of polygonal models, mapping surface normals and the magnitudes of surface curvature using a spherical projection. Unlike other visualizations of surface curvature, we create our Gauss map directly from polygonal meshes without requiring any complex intermediate calculations of differential geometry. For anything other than simple shapes, surface information is densely mapped into the Gaussian normal image, inviting the use of visualization techniques to amplify and emphasize details hidden within the wealth of data. We present the use of interactive visualization tools such as brushing and linking to explore the surface properties of solid shapes. The Gauss map is shown to be simple to compute, easy to view dynamically, and effective at portraying important features of polygonal models.	Lowekamp, B.;Rheingans, P.;Yoo, T.S.	Maryland Univ., Baltimore, MD, USA|c|;;	38147235600;37282292000;37418915200
	SciVis	1-1 Nov. 2002	A case study on the applications of a generic library for low-cost polychromatic passive stereo	10.1109/VISUAL.2002.1183829	http://dx.doi.org/10.1109/VISUAL.2002.1183829	557	560	1183829	computer vision;data visualisation;software libraries;stereo image processing	computer graphics;generic library;image generation;low-cost polychromatic passive stereo;stereo vision;teleworking;ubiquitous computing	Application software;Computer industry;Design engineering;Hardware;Image generation;Libraries;Pervasive computing;Stereo vision;Teleworking;Ubiquitous computing		Active stereo has been used by engineers and industrial designers for several years to enhance the perception of computer generated three-dimensional images. Unfortunately, active stereo requires specialized hardware. Therefore, as ubiquitous computing and teleworking gain importance, using active stereo becomes a problem. The goal of this case study is to examine the concept of a generic library for polychromatic passive stereo to make stereo vision available everywhere.	Stegmaier, S.;Rose, D.;Ertl, T.	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	37267809900;37277264800;37268023800
	SciVis	1-1 Nov. 2002	Case study: the &#34;Office of Real Soon Now&#34; for visualization	10.1109/VISUAL.2002.1183830	http://dx.doi.org/10.1109/VISUAL.2002.1183830	561	564	1183830	Unix;computer displays;data visualisation;office automation;workstations	Lawrence Livermore National Laboratory;Linux;Office of Real Soon Now project;Unix-based applications;display systems;hardware-accelerated 3D graphics;high-resolution projectors;visualization;workstations	Application software;Computer aided software engineering;Computer displays;Computer graphics;Data visualization;Hardware;Laboratories;Linux;Three dimensional displays;Workstations		"As part of a larger effort exploring alternative display systems, Lawrence Livermore National Laboratory has installed systems in two offices that extend and update the previously described ""Office of Real Soon Now"" project to improve the value for visualization tasks. These new systems use higher resolution projectors driven by workstations that run Unix-based applications via Linux and support hardware-accelerated 3D graphics, even across the boundary between displays."	Uselton, S.P.		37372247300
