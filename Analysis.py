'''
Created on 04.09.2014

@file: Analysis.py
@author: RM
@since: 2014-09-04

Analyses topics generated by LDA.py (distance function calculations,
distribution of probabilities, etc.).

'''

import os, csv
import time
from dataModel.Topic import *

# Get file location
__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))
print __location__

# Set up logger
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

# Model parameters
k = 20

# One map/dictionary for each topic: keyword -> probability for this topic
keywordProbability_maps = [dict() for x in range(k)]

# Init container for k topics
topics = [Topic(x) for x in range(k)]

# ---------------------------------------------------------------------------------------------------------------

# Open csv with LDA topics
#with codecs.open('data/LDATopics.csv', 'rb', 'utf-8') as topicfile:
# Option: Try reading with unicodecsv.reader to avoid remaining charset-problem 
with open('data/LDATopics.csv', 'rb') as topicfile:
    topicInputData = csv.reader(topicfile, delimiter=' ', quotechar='|')
    # i denotes number of row in csv (up to number of features)
    i = 0
    topicKeywords = []
    
    # Reminder: In used format, each column represents one topic
    for row in topicInputData:
        if i > 0:
            topicKeywords = row[0].split(',')
            #print '\n----------------\nrow #' + str(i) + "\n----------------"
            
            # Insert data into maps.
            # inner_i denotes number of current topic this keyword/probability mapping is associated with,
            # i.e.: We read the ith-most important keyword for each topic (and write it in our map).
            inner_i = 0
            for keywordProbabilities in topicKeywords:
                inner_i = inner_i + topics[inner_i].addKeywordDataset(keywordProbabilities)
        i = i + 1
        topicKeywords = []
        
# Created sorted list representation of keyword/probability map
for topic in topics:
    topic.createdSortedListOfTuples()
    
# ---------------------------------------------------------------------------------------------------------------

topics[0].plotKeywordProbabilities()
    
# Test: Compare two topics with...
#    ...L2 distance/norm
print "L2: " + str(topics[0].calculateL2Distance(topics[1]))
#    ..Kullback-Leibler distance
print "Kullback-Leibler: " + str(topics[0].calculateKullbackLeiblerDistance(topics[1]))
#    ...Jensen-Shannon divergence
print "Jensen-Shannon: " + str(topics[0].calculateJensenShannonDivergence(topics[1]))
#    ...Bhattacharyya distance
print "Bhattacharyya: " + str(topics[0].calculateBhattacharyyaDistance(topics[1]))
#    ...Hellinger distance
print "Hellinger: " + str(topics[0].calculateHellingerDistance(topics[1]))

# Test distance calculation for two topics (here: between topic 1 and topic 2)
#df.calculateDistance(keywordProbability_maps[0], keywordProbability_maps[1])